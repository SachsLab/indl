{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction indl (Intracranial Neurophys and Deep Learning) is a Python package providing some tools to assist with deep-learning analysis of neurophysiology data, with an emphasis on intracranial neurophysiology. This library is a dependency in some of the lab's research projects and its Tutorial on Intracranial Neurophysiology and Deep Learning . You may be interested in the notebook on disentangling sequential autoencoders that explores many aspects of this library. Install pip install git+https://github.com/SachsLab/indl.git Dependencies The Python package dependencies should be handled automatically during pip install. If you need Tensorflow with GPU support then this requires cuda toolkit. The easiest way to get a compatible set of tensorflow, cuda toolkit, python, kernel, etc. is to use a conda environment. Use conda install tensorflow-gpu in a conda environment before pip-installing this package. Documentation The documentation is under construction but can be found hosted at https://SachsLab.github.io/indl/ . Use the navigation bar to select different elements. The API docs are auto-generated from the code. The DSAE docs contain some information about how the library can be used for disentangling sequential auto-encoders. Maintenance Notes Some notes for ongoing maintenance of this repository. Repository Organization docs -- Documentation If you build the docs locally then you'll also get the /site directory, but this should be git ignored. indl -- Library code tests -- Unit tests. Note this uses the pytest framework and conventions. The unit tests are also good examples on how to use specific functions. Setting up a developer environment. Clone this repo and change into its directory. Create a conda env and install the cuda toolkit that is compatible with tensorflow-gpu for python 3.9. conda create -n indl python=3.9 tensorflow-gpu nodejs conda activate indl You will need additional packages for development. pip install build packaging twine jupyter matplotlib nni pytest jupyterlab See this list under \"Maintaining the Documentation\" below. pip install -e . to install this package in developer mode. At this point I open the indl directory in PyCharm and set its interpreter to be the indl conda environment. Maintaining the Documentation You will need to install several Python packages to maintain the documentation. pip install mkdocs mkdocstrings mknotebooks mkdocs-material Pygments The docs/API folder has stubs to tell the mkdocstrings plugin to build the API documentation from the docstrings in the library code itself. The docs/{top-level-section} folders contain a mix of .md and .ipynb documentation. The latter are converted to .md by the mknotebooks plugin during building. Here is a guide for mkdocstrings syntax. Configure your IDE to use Google-style docstrings. Testing the Documentation Locally mkdocs serve Deploying the Documentation mkdocs gh-deploy This builds the documentation, commits to the gh-deploy branch, and pushes to GitHub. This will make the documentation available at https://SachsLab.github.io/indl/ Running the unit tests I typically run the unit tests within PyCharm as part of my development process, and I'm the only developer on the project, so I haven't paid much attention to testing in CI. Publishing the package python -m build twine upload dist/* username: __token__ password: {<}actual token that you saved previously}","title":"Introduction"},{"location":"#introduction","text":"indl (Intracranial Neurophys and Deep Learning) is a Python package providing some tools to assist with deep-learning analysis of neurophysiology data, with an emphasis on intracranial neurophysiology. This library is a dependency in some of the lab's research projects and its Tutorial on Intracranial Neurophysiology and Deep Learning . You may be interested in the notebook on disentangling sequential autoencoders that explores many aspects of this library.","title":"Introduction"},{"location":"#install","text":"pip install git+https://github.com/SachsLab/indl.git","title":"Install"},{"location":"#dependencies","text":"The Python package dependencies should be handled automatically during pip install. If you need Tensorflow with GPU support then this requires cuda toolkit. The easiest way to get a compatible set of tensorflow, cuda toolkit, python, kernel, etc. is to use a conda environment. Use conda install tensorflow-gpu in a conda environment before pip-installing this package.","title":"Dependencies"},{"location":"#documentation","text":"The documentation is under construction but can be found hosted at https://SachsLab.github.io/indl/ . Use the navigation bar to select different elements. The API docs are auto-generated from the code. The DSAE docs contain some information about how the library can be used for disentangling sequential auto-encoders.","title":"Documentation"},{"location":"#maintenance-notes","text":"Some notes for ongoing maintenance of this repository.","title":"Maintenance Notes"},{"location":"#repository-organization","text":"docs -- Documentation If you build the docs locally then you'll also get the /site directory, but this should be git ignored. indl -- Library code tests -- Unit tests. Note this uses the pytest framework and conventions. The unit tests are also good examples on how to use specific functions.","title":"Repository Organization"},{"location":"#setting-up-a-developer-environment","text":"Clone this repo and change into its directory. Create a conda env and install the cuda toolkit that is compatible with tensorflow-gpu for python 3.9. conda create -n indl python=3.9 tensorflow-gpu nodejs conda activate indl You will need additional packages for development. pip install build packaging twine jupyter matplotlib nni pytest jupyterlab See this list under \"Maintaining the Documentation\" below. pip install -e . to install this package in developer mode. At this point I open the indl directory in PyCharm and set its interpreter to be the indl conda environment.","title":"Setting up a developer environment."},{"location":"#maintaining-the-documentation","text":"You will need to install several Python packages to maintain the documentation. pip install mkdocs mkdocstrings mknotebooks mkdocs-material Pygments The docs/API folder has stubs to tell the mkdocstrings plugin to build the API documentation from the docstrings in the library code itself. The docs/{top-level-section} folders contain a mix of .md and .ipynb documentation. The latter are converted to .md by the mknotebooks plugin during building. Here is a guide for mkdocstrings syntax. Configure your IDE to use Google-style docstrings.","title":"Maintaining the Documentation"},{"location":"#testing-the-documentation-locally","text":"mkdocs serve","title":"Testing the Documentation Locally"},{"location":"#deploying-the-documentation","text":"mkdocs gh-deploy This builds the documentation, commits to the gh-deploy branch, and pushes to GitHub. This will make the documentation available at https://SachsLab.github.io/indl/","title":"Deploying the Documentation"},{"location":"#running-the-unit-tests","text":"I typically run the unit tests within PyCharm as part of my development process, and I'm the only developer on the project, so I haven't paid much attention to testing in CI.","title":"Running the unit tests"},{"location":"#publishing-the-package","text":"python -m build twine upload dist/* username: __token__ password: {<}actual token that you saved previously}","title":"Publishing the package"},{"location":"API/data/","text":"data augmentations add_depth_dim ( X , y ) Add extra dimension at tail for x only. This is trivial to do in-line. This is slightly more convenient than writing a labmda. Parameters: Name Type Description Default X tf.tensor required y tf.tensor required Returns: Type Description tf.tensor, tf.tensor X, y tuple, with X having a new trailing dimension. Source code in indl/data/augmentations.py def add_depth_dim ( X , y ): \"\"\" Add extra dimension at tail for x only. This is trivial to do in-line. This is slightly more convenient than writing a labmda. Args: X (tf.tensor): y (tf.tensor): Returns: tf.tensor, tf.tensor: X, y tuple, with X having a new trailing dimension. \"\"\" x_dat = tf . expand_dims ( X , - 1 ) # Prepare as an image, with only 1 colour-depth channel. return x_dat , y cast_type ( X , y , x_type = tf . float32 , y_type = tf . uint8 ) Cast input pair to new dtypes. Parameters: Name Type Description Default X tf.tensor Input tensor required y tf.tensor Input labels required x_type tf.dtypes tf data type tf.float32 y_type tf.dtypes tf data type tf.uint8 Returns: Type Description tf.tensor, tf.tensor X, y tuple, each cast to its new type. Source code in indl/data/augmentations.py def cast_type ( X , y , x_type = tf . float32 , y_type = tf . uint8 ): \"\"\" Cast input pair to new dtypes. Args: X (tf.tensor): Input tensor y (tf.tensor): Input labels x_type (tf.dtypes): tf data type y_type (tf.dtypes): tf data type Returns: tf.tensor, tf.tensor: X, y tuple, each cast to its new type. \"\"\" x_dat = tf . cast ( X , x_type ) y_dat = tf . cast ( y , y_type ) return x_dat , y_dat random_slice ( X , y , training = True , max_offset = 0 , axis = 1 ) Slice a tensor X along axis, beginning at a random offset up to max_offset, taking (X.shape[axis] - max_offset) samples. If training==False, this will take the last N-max_offset samples. Parameters: Name Type Description Default X tf.tensor input tensor required y tf.tensor input labels required training bool if the model is run in training state True max_offset int number of samples 0 axis int axis along which to slice 1 Returns: Type Description tf.tensor, tf.tensor X, y tuple randomly sliced. Source code in indl/data/augmentations.py def random_slice ( X , y , training = True , max_offset = 0 , axis = 1 ): \"\"\" Slice a tensor X along axis, beginning at a random offset up to max_offset, taking (X.shape[axis] - max_offset) samples. If training==False, this will take the last N-max_offset samples. Args: X (tf.tensor): input tensor y (tf.tensor): input labels training (bool): if the model is run in training state max_offset (int): number of samples axis (int): axis along which to slice Returns: tf.tensor, tf.tensor: X, y tuple randomly sliced. \"\"\" if training : offset = tf . random . uniform ( shape = [], minval = 0 , maxval = max_offset , dtype = tf . int32 ) else : offset = max_offset n_subsamps = X . shape [ axis ] - max_offset if axis == 0 : if len ( y . shape ) > axis and y . shape [ axis ] == X . shape [ axis ]: y = tf . slice ( y , [ offset , 0 ], [ n_subsamps , - 1 ]) X = tf . slice ( X , [ offset , 0 ], [ n_subsamps , - 1 ]) else : # axis == 1 if len ( y . shape ) > axis and y . shape [ axis ] == X . shape [ axis ]: y = tf . slice ( y , [ 0 , offset ], [ - 1 , n_subsamps ]) X = tf . slice ( X , [ 0 , offset ], [ - 1 , n_subsamps ]) return X , y helper get_tf_dataset ( X , Y , training = True , batch_size = 8 , max_offset = 0 , slice_ax = 1 ) Convert a pair of tf tensors into a tf.data.Dataset with some augmentations. The added augmentations are: add_depth_dim (with default params) cast_type (with default params) random_slice Parameters: Name Type Description Default X tf.tensor X data - must be compatible with above augmentations. required Y tf.tensor Y data - must be compatible with above augmentations. required training bool or tuple passed to random_slice , or if a tuple (e.g. from sklearn.model_selection.train_test_split) then this function returns training and test sets. True batch_size int Unused I think. 8 max_offset int Passed to random_slice 0 slice_ax int Passed to random_slice 1 Returns: Type Description tf.data.Dataset(, tf.Dataset) A tensorflow dataset with extra augmentations. If training is a tuple then two datasets are returning: training set and test set. Source code in indl/data/helper.py def get_tf_dataset ( X , Y , training = True , batch_size = 8 , max_offset = 0 , slice_ax = 1 ): \"\"\" Convert a pair of tf tensors into a tf.data.Dataset with some augmentations. The added augmentations are: - `add_depth_dim` (with default params) - `cast_type` (with default params) - `random_slice` Args: X (tf.tensor): X data - must be compatible with above augmentations. Y (tf.tensor): Y data - must be compatible with above augmentations. training (bool or tuple): passed to `random_slice`, or if a tuple (e.g. from sklearn.model_selection.train_test_split) then this function returns training and test sets. batch_size (int): Unused I think. max_offset (int): Passed to `random_slice` slice_ax (int): Passed to `random_slice` Returns: tf.data.Dataset(, tf.Dataset): A tensorflow dataset with extra augmentations. If training is a tuple then two datasets are returning: training set and test set. \"\"\" # TODO: trn_test as arg if isinstance ( training , tuple ): ds_train = get_tf_dataset ( X [ training [ 0 ]], Y [ training [ 0 ]], training = True , batch_size = batch_size ) ds_test = get_tf_dataset ( X [ training [ 1 ]], Y [ training [ 1 ]], training = False , batch_size = batch_size ) return ds_train , ds_test _ds = tf . data . Dataset . from_tensor_slices (( X , Y )) _ds = _ds . map ( add_depth_dim ) _ds = _ds . map ( cast_type ) slice_fun = partial ( random_slice , training = training , max_offset = max_offset , axis = slice_ax ) _ds = _ds . map ( slice_fun ) if training : _ds = _ds . shuffle () _ds = _ds . batch ( X . shape [ 0 ] + 1 , drop_remainder = not training ) return _ds","title":"data"},{"location":"API/data/#data","text":"","title":"data"},{"location":"API/data/#indl.data.augmentations","text":"","title":"augmentations"},{"location":"API/data/#indl.data.augmentations.add_depth_dim","text":"Add extra dimension at tail for x only. This is trivial to do in-line. This is slightly more convenient than writing a labmda. Parameters: Name Type Description Default X tf.tensor required y tf.tensor required Returns: Type Description tf.tensor, tf.tensor X, y tuple, with X having a new trailing dimension. Source code in indl/data/augmentations.py def add_depth_dim ( X , y ): \"\"\" Add extra dimension at tail for x only. This is trivial to do in-line. This is slightly more convenient than writing a labmda. Args: X (tf.tensor): y (tf.tensor): Returns: tf.tensor, tf.tensor: X, y tuple, with X having a new trailing dimension. \"\"\" x_dat = tf . expand_dims ( X , - 1 ) # Prepare as an image, with only 1 colour-depth channel. return x_dat , y","title":"add_depth_dim()"},{"location":"API/data/#indl.data.augmentations.cast_type","text":"Cast input pair to new dtypes. Parameters: Name Type Description Default X tf.tensor Input tensor required y tf.tensor Input labels required x_type tf.dtypes tf data type tf.float32 y_type tf.dtypes tf data type tf.uint8 Returns: Type Description tf.tensor, tf.tensor X, y tuple, each cast to its new type. Source code in indl/data/augmentations.py def cast_type ( X , y , x_type = tf . float32 , y_type = tf . uint8 ): \"\"\" Cast input pair to new dtypes. Args: X (tf.tensor): Input tensor y (tf.tensor): Input labels x_type (tf.dtypes): tf data type y_type (tf.dtypes): tf data type Returns: tf.tensor, tf.tensor: X, y tuple, each cast to its new type. \"\"\" x_dat = tf . cast ( X , x_type ) y_dat = tf . cast ( y , y_type ) return x_dat , y_dat","title":"cast_type()"},{"location":"API/data/#indl.data.augmentations.random_slice","text":"Slice a tensor X along axis, beginning at a random offset up to max_offset, taking (X.shape[axis] - max_offset) samples. If training==False, this will take the last N-max_offset samples. Parameters: Name Type Description Default X tf.tensor input tensor required y tf.tensor input labels required training bool if the model is run in training state True max_offset int number of samples 0 axis int axis along which to slice 1 Returns: Type Description tf.tensor, tf.tensor X, y tuple randomly sliced. Source code in indl/data/augmentations.py def random_slice ( X , y , training = True , max_offset = 0 , axis = 1 ): \"\"\" Slice a tensor X along axis, beginning at a random offset up to max_offset, taking (X.shape[axis] - max_offset) samples. If training==False, this will take the last N-max_offset samples. Args: X (tf.tensor): input tensor y (tf.tensor): input labels training (bool): if the model is run in training state max_offset (int): number of samples axis (int): axis along which to slice Returns: tf.tensor, tf.tensor: X, y tuple randomly sliced. \"\"\" if training : offset = tf . random . uniform ( shape = [], minval = 0 , maxval = max_offset , dtype = tf . int32 ) else : offset = max_offset n_subsamps = X . shape [ axis ] - max_offset if axis == 0 : if len ( y . shape ) > axis and y . shape [ axis ] == X . shape [ axis ]: y = tf . slice ( y , [ offset , 0 ], [ n_subsamps , - 1 ]) X = tf . slice ( X , [ offset , 0 ], [ n_subsamps , - 1 ]) else : # axis == 1 if len ( y . shape ) > axis and y . shape [ axis ] == X . shape [ axis ]: y = tf . slice ( y , [ 0 , offset ], [ - 1 , n_subsamps ]) X = tf . slice ( X , [ 0 , offset ], [ - 1 , n_subsamps ]) return X , y","title":"random_slice()"},{"location":"API/data/#indl.data.helper","text":"","title":"helper"},{"location":"API/data/#indl.data.helper.get_tf_dataset","text":"Convert a pair of tf tensors into a tf.data.Dataset with some augmentations. The added augmentations are: add_depth_dim (with default params) cast_type (with default params) random_slice Parameters: Name Type Description Default X tf.tensor X data - must be compatible with above augmentations. required Y tf.tensor Y data - must be compatible with above augmentations. required training bool or tuple passed to random_slice , or if a tuple (e.g. from sklearn.model_selection.train_test_split) then this function returns training and test sets. True batch_size int Unused I think. 8 max_offset int Passed to random_slice 0 slice_ax int Passed to random_slice 1 Returns: Type Description tf.data.Dataset(, tf.Dataset) A tensorflow dataset with extra augmentations. If training is a tuple then two datasets are returning: training set and test set. Source code in indl/data/helper.py def get_tf_dataset ( X , Y , training = True , batch_size = 8 , max_offset = 0 , slice_ax = 1 ): \"\"\" Convert a pair of tf tensors into a tf.data.Dataset with some augmentations. The added augmentations are: - `add_depth_dim` (with default params) - `cast_type` (with default params) - `random_slice` Args: X (tf.tensor): X data - must be compatible with above augmentations. Y (tf.tensor): Y data - must be compatible with above augmentations. training (bool or tuple): passed to `random_slice`, or if a tuple (e.g. from sklearn.model_selection.train_test_split) then this function returns training and test sets. batch_size (int): Unused I think. max_offset (int): Passed to `random_slice` slice_ax (int): Passed to `random_slice` Returns: tf.data.Dataset(, tf.Dataset): A tensorflow dataset with extra augmentations. If training is a tuple then two datasets are returning: training set and test set. \"\"\" # TODO: trn_test as arg if isinstance ( training , tuple ): ds_train = get_tf_dataset ( X [ training [ 0 ]], Y [ training [ 0 ]], training = True , batch_size = batch_size ) ds_test = get_tf_dataset ( X [ training [ 1 ]], Y [ training [ 1 ]], training = False , batch_size = batch_size ) return ds_train , ds_test _ds = tf . data . Dataset . from_tensor_slices (( X , Y )) _ds = _ds . map ( add_depth_dim ) _ds = _ds . map ( cast_type ) slice_fun = partial ( random_slice , training = training , max_offset = max_offset , axis = slice_ax ) _ds = _ds . map ( slice_fun ) if training : _ds = _ds . shuffle () _ds = _ds . batch ( X . shape [ 0 ] + 1 , drop_remainder = not training ) return _ds","title":"get_tf_dataset()"},{"location":"API/dists/","text":"dists LearnableMultivariateNormalCell ( Model ) Multivariate normal distribution RNN cell. The model is a RNN-based recurrent function that computes the parameters for a multivariate normal distribution at each timestep t . Based on: https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L242 Source code in indl/dists/__init__.py class LearnableMultivariateNormalCell ( tf . keras . Model ): \"\"\"Multivariate normal distribution RNN cell. The model is a RNN-based recurrent function that computes the parameters for a multivariate normal distribution at each timestep `t`. Based on: https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L242 \"\"\" def __init__ ( self , units : int , out_dim : int , shift_std : float = 0.1 , cell_type : str = 'lstm' , offdiag : bool = False ): \"\"\"Constructs a learnable multivariate normal cell. Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" super ( LearnableMultivariateNormalCell , self ) . __init__ () self . offdiag = offdiag self . output_dimensions = out_dim self . units = units if cell_type . upper () . endswith ( 'LSTM' ): self . rnn_cell = tfkl . LSTMCell ( self . units , implementation = 1 , name = \"mvncell\" ) # why does the jupyter notebook version require implementation=1 but not in pycharm? elif cell_type . upper () . endswith ( 'GRU' ): self . rnn_cell = tfkl . GRUCell ( self . units , name = \"mvnell\" ) elif cell_type . upper () . endswith ( 'RNN' ): self . rnn_cell = tfkl . SimpleRNNCell ( self . units , name = \"mvncell\" ) elif cell_type . upper () . endswith ( 'GRUCLIP' ): from indl.rnn.gru_clip import GRUClipCell self . rnn_cell = GRUClipCell ( self . units , name = \"mvncell\" ) else : raise ValueError ( \"cell_type %s not recognized\" % cell_type ) self . loc_layer = tfkl . Dense ( self . output_dimensions , name = \"mvncell_loc\" ) n_scale_dim = ( tfpl . MultivariateNormalTriL . params_size ( out_dim ) - out_dim ) if offdiag \\ else ( tfpl . IndependentNormal . params_size ( out_dim ) - out_dim ) self . scale_untransformed_layer = tfkl . Dense ( n_scale_dim , name = \"mvndiagcell_scale\" ) self . _scale_shift = np . log ( np . exp ( shift_std ) - 1 ) . astype ( np . float32 ) #def build(self, input_shape): #super(LearnableMultivariateNormalDiagCell, self).build(input_shape) #self.lstm_cell.build(input_shape) #self.loc_layer.build(input_shape) #self.scale_untransformed_layer.build(input_shape) #self.built = True def zero_state ( self , sample_batch_shape = ()): \"\"\"Returns an initial state for the RNN cell. Args: sample_batch_shape: A 0D or 1D tensor of the combined sample and batch shape. Returns: A tuple of the initial previous output at timestep 0 of shape [sample_batch_shape, dimensions], and the cell state. \"\"\" zero_state = self . rnn_cell . get_initial_state ( batch_size = sample_batch_shape [ - 1 ], dtype = tf . float32 ) sample_batch_shape = tf . convert_to_tensor ( value = sample_batch_shape , dtype = tf . int32 ) out_shape = tf . concat (( sample_batch_shape , [ self . output_dimensions ]), axis =- 1 ) previous_output = tf . zeros ( out_shape ) return previous_output , zero_state def call ( self , inputs , state ): \"\"\"Runs the model to generate a distribution for a single timestep. This generates a batched MultivariateNormalDiag distribution using the output of the recurrent model at the current timestep to parameterize the distribution. Args: inputs: The sampled value of `z` at the previous timestep, i.e., `z_{t-1}`, of shape [..., dimensions]. `z_0` should be set to the empty matrix. state: A tuple containing the (hidden, cell) state. Returns: A tuple of a MultivariateNormalDiag distribution, and the state of the recurrent function at the end of the current timestep. The distribution will have event shape [dimensions], batch shape [...], and sample shape [sample_shape, ..., dimensions]. \"\"\" # In order to allow the user to pass in a single example without a batch # dimension, we always expand the input to at least two dimensions, then # fix the output shape to remove the batch dimension if necessary. original_shape = inputs . shape if len ( original_shape ) < 2 : inputs = tf . reshape ( inputs , [ 1 , - 1 ]) out , state = self . rnn_cell ( inputs , state ) parms_shape = tf . concat (( original_shape [: - 1 ], [ self . output_dimensions ]), 0 ) loc = tf . reshape ( self . loc_layer ( out ), parms_shape ) scale = self . scale_untransformed_layer ( out ) scale = tf . nn . softplus ( scale + self . _scale_shift ) + 1e-5 scale = tf . reshape ( scale , parms_shape ) if self . offdiag : return tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : return tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ), state __init__ ( self , units , out_dim , shift_std = 0.1 , cell_type = 'lstm' , offdiag = False ) special Constructs a learnable multivariate normal cell. Parameters: Name Type Description Default units int Dimensionality of the RNN function parameters. required out_dim int The dimensionality of the distribution. required shift_std float Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. 0.1 cell_type str an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. 'lstm' offdiag bool set True to allow non-zero covariance (within-timestep) in the returned distribution. False Source code in indl/dists/__init__.py def __init__ ( self , units : int , out_dim : int , shift_std : float = 0.1 , cell_type : str = 'lstm' , offdiag : bool = False ): \"\"\"Constructs a learnable multivariate normal cell. Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" super ( LearnableMultivariateNormalCell , self ) . __init__ () self . offdiag = offdiag self . output_dimensions = out_dim self . units = units if cell_type . upper () . endswith ( 'LSTM' ): self . rnn_cell = tfkl . LSTMCell ( self . units , implementation = 1 , name = \"mvncell\" ) # why does the jupyter notebook version require implementation=1 but not in pycharm? elif cell_type . upper () . endswith ( 'GRU' ): self . rnn_cell = tfkl . GRUCell ( self . units , name = \"mvnell\" ) elif cell_type . upper () . endswith ( 'RNN' ): self . rnn_cell = tfkl . SimpleRNNCell ( self . units , name = \"mvncell\" ) elif cell_type . upper () . endswith ( 'GRUCLIP' ): from indl.rnn.gru_clip import GRUClipCell self . rnn_cell = GRUClipCell ( self . units , name = \"mvncell\" ) else : raise ValueError ( \"cell_type %s not recognized\" % cell_type ) self . loc_layer = tfkl . Dense ( self . output_dimensions , name = \"mvncell_loc\" ) n_scale_dim = ( tfpl . MultivariateNormalTriL . params_size ( out_dim ) - out_dim ) if offdiag \\ else ( tfpl . IndependentNormal . params_size ( out_dim ) - out_dim ) self . scale_untransformed_layer = tfkl . Dense ( n_scale_dim , name = \"mvndiagcell_scale\" ) self . _scale_shift = np . log ( np . exp ( shift_std ) - 1 ) . astype ( np . float32 ) #def build(self, input_shape): #super(LearnableMultivariateNormalDiagCell, self).build(input_shape) #self.lstm_cell.build(input_shape) #self.loc_layer.build(input_shape) #self.scale_untransformed_layer.build(input_shape) #self.built = True call ( self , inputs , state ) Runs the model to generate a distribution for a single timestep. This generates a batched MultivariateNormalDiag distribution using the output of the recurrent model at the current timestep to parameterize the distribution. Parameters: Name Type Description Default inputs The sampled value of z at the previous timestep, i.e., z_{t-1} , of shape [..., dimensions]. z_0 should be set to the empty matrix. required state A tuple containing the (hidden, cell) state. required Returns: Type Description A tuple of a MultivariateNormalDiag distribution, and the state of the recurrent function at the end of the current timestep. The distribution will have event shape [dimensions], batch shape [...], and sample shape [sample_shape, ..., dimensions]. Source code in indl/dists/__init__.py def call ( self , inputs , state ): \"\"\"Runs the model to generate a distribution for a single timestep. This generates a batched MultivariateNormalDiag distribution using the output of the recurrent model at the current timestep to parameterize the distribution. Args: inputs: The sampled value of `z` at the previous timestep, i.e., `z_{t-1}`, of shape [..., dimensions]. `z_0` should be set to the empty matrix. state: A tuple containing the (hidden, cell) state. Returns: A tuple of a MultivariateNormalDiag distribution, and the state of the recurrent function at the end of the current timestep. The distribution will have event shape [dimensions], batch shape [...], and sample shape [sample_shape, ..., dimensions]. \"\"\" # In order to allow the user to pass in a single example without a batch # dimension, we always expand the input to at least two dimensions, then # fix the output shape to remove the batch dimension if necessary. original_shape = inputs . shape if len ( original_shape ) < 2 : inputs = tf . reshape ( inputs , [ 1 , - 1 ]) out , state = self . rnn_cell ( inputs , state ) parms_shape = tf . concat (( original_shape [: - 1 ], [ self . output_dimensions ]), 0 ) loc = tf . reshape ( self . loc_layer ( out ), parms_shape ) scale = self . scale_untransformed_layer ( out ) scale = tf . nn . softplus ( scale + self . _scale_shift ) + 1e-5 scale = tf . reshape ( scale , parms_shape ) if self . offdiag : return tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : return tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ), state zero_state ( self , sample_batch_shape = ()) Returns an initial state for the RNN cell. Parameters: Name Type Description Default sample_batch_shape A 0D or 1D tensor of the combined sample and batch shape. () Returns: Type Description A tuple of the initial previous output at timestep 0 of shape [sample_batch_shape, dimensions], and the cell state. Source code in indl/dists/__init__.py def zero_state ( self , sample_batch_shape = ()): \"\"\"Returns an initial state for the RNN cell. Args: sample_batch_shape: A 0D or 1D tensor of the combined sample and batch shape. Returns: A tuple of the initial previous output at timestep 0 of shape [sample_batch_shape, dimensions], and the cell state. \"\"\" zero_state = self . rnn_cell . get_initial_state ( batch_size = sample_batch_shape [ - 1 ], dtype = tf . float32 ) sample_batch_shape = tf . convert_to_tensor ( value = sample_batch_shape , dtype = tf . int32 ) out_shape = tf . concat (( sample_batch_shape , [ self . output_dimensions ]), axis =- 1 ) previous_output = tf . zeros ( out_shape ) return previous_output , zero_state LearnableMultivariateNormalDiag ( Model ) Learnable multivariate diagonal normal distribution. The model is a multivariate normal distribution with learnable mean and stddev parameters. See make_mvn_prior for a description. Source code in indl/dists/__init__.py class LearnableMultivariateNormalDiag ( tf . keras . Model ): \"\"\"Learnable multivariate diagonal normal distribution. The model is a multivariate normal distribution with learnable `mean` and `stddev` parameters. See make_mvn_prior for a description. \"\"\" def __init__ ( self , dimensions , init_std = 1.0 , trainable_mean = True , trainable_var = True ): \"\"\"Constructs a learnable multivariate diagonal normal model. Args: dimensions: An integer corresponding to the dimensionality of the distribution. \"\"\" super ( LearnableMultivariateNormalDiag , self ) . __init__ () with tf . name_scope ( self . _name ): self . dimensions = dimensions if trainable_mean : self . _mean = tf . Variable ( tf . random . normal ([ dimensions ], stddev = 0.1 ), name = \"mean\" ) else : self . _mean = tf . zeros ( dimensions ) if trainable_var : _scale_shift = np . log ( np . exp ( init_std ) - 1 ) . astype ( np . float32 ) self . _scale = tfp . util . TransformedVariable ( tf . random . normal ([ dimensions ], mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), bijector = tfb . Chain ([ tfb . Shift ( 1e-5 ), tfb . Softplus (), tfb . Shift ( _scale_shift )]), name = \"transformed_scale\" ) else : self . _scale = init_std * tf . ones ( dimensions ) def __call__ ( self , * args , ** kwargs ): # Allow this Model to be called without inputs. dummy = tf . zeros ( self . dimensions ) return super ( LearnableMultivariateNormalDiag , self ) . __call__ ( dummy , * args , ** kwargs ) def call ( self , inputs ): \"\"\"Runs the model to generate multivariate normal distribution. Args: inputs: Unused. Returns: A MultivariateNormalDiag distribution with event shape [dimensions], batch shape [], and sample shape [sample_shape, dimensions]. \"\"\" del inputs # unused with tf . name_scope ( self . _name ): return tfd . MultivariateNormalDiag ( loc = self . loc , scale_diag = self . scale_diag ) @property def loc ( self ): \"\"\"The mean of the normal distribution.\"\"\" return self . _mean @property def scale_diag ( self ): \"\"\"The diagonal standard deviation of the normal distribution.\"\"\" return self . _scale loc property readonly The mean of the normal distribution. scale_diag property readonly The diagonal standard deviation of the normal distribution. __init__ ( self , dimensions , init_std = 1.0 , trainable_mean = True , trainable_var = True ) special Constructs a learnable multivariate diagonal normal model. Parameters: Name Type Description Default dimensions An integer corresponding to the dimensionality of the distribution. required Source code in indl/dists/__init__.py def __init__ ( self , dimensions , init_std = 1.0 , trainable_mean = True , trainable_var = True ): \"\"\"Constructs a learnable multivariate diagonal normal model. Args: dimensions: An integer corresponding to the dimensionality of the distribution. \"\"\" super ( LearnableMultivariateNormalDiag , self ) . __init__ () with tf . name_scope ( self . _name ): self . dimensions = dimensions if trainable_mean : self . _mean = tf . Variable ( tf . random . normal ([ dimensions ], stddev = 0.1 ), name = \"mean\" ) else : self . _mean = tf . zeros ( dimensions ) if trainable_var : _scale_shift = np . log ( np . exp ( init_std ) - 1 ) . astype ( np . float32 ) self . _scale = tfp . util . TransformedVariable ( tf . random . normal ([ dimensions ], mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), bijector = tfb . Chain ([ tfb . Shift ( 1e-5 ), tfb . Softplus (), tfb . Shift ( _scale_shift )]), name = \"transformed_scale\" ) else : self . _scale = init_std * tf . ones ( dimensions ) call ( self , inputs ) Runs the model to generate multivariate normal distribution. Parameters: Name Type Description Default inputs Unused. required Returns: Type Description A MultivariateNormalDiag distribution with event shape [dimensions], batch shape [], and sample shape [sample_shape, dimensions]. Source code in indl/dists/__init__.py def call ( self , inputs ): \"\"\"Runs the model to generate multivariate normal distribution. Args: inputs: Unused. Returns: A MultivariateNormalDiag distribution with event shape [dimensions], batch shape [], and sample shape [sample_shape, dimensions]. \"\"\" del inputs # unused with tf . name_scope ( self . _name ): return tfd . MultivariateNormalDiag ( loc = self . loc , scale_diag = self . scale_diag ) make_learnable_mvn_params ( ndim , init_std = 1.0 , trainable_mean = True , trainable_var = True , offdiag = False ) Return mean (loc) and stddev (scale) parameters for initializing multivariate normal distributions. If trainable_mean then it will be initialized with random normal (stddev=0.1), otherwise zeros. If trainable_var then it will be initialized with random normal centered at a value such that the bijector transformation yields the value in init_std. When init_std is 1.0 (default) then the inverse-bijected value is approximately 0.0. If not trainable_var then scale is a vector or matrix of init_std of appropriate shape for the dist. Parameters: Name Type Description Default ndim int Number of dimensions. required init_std float Initial value for the standard deviation. 1.0 trainable_mean bool Whether or not the mean (loc) is a trainable tf.Variable. True trainable_var bool Whether or not the variance (scale) is a trainable tf.Variable. True offdiag bool Whether or not off-diagonal elements are allowed. False Returns: loc, scale Source code in indl/dists/__init__.py def make_learnable_mvn_params ( ndim : int , init_std : float = 1.0 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Return mean (loc) and stddev (scale) parameters for initializing multivariate normal distributions. If trainable_mean then it will be initialized with random normal (stddev=0.1), otherwise zeros. If trainable_var then it will be initialized with random normal centered at a value such that the bijector transformation yields the value in init_std. When init_std is 1.0 (default) then the inverse-bijected value is approximately 0.0. If not trainable_var then scale is a vector or matrix of init_std of appropriate shape for the dist. Args: ndim: Number of dimensions. init_std: Initial value for the standard deviation. trainable_mean: Whether or not the mean (loc) is a trainable tf.Variable. trainable_var: Whether or not the variance (scale) is a trainable tf.Variable. offdiag: Whether or not off-diagonal elements are allowed. Returns: loc, scale \"\"\" if trainable_mean : loc = tf . Variable ( tf . random . normal ([ ndim ], stddev = 0.1 , dtype = tf . float32 )) else : loc = tf . zeros ( ndim ) # Initialize the variance (scale), trainable or not, offdiag or not. if trainable_var : if offdiag : _ndim = [ ndim , ndim ] scale = tfp . util . TransformedVariable ( # init_std * tf.eye(ndim, dtype=tf.float32), tf . random . normal ( _ndim , mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), tfp . bijectors . FillScaleTriL (), name = \"prior_scale\" ) else : _scale_shift = np . log ( np . exp ( init_std ) - 1 ) . astype ( np . float32 ) # tfp.math.softplus_inverse(init_std) scale = tfp . util . TransformedVariable ( # init_std * tf.ones(ndim, dtype=tf.float32), tf . random . normal ([ ndim ], mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), tfb . Chain ([ tfb . Shift ( 1e-5 ), tfb . Softplus (), tfb . Shift ( _scale_shift )]), name = \"prior_scale\" ) else : if offdiag : scale = init_std * tf . eye ( ndim ) else : scale = init_std * tf . ones ( ndim ) return loc , scale make_mvn_dist_fn ( _x_ , ndim , shift_std = 1.0 , offdiag = False , loc_name = None , scale_name = None , use_mvn_diag = True ) Take a 1-D tensor and use it to parameterize a MVN dist. This doesn't return the distribution, but the function to make the distribution and its arguments. make_dist_fn, [loc, scale] You can supply it to tfpl.DistributionLambda Parameters: Name Type Description Default _x_ Tensor required ndim int required shift_std float 1.0 offdiag bool False loc_name Optional[str] None scale_name Optional[str] None use_mvn_diag bool True Returns: Type Description Tuple[Callable[[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.ops.Tensor], tensorflow_probability.python.distributions.distribution.Distribution], List[tensorflow.python.framework.ops.Tensor]] make_dist_fn, [loc, scale] Source code in indl/dists/__init__.py def make_mvn_dist_fn ( _x_ : tf . Tensor , ndim : int , shift_std : float = 1.0 , offdiag : bool = False , loc_name : Optional [ str ] = None , scale_name : Optional [ str ] = None , use_mvn_diag : bool = True ) -> Tuple [ Callable [[ tf . Tensor , tf . Tensor ], tfd . Distribution ], List [ tf . Tensor ]]: \"\"\" Take a 1-D tensor and use it to parameterize a MVN dist. This doesn't return the distribution, but the function to make the distribution and its arguments. make_dist_fn, [loc, scale] You can supply it to tfpl.DistributionLambda Args: _x_: ndim: shift_std: offdiag: loc_name: scale_name: use_mvn_diag: Returns: make_dist_fn, [loc, scale] \"\"\" _scale_shift = np . log ( np . exp ( shift_std ) - 1 ) . astype ( np . float32 ) _loc = tfkl . Dense ( ndim , name = loc_name )( _x_ ) n_scale_dim = ( tfpl . MultivariateNormalTriL . params_size ( ndim ) - ndim ) if offdiag \\ else ( tfpl . IndependentNormal . params_size ( ndim ) - ndim ) _scale = tfkl . Dense ( n_scale_dim , name = scale_name )( _x_ ) _scale = tf . math . softplus ( _scale + _scale_shift ) + 1e-5 if offdiag : _scale = tfb . FillTriangular ()( _scale ) make_dist_fn = lambda t : tfd . MultivariateNormalTriL ( loc = t [ 0 ], scale_tril = t [ 1 ]) else : if use_mvn_diag : # Match type with prior make_dist_fn = lambda t : tfd . MultivariateNormalDiag ( loc = t [ 0 ], scale_diag = t [ 1 ]) else : make_dist_fn = lambda t : tfd . Independent ( tfd . Normal ( loc = t [ 0 ], scale = t [ 1 ])) return make_dist_fn , [ _loc , _scale ] make_mvn_prior ( ndim , init_std = 1.0 , trainable_mean = True , trainable_var = True , offdiag = False ) Creates a tensorflow-probability distribution: MultivariateNormalTriL if offdiag else MultivariateNormalDiag Mean (loc) and sigma (scale) can be trainable or not. Mean initializes to random.normal around 0 (stddev=0.1) if trainable, else zeros. Scale initialies to init_std if not trainable. If it is trainable, it initializes to a tfp TransformedVariable that will be centered at 0 for easy training under the hood, but will be transformed via softplus to give something initially close to init_var. loc and scale are tracked by the MVNDiag class. For LFADS ics prior, trainable_mean=True, trainable_var=False For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True In either case, var was initialized with 0.1 (==> logvar with log(0.1)) Unlike the LFADS' LearnableDiagonalGaussian, here we don't support multi-dimensional, just a vector. See also LearnableMultivariateNormalDiag for a tf.keras.Model version of this. Parameters: Name Type Description Default ndim int latent dimension of distribution. Currently only supports 1 d (I think ) required init_std float initial standard deviation of the gaussian. If trainable_var then the initial standard deviation will be drawn from a random.normal distribution with mean init_std and stddev 1/10th of that. 1.0 trainable_mean bool If the mean should be a tf.Variable True trainable_var bool If the variance/stddev/scale (whatever you call it) should be a tf.Variable True offdiag bool If the variance-covariance matrix is allowed non-zero off-diagonal elements. False Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL] A tensorflow-probability distribution (either MultivariateNormalTriL or MultivariateNormalDiag). Source code in indl/dists/__init__.py def make_mvn_prior ( ndim : int , init_std : float = 1.0 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Creates a tensorflow-probability distribution: MultivariateNormalTriL if offdiag else MultivariateNormalDiag Mean (loc) and sigma (scale) can be trainable or not. Mean initializes to random.normal around 0 (stddev=0.1) if trainable, else zeros. Scale initialies to init_std if not trainable. If it is trainable, it initializes to a tfp TransformedVariable that will be centered at 0 for easy training under the hood, but will be transformed via softplus to give something initially close to init_var. loc and scale are tracked by the MVNDiag class. For LFADS ics prior, trainable_mean=True, trainable_var=False For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True In either case, var was initialized with 0.1 (==> logvar with log(0.1)) Unlike the LFADS' LearnableDiagonalGaussian, here we don't support multi-dimensional, just a vector. See also LearnableMultivariateNormalDiag for a tf.keras.Model version of this. Args: ndim: latent dimension of distribution. Currently only supports 1 d (I think ) init_std: initial standard deviation of the gaussian. If trainable_var then the initial standard deviation will be drawn from a random.normal distribution with mean init_std and stddev 1/10th of that. trainable_mean: If the mean should be a tf.Variable trainable_var: If the variance/stddev/scale (whatever you call it) should be a tf.Variable offdiag: If the variance-covariance matrix is allowed non-zero off-diagonal elements. Returns: A tensorflow-probability distribution (either MultivariateNormalTriL or MultivariateNormalDiag). \"\"\" loc , scale = make_learnable_mvn_params ( ndim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) # Initialize the prior. if offdiag : # Note: Diag must be > 0, upper triangular must be 0, and lower triangular may be != 0. prior = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : prior = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) # kl_exact needs same dist types for prior and latent. # We would switch to the next line if we switched our latent to using tf.Independent(tfd.Normal) # prior = tfd.Independent(tfd.Normal(loc=tf.zeros(ndim), scale=1), reinterpreted_batch_ndims=1) return prior make_variational ( x , dist_dim , init_std = 1.0 , offdiag = False , samps = 1 , loc_name = 'loc' , scale_name = 'scale' , dist_name = 'q' , use_mvn_diag = True ) Take an input tensor and return a multivariate normal distribution parameterized by that input tensor. Parameters: Name Type Description Default x Tensor input tensor required dist_dim int the dimensionality of the distribution required init_std float initial stddev SHIFT of the distribution when input is 0. 1.0 offdiag bool whether or not to include covariances False samps int the number of samples to draw when using implied convert_to_tensor_fn 1 loc_name not used (I need to handle naming better) 'loc' scale_name not used 'scale' dist_name not used 'q' use_mvn_diag bool whether to use tfd.MultivariateNormal(Diag|TriL) (True) or tfd.Independent(tfd.Normal) (False) Latter is untested. Note that the mvn dists will put the timesteps dimension (if present in the input) into the \"batch dimension\" while the \"event\" dimension will be the last dimension only. You can use tfd.Independent(q_dist, reinterpreted_batch_ndims=1) to move the timestep dimension to the event dimension if necessary. (tfd.Independent doesn't play well with tf.keras.Model inputs/outputs). True Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL, tensorflow_probability.python.distributions.independent.Independent] A tfd.Distribution. The distribution is of type MultivariateNormalDiag (or MultivariateNormalTriL if offdiag) if use_mvn_diag is set. Source code in indl/dists/__init__.py def make_variational ( x : tf . Tensor , dist_dim : int , init_std : float = 1.0 , offdiag : bool = False , samps : int = 1 , loc_name = \"loc\" , scale_name = \"scale\" , dist_name = \"q\" , use_mvn_diag : bool = True ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL , tfd . Independent ]: \"\"\" Take an input tensor and return a multivariate normal distribution parameterized by that input tensor. Args: x: input tensor dist_dim: the dimensionality of the distribution init_std: initial stddev SHIFT of the distribution when input is 0. offdiag: whether or not to include covariances samps: the number of samples to draw when using implied convert_to_tensor_fn loc_name: not used (I need to handle naming better) scale_name: not used dist_name: not used use_mvn_diag: whether to use tfd.MultivariateNormal(Diag|TriL) (True) or tfd.Independent(tfd.Normal) (False) Latter is untested. Note that the mvn dists will put the timesteps dimension (if present in the input) into the \"batch dimension\" while the \"event\" dimension will be the last dimension only. You can use tfd.Independent(q_dist, reinterpreted_batch_ndims=1) to move the timestep dimension to the event dimension if necessary. (tfd.Independent doesn't play well with tf.keras.Model inputs/outputs). Returns: A tfd.Distribution. The distribution is of type MultivariateNormalDiag (or MultivariateNormalTriL if offdiag) if use_mvn_diag is set. \"\"\" make_dist_fn , dist_params = make_mvn_dist_fn ( x , dist_dim , shift_std = init_std , offdiag = offdiag , # loc_name=loc_name, scale_name=scale_name, use_mvn_diag = use_mvn_diag ) # Python `callable` that takes a `tfd.Distribution` # instance and returns a `tf.Tensor`-like object. \"\"\" # Unfortunately I couldn't get this to work :( # Will have to explicitly q_f.value() | qf.mean() from dist in train_step def custom_convert_fn(d, training=None): if training is None: training = K.learning_phase() output = tf_utils.smart_cond(training, lambda: d.sample(samps), lambda: d.mean() ) return output def convert_fn(d): return K.in_train_phase(tfd.Distribution.sample if samps <= 1 else lambda: d.sample(samps), lambda: d.mean()) \"\"\" convert_fn = tfd . Distribution . sample if samps <= 1 else lambda d : d . sample ( samps ) q_dist = tfpl . DistributionLambda ( make_distribution_fn = make_dist_fn , convert_to_tensor_fn = convert_fn , )( dist_params ) # if tf.shape(x).shape[0] > 2: # q_dist = tfd.Independent(q_dist, reinterpreted_batch_ndims=1) return q_dist sequential AR1ProcessMVNGenerator ( IProcessMVNGenerator ) Similar to LFADS' LearnableAutoRegressive1Prior. Here we use the terminology from: https://en.wikipedia.org/wiki/Autoregressive_model#Example:_An_AR(1)_process The autoregressive function takes the form: E(X_t) = E(c) + phi * E(X_{t-1}) + e_t E(c) is a constant. phi is a parameter, which is equivalent to exp(-1/tau) = exp(-exp(-logtau)). where tau is a time constant. e_t is white noise with zero-mean with evar = sigma_e**2 When there's no previous sample, E(X_t) = E(c) + e_t, which is a draw from N(c, sigma_e 2) When there is a previous sample, E(X_t) = E(c) + phi * E(X_{t-1}) + e_t, which means a draw from N(c + phi * X_{t-1}, sigma_p 2) where sigma_p 2 = phi 2 * var(X_{t-1}) + sigma_e 2 = sigma_e 2 / (1 - phi**2) or logpvar = logevar - (log(1 - phi) + log(1 + phi)) Note that this could be roughly equivalent to tfd.Autoregressive if it was passed a distribution_fn with the same transition. See issue: https://github.com/snel-repo/lfads-cd/issues/1 Source code in indl/dists/sequential.py class AR1ProcessMVNGenerator ( IProcessMVNGenerator ): \"\"\" Similar to LFADS' LearnableAutoRegressive1Prior. Here we use the terminology from: https://en.wikipedia.org/wiki/Autoregressive_model#Example:_An_AR(1)_process The autoregressive function takes the form: E(X_t) = E(c) + phi * E(X_{t-1}) + e_t E(c) is a constant. phi is a parameter, which is equivalent to exp(-1/tau) = exp(-exp(-logtau)). where tau is a time constant. e_t is white noise with zero-mean with evar = sigma_e**2 When there's no previous sample, E(X_t) = E(c) + e_t, which is a draw from N(c, sigma_e**2) When there is a previous sample, E(X_t) = E(c) + phi * E(X_{t-1}) + e_t, which means a draw from N(c + phi * X_{t-1}, sigma_p**2) where sigma_p**2 = phi**2 * var(X_{t-1}) + sigma_e**2 = sigma_e**2 / (1 - phi**2) or logpvar = logevar - (log(1 - phi) + log(1 + phi)) Note that this could be roughly equivalent to tfd.Autoregressive if it was passed a `distribution_fn` with the same transition. See issue: https://github.com/snel-repo/lfads-cd/issues/1 \"\"\" def __init__ ( self , init_taus : Union [ float , List [ float ]], init_std : Union [ float , List [ float ]] = 0.1 , trainable_mean : bool = False , trainable_tau : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: init_taus: Initial values of tau init_std: Initial value of sigma_e trainable_mean: set True if the mean (e_c) is trainable. trainable_tau: set True to trainable_nvar: \"\"\" self . _offdiag = offdiag if isinstance ( init_taus , float ): init_taus = [ init_taus ] # TODO: Add time axis for easier broadcasting ndim = len ( init_taus ) self . _e_c , self . _e_scale = make_learnable_mvn_params ( ndim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) self . _logtau = tf . Variable ( tf . math . log ( init_taus ), dtype = tf . float32 , trainable = trainable_tau ) self . _phi = tf . exp ( - tf . exp ( - self . _logtau )) self . _p_scale = tf . exp ( tf . math . log ( self . _e_scale ) - ( tf . math . log ( 1 - self . _phi ) + tf . math . log ( 1 + self . _phi ))) def get_dist ( self , timesteps , samples = 1 , batch_size = 1 , fixed = False ): locs = [] scales = [] sample_list = [] # Add a time dimension e_c = tf . expand_dims ( self . _e_c , 0 ) e_scale = tf . expand_dims ( self . _e_scale , 0 ) p_scale = tf . expand_dims ( self . _p_scale , 0 ) sample = tf . expand_dims ( tf . expand_dims ( tf . zeros_like ( e_c ), 0 ), 0 ) sample = tf . tile ( sample , [ samples , batch_size , 1 , 1 ]) for _ in range ( timesteps ): loc = e_c + self . _phi * sample scale = p_scale if _ > 0 else e_scale locs . append ( loc ) scales . append ( scale ) if self . _offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) sample = dist . sample () sample_list . append ( sample ) sample = tf . concat ( sample_list , axis = 2 ) loc = tf . concat ( locs , axis = 2 ) scale = tf . concat ( scales , axis =- 2 ) if self . _offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return sample , dist __init__ ( self , init_taus , init_std = 0.1 , trainable_mean = False , trainable_tau = True , trainable_var = True , offdiag = False ) special Parameters: Name Type Description Default init_taus Union[float, List[float]] Initial values of tau required init_std Union[float, List[float]] Initial value of sigma_e 0.1 trainable_mean bool set True if the mean (e_c) is trainable. False trainable_tau bool set True to True trainable_nvar required Source code in indl/dists/sequential.py def __init__ ( self , init_taus : Union [ float , List [ float ]], init_std : Union [ float , List [ float ]] = 0.1 , trainable_mean : bool = False , trainable_tau : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: init_taus: Initial values of tau init_std: Initial value of sigma_e trainable_mean: set True if the mean (e_c) is trainable. trainable_tau: set True to trainable_nvar: \"\"\" self . _offdiag = offdiag if isinstance ( init_taus , float ): init_taus = [ init_taus ] # TODO: Add time axis for easier broadcasting ndim = len ( init_taus ) self . _e_c , self . _e_scale = make_learnable_mvn_params ( ndim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) self . _logtau = tf . Variable ( tf . math . log ( init_taus ), dtype = tf . float32 , trainable = trainable_tau ) self . _phi = tf . exp ( - tf . exp ( - self . _logtau )) self . _p_scale = tf . exp ( tf . math . log ( self . _e_scale ) - ( tf . math . log ( 1 - self . _phi ) + tf . math . log ( 1 + self . _phi ))) RNNMVNGenerator ( IProcessMVNGenerator ) Similar to DSAE's LearnableMultivariateNormalDiagCell Source code in indl/dists/sequential.py class RNNMVNGenerator ( IProcessMVNGenerator ): \"\"\" Similar to DSAE's LearnableMultivariateNormalDiagCell \"\"\" def __init__ ( self , units : int , out_dim : int , cell_type : str , shift_std : float = 0.1 , offdiag : bool = False ): \"\"\" Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" self . cell = LearnableMultivariateNormalCell ( units , out_dim , cell_type = cell_type , shift_std = shift_std , offdiag = offdiag ) def get_dist ( self , timesteps , samples = 1 , batch_size = 1 , fixed = True ): \"\"\" Samples from self.cell `timesteps` times. On each step, the previous (sample, state) is fed back into the cell (zero_state used for 0th step). The cell returns a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Args: timesteps: Number of times to sample from the dynamic_prior_cell. Output will have samples: Number of samples to draw from the latent distribution. batch_size: Number of sequences to sample. fixed: Boolean for whether or not to share the same random sample across all sequences in batch. https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887 Returns: \"\"\" if fixed : sample_batch_size = 1 else : sample_batch_size = batch_size sample , state = self . cell . zero_state ([ samples , sample_batch_size ]) locs = [] scales = [] sample_list = [] scale_parm_name = \"scale_tril\" if self . cell . offdiag else \"scale_diag\" # TODO: Check this for offdiag for _ in range ( timesteps ): dist , state = self . cell ( sample , state ) sample = dist . sample () locs . append ( dist . parameters [ \"loc\" ]) scales . append ( dist . parameters [ scale_parm_name ]) sample_list . append ( sample ) sample = tf . stack ( sample_list , axis = 2 ) loc = tf . stack ( locs , axis = 2 ) scale = tf . stack ( scales , axis = 2 ) if fixed : # tile along the batch axis sample = sample + tf . zeros ([ batch_size , 1 , 1 ]) if self . cell . offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return sample , dist __init__ ( self , units , out_dim , cell_type , shift_std = 0.1 , offdiag = False ) special Parameters: Name Type Description Default units int Dimensionality of the RNN function parameters. required out_dim int The dimensionality of the distribution. required cell_type str an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. required shift_std float Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. 0.1 offdiag bool set True to allow non-zero covariance (within-timestep) in the returned distribution. False Source code in indl/dists/sequential.py def __init__ ( self , units : int , out_dim : int , cell_type : str , shift_std : float = 0.1 , offdiag : bool = False ): \"\"\" Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" self . cell = LearnableMultivariateNormalCell ( units , out_dim , cell_type = cell_type , shift_std = shift_std , offdiag = offdiag ) get_dist ( self , timesteps , samples = 1 , batch_size = 1 , fixed = True ) Samples from self.cell `timesteps` times. On each step, the previous (sample, state) is fed back into the cell (zero_state used for 0th step). The cell returns a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. !!! args timesteps: Number of times to sample from the dynamic_prior_cell. Output will have samples: Number of samples to draw from the latent distribution. batch_size: Number of sequences to sample. !!! fixed \"Boolean for whether or not to share the same random\" sample across all sequences in batch. https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887 Returns: Source code in indl/dists/sequential.py def get_dist ( self , timesteps , samples = 1 , batch_size = 1 , fixed = True ): \"\"\" Samples from self.cell `timesteps` times. On each step, the previous (sample, state) is fed back into the cell (zero_state used for 0th step). The cell returns a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Args: timesteps: Number of times to sample from the dynamic_prior_cell. Output will have samples: Number of samples to draw from the latent distribution. batch_size: Number of sequences to sample. fixed: Boolean for whether or not to share the same random sample across all sequences in batch. https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887 Returns: \"\"\" if fixed : sample_batch_size = 1 else : sample_batch_size = batch_size sample , state = self . cell . zero_state ([ samples , sample_batch_size ]) locs = [] scales = [] sample_list = [] scale_parm_name = \"scale_tril\" if self . cell . offdiag else \"scale_diag\" # TODO: Check this for offdiag for _ in range ( timesteps ): dist , state = self . cell ( sample , state ) sample = dist . sample () locs . append ( dist . parameters [ \"loc\" ]) scales . append ( dist . parameters [ scale_parm_name ]) sample_list . append ( sample ) sample = tf . stack ( sample_list , axis = 2 ) loc = tf . stack ( locs , axis = 2 ) scale = tf . stack ( scales , axis = 2 ) if fixed : # tile along the batch axis sample = sample + tf . zeros ([ batch_size , 1 , 1 ]) if self . cell . offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return sample , dist RNNMultivariateNormalDiag ( MultivariateNormalDiag ) Source code in indl/dists/sequential.py class RNNMultivariateNormalDiag ( tfd . MultivariateNormalDiag ): def __init__ ( self , cell , n_timesteps = 1 , output_dim = None , name = \"rnn_mvn_diag\" , ** kwargs ): self . cell = cell if output_dim is not None and hasattr ( self . cell , 'output_dim' ): self . cell . output_dim = output_dim if hasattr ( self . cell , 'output_dim' ): output_dim = self . cell . output_dim else : output_dim = output_dim or self . cell . units h0 = tf . zeros ([ 1 , self . cell . units ]) c0 = tf . zeros ([ 1 , self . cell . units ]) input0 = tf . zeros (( 1 , output_dim )) if hasattr ( cell , 'reset_dropout_mask' ): self . cell . reset_dropout_mask () self . cell . reset_recurrent_dropout_mask () input_ = input0 states_ = ( h0 , c0 ) successive_outputs = [] for i in range ( n_timesteps ): input_ , states_ = self . cell ( input_ , states_ ) successive_outputs . append ( input_ ) loc = tf . concat ([ _ . parameters [ \"distribution\" ] . parameters [ \"loc\" ] for _ in successive_outputs ], axis = 0 ) scale_diag = tf . concat ([ _ . parameters [ \"distribution\" ] . parameters [ \"scale_diag\" ] for _ in successive_outputs ], axis = 0 ) super ( RNNMultivariateNormalDiag , self ) . __init__ ( loc = loc , scale_diag = scale_diag , name = name , ** kwargs ) cross_entropy ( self , other , name = 'cross_entropy' ) Computes the (Shannon) cross entropy. Denote this distribution ( self ) by P and the other distribution by Q . Assuming P, Q are absolutely continuous with respect to one another and permit densities p(x) dr(x) and q(x) dr(x) , (Shannon) cross entropy is defined as: H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x) where F denotes the support of the random variable X ~ P . Parameters: Name Type Description Default other tfp.distributions.Distribution instance. required name Python str prepended to names of ops created by this function. 'cross_entropy' Returns: Type Description cross_entropy self.dtype Tensor with shape [B1, ..., Bn] representing n different calculations of (Shannon) cross entropy. Source code in indl/dists/sequential.py def cross_entropy ( self , other , name = 'cross_entropy' ): \"\"\"Computes the (Shannon) cross entropy. Denote this distribution (`self`) by `P` and the `other` distribution by `Q`. Assuming `P, Q` are absolutely continuous with respect to one another and permit densities `p(x) dr(x)` and `q(x) dr(x)`, (Shannon) cross entropy is defined as: ```none H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x) ``` where `F` denotes the support of the random variable `X ~ P`. Args: other: `tfp.distributions.Distribution` instance. name: Python `str` prepended to names of ops created by this function. Returns: cross_entropy: `self.dtype` `Tensor` with shape `[B1, ..., Bn]` representing `n` different calculations of (Shannon) cross entropy. \"\"\" with self . _name_and_control_scope ( name ): return self . _cross_entropy ( other ) kl_divergence ( self , other , name = 'kl_divergence' ) Computes the Kullback--Leibler divergence. Denote this distribution ( self ) by p and the other distribution by q . Assuming p, q are absolutely continuous with respect to reference measure r , the KL divergence is defined as: KL[p, q] = E_p[log(p(X)/q(X))] = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x) = H[p, q] - H[p] where F denotes the support of the random variable X ~ p , H[., .] denotes (Shannon) cross entropy, and H[.] denotes (Shannon) entropy. Parameters: Name Type Description Default other tfp.distributions.Distribution instance. required name Python str prepended to names of ops created by this function. 'kl_divergence' Returns: Type Description kl_divergence self.dtype Tensor with shape [B1, ..., Bn] representing n different calculations of the Kullback-Leibler divergence. Source code in indl/dists/sequential.py def kl_divergence ( self , other , name = 'kl_divergence' ): \"\"\"Computes the Kullback--Leibler divergence. Denote this distribution (`self`) by `p` and the `other` distribution by `q`. Assuming `p, q` are absolutely continuous with respect to reference measure `r`, the KL divergence is defined as: ```none KL[p, q] = E_p[log(p(X)/q(X))] = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x) = H[p, q] - H[p] ``` where `F` denotes the support of the random variable `X ~ p`, `H[., .]` denotes (Shannon) cross entropy, and `H[.]` denotes (Shannon) entropy. Args: other: `tfp.distributions.Distribution` instance. name: Python `str` prepended to names of ops created by this function. Returns: kl_divergence: `self.dtype` `Tensor` with shape `[B1, ..., Bn]` representing `n` different calculations of the Kullback-Leibler divergence. \"\"\" # NOTE: We do not enter a `self._name_and_control_scope` here. We rely on # `tfd.kl_divergence(self, other)` to use `_name_and_control_scope` to apply # assertions on both Distributions. # # Subclasses that override `Distribution.kl_divergence` or `_kl_divergence` # must ensure that assertions are applied for both `self` and `other`. return self . _kl_divergence ( other ) TiledMVNGenerator ( IProcessMVNGenerator ) Similar to LFADS' LearnableDiagonalGaussian. Uses a single learnable loc and scale which are tiled across timesteps. Source code in indl/dists/sequential.py class TiledMVNGenerator ( IProcessMVNGenerator ): \"\"\" Similar to LFADS' LearnableDiagonalGaussian. Uses a single learnable loc and scale which are tiled across timesteps. \"\"\" def __init__ ( self , latent_dim : int , init_std : float = 0.1 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: latent_dim: Number of dimensions in a single timestep (params['f_latent_size']) init_std: Initial value of standard deviation (params['q_z_init_std']) trainable_mean: True if mean should be trainable (params['z_prior_train_mean']) trainable_var: True if variance should be trainable (params['z_prior_train_var']) offdiag: True if off-diagonal elements (non-orthogonality) allowed. (params['z_prior_off_diag']) \"\"\" self . _offdiag = offdiag self . _loc , self . _scale = make_learnable_mvn_params ( latent_dim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) def get_dist ( self , timesteps , samples = 1 , batch_size = 1 ): \"\"\" Tiles the saved loc and scale to the same shape as `posterior` then uses them to create a MVN dist with appropriate shape. Each timestep has the same loc and scale but if it were sampled then each timestep would return different values. Args: timesteps: samples: batch_size: Returns: MVNDiag distribution of the same shape as `posterior` \"\"\" loc = tf . tile ( tf . expand_dims ( self . _loc , 0 ), [ timesteps , 1 ]) scale = tf . expand_dims ( self . _scale , 0 ) if self . _offdiag : scale = tf . tile ( scale , [ timesteps , 1 , 1 ]) dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : scale = tf . tile ( scale , [ timesteps , 1 ]) dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return dist . sample ([ samples , batch_size ]), dist __init__ ( self , latent_dim , init_std = 0.1 , trainable_mean = True , trainable_var = True , offdiag = False ) special Parameters: Name Type Description Default latent_dim int Number of dimensions in a single timestep (params['f_latent_size']) required init_std float Initial value of standard deviation (params['q_z_init_std']) 0.1 trainable_mean bool True if mean should be trainable (params['z_prior_train_mean']) True trainable_var bool True if variance should be trainable (params['z_prior_train_var']) True offdiag bool True if off-diagonal elements (non-orthogonality) allowed. (params['z_prior_off_diag']) False Source code in indl/dists/sequential.py def __init__ ( self , latent_dim : int , init_std : float = 0.1 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: latent_dim: Number of dimensions in a single timestep (params['f_latent_size']) init_std: Initial value of standard deviation (params['q_z_init_std']) trainable_mean: True if mean should be trainable (params['z_prior_train_mean']) trainable_var: True if variance should be trainable (params['z_prior_train_var']) offdiag: True if off-diagonal elements (non-orthogonality) allowed. (params['z_prior_off_diag']) \"\"\" self . _offdiag = offdiag self . _loc , self . _scale = make_learnable_mvn_params ( latent_dim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) get_dist ( self , timesteps , samples = 1 , batch_size = 1 ) Tiles the saved loc and scale to the same shape as posterior then uses them to create a MVN dist with appropriate shape. Each timestep has the same loc and scale but if it were sampled then each timestep would return different values. Parameters: Name Type Description Default timesteps required samples 1 batch_size 1 Returns: Type Description MVNDiag distribution of the same shape as posterior Source code in indl/dists/sequential.py def get_dist ( self , timesteps , samples = 1 , batch_size = 1 ): \"\"\" Tiles the saved loc and scale to the same shape as `posterior` then uses them to create a MVN dist with appropriate shape. Each timestep has the same loc and scale but if it were sampled then each timestep would return different values. Args: timesteps: samples: batch_size: Returns: MVNDiag distribution of the same shape as `posterior` \"\"\" loc = tf . tile ( tf . expand_dims ( self . _loc , 0 ), [ timesteps , 1 ]) scale = tf . expand_dims ( self . _scale , 0 ) if self . _offdiag : scale = tf . tile ( scale , [ timesteps , 1 , 1 ]) dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : scale = tf . tile ( scale , [ timesteps , 1 ]) dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return dist . sample ([ samples , batch_size ]), dist VariationalLSTMCell ( LSTMCell ) Source code in indl/dists/sequential.py class VariationalLSTMCell ( tfkl . LSTMCell ): def __init__ ( self , units , make_dist_fn = None , make_dist_model = None , ** kwargs ): super ( VariationalLSTMCell , self ) . __init__ ( units , ** kwargs ) self . make_dist_fn = make_dist_fn self . make_dist_model = make_dist_model # For some reason the below code doesn't work during build. # So I don't know how to use the outer VariationalRNN to set this cell's output_size if self . make_dist_fn is None : self . make_dist_fn = lambda t : tfd . MultivariateNormalDiag ( loc = t [ 0 ], scale_diag = t [ 1 ]) if self . make_dist_model is None : fake_cell_output = tfkl . Input (( self . units ,)) loc = tfkl . Dense ( self . output_size , name = \"VarLSTMCell_loc\" )( fake_cell_output ) scale = tfkl . Dense ( self . output_size , name = \"VarLSTMCell_scale\" )( fake_cell_output ) scale = tf . nn . softplus ( scale + scale_shift ) + 1e-5 dist_layer = tfpl . DistributionLambda ( make_distribution_fn = self . make_dist_fn , # TODO: convert_to_tensor_fn=lambda s: s.sample(N_SAMPLES) )([ loc , scale ]) self . make_dist_model = tf . keras . Model ( fake_cell_output , dist_layer ) def build ( self , input_shape ): super ( VariationalLSTMCell , self ) . build ( input_shape ) # It would be good to defer making self.make_dist_model until here, # but it doesn't work for some reason. # def input_zero(self, inputs_): # input0 = inputs_[..., -1, :] # input0 = tf.matmul(input0, tf.zeros((input0.shape[-1], self.units))) # dist0 = self.make_dist_model(input0) # return dist0 def call ( self , inputs , states , training = None ): inputs = tf . convert_to_tensor ( inputs ) output , state = super ( VariationalLSTMCell , self ) . call ( inputs , states , training = training ) dist = self . make_dist_model ( output ) return dist , state build ( self , input_shape ) Creates the variables of the layer (optional, for subclass implementers). This is a method that implementers of subclasses of Layer or Model can override if they need a state-creation step in-between layer instantiation and layer call. This is typically used to create the weights of Layer subclasses. Parameters: Name Type Description Default input_shape Instance of TensorShape , or list of instances of TensorShape if the layer expects a list of inputs (one instance per input). required Source code in indl/dists/sequential.py def build ( self , input_shape ): super ( VariationalLSTMCell , self ) . build ( input_shape ) # It would be good to defer making self.make_dist_model until here, # but it doesn't work for some reason. call ( self , inputs , states , training = None ) This is where the layer's logic lives. Note here that call() method in tf.keras is little bit different from keras API. In keras API, you can pass support masking for layers as additional arguments. Whereas tf.keras has compute_mask() method to support masking. Parameters: Name Type Description Default inputs Input tensor, or list/tuple of input tensors. required **kwargs Additional keyword arguments. Currently unused. required Returns: Type Description A tensor or list/tuple of tensors. Source code in indl/dists/sequential.py def call ( self , inputs , states , training = None ): inputs = tf . convert_to_tensor ( inputs ) output , state = super ( VariationalLSTMCell , self ) . call ( inputs , states , training = training ) dist = self . make_dist_model ( output ) return dist , state","title":"dists"},{"location":"API/dists/#dists","text":"","title":"dists"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalCell","text":"Multivariate normal distribution RNN cell. The model is a RNN-based recurrent function that computes the parameters for a multivariate normal distribution at each timestep t . Based on: https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L242 Source code in indl/dists/__init__.py class LearnableMultivariateNormalCell ( tf . keras . Model ): \"\"\"Multivariate normal distribution RNN cell. The model is a RNN-based recurrent function that computes the parameters for a multivariate normal distribution at each timestep `t`. Based on: https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L242 \"\"\" def __init__ ( self , units : int , out_dim : int , shift_std : float = 0.1 , cell_type : str = 'lstm' , offdiag : bool = False ): \"\"\"Constructs a learnable multivariate normal cell. Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" super ( LearnableMultivariateNormalCell , self ) . __init__ () self . offdiag = offdiag self . output_dimensions = out_dim self . units = units if cell_type . upper () . endswith ( 'LSTM' ): self . rnn_cell = tfkl . LSTMCell ( self . units , implementation = 1 , name = \"mvncell\" ) # why does the jupyter notebook version require implementation=1 but not in pycharm? elif cell_type . upper () . endswith ( 'GRU' ): self . rnn_cell = tfkl . GRUCell ( self . units , name = \"mvnell\" ) elif cell_type . upper () . endswith ( 'RNN' ): self . rnn_cell = tfkl . SimpleRNNCell ( self . units , name = \"mvncell\" ) elif cell_type . upper () . endswith ( 'GRUCLIP' ): from indl.rnn.gru_clip import GRUClipCell self . rnn_cell = GRUClipCell ( self . units , name = \"mvncell\" ) else : raise ValueError ( \"cell_type %s not recognized\" % cell_type ) self . loc_layer = tfkl . Dense ( self . output_dimensions , name = \"mvncell_loc\" ) n_scale_dim = ( tfpl . MultivariateNormalTriL . params_size ( out_dim ) - out_dim ) if offdiag \\ else ( tfpl . IndependentNormal . params_size ( out_dim ) - out_dim ) self . scale_untransformed_layer = tfkl . Dense ( n_scale_dim , name = \"mvndiagcell_scale\" ) self . _scale_shift = np . log ( np . exp ( shift_std ) - 1 ) . astype ( np . float32 ) #def build(self, input_shape): #super(LearnableMultivariateNormalDiagCell, self).build(input_shape) #self.lstm_cell.build(input_shape) #self.loc_layer.build(input_shape) #self.scale_untransformed_layer.build(input_shape) #self.built = True def zero_state ( self , sample_batch_shape = ()): \"\"\"Returns an initial state for the RNN cell. Args: sample_batch_shape: A 0D or 1D tensor of the combined sample and batch shape. Returns: A tuple of the initial previous output at timestep 0 of shape [sample_batch_shape, dimensions], and the cell state. \"\"\" zero_state = self . rnn_cell . get_initial_state ( batch_size = sample_batch_shape [ - 1 ], dtype = tf . float32 ) sample_batch_shape = tf . convert_to_tensor ( value = sample_batch_shape , dtype = tf . int32 ) out_shape = tf . concat (( sample_batch_shape , [ self . output_dimensions ]), axis =- 1 ) previous_output = tf . zeros ( out_shape ) return previous_output , zero_state def call ( self , inputs , state ): \"\"\"Runs the model to generate a distribution for a single timestep. This generates a batched MultivariateNormalDiag distribution using the output of the recurrent model at the current timestep to parameterize the distribution. Args: inputs: The sampled value of `z` at the previous timestep, i.e., `z_{t-1}`, of shape [..., dimensions]. `z_0` should be set to the empty matrix. state: A tuple containing the (hidden, cell) state. Returns: A tuple of a MultivariateNormalDiag distribution, and the state of the recurrent function at the end of the current timestep. The distribution will have event shape [dimensions], batch shape [...], and sample shape [sample_shape, ..., dimensions]. \"\"\" # In order to allow the user to pass in a single example without a batch # dimension, we always expand the input to at least two dimensions, then # fix the output shape to remove the batch dimension if necessary. original_shape = inputs . shape if len ( original_shape ) < 2 : inputs = tf . reshape ( inputs , [ 1 , - 1 ]) out , state = self . rnn_cell ( inputs , state ) parms_shape = tf . concat (( original_shape [: - 1 ], [ self . output_dimensions ]), 0 ) loc = tf . reshape ( self . loc_layer ( out ), parms_shape ) scale = self . scale_untransformed_layer ( out ) scale = tf . nn . softplus ( scale + self . _scale_shift ) + 1e-5 scale = tf . reshape ( scale , parms_shape ) if self . offdiag : return tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : return tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ), state","title":"LearnableMultivariateNormalCell"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalCell.__init__","text":"Constructs a learnable multivariate normal cell. Parameters: Name Type Description Default units int Dimensionality of the RNN function parameters. required out_dim int The dimensionality of the distribution. required shift_std float Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. 0.1 cell_type str an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. 'lstm' offdiag bool set True to allow non-zero covariance (within-timestep) in the returned distribution. False Source code in indl/dists/__init__.py def __init__ ( self , units : int , out_dim : int , shift_std : float = 0.1 , cell_type : str = 'lstm' , offdiag : bool = False ): \"\"\"Constructs a learnable multivariate normal cell. Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" super ( LearnableMultivariateNormalCell , self ) . __init__ () self . offdiag = offdiag self . output_dimensions = out_dim self . units = units if cell_type . upper () . endswith ( 'LSTM' ): self . rnn_cell = tfkl . LSTMCell ( self . units , implementation = 1 , name = \"mvncell\" ) # why does the jupyter notebook version require implementation=1 but not in pycharm? elif cell_type . upper () . endswith ( 'GRU' ): self . rnn_cell = tfkl . GRUCell ( self . units , name = \"mvnell\" ) elif cell_type . upper () . endswith ( 'RNN' ): self . rnn_cell = tfkl . SimpleRNNCell ( self . units , name = \"mvncell\" ) elif cell_type . upper () . endswith ( 'GRUCLIP' ): from indl.rnn.gru_clip import GRUClipCell self . rnn_cell = GRUClipCell ( self . units , name = \"mvncell\" ) else : raise ValueError ( \"cell_type %s not recognized\" % cell_type ) self . loc_layer = tfkl . Dense ( self . output_dimensions , name = \"mvncell_loc\" ) n_scale_dim = ( tfpl . MultivariateNormalTriL . params_size ( out_dim ) - out_dim ) if offdiag \\ else ( tfpl . IndependentNormal . params_size ( out_dim ) - out_dim ) self . scale_untransformed_layer = tfkl . Dense ( n_scale_dim , name = \"mvndiagcell_scale\" ) self . _scale_shift = np . log ( np . exp ( shift_std ) - 1 ) . astype ( np . float32 ) #def build(self, input_shape): #super(LearnableMultivariateNormalDiagCell, self).build(input_shape) #self.lstm_cell.build(input_shape) #self.loc_layer.build(input_shape) #self.scale_untransformed_layer.build(input_shape) #self.built = True","title":"__init__()"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalCell.call","text":"Runs the model to generate a distribution for a single timestep. This generates a batched MultivariateNormalDiag distribution using the output of the recurrent model at the current timestep to parameterize the distribution. Parameters: Name Type Description Default inputs The sampled value of z at the previous timestep, i.e., z_{t-1} , of shape [..., dimensions]. z_0 should be set to the empty matrix. required state A tuple containing the (hidden, cell) state. required Returns: Type Description A tuple of a MultivariateNormalDiag distribution, and the state of the recurrent function at the end of the current timestep. The distribution will have event shape [dimensions], batch shape [...], and sample shape [sample_shape, ..., dimensions]. Source code in indl/dists/__init__.py def call ( self , inputs , state ): \"\"\"Runs the model to generate a distribution for a single timestep. This generates a batched MultivariateNormalDiag distribution using the output of the recurrent model at the current timestep to parameterize the distribution. Args: inputs: The sampled value of `z` at the previous timestep, i.e., `z_{t-1}`, of shape [..., dimensions]. `z_0` should be set to the empty matrix. state: A tuple containing the (hidden, cell) state. Returns: A tuple of a MultivariateNormalDiag distribution, and the state of the recurrent function at the end of the current timestep. The distribution will have event shape [dimensions], batch shape [...], and sample shape [sample_shape, ..., dimensions]. \"\"\" # In order to allow the user to pass in a single example without a batch # dimension, we always expand the input to at least two dimensions, then # fix the output shape to remove the batch dimension if necessary. original_shape = inputs . shape if len ( original_shape ) < 2 : inputs = tf . reshape ( inputs , [ 1 , - 1 ]) out , state = self . rnn_cell ( inputs , state ) parms_shape = tf . concat (( original_shape [: - 1 ], [ self . output_dimensions ]), 0 ) loc = tf . reshape ( self . loc_layer ( out ), parms_shape ) scale = self . scale_untransformed_layer ( out ) scale = tf . nn . softplus ( scale + self . _scale_shift ) + 1e-5 scale = tf . reshape ( scale , parms_shape ) if self . offdiag : return tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : return tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ), state","title":"call()"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalCell.zero_state","text":"Returns an initial state for the RNN cell. Parameters: Name Type Description Default sample_batch_shape A 0D or 1D tensor of the combined sample and batch shape. () Returns: Type Description A tuple of the initial previous output at timestep 0 of shape [sample_batch_shape, dimensions], and the cell state. Source code in indl/dists/__init__.py def zero_state ( self , sample_batch_shape = ()): \"\"\"Returns an initial state for the RNN cell. Args: sample_batch_shape: A 0D or 1D tensor of the combined sample and batch shape. Returns: A tuple of the initial previous output at timestep 0 of shape [sample_batch_shape, dimensions], and the cell state. \"\"\" zero_state = self . rnn_cell . get_initial_state ( batch_size = sample_batch_shape [ - 1 ], dtype = tf . float32 ) sample_batch_shape = tf . convert_to_tensor ( value = sample_batch_shape , dtype = tf . int32 ) out_shape = tf . concat (( sample_batch_shape , [ self . output_dimensions ]), axis =- 1 ) previous_output = tf . zeros ( out_shape ) return previous_output , zero_state","title":"zero_state()"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalDiag","text":"Learnable multivariate diagonal normal distribution. The model is a multivariate normal distribution with learnable mean and stddev parameters. See make_mvn_prior for a description. Source code in indl/dists/__init__.py class LearnableMultivariateNormalDiag ( tf . keras . Model ): \"\"\"Learnable multivariate diagonal normal distribution. The model is a multivariate normal distribution with learnable `mean` and `stddev` parameters. See make_mvn_prior for a description. \"\"\" def __init__ ( self , dimensions , init_std = 1.0 , trainable_mean = True , trainable_var = True ): \"\"\"Constructs a learnable multivariate diagonal normal model. Args: dimensions: An integer corresponding to the dimensionality of the distribution. \"\"\" super ( LearnableMultivariateNormalDiag , self ) . __init__ () with tf . name_scope ( self . _name ): self . dimensions = dimensions if trainable_mean : self . _mean = tf . Variable ( tf . random . normal ([ dimensions ], stddev = 0.1 ), name = \"mean\" ) else : self . _mean = tf . zeros ( dimensions ) if trainable_var : _scale_shift = np . log ( np . exp ( init_std ) - 1 ) . astype ( np . float32 ) self . _scale = tfp . util . TransformedVariable ( tf . random . normal ([ dimensions ], mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), bijector = tfb . Chain ([ tfb . Shift ( 1e-5 ), tfb . Softplus (), tfb . Shift ( _scale_shift )]), name = \"transformed_scale\" ) else : self . _scale = init_std * tf . ones ( dimensions ) def __call__ ( self , * args , ** kwargs ): # Allow this Model to be called without inputs. dummy = tf . zeros ( self . dimensions ) return super ( LearnableMultivariateNormalDiag , self ) . __call__ ( dummy , * args , ** kwargs ) def call ( self , inputs ): \"\"\"Runs the model to generate multivariate normal distribution. Args: inputs: Unused. Returns: A MultivariateNormalDiag distribution with event shape [dimensions], batch shape [], and sample shape [sample_shape, dimensions]. \"\"\" del inputs # unused with tf . name_scope ( self . _name ): return tfd . MultivariateNormalDiag ( loc = self . loc , scale_diag = self . scale_diag ) @property def loc ( self ): \"\"\"The mean of the normal distribution.\"\"\" return self . _mean @property def scale_diag ( self ): \"\"\"The diagonal standard deviation of the normal distribution.\"\"\" return self . _scale","title":"LearnableMultivariateNormalDiag"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalDiag.loc","text":"The mean of the normal distribution.","title":"loc"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalDiag.scale_diag","text":"The diagonal standard deviation of the normal distribution.","title":"scale_diag"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalDiag.__init__","text":"Constructs a learnable multivariate diagonal normal model. Parameters: Name Type Description Default dimensions An integer corresponding to the dimensionality of the distribution. required Source code in indl/dists/__init__.py def __init__ ( self , dimensions , init_std = 1.0 , trainable_mean = True , trainable_var = True ): \"\"\"Constructs a learnable multivariate diagonal normal model. Args: dimensions: An integer corresponding to the dimensionality of the distribution. \"\"\" super ( LearnableMultivariateNormalDiag , self ) . __init__ () with tf . name_scope ( self . _name ): self . dimensions = dimensions if trainable_mean : self . _mean = tf . Variable ( tf . random . normal ([ dimensions ], stddev = 0.1 ), name = \"mean\" ) else : self . _mean = tf . zeros ( dimensions ) if trainable_var : _scale_shift = np . log ( np . exp ( init_std ) - 1 ) . astype ( np . float32 ) self . _scale = tfp . util . TransformedVariable ( tf . random . normal ([ dimensions ], mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), bijector = tfb . Chain ([ tfb . Shift ( 1e-5 ), tfb . Softplus (), tfb . Shift ( _scale_shift )]), name = \"transformed_scale\" ) else : self . _scale = init_std * tf . ones ( dimensions )","title":"__init__()"},{"location":"API/dists/#indl.dists.LearnableMultivariateNormalDiag.call","text":"Runs the model to generate multivariate normal distribution. Parameters: Name Type Description Default inputs Unused. required Returns: Type Description A MultivariateNormalDiag distribution with event shape [dimensions], batch shape [], and sample shape [sample_shape, dimensions]. Source code in indl/dists/__init__.py def call ( self , inputs ): \"\"\"Runs the model to generate multivariate normal distribution. Args: inputs: Unused. Returns: A MultivariateNormalDiag distribution with event shape [dimensions], batch shape [], and sample shape [sample_shape, dimensions]. \"\"\" del inputs # unused with tf . name_scope ( self . _name ): return tfd . MultivariateNormalDiag ( loc = self . loc , scale_diag = self . scale_diag )","title":"call()"},{"location":"API/dists/#indl.dists.make_learnable_mvn_params","text":"Return mean (loc) and stddev (scale) parameters for initializing multivariate normal distributions. If trainable_mean then it will be initialized with random normal (stddev=0.1), otherwise zeros. If trainable_var then it will be initialized with random normal centered at a value such that the bijector transformation yields the value in init_std. When init_std is 1.0 (default) then the inverse-bijected value is approximately 0.0. If not trainable_var then scale is a vector or matrix of init_std of appropriate shape for the dist. Parameters: Name Type Description Default ndim int Number of dimensions. required init_std float Initial value for the standard deviation. 1.0 trainable_mean bool Whether or not the mean (loc) is a trainable tf.Variable. True trainable_var bool Whether or not the variance (scale) is a trainable tf.Variable. True offdiag bool Whether or not off-diagonal elements are allowed. False Returns: loc, scale Source code in indl/dists/__init__.py def make_learnable_mvn_params ( ndim : int , init_std : float = 1.0 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Return mean (loc) and stddev (scale) parameters for initializing multivariate normal distributions. If trainable_mean then it will be initialized with random normal (stddev=0.1), otherwise zeros. If trainable_var then it will be initialized with random normal centered at a value such that the bijector transformation yields the value in init_std. When init_std is 1.0 (default) then the inverse-bijected value is approximately 0.0. If not trainable_var then scale is a vector or matrix of init_std of appropriate shape for the dist. Args: ndim: Number of dimensions. init_std: Initial value for the standard deviation. trainable_mean: Whether or not the mean (loc) is a trainable tf.Variable. trainable_var: Whether or not the variance (scale) is a trainable tf.Variable. offdiag: Whether or not off-diagonal elements are allowed. Returns: loc, scale \"\"\" if trainable_mean : loc = tf . Variable ( tf . random . normal ([ ndim ], stddev = 0.1 , dtype = tf . float32 )) else : loc = tf . zeros ( ndim ) # Initialize the variance (scale), trainable or not, offdiag or not. if trainable_var : if offdiag : _ndim = [ ndim , ndim ] scale = tfp . util . TransformedVariable ( # init_std * tf.eye(ndim, dtype=tf.float32), tf . random . normal ( _ndim , mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), tfp . bijectors . FillScaleTriL (), name = \"prior_scale\" ) else : _scale_shift = np . log ( np . exp ( init_std ) - 1 ) . astype ( np . float32 ) # tfp.math.softplus_inverse(init_std) scale = tfp . util . TransformedVariable ( # init_std * tf.ones(ndim, dtype=tf.float32), tf . random . normal ([ ndim ], mean = init_std , stddev = init_std / 10 , dtype = tf . float32 ), tfb . Chain ([ tfb . Shift ( 1e-5 ), tfb . Softplus (), tfb . Shift ( _scale_shift )]), name = \"prior_scale\" ) else : if offdiag : scale = init_std * tf . eye ( ndim ) else : scale = init_std * tf . ones ( ndim ) return loc , scale","title":"make_learnable_mvn_params()"},{"location":"API/dists/#indl.dists.make_mvn_dist_fn","text":"Take a 1-D tensor and use it to parameterize a MVN dist. This doesn't return the distribution, but the function to make the distribution and its arguments. make_dist_fn, [loc, scale] You can supply it to tfpl.DistributionLambda Parameters: Name Type Description Default _x_ Tensor required ndim int required shift_std float 1.0 offdiag bool False loc_name Optional[str] None scale_name Optional[str] None use_mvn_diag bool True Returns: Type Description Tuple[Callable[[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.ops.Tensor], tensorflow_probability.python.distributions.distribution.Distribution], List[tensorflow.python.framework.ops.Tensor]] make_dist_fn, [loc, scale] Source code in indl/dists/__init__.py def make_mvn_dist_fn ( _x_ : tf . Tensor , ndim : int , shift_std : float = 1.0 , offdiag : bool = False , loc_name : Optional [ str ] = None , scale_name : Optional [ str ] = None , use_mvn_diag : bool = True ) -> Tuple [ Callable [[ tf . Tensor , tf . Tensor ], tfd . Distribution ], List [ tf . Tensor ]]: \"\"\" Take a 1-D tensor and use it to parameterize a MVN dist. This doesn't return the distribution, but the function to make the distribution and its arguments. make_dist_fn, [loc, scale] You can supply it to tfpl.DistributionLambda Args: _x_: ndim: shift_std: offdiag: loc_name: scale_name: use_mvn_diag: Returns: make_dist_fn, [loc, scale] \"\"\" _scale_shift = np . log ( np . exp ( shift_std ) - 1 ) . astype ( np . float32 ) _loc = tfkl . Dense ( ndim , name = loc_name )( _x_ ) n_scale_dim = ( tfpl . MultivariateNormalTriL . params_size ( ndim ) - ndim ) if offdiag \\ else ( tfpl . IndependentNormal . params_size ( ndim ) - ndim ) _scale = tfkl . Dense ( n_scale_dim , name = scale_name )( _x_ ) _scale = tf . math . softplus ( _scale + _scale_shift ) + 1e-5 if offdiag : _scale = tfb . FillTriangular ()( _scale ) make_dist_fn = lambda t : tfd . MultivariateNormalTriL ( loc = t [ 0 ], scale_tril = t [ 1 ]) else : if use_mvn_diag : # Match type with prior make_dist_fn = lambda t : tfd . MultivariateNormalDiag ( loc = t [ 0 ], scale_diag = t [ 1 ]) else : make_dist_fn = lambda t : tfd . Independent ( tfd . Normal ( loc = t [ 0 ], scale = t [ 1 ])) return make_dist_fn , [ _loc , _scale ]","title":"make_mvn_dist_fn()"},{"location":"API/dists/#indl.dists.make_mvn_prior","text":"Creates a tensorflow-probability distribution: MultivariateNormalTriL if offdiag else MultivariateNormalDiag Mean (loc) and sigma (scale) can be trainable or not. Mean initializes to random.normal around 0 (stddev=0.1) if trainable, else zeros. Scale initialies to init_std if not trainable. If it is trainable, it initializes to a tfp TransformedVariable that will be centered at 0 for easy training under the hood, but will be transformed via softplus to give something initially close to init_var. loc and scale are tracked by the MVNDiag class. For LFADS ics prior, trainable_mean=True, trainable_var=False For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True In either case, var was initialized with 0.1 (==> logvar with log(0.1)) Unlike the LFADS' LearnableDiagonalGaussian, here we don't support multi-dimensional, just a vector. See also LearnableMultivariateNormalDiag for a tf.keras.Model version of this. Parameters: Name Type Description Default ndim int latent dimension of distribution. Currently only supports 1 d (I think ) required init_std float initial standard deviation of the gaussian. If trainable_var then the initial standard deviation will be drawn from a random.normal distribution with mean init_std and stddev 1/10th of that. 1.0 trainable_mean bool If the mean should be a tf.Variable True trainable_var bool If the variance/stddev/scale (whatever you call it) should be a tf.Variable True offdiag bool If the variance-covariance matrix is allowed non-zero off-diagonal elements. False Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL] A tensorflow-probability distribution (either MultivariateNormalTriL or MultivariateNormalDiag). Source code in indl/dists/__init__.py def make_mvn_prior ( ndim : int , init_std : float = 1.0 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Creates a tensorflow-probability distribution: MultivariateNormalTriL if offdiag else MultivariateNormalDiag Mean (loc) and sigma (scale) can be trainable or not. Mean initializes to random.normal around 0 (stddev=0.1) if trainable, else zeros. Scale initialies to init_std if not trainable. If it is trainable, it initializes to a tfp TransformedVariable that will be centered at 0 for easy training under the hood, but will be transformed via softplus to give something initially close to init_var. loc and scale are tracked by the MVNDiag class. For LFADS ics prior, trainable_mean=True, trainable_var=False For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True In either case, var was initialized with 0.1 (==> logvar with log(0.1)) Unlike the LFADS' LearnableDiagonalGaussian, here we don't support multi-dimensional, just a vector. See also LearnableMultivariateNormalDiag for a tf.keras.Model version of this. Args: ndim: latent dimension of distribution. Currently only supports 1 d (I think ) init_std: initial standard deviation of the gaussian. If trainable_var then the initial standard deviation will be drawn from a random.normal distribution with mean init_std and stddev 1/10th of that. trainable_mean: If the mean should be a tf.Variable trainable_var: If the variance/stddev/scale (whatever you call it) should be a tf.Variable offdiag: If the variance-covariance matrix is allowed non-zero off-diagonal elements. Returns: A tensorflow-probability distribution (either MultivariateNormalTriL or MultivariateNormalDiag). \"\"\" loc , scale = make_learnable_mvn_params ( ndim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) # Initialize the prior. if offdiag : # Note: Diag must be > 0, upper triangular must be 0, and lower triangular may be != 0. prior = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : prior = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) # kl_exact needs same dist types for prior and latent. # We would switch to the next line if we switched our latent to using tf.Independent(tfd.Normal) # prior = tfd.Independent(tfd.Normal(loc=tf.zeros(ndim), scale=1), reinterpreted_batch_ndims=1) return prior","title":"make_mvn_prior()"},{"location":"API/dists/#indl.dists.make_variational","text":"Take an input tensor and return a multivariate normal distribution parameterized by that input tensor. Parameters: Name Type Description Default x Tensor input tensor required dist_dim int the dimensionality of the distribution required init_std float initial stddev SHIFT of the distribution when input is 0. 1.0 offdiag bool whether or not to include covariances False samps int the number of samples to draw when using implied convert_to_tensor_fn 1 loc_name not used (I need to handle naming better) 'loc' scale_name not used 'scale' dist_name not used 'q' use_mvn_diag bool whether to use tfd.MultivariateNormal(Diag|TriL) (True) or tfd.Independent(tfd.Normal) (False) Latter is untested. Note that the mvn dists will put the timesteps dimension (if present in the input) into the \"batch dimension\" while the \"event\" dimension will be the last dimension only. You can use tfd.Independent(q_dist, reinterpreted_batch_ndims=1) to move the timestep dimension to the event dimension if necessary. (tfd.Independent doesn't play well with tf.keras.Model inputs/outputs). True Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL, tensorflow_probability.python.distributions.independent.Independent] A tfd.Distribution. The distribution is of type MultivariateNormalDiag (or MultivariateNormalTriL if offdiag) if use_mvn_diag is set. Source code in indl/dists/__init__.py def make_variational ( x : tf . Tensor , dist_dim : int , init_std : float = 1.0 , offdiag : bool = False , samps : int = 1 , loc_name = \"loc\" , scale_name = \"scale\" , dist_name = \"q\" , use_mvn_diag : bool = True ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL , tfd . Independent ]: \"\"\" Take an input tensor and return a multivariate normal distribution parameterized by that input tensor. Args: x: input tensor dist_dim: the dimensionality of the distribution init_std: initial stddev SHIFT of the distribution when input is 0. offdiag: whether or not to include covariances samps: the number of samples to draw when using implied convert_to_tensor_fn loc_name: not used (I need to handle naming better) scale_name: not used dist_name: not used use_mvn_diag: whether to use tfd.MultivariateNormal(Diag|TriL) (True) or tfd.Independent(tfd.Normal) (False) Latter is untested. Note that the mvn dists will put the timesteps dimension (if present in the input) into the \"batch dimension\" while the \"event\" dimension will be the last dimension only. You can use tfd.Independent(q_dist, reinterpreted_batch_ndims=1) to move the timestep dimension to the event dimension if necessary. (tfd.Independent doesn't play well with tf.keras.Model inputs/outputs). Returns: A tfd.Distribution. The distribution is of type MultivariateNormalDiag (or MultivariateNormalTriL if offdiag) if use_mvn_diag is set. \"\"\" make_dist_fn , dist_params = make_mvn_dist_fn ( x , dist_dim , shift_std = init_std , offdiag = offdiag , # loc_name=loc_name, scale_name=scale_name, use_mvn_diag = use_mvn_diag ) # Python `callable` that takes a `tfd.Distribution` # instance and returns a `tf.Tensor`-like object. \"\"\" # Unfortunately I couldn't get this to work :( # Will have to explicitly q_f.value() | qf.mean() from dist in train_step def custom_convert_fn(d, training=None): if training is None: training = K.learning_phase() output = tf_utils.smart_cond(training, lambda: d.sample(samps), lambda: d.mean() ) return output def convert_fn(d): return K.in_train_phase(tfd.Distribution.sample if samps <= 1 else lambda: d.sample(samps), lambda: d.mean()) \"\"\" convert_fn = tfd . Distribution . sample if samps <= 1 else lambda d : d . sample ( samps ) q_dist = tfpl . DistributionLambda ( make_distribution_fn = make_dist_fn , convert_to_tensor_fn = convert_fn , )( dist_params ) # if tf.shape(x).shape[0] > 2: # q_dist = tfd.Independent(q_dist, reinterpreted_batch_ndims=1) return q_dist","title":"make_variational()"},{"location":"API/dists/#indl.dists.sequential","text":"","title":"sequential"},{"location":"API/dists/#indl.dists.sequential.AR1ProcessMVNGenerator","text":"Similar to LFADS' LearnableAutoRegressive1Prior. Here we use the terminology from: https://en.wikipedia.org/wiki/Autoregressive_model#Example:_An_AR(1)_process The autoregressive function takes the form: E(X_t) = E(c) + phi * E(X_{t-1}) + e_t E(c) is a constant. phi is a parameter, which is equivalent to exp(-1/tau) = exp(-exp(-logtau)). where tau is a time constant. e_t is white noise with zero-mean with evar = sigma_e**2 When there's no previous sample, E(X_t) = E(c) + e_t, which is a draw from N(c, sigma_e 2) When there is a previous sample, E(X_t) = E(c) + phi * E(X_{t-1}) + e_t, which means a draw from N(c + phi * X_{t-1}, sigma_p 2) where sigma_p 2 = phi 2 * var(X_{t-1}) + sigma_e 2 = sigma_e 2 / (1 - phi**2) or logpvar = logevar - (log(1 - phi) + log(1 + phi)) Note that this could be roughly equivalent to tfd.Autoregressive if it was passed a distribution_fn with the same transition. See issue: https://github.com/snel-repo/lfads-cd/issues/1 Source code in indl/dists/sequential.py class AR1ProcessMVNGenerator ( IProcessMVNGenerator ): \"\"\" Similar to LFADS' LearnableAutoRegressive1Prior. Here we use the terminology from: https://en.wikipedia.org/wiki/Autoregressive_model#Example:_An_AR(1)_process The autoregressive function takes the form: E(X_t) = E(c) + phi * E(X_{t-1}) + e_t E(c) is a constant. phi is a parameter, which is equivalent to exp(-1/tau) = exp(-exp(-logtau)). where tau is a time constant. e_t is white noise with zero-mean with evar = sigma_e**2 When there's no previous sample, E(X_t) = E(c) + e_t, which is a draw from N(c, sigma_e**2) When there is a previous sample, E(X_t) = E(c) + phi * E(X_{t-1}) + e_t, which means a draw from N(c + phi * X_{t-1}, sigma_p**2) where sigma_p**2 = phi**2 * var(X_{t-1}) + sigma_e**2 = sigma_e**2 / (1 - phi**2) or logpvar = logevar - (log(1 - phi) + log(1 + phi)) Note that this could be roughly equivalent to tfd.Autoregressive if it was passed a `distribution_fn` with the same transition. See issue: https://github.com/snel-repo/lfads-cd/issues/1 \"\"\" def __init__ ( self , init_taus : Union [ float , List [ float ]], init_std : Union [ float , List [ float ]] = 0.1 , trainable_mean : bool = False , trainable_tau : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: init_taus: Initial values of tau init_std: Initial value of sigma_e trainable_mean: set True if the mean (e_c) is trainable. trainable_tau: set True to trainable_nvar: \"\"\" self . _offdiag = offdiag if isinstance ( init_taus , float ): init_taus = [ init_taus ] # TODO: Add time axis for easier broadcasting ndim = len ( init_taus ) self . _e_c , self . _e_scale = make_learnable_mvn_params ( ndim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) self . _logtau = tf . Variable ( tf . math . log ( init_taus ), dtype = tf . float32 , trainable = trainable_tau ) self . _phi = tf . exp ( - tf . exp ( - self . _logtau )) self . _p_scale = tf . exp ( tf . math . log ( self . _e_scale ) - ( tf . math . log ( 1 - self . _phi ) + tf . math . log ( 1 + self . _phi ))) def get_dist ( self , timesteps , samples = 1 , batch_size = 1 , fixed = False ): locs = [] scales = [] sample_list = [] # Add a time dimension e_c = tf . expand_dims ( self . _e_c , 0 ) e_scale = tf . expand_dims ( self . _e_scale , 0 ) p_scale = tf . expand_dims ( self . _p_scale , 0 ) sample = tf . expand_dims ( tf . expand_dims ( tf . zeros_like ( e_c ), 0 ), 0 ) sample = tf . tile ( sample , [ samples , batch_size , 1 , 1 ]) for _ in range ( timesteps ): loc = e_c + self . _phi * sample scale = p_scale if _ > 0 else e_scale locs . append ( loc ) scales . append ( scale ) if self . _offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) sample = dist . sample () sample_list . append ( sample ) sample = tf . concat ( sample_list , axis = 2 ) loc = tf . concat ( locs , axis = 2 ) scale = tf . concat ( scales , axis =- 2 ) if self . _offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return sample , dist","title":"AR1ProcessMVNGenerator"},{"location":"API/dists/#indl.dists.sequential.AR1ProcessMVNGenerator.__init__","text":"Parameters: Name Type Description Default init_taus Union[float, List[float]] Initial values of tau required init_std Union[float, List[float]] Initial value of sigma_e 0.1 trainable_mean bool set True if the mean (e_c) is trainable. False trainable_tau bool set True to True trainable_nvar required Source code in indl/dists/sequential.py def __init__ ( self , init_taus : Union [ float , List [ float ]], init_std : Union [ float , List [ float ]] = 0.1 , trainable_mean : bool = False , trainable_tau : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: init_taus: Initial values of tau init_std: Initial value of sigma_e trainable_mean: set True if the mean (e_c) is trainable. trainable_tau: set True to trainable_nvar: \"\"\" self . _offdiag = offdiag if isinstance ( init_taus , float ): init_taus = [ init_taus ] # TODO: Add time axis for easier broadcasting ndim = len ( init_taus ) self . _e_c , self . _e_scale = make_learnable_mvn_params ( ndim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) self . _logtau = tf . Variable ( tf . math . log ( init_taus ), dtype = tf . float32 , trainable = trainable_tau ) self . _phi = tf . exp ( - tf . exp ( - self . _logtau )) self . _p_scale = tf . exp ( tf . math . log ( self . _e_scale ) - ( tf . math . log ( 1 - self . _phi ) + tf . math . log ( 1 + self . _phi )))","title":"__init__()"},{"location":"API/dists/#indl.dists.sequential.RNNMVNGenerator","text":"Similar to DSAE's LearnableMultivariateNormalDiagCell Source code in indl/dists/sequential.py class RNNMVNGenerator ( IProcessMVNGenerator ): \"\"\" Similar to DSAE's LearnableMultivariateNormalDiagCell \"\"\" def __init__ ( self , units : int , out_dim : int , cell_type : str , shift_std : float = 0.1 , offdiag : bool = False ): \"\"\" Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" self . cell = LearnableMultivariateNormalCell ( units , out_dim , cell_type = cell_type , shift_std = shift_std , offdiag = offdiag ) def get_dist ( self , timesteps , samples = 1 , batch_size = 1 , fixed = True ): \"\"\" Samples from self.cell `timesteps` times. On each step, the previous (sample, state) is fed back into the cell (zero_state used for 0th step). The cell returns a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Args: timesteps: Number of times to sample from the dynamic_prior_cell. Output will have samples: Number of samples to draw from the latent distribution. batch_size: Number of sequences to sample. fixed: Boolean for whether or not to share the same random sample across all sequences in batch. https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887 Returns: \"\"\" if fixed : sample_batch_size = 1 else : sample_batch_size = batch_size sample , state = self . cell . zero_state ([ samples , sample_batch_size ]) locs = [] scales = [] sample_list = [] scale_parm_name = \"scale_tril\" if self . cell . offdiag else \"scale_diag\" # TODO: Check this for offdiag for _ in range ( timesteps ): dist , state = self . cell ( sample , state ) sample = dist . sample () locs . append ( dist . parameters [ \"loc\" ]) scales . append ( dist . parameters [ scale_parm_name ]) sample_list . append ( sample ) sample = tf . stack ( sample_list , axis = 2 ) loc = tf . stack ( locs , axis = 2 ) scale = tf . stack ( scales , axis = 2 ) if fixed : # tile along the batch axis sample = sample + tf . zeros ([ batch_size , 1 , 1 ]) if self . cell . offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return sample , dist","title":"RNNMVNGenerator"},{"location":"API/dists/#indl.dists.sequential.RNNMVNGenerator.__init__","text":"Parameters: Name Type Description Default units int Dimensionality of the RNN function parameters. required out_dim int The dimensionality of the distribution. required cell_type str an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. required shift_std float Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. 0.1 offdiag bool set True to allow non-zero covariance (within-timestep) in the returned distribution. False Source code in indl/dists/sequential.py def __init__ ( self , units : int , out_dim : int , cell_type : str , shift_std : float = 0.1 , offdiag : bool = False ): \"\"\" Args: units: Dimensionality of the RNN function parameters. out_dim: The dimensionality of the distribution. cell_type: an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive. shift_std: Shift applied to MVN std before building the dist. Providing a shift toward the expected std allows the input values to be closer to 0. offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution. \"\"\" self . cell = LearnableMultivariateNormalCell ( units , out_dim , cell_type = cell_type , shift_std = shift_std , offdiag = offdiag )","title":"__init__()"},{"location":"API/dists/#indl.dists.sequential.RNNMVNGenerator.get_dist","text":"Samples from self.cell `timesteps` times. On each step, the previous (sample, state) is fed back into the cell (zero_state used for 0th step). The cell returns a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. !!! args timesteps: Number of times to sample from the dynamic_prior_cell. Output will have samples: Number of samples to draw from the latent distribution. batch_size: Number of sequences to sample. !!! fixed \"Boolean for whether or not to share the same random\" sample across all sequences in batch. https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887 Returns: Source code in indl/dists/sequential.py def get_dist ( self , timesteps , samples = 1 , batch_size = 1 , fixed = True ): \"\"\" Samples from self.cell `timesteps` times. On each step, the previous (sample, state) is fed back into the cell (zero_state used for 0th step). The cell returns a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Args: timesteps: Number of times to sample from the dynamic_prior_cell. Output will have samples: Number of samples to draw from the latent distribution. batch_size: Number of sequences to sample. fixed: Boolean for whether or not to share the same random sample across all sequences in batch. https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887 Returns: \"\"\" if fixed : sample_batch_size = 1 else : sample_batch_size = batch_size sample , state = self . cell . zero_state ([ samples , sample_batch_size ]) locs = [] scales = [] sample_list = [] scale_parm_name = \"scale_tril\" if self . cell . offdiag else \"scale_diag\" # TODO: Check this for offdiag for _ in range ( timesteps ): dist , state = self . cell ( sample , state ) sample = dist . sample () locs . append ( dist . parameters [ \"loc\" ]) scales . append ( dist . parameters [ scale_parm_name ]) sample_list . append ( sample ) sample = tf . stack ( sample_list , axis = 2 ) loc = tf . stack ( locs , axis = 2 ) scale = tf . stack ( scales , axis = 2 ) if fixed : # tile along the batch axis sample = sample + tf . zeros ([ batch_size , 1 , 1 ]) if self . cell . offdiag : dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return sample , dist","title":"get_dist()"},{"location":"API/dists/#indl.dists.sequential.RNNMultivariateNormalDiag","text":"Source code in indl/dists/sequential.py class RNNMultivariateNormalDiag ( tfd . MultivariateNormalDiag ): def __init__ ( self , cell , n_timesteps = 1 , output_dim = None , name = \"rnn_mvn_diag\" , ** kwargs ): self . cell = cell if output_dim is not None and hasattr ( self . cell , 'output_dim' ): self . cell . output_dim = output_dim if hasattr ( self . cell , 'output_dim' ): output_dim = self . cell . output_dim else : output_dim = output_dim or self . cell . units h0 = tf . zeros ([ 1 , self . cell . units ]) c0 = tf . zeros ([ 1 , self . cell . units ]) input0 = tf . zeros (( 1 , output_dim )) if hasattr ( cell , 'reset_dropout_mask' ): self . cell . reset_dropout_mask () self . cell . reset_recurrent_dropout_mask () input_ = input0 states_ = ( h0 , c0 ) successive_outputs = [] for i in range ( n_timesteps ): input_ , states_ = self . cell ( input_ , states_ ) successive_outputs . append ( input_ ) loc = tf . concat ([ _ . parameters [ \"distribution\" ] . parameters [ \"loc\" ] for _ in successive_outputs ], axis = 0 ) scale_diag = tf . concat ([ _ . parameters [ \"distribution\" ] . parameters [ \"scale_diag\" ] for _ in successive_outputs ], axis = 0 ) super ( RNNMultivariateNormalDiag , self ) . __init__ ( loc = loc , scale_diag = scale_diag , name = name , ** kwargs )","title":"RNNMultivariateNormalDiag"},{"location":"API/dists/#indl.dists.sequential.RNNMultivariateNormalDiag.cross_entropy","text":"Computes the (Shannon) cross entropy. Denote this distribution ( self ) by P and the other distribution by Q . Assuming P, Q are absolutely continuous with respect to one another and permit densities p(x) dr(x) and q(x) dr(x) , (Shannon) cross entropy is defined as: H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x) where F denotes the support of the random variable X ~ P . Parameters: Name Type Description Default other tfp.distributions.Distribution instance. required name Python str prepended to names of ops created by this function. 'cross_entropy' Returns: Type Description cross_entropy self.dtype Tensor with shape [B1, ..., Bn] representing n different calculations of (Shannon) cross entropy. Source code in indl/dists/sequential.py def cross_entropy ( self , other , name = 'cross_entropy' ): \"\"\"Computes the (Shannon) cross entropy. Denote this distribution (`self`) by `P` and the `other` distribution by `Q`. Assuming `P, Q` are absolutely continuous with respect to one another and permit densities `p(x) dr(x)` and `q(x) dr(x)`, (Shannon) cross entropy is defined as: ```none H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x) ``` where `F` denotes the support of the random variable `X ~ P`. Args: other: `tfp.distributions.Distribution` instance. name: Python `str` prepended to names of ops created by this function. Returns: cross_entropy: `self.dtype` `Tensor` with shape `[B1, ..., Bn]` representing `n` different calculations of (Shannon) cross entropy. \"\"\" with self . _name_and_control_scope ( name ): return self . _cross_entropy ( other )","title":"cross_entropy()"},{"location":"API/dists/#indl.dists.sequential.RNNMultivariateNormalDiag.kl_divergence","text":"Computes the Kullback--Leibler divergence. Denote this distribution ( self ) by p and the other distribution by q . Assuming p, q are absolutely continuous with respect to reference measure r , the KL divergence is defined as: KL[p, q] = E_p[log(p(X)/q(X))] = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x) = H[p, q] - H[p] where F denotes the support of the random variable X ~ p , H[., .] denotes (Shannon) cross entropy, and H[.] denotes (Shannon) entropy. Parameters: Name Type Description Default other tfp.distributions.Distribution instance. required name Python str prepended to names of ops created by this function. 'kl_divergence' Returns: Type Description kl_divergence self.dtype Tensor with shape [B1, ..., Bn] representing n different calculations of the Kullback-Leibler divergence. Source code in indl/dists/sequential.py def kl_divergence ( self , other , name = 'kl_divergence' ): \"\"\"Computes the Kullback--Leibler divergence. Denote this distribution (`self`) by `p` and the `other` distribution by `q`. Assuming `p, q` are absolutely continuous with respect to reference measure `r`, the KL divergence is defined as: ```none KL[p, q] = E_p[log(p(X)/q(X))] = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x) = H[p, q] - H[p] ``` where `F` denotes the support of the random variable `X ~ p`, `H[., .]` denotes (Shannon) cross entropy, and `H[.]` denotes (Shannon) entropy. Args: other: `tfp.distributions.Distribution` instance. name: Python `str` prepended to names of ops created by this function. Returns: kl_divergence: `self.dtype` `Tensor` with shape `[B1, ..., Bn]` representing `n` different calculations of the Kullback-Leibler divergence. \"\"\" # NOTE: We do not enter a `self._name_and_control_scope` here. We rely on # `tfd.kl_divergence(self, other)` to use `_name_and_control_scope` to apply # assertions on both Distributions. # # Subclasses that override `Distribution.kl_divergence` or `_kl_divergence` # must ensure that assertions are applied for both `self` and `other`. return self . _kl_divergence ( other )","title":"kl_divergence()"},{"location":"API/dists/#indl.dists.sequential.TiledMVNGenerator","text":"Similar to LFADS' LearnableDiagonalGaussian. Uses a single learnable loc and scale which are tiled across timesteps. Source code in indl/dists/sequential.py class TiledMVNGenerator ( IProcessMVNGenerator ): \"\"\" Similar to LFADS' LearnableDiagonalGaussian. Uses a single learnable loc and scale which are tiled across timesteps. \"\"\" def __init__ ( self , latent_dim : int , init_std : float = 0.1 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: latent_dim: Number of dimensions in a single timestep (params['f_latent_size']) init_std: Initial value of standard deviation (params['q_z_init_std']) trainable_mean: True if mean should be trainable (params['z_prior_train_mean']) trainable_var: True if variance should be trainable (params['z_prior_train_var']) offdiag: True if off-diagonal elements (non-orthogonality) allowed. (params['z_prior_off_diag']) \"\"\" self . _offdiag = offdiag self . _loc , self . _scale = make_learnable_mvn_params ( latent_dim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag ) def get_dist ( self , timesteps , samples = 1 , batch_size = 1 ): \"\"\" Tiles the saved loc and scale to the same shape as `posterior` then uses them to create a MVN dist with appropriate shape. Each timestep has the same loc and scale but if it were sampled then each timestep would return different values. Args: timesteps: samples: batch_size: Returns: MVNDiag distribution of the same shape as `posterior` \"\"\" loc = tf . tile ( tf . expand_dims ( self . _loc , 0 ), [ timesteps , 1 ]) scale = tf . expand_dims ( self . _scale , 0 ) if self . _offdiag : scale = tf . tile ( scale , [ timesteps , 1 , 1 ]) dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : scale = tf . tile ( scale , [ timesteps , 1 ]) dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return dist . sample ([ samples , batch_size ]), dist","title":"TiledMVNGenerator"},{"location":"API/dists/#indl.dists.sequential.TiledMVNGenerator.__init__","text":"Parameters: Name Type Description Default latent_dim int Number of dimensions in a single timestep (params['f_latent_size']) required init_std float Initial value of standard deviation (params['q_z_init_std']) 0.1 trainable_mean bool True if mean should be trainable (params['z_prior_train_mean']) True trainable_var bool True if variance should be trainable (params['z_prior_train_var']) True offdiag bool True if off-diagonal elements (non-orthogonality) allowed. (params['z_prior_off_diag']) False Source code in indl/dists/sequential.py def __init__ ( self , latent_dim : int , init_std : float = 0.1 , trainable_mean : bool = True , trainable_var : bool = True , offdiag : bool = False ): \"\"\" Args: latent_dim: Number of dimensions in a single timestep (params['f_latent_size']) init_std: Initial value of standard deviation (params['q_z_init_std']) trainable_mean: True if mean should be trainable (params['z_prior_train_mean']) trainable_var: True if variance should be trainable (params['z_prior_train_var']) offdiag: True if off-diagonal elements (non-orthogonality) allowed. (params['z_prior_off_diag']) \"\"\" self . _offdiag = offdiag self . _loc , self . _scale = make_learnable_mvn_params ( latent_dim , init_std = init_std , trainable_mean = trainable_mean , trainable_var = trainable_var , offdiag = offdiag )","title":"__init__()"},{"location":"API/dists/#indl.dists.sequential.TiledMVNGenerator.get_dist","text":"Tiles the saved loc and scale to the same shape as posterior then uses them to create a MVN dist with appropriate shape. Each timestep has the same loc and scale but if it were sampled then each timestep would return different values. Parameters: Name Type Description Default timesteps required samples 1 batch_size 1 Returns: Type Description MVNDiag distribution of the same shape as posterior Source code in indl/dists/sequential.py def get_dist ( self , timesteps , samples = 1 , batch_size = 1 ): \"\"\" Tiles the saved loc and scale to the same shape as `posterior` then uses them to create a MVN dist with appropriate shape. Each timestep has the same loc and scale but if it were sampled then each timestep would return different values. Args: timesteps: samples: batch_size: Returns: MVNDiag distribution of the same shape as `posterior` \"\"\" loc = tf . tile ( tf . expand_dims ( self . _loc , 0 ), [ timesteps , 1 ]) scale = tf . expand_dims ( self . _scale , 0 ) if self . _offdiag : scale = tf . tile ( scale , [ timesteps , 1 , 1 ]) dist = tfd . MultivariateNormalTriL ( loc = loc , scale_tril = scale ) else : scale = tf . tile ( scale , [ timesteps , 1 ]) dist = tfd . MultivariateNormalDiag ( loc = loc , scale_diag = scale ) dist = tfd . Independent ( dist , reinterpreted_batch_ndims = 1 ) return dist . sample ([ samples , batch_size ]), dist","title":"get_dist()"},{"location":"API/dists/#indl.dists.sequential.VariationalLSTMCell","text":"Source code in indl/dists/sequential.py class VariationalLSTMCell ( tfkl . LSTMCell ): def __init__ ( self , units , make_dist_fn = None , make_dist_model = None , ** kwargs ): super ( VariationalLSTMCell , self ) . __init__ ( units , ** kwargs ) self . make_dist_fn = make_dist_fn self . make_dist_model = make_dist_model # For some reason the below code doesn't work during build. # So I don't know how to use the outer VariationalRNN to set this cell's output_size if self . make_dist_fn is None : self . make_dist_fn = lambda t : tfd . MultivariateNormalDiag ( loc = t [ 0 ], scale_diag = t [ 1 ]) if self . make_dist_model is None : fake_cell_output = tfkl . Input (( self . units ,)) loc = tfkl . Dense ( self . output_size , name = \"VarLSTMCell_loc\" )( fake_cell_output ) scale = tfkl . Dense ( self . output_size , name = \"VarLSTMCell_scale\" )( fake_cell_output ) scale = tf . nn . softplus ( scale + scale_shift ) + 1e-5 dist_layer = tfpl . DistributionLambda ( make_distribution_fn = self . make_dist_fn , # TODO: convert_to_tensor_fn=lambda s: s.sample(N_SAMPLES) )([ loc , scale ]) self . make_dist_model = tf . keras . Model ( fake_cell_output , dist_layer ) def build ( self , input_shape ): super ( VariationalLSTMCell , self ) . build ( input_shape ) # It would be good to defer making self.make_dist_model until here, # but it doesn't work for some reason. # def input_zero(self, inputs_): # input0 = inputs_[..., -1, :] # input0 = tf.matmul(input0, tf.zeros((input0.shape[-1], self.units))) # dist0 = self.make_dist_model(input0) # return dist0 def call ( self , inputs , states , training = None ): inputs = tf . convert_to_tensor ( inputs ) output , state = super ( VariationalLSTMCell , self ) . call ( inputs , states , training = training ) dist = self . make_dist_model ( output ) return dist , state","title":"VariationalLSTMCell"},{"location":"API/dists/#indl.dists.sequential.VariationalLSTMCell.build","text":"Creates the variables of the layer (optional, for subclass implementers). This is a method that implementers of subclasses of Layer or Model can override if they need a state-creation step in-between layer instantiation and layer call. This is typically used to create the weights of Layer subclasses. Parameters: Name Type Description Default input_shape Instance of TensorShape , or list of instances of TensorShape if the layer expects a list of inputs (one instance per input). required Source code in indl/dists/sequential.py def build ( self , input_shape ): super ( VariationalLSTMCell , self ) . build ( input_shape ) # It would be good to defer making self.make_dist_model until here, # but it doesn't work for some reason.","title":"build()"},{"location":"API/dists/#indl.dists.sequential.VariationalLSTMCell.call","text":"This is where the layer's logic lives. Note here that call() method in tf.keras is little bit different from keras API. In keras API, you can pass support masking for layers as additional arguments. Whereas tf.keras has compute_mask() method to support masking. Parameters: Name Type Description Default inputs Input tensor, or list/tuple of input tensors. required **kwargs Additional keyword arguments. Currently unused. required Returns: Type Description A tensor or list/tuple of tensors. Source code in indl/dists/sequential.py def call ( self , inputs , states , training = None ): inputs = tf . convert_to_tensor ( inputs ) output , state = super ( VariationalLSTMCell , self ) . call ( inputs , states , training = training ) dist = self . make_dist_model ( output ) return dist , state","title":"call()"},{"location":"API/layers/","text":"layers CoordinatedDropout ( Dropout ) Applies Dropout to the input. Its call returns a tuple of the dropped inputs and the mask indicating dropped features. Source code in indl/layers/__init__.py class CoordinatedDropout ( tfkl . Dropout ): \"\"\" Applies Dropout to the input. Its call returns a tuple of the dropped inputs and the mask indicating dropped features. \"\"\" def compute_output_shape ( self , input_shape ): return input_shape , input_shape def call ( self , inputs , training = None ): if training is None : training = K . learning_phase () def dropped_inputs (): rate = self . rate noise_shape = self . noise_shape seed = self . seed with ops . name_scope ( None , \"coordinated_dropout\" , [ inputs ]) as name : is_rate_number = isinstance ( rate , numbers . Real ) if is_rate_number and ( rate < 0 or rate >= 1 ): raise ValueError ( \"rate must be a scalar tensor or a float in the \" \"range [0, 1), got %g \" % rate ) x = ops . convert_to_tensor ( inputs , name = \"x\" ) x_dtype = x . dtype if not x_dtype . is_floating : raise ValueError ( \"x has to be a floating point tensor since it's going \" \"to be scaled. Got a %s tensor instead.\" % x_dtype ) is_executing_eagerly = context . executing_eagerly () if not tensor_util . is_tensor ( rate ): if is_rate_number : keep_prob = 1 - rate scale = 1 / keep_prob scale = ops . convert_to_tensor ( scale , dtype = x_dtype ) ret = gen_math_ops . mul ( x , scale ) else : raise ValueError ( \"rate is neither scalar nor scalar tensor %r \" % rate ) else : rate . get_shape () . assert_has_rank ( 0 ) rate_dtype = rate . dtype if rate_dtype != x_dtype : if not rate_dtype . is_compatible_with ( x_dtype ): raise ValueError ( \"Tensor dtype %s is incomptaible with Tensor dtype %s : %r \" % ( x_dtype . name , rate_dtype . name , rate )) rate = gen_math_ops . cast ( rate , x_dtype , name = \"rate\" ) one_tensor = constant_op . constant ( 1 , dtype = x_dtype ) ret = gen_math_ops . real_div ( x , gen_math_ops . sub ( one_tensor , rate )) noise_shape = nn_ops . _get_noise_shape ( x , noise_shape ) # Sample a uniform distribution on [0.0, 1.0) and select values larger # than rate. # # NOTE: Random uniform can only generate 2^23 floats on [1.0, 2.0) # and subtract 1.0. random_tensor = random_ops . random_uniform ( noise_shape , seed = seed , dtype = x_dtype ) # NOTE: if (1.0 + rate) - 1 is equal to rate, then that float is selected, # hence a >= comparison is used. keep_mask = random_tensor >= rate ret = gen_math_ops . mul ( ret , gen_math_ops . cast ( keep_mask , x_dtype )) if not is_executing_eagerly : ret . set_shape ( x . get_shape ()) return ret , keep_mask output = control_flow_util . smart_cond ( training , dropped_inputs , lambda : ( array_ops . identity ( inputs ), array_ops . ones_like ( inputs ) > 0 )) return output call ( self , inputs , training = None ) This is where the layer's logic lives. Note here that call() method in tf.keras is little bit different from keras API. In keras API, you can pass support masking for layers as additional arguments. Whereas tf.keras has compute_mask() method to support masking. Parameters: Name Type Description Default inputs Input tensor, or list/tuple of input tensors. required **kwargs Additional keyword arguments. Currently unused. required Returns: Type Description A tensor or list/tuple of tensors. Source code in indl/layers/__init__.py def call ( self , inputs , training = None ): if training is None : training = K . learning_phase () def dropped_inputs (): rate = self . rate noise_shape = self . noise_shape seed = self . seed with ops . name_scope ( None , \"coordinated_dropout\" , [ inputs ]) as name : is_rate_number = isinstance ( rate , numbers . Real ) if is_rate_number and ( rate < 0 or rate >= 1 ): raise ValueError ( \"rate must be a scalar tensor or a float in the \" \"range [0, 1), got %g \" % rate ) x = ops . convert_to_tensor ( inputs , name = \"x\" ) x_dtype = x . dtype if not x_dtype . is_floating : raise ValueError ( \"x has to be a floating point tensor since it's going \" \"to be scaled. Got a %s tensor instead.\" % x_dtype ) is_executing_eagerly = context . executing_eagerly () if not tensor_util . is_tensor ( rate ): if is_rate_number : keep_prob = 1 - rate scale = 1 / keep_prob scale = ops . convert_to_tensor ( scale , dtype = x_dtype ) ret = gen_math_ops . mul ( x , scale ) else : raise ValueError ( \"rate is neither scalar nor scalar tensor %r \" % rate ) else : rate . get_shape () . assert_has_rank ( 0 ) rate_dtype = rate . dtype if rate_dtype != x_dtype : if not rate_dtype . is_compatible_with ( x_dtype ): raise ValueError ( \"Tensor dtype %s is incomptaible with Tensor dtype %s : %r \" % ( x_dtype . name , rate_dtype . name , rate )) rate = gen_math_ops . cast ( rate , x_dtype , name = \"rate\" ) one_tensor = constant_op . constant ( 1 , dtype = x_dtype ) ret = gen_math_ops . real_div ( x , gen_math_ops . sub ( one_tensor , rate )) noise_shape = nn_ops . _get_noise_shape ( x , noise_shape ) # Sample a uniform distribution on [0.0, 1.0) and select values larger # than rate. # # NOTE: Random uniform can only generate 2^23 floats on [1.0, 2.0) # and subtract 1.0. random_tensor = random_ops . random_uniform ( noise_shape , seed = seed , dtype = x_dtype ) # NOTE: if (1.0 + rate) - 1 is equal to rate, then that float is selected, # hence a >= comparison is used. keep_mask = random_tensor >= rate ret = gen_math_ops . mul ( ret , gen_math_ops . cast ( keep_mask , x_dtype )) if not is_executing_eagerly : ret . set_shape ( x . get_shape ()) return ret , keep_mask output = control_flow_util . smart_cond ( training , dropped_inputs , lambda : ( array_ops . identity ( inputs ), array_ops . ones_like ( inputs ) > 0 )) return output compute_output_shape ( self , input_shape ) Computes the output shape of the layer. If the layer has not been built, this method will call build on the layer. This assumes that the layer will later be used with inputs that match the input shape provided here. Parameters: Name Type Description Default input_shape Shape tuple (tuple of integers) or list of shape tuples (one per output tensor of the layer). Shape tuples can include None for free dimensions, instead of an integer. required Returns: Type Description An input shape tuple. Source code in indl/layers/__init__.py def compute_output_shape ( self , input_shape ): return input_shape , input_shape","title":"layers"},{"location":"API/layers/#layers","text":"","title":"layers"},{"location":"API/layers/#indl.layers.CoordinatedDropout","text":"Applies Dropout to the input. Its call returns a tuple of the dropped inputs and the mask indicating dropped features. Source code in indl/layers/__init__.py class CoordinatedDropout ( tfkl . Dropout ): \"\"\" Applies Dropout to the input. Its call returns a tuple of the dropped inputs and the mask indicating dropped features. \"\"\" def compute_output_shape ( self , input_shape ): return input_shape , input_shape def call ( self , inputs , training = None ): if training is None : training = K . learning_phase () def dropped_inputs (): rate = self . rate noise_shape = self . noise_shape seed = self . seed with ops . name_scope ( None , \"coordinated_dropout\" , [ inputs ]) as name : is_rate_number = isinstance ( rate , numbers . Real ) if is_rate_number and ( rate < 0 or rate >= 1 ): raise ValueError ( \"rate must be a scalar tensor or a float in the \" \"range [0, 1), got %g \" % rate ) x = ops . convert_to_tensor ( inputs , name = \"x\" ) x_dtype = x . dtype if not x_dtype . is_floating : raise ValueError ( \"x has to be a floating point tensor since it's going \" \"to be scaled. Got a %s tensor instead.\" % x_dtype ) is_executing_eagerly = context . executing_eagerly () if not tensor_util . is_tensor ( rate ): if is_rate_number : keep_prob = 1 - rate scale = 1 / keep_prob scale = ops . convert_to_tensor ( scale , dtype = x_dtype ) ret = gen_math_ops . mul ( x , scale ) else : raise ValueError ( \"rate is neither scalar nor scalar tensor %r \" % rate ) else : rate . get_shape () . assert_has_rank ( 0 ) rate_dtype = rate . dtype if rate_dtype != x_dtype : if not rate_dtype . is_compatible_with ( x_dtype ): raise ValueError ( \"Tensor dtype %s is incomptaible with Tensor dtype %s : %r \" % ( x_dtype . name , rate_dtype . name , rate )) rate = gen_math_ops . cast ( rate , x_dtype , name = \"rate\" ) one_tensor = constant_op . constant ( 1 , dtype = x_dtype ) ret = gen_math_ops . real_div ( x , gen_math_ops . sub ( one_tensor , rate )) noise_shape = nn_ops . _get_noise_shape ( x , noise_shape ) # Sample a uniform distribution on [0.0, 1.0) and select values larger # than rate. # # NOTE: Random uniform can only generate 2^23 floats on [1.0, 2.0) # and subtract 1.0. random_tensor = random_ops . random_uniform ( noise_shape , seed = seed , dtype = x_dtype ) # NOTE: if (1.0 + rate) - 1 is equal to rate, then that float is selected, # hence a >= comparison is used. keep_mask = random_tensor >= rate ret = gen_math_ops . mul ( ret , gen_math_ops . cast ( keep_mask , x_dtype )) if not is_executing_eagerly : ret . set_shape ( x . get_shape ()) return ret , keep_mask output = control_flow_util . smart_cond ( training , dropped_inputs , lambda : ( array_ops . identity ( inputs ), array_ops . ones_like ( inputs ) > 0 )) return output","title":"CoordinatedDropout"},{"location":"API/layers/#indl.layers.CoordinatedDropout.call","text":"This is where the layer's logic lives. Note here that call() method in tf.keras is little bit different from keras API. In keras API, you can pass support masking for layers as additional arguments. Whereas tf.keras has compute_mask() method to support masking. Parameters: Name Type Description Default inputs Input tensor, or list/tuple of input tensors. required **kwargs Additional keyword arguments. Currently unused. required Returns: Type Description A tensor or list/tuple of tensors. Source code in indl/layers/__init__.py def call ( self , inputs , training = None ): if training is None : training = K . learning_phase () def dropped_inputs (): rate = self . rate noise_shape = self . noise_shape seed = self . seed with ops . name_scope ( None , \"coordinated_dropout\" , [ inputs ]) as name : is_rate_number = isinstance ( rate , numbers . Real ) if is_rate_number and ( rate < 0 or rate >= 1 ): raise ValueError ( \"rate must be a scalar tensor or a float in the \" \"range [0, 1), got %g \" % rate ) x = ops . convert_to_tensor ( inputs , name = \"x\" ) x_dtype = x . dtype if not x_dtype . is_floating : raise ValueError ( \"x has to be a floating point tensor since it's going \" \"to be scaled. Got a %s tensor instead.\" % x_dtype ) is_executing_eagerly = context . executing_eagerly () if not tensor_util . is_tensor ( rate ): if is_rate_number : keep_prob = 1 - rate scale = 1 / keep_prob scale = ops . convert_to_tensor ( scale , dtype = x_dtype ) ret = gen_math_ops . mul ( x , scale ) else : raise ValueError ( \"rate is neither scalar nor scalar tensor %r \" % rate ) else : rate . get_shape () . assert_has_rank ( 0 ) rate_dtype = rate . dtype if rate_dtype != x_dtype : if not rate_dtype . is_compatible_with ( x_dtype ): raise ValueError ( \"Tensor dtype %s is incomptaible with Tensor dtype %s : %r \" % ( x_dtype . name , rate_dtype . name , rate )) rate = gen_math_ops . cast ( rate , x_dtype , name = \"rate\" ) one_tensor = constant_op . constant ( 1 , dtype = x_dtype ) ret = gen_math_ops . real_div ( x , gen_math_ops . sub ( one_tensor , rate )) noise_shape = nn_ops . _get_noise_shape ( x , noise_shape ) # Sample a uniform distribution on [0.0, 1.0) and select values larger # than rate. # # NOTE: Random uniform can only generate 2^23 floats on [1.0, 2.0) # and subtract 1.0. random_tensor = random_ops . random_uniform ( noise_shape , seed = seed , dtype = x_dtype ) # NOTE: if (1.0 + rate) - 1 is equal to rate, then that float is selected, # hence a >= comparison is used. keep_mask = random_tensor >= rate ret = gen_math_ops . mul ( ret , gen_math_ops . cast ( keep_mask , x_dtype )) if not is_executing_eagerly : ret . set_shape ( x . get_shape ()) return ret , keep_mask output = control_flow_util . smart_cond ( training , dropped_inputs , lambda : ( array_ops . identity ( inputs ), array_ops . ones_like ( inputs ) > 0 )) return output","title":"call()"},{"location":"API/layers/#indl.layers.CoordinatedDropout.compute_output_shape","text":"Computes the output shape of the layer. If the layer has not been built, this method will call build on the layer. This assumes that the layer will later be used with inputs that match the input shape provided here. Parameters: Name Type Description Default input_shape Shape tuple (tuple of integers) or list of shape tuples (one per output tensor of the layer). Shape tuples can include None for free dimensions, instead of an integer. required Returns: Type Description An input shape tuple. Source code in indl/layers/__init__.py def compute_output_shape ( self , input_shape ): return input_shape , input_shape","title":"compute_output_shape()"},{"location":"API/misc/","text":"misc kernels Alpha ( x , sigma , reverse = False ) Parameters: Name Type Description Default x ndarray required sigma float required reverse bool Reverse the direction of the kernel. False Returns: Type Description ndarray (x >= 0) * 2. * (x / sigma ** 2) * np.exp(-x * np.sqrt(2.) / sigma) Source code in indl/misc/kernels.py def Alpha ( x : np . ndarray , sigma : float , reverse : bool = False ) -> np . ndarray : \"\"\" Args: x: sigma: reverse: Reverse the direction of the kernel. Returns: ```math (x >= 0) * 2. * (x / sigma ** 2) * np.exp(-x * np.sqrt(2.) / sigma) ``` \"\"\" if reverse : return ( x <= 0 ) * - 2. * ( x / sigma ** 2 ) * np . exp ( x * np . sqrt ( 2. ) / sigma ) else : return ( x >= 0 ) * 2. * ( x / sigma ** 2 ) * np . exp ( - x * np . sqrt ( 2. ) / sigma ) Boxcar ( x , sigma , reverse = None ) Parameters: Name Type Description Default x np.ndarray required sigma float required reverse Optional[bool] unused None Returns: Type Description ndarray (0.5 / (np.sqrt(3.0) * sigma)) * (np.abs(x) < (np.sqrt(3.0) * sigma)) Source code in indl/misc/kernels.py def Boxcar ( x : np . ndarray , sigma : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x (np.ndarray): sigma: reverse: unused Returns: ```math (0.5 / (np.sqrt(3.0) * sigma)) * (np.abs(x) < (np.sqrt(3.0) * sigma)) ``` \"\"\" return ( 0.5 / ( np . sqrt ( 3.0 ) * sigma )) * ( np . abs ( x ) < ( np . sqrt ( 3.0 ) * sigma )) Cauchy ( x , w , reverse = None ) Parameters: Name Type Description Default x np.ndarray required w float required reverse Optional[bool] unused None Returns: Type Description ndarray 1 / (np.pi * w * (1 + (x / w)**2)) Source code in indl/misc/kernels.py def Cauchy ( x : np . ndarray , w : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x (np.ndarray): w: reverse: unused Returns: ```math 1 / (np.pi * w * (1 + (x / w)**2)) ``` \"\"\" return 1 / ( np . pi * w * ( 1 + ( x / w ) ** 2 )) Exponential ( x , sigma , reverse = False ) Parameters: Name Type Description Default x ndarray required sigma float required reverse bool False Returns: Type Description ndarray (x >= 0) * (1. / sigma) * np.exp(-x / sigma) Source code in indl/misc/kernels.py def Exponential ( x : np . ndarray , sigma : float , reverse : bool = False ) -> np . ndarray : \"\"\" Args: x: sigma: reverse: Returns: ```math (x >= 0) * (1. / sigma) * np.exp(-x / sigma) ``` \"\"\" if reverse : return ( x <= 0 ) * ( 1. / sigma ) * np . exp ( x / sigma ) else : return ( x >= 0 ) * ( 1. / sigma ) * np . exp ( - x / sigma ) Gauss ( x , sigma , reverse = None ) Parameters: Name Type Description Default x ndarray required sigma float required reverse Optional[bool] unused None Returns: Type Description ndarray (1.0 / (np.sqrt(2.0 * np.pi) * sigma)) * np.exp(-0.5 * (x / sigma) ** 2) Source code in indl/misc/kernels.py def Gauss ( x : np . ndarray , sigma : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x: sigma: reverse: unused Returns: ```math (1.0 / (np.sqrt(2.0 * np.pi) * sigma)) * np.exp(-0.5 * (x / sigma) ** 2) ``` \"\"\" return ( 1.0 / ( np . sqrt ( 2.0 * np . pi ) * sigma )) * np . exp ( - 0.5 * ( x / sigma ) ** 2 ) Laplace ( x , w , reverse = None ) Parameters: Name Type Description Default x np.ndarray required w float required reverse Optional[bool] unused None Returns: Type Description ndarray 1 / 2**0.5 / w * np.exp(-(2**0.5) / w / np.abs(x)) Source code in indl/misc/kernels.py def Laplace ( x : np . ndarray , w : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x (np.ndarray): w: reverse: unused Returns: ```math 1 / 2**0.5 / w * np.exp(-(2**0.5) / w / np.abs(x)) ``` \"\"\" return 1 / 2 ** 0.5 / w * np . exp ( - ( 2 ** 0.5 ) / w / np . abs ( x )) fftkernel ( x , w ) Parameters: Name Type Description Default x ndarray required w float required Source code in indl/misc/kernels.py def fftkernel ( x : np . ndarray , w : float ) -> np . ndarray : \"\"\" Args: x: w: Returns: \"\"\" # forward padded transform L = x . size Lmax = L + 3 * w n = int ( 2 ** np . ceil ( np . log2 ( Lmax ))) X = np . fft . fft ( x , n ) # generate kernel domain f = np . linspace ( 0 , n - 1 , n ) / n f = np . concatenate (( - f [ 0 : np . int ( n / 2 + 1 )], f [ 1 : np . int ( n / 2 - 1 + 1 )][:: - 1 ])) # evaluate kernel K = np . exp ( - 0.5 * ( w * 2 * np . pi * f ) ** 2 ) # convolve and transform back from frequency domain y = np . real ( np . fft . ifft ( X * K , n )) y = y [ 0 : L ] return y fftkernelWin ( x , w , WinFunc ) Parameters: Name Type Description Default x ndarray data required w float kernel parameter required WinFunc str 'Boxcar', 'Laplace', 'Cauchy', 'Gauss' (default) required Source code in indl/misc/kernels.py def fftkernelWin ( x : np . ndarray , w : float , WinFunc : str ) -> np . ndarray : \"\"\" Args: x: data w: kernel parameter WinFunc: 'Boxcar', 'Laplace', 'Cauchy', 'Gauss' (default) Returns: \"\"\" # forward padded transform L = x . size Lmax = L + 3 * w n = 2 ** np . ceil ( np . log2 ( Lmax )) X = np . fft . fft ( x , n . astype ( np . int )) # generate kernel domain f = np . linspace ( 0 , n - 1 , n ) / n f = np . concatenate (( - f [ 0 : np . int ( n / 2 + 1 )], f [ 1 : np . int ( n / 2 - 1 + 1 )][:: - 1 ])) t = 2 * np . pi * f # determine window function - evaluate kernel if WinFunc == 'Boxcar' : a = 12 ** 0.5 * w K = 2 * np . sin ( a * t / 2 ) / ( a * t ) K [ 0 ] = 1 elif WinFunc == 'Laplace' : K = 1 / ( 1 + ( w * 2 * np . pi * f ) ** 2 / 2 ) elif WinFunc == 'Cauchy' : K = np . exp ( - w * np . abs ( 2 * np . pi * f )) else : # WinFunc == 'Gauss' K = np . exp ( - 0.5 * ( w * 2 * np . pi * f ) ** 2 ) # convolve and transform back from frequency domain y = np . real ( np . fft . ifft ( X * K , n )) y = y [ 0 : L ] return y ilogexp ( x ) Parameters: Name Type Description Default x ndarray required Source code in indl/misc/kernels.py def ilogexp ( x : np . ndarray ) -> np . ndarray : \"\"\" Args: x: Returns: \"\"\" # TODO: Check dtype and convert x scalars to numpy array y = np . zeros ( x . shape ) y [ x < 1e2 ] = np . log ( np . exp ( x [ x < 1e2 ]) - 1 ) y [ x >= 1e2 ] = x [ x >= 1e2 ] return y logexp ( x ) Parameters: Name Type Description Default x ndarray required Source code in indl/misc/kernels.py def logexp ( x : np . ndarray ) -> np . ndarray : \"\"\" Args: x: Returns: \"\"\" # TODO: Check dtype and convert x scalars to numpy array y = np . zeros ( x . shape ) y [ x < 1e2 ] = np . log ( 1 + np . exp ( x [ x < 1e2 ])) y [ x >= 1e2 ] = x [ x >= 1e2 ] return y sshist ( x , N = range ( 2 , 501 ), SN = 30 ) Returns the optimal number of bins in a histogram used for density estimation. Optimization principle is to minimize expected L2 loss function between the histogram and an unknown underlying density function. An assumption made is merely that samples are drawn from the density independently each other. The optimal binwidth D* is obtained as a minimizer of the formula, (2K-V) / D^2, where K and V are mean and variance of sample counts across bins with width D. Optimal number of bins is given as (max(x) - min(x)) / D. Parameters x : array_like One-dimensional data to fit histogram to. N : array_like, optional Array containing number of histogram bins to evaluate for fit. Default value = 500. SN : double, optional Scalar natural number defining number of bins for shift-averaging. Returns optN : int Optimal number of bins to represent the data in X N : double Maximum number of bins to be evaluated. Default value = 500. C : array_like Cost function C[i] of evaluating histogram fit with N[i] bins See Also sskernel, ssvkernel References .. [1] H. Shimazaki and S. Shinomoto, \"A method for selecting the bin size of a time histogram,\" in Neural Computation 19(6), 1503-1527, 2007 http://dx.doi.org/10.1162/neco.2007.19.6.1503 Source code in indl/misc/kernels.py def sshist ( x : np . ndarray , N = range ( 2 , 501 ), SN : int = 30 ) -> Tuple [ int , float , np . ndarray ]: \"\"\" Returns the optimal number of bins in a histogram used for density estimation. Optimization principle is to minimize expected L2 loss function between the histogram and an unknown underlying density function. An assumption made is merely that samples are drawn from the density independently each other. The optimal binwidth D* is obtained as a minimizer of the formula, (2K-V) / D^2, where K and V are mean and variance of sample counts across bins with width D. Optimal number of bins is given as (max(x) - min(x)) / D. Parameters ---------- x : array_like One-dimensional data to fit histogram to. N : array_like, optional Array containing number of histogram bins to evaluate for fit. Default value = 500. SN : double, optional Scalar natural number defining number of bins for shift-averaging. Returns ------- optN : int Optimal number of bins to represent the data in X N : double Maximum number of bins to be evaluated. Default value = 500. C : array_like Cost function C[i] of evaluating histogram fit with N[i] bins See Also -------- sskernel, ssvkernel References ---------- .. [1] H. Shimazaki and S. Shinomoto, \"A method for selecting the bin size of a time histogram,\" in Neural Computation 19(6), 1503-1527, 2007 http://dx.doi.org/10.1162/neco.2007.19.6.1503 \"\"\" # determine range of input 'x' x_min = np . min ( x ) x_max = np . max ( x ) # get smallest difference 'dx' between all pairwise samples buf = np . abs ( np . diff ( np . sort ( x ))) dx = min ( buf [ buf > 0 ]) # setup bins to evaluate N_MIN = 2 N_MAX = min ( np . floor (( x_max - x_min ) / ( 2 * dx )), max ( N )) N = range ( N_MIN , N_MAX + 1 ) D = ( x_max - x_min ) / N # compute cost function over each possible number of bins Cs = np . zeros (( len ( N ), SN )) for i , n in enumerate ( N ): # loop over number of bins shift = np . linspace ( 0 , D [ i ], SN ) for p , sh in enumerate ( shift ): # loop over shift window positions # define bin edges edges = np . linspace ( x_min + sh - D [ i ] / 2 , x_max + sh - D [ i ] / 2 , N [ i ] + 1 ) # count number of events in these bins ki = np . histogram ( x , edges ) # get mean and variance of events k = ki [ 0 ] . mean () v = np . sum (( ki [ 0 ] - k ) ** 2 ) / N [ i ] Cs [ i , p ] = ( 2 * k - v ) / D [ i ] ** 2 # average over shift window C = Cs . mean ( axis = 1 ) # get bin count that minimizes cost C idx = np . argmin ( C ) optN = N [ idx ] optD = D [ idx ] edges = np . linspace ( x_min , x_max , optN ) return optN , optD , edges , C , N sskernel ( x , tin = None , W = None , nbs = 1000.0 ) Generates a kernel density estimate with globally-optimized bandwidth. The optimal bandwidth is obtained as a minimizer of the formula, sum_{i,j} \\int k(x - x_i) k(x - x_j) dx - 2 sum_{i~=j} k(x_i - x_j), where k(x) is the kernel function. Parameters x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. W : array_like, optional The kernel bandwidths to use in optimization. Should not be chosen smaller than the sampling resolution of 'x'. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y' Returns y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : double The optimal global kernel bandwidth. W : array_like The kernel bandwidths evaluated during optimization. C : array_like The cost functions associated with the bandwidths 'W'. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample. See Also sshist, ssvkernel References .. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 Source code in indl/misc/kernels.py def sskernel ( x : np . ndarray , tin : Optional [ np . ndarray ] = None , W : Optional [ np . ndarray ] = None , nbs : Optional [ int ] = 1e3 ) -> Tuple [ np . ndarray , np . ndarray , float , np . ndarray , np . ndarray , np . ndarray , np . ndarray ]: \"\"\" Generates a kernel density estimate with globally-optimized bandwidth. The optimal bandwidth is obtained as a minimizer of the formula, sum_{i,j} \\int k(x - x_i) k(x - x_j) dx - 2 sum_{i~=j} k(x_i - x_j), where k(x) is the kernel function. Parameters ---------- x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. W : array_like, optional The kernel bandwidths to use in optimization. Should not be chosen smaller than the sampling resolution of 'x'. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y' Returns ------- y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : double The optimal global kernel bandwidth. W : array_like The kernel bandwidths evaluated during optimization. C : array_like The cost functions associated with the bandwidths 'W'. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample. See Also -------- sshist, ssvkernel References ---------- .. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 \"\"\" def CostFunction ( y_hist , N , w , dt ): # build normal smoothing kernel yh = fftkernel ( y_hist , w / dt ) # formula for density C = np . sum ( yh ** 2 ) * dt - 2 * np . sum ( yh * y_hist ) * dt + 2 \\ / ( 2 * np . pi ) ** 0.5 / w / N C = C * N ** 2 return C , yh T = np . max ( x ) - np . min ( x ) # Total span of input spike times dx = np . sort ( np . diff ( np . sort ( x ))) # Sorted ISIs dt_samp = dx [ np . nonzero ( dx )][ 0 ] # Smallest nonzero ISI # set argument 't' if not provided if tin is None : tin = np . linspace ( np . min ( x ), np . max ( x ), int ( min ( np . ceil ( T / dt_samp ), 1e3 ))) t = tin else : if dt_samp > min ( np . diff ( tin )): t = np . linspace ( min ( tin ), max ( tin ), int ( min ( np . ceil ( T / dt_samp ), 1e3 ))) else : t = tin x_ab = x [( x >= min ( tin )) & ( x <= max ( tin ))] # Spike times that fall within tin # calculate delta t dt = min ( np . diff ( t )) # create the finest histogram thist_edges = np . r_ [ t - dt / 2 , t [ - 1 ] + dt / 2 ] y_hist , _ = np . histogram ( x_ab , thist_edges ) N = sum ( y_hist ) . astype ( np . float ) y_hist = y_hist / ( N * dt ) # density # global search if input 'W' is defined if W is not None : C = np . zeros (( 1 , len ( W ))) C_min = np . Inf for k , w in enumerate ( W ): C [ k ], yh = CostFunction ( y_hist , N , w , dt ) if ( C [ k ] < C_min ): C_min = C [ k ] optw = w y = yh else : # optimized search using golden section k = 0 C = np . zeros (( 20 , 1 )) W = np . zeros (( 20 , 1 )) Wmin = 2 * dt Wmax = np . max ( x ) - np . min ( x ) tol = 10e-5 phi = ( 5 ** 0.5 + 1 ) / 2 a = ilogexp ( Wmin ) b = ilogexp ( Wmax ) c1 = ( phi - 1 ) * a + ( 2 - phi ) * b c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 , dummy = CostFunction ( y_hist , N , logexp ( c1 ), dt ) f2 , dummy = CostFunction ( y_hist , N , logexp ( c2 ), dt ) while ( np . abs ( b - a ) > tol * ( np . abs ( c1 ) + np . abs ( c2 ))) & ( k < 20 ): if f1 < f2 : b = c2 c2 = c1 c1 = ( phi - 1 ) * a + ( 2 - phi ) * b f2 = f1 f1 , yh1 = CostFunction ( y_hist , N , logexp ( c1 ), dt ) W [ k ] = logexp ( c1 ) C [ k ] = f1 optw = logexp ( c1 ) y = yh1 / np . sum ( yh1 * dt ) else : a = c1 c1 = c2 c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 = f2 f2 , yh2 = CostFunction ( y_hist , N , logexp ( c2 ), dt ) W [ k ] = logexp ( c2 ) C [ k ] = f2 optw = logexp ( c2 ) y = yh2 / np . sum ( yh2 * dt ) # increment iteration counter k = k + 1 # discard unused entries in gs, C C = C [ 0 : k ] W = W [ 0 : k ] # estimate confidence intervals by bootstrapping yb = None confb95 = None if nbs > 0 : nbs = np . asarray ( nbs ) yb = np . zeros (( nbs , len ( tin ))) for i in range ( nbs ): idx = np . random . randint ( 0 , len ( x_ab ) - 1 , len ( x_ab )) xb = x_ab [ idx ] thist = np . concatenate (( t , ( t [ - 1 ] + dt )[ np . newaxis ])) y_histb = np . histogram ( xb , thist - dt / 2 )[ 0 ] / dt / N yb_buf = fftkernel ( y_histb , optw / dt ) yb_buf = yb_buf / np . sum ( yb_buf * dt ) yb [ i , ] = np . interp ( tin , t , yb_buf ) ybsort = np . sort ( yb , axis = 0 ) y95b = ybsort [ np . int ( np . floor ( 0.05 * nbs )), :] y95u = ybsort [ np . int ( np . floor ( 0.95 * nbs )), :] confb95 = np . concatenate (( y95b [ np . newaxis ], y95u [ np . newaxis ]), axis = 0 ) # return outputs y = np . interp ( tin , t , y ) t = tin return y , t , optw , W , C , confb95 , yb ssvkernel ( x , tin = None , M = 80 , nbs = 100.0 , WinFunc = 'Boxcar' ) Generates a locally adaptive kernel-density estimate for one-dimensional data. The user provides a one-dimensional vector of samples drawn from some underlying unknown distribution, and optionally the values where they want to estimate the probability density of that distribution. The algorithm solves an optimization problem to identify variable bandwidths across the domain where the data is provided. The optimization is based on a principle of minimizing expected L2 loss function between the kernel estimate and an unknown underlying density function. An assumption is merely that samples are drawn from the density independently of each other. The locally adaptive bandwidth is obtained by iteratively computing optimal fixed-size bandwidths wihtihn local intervals. The optimal bandwidths are selected such that they are selected in the intervals that are gamma times larger than the optimal bandwidths themselves. The paramter gamma is optimized by minimizing the L2 risk estimate. Parameters x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. Default value = None. M : int, optional The number of window sizes to evaluate. Default value = 80. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y'. WinFunc : string, optional The type of window function to use in estimating local bandwidth. Choose from one of 'Boxcar', 'Laplace', 'Cauchy' and 'Gauss'. Default value = 'Gauss'. Returns y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : array_like The optimal local kernel bandwidths at 't'. gs : array_like The stiffness constants of the variables bandwidths evaluated. C : array_like Cost functions associated with stiffness constraints. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample. See Also sshist, sskernel References .. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 Source code in indl/misc/kernels.py def ssvkernel ( x : np . ndarray , tin : Optional [ np . ndarray ] = None , M : int = 80 , nbs : int = 1e2 , WinFunc : str = 'Boxcar' ) -> Tuple [ np . ndarray , np . ndarray , np . ndarray , np . ndarray , np . ndarray , np . ndarray , np . ndarray ]: \"\"\" Generates a locally adaptive kernel-density estimate for one-dimensional data. The user provides a one-dimensional vector of samples drawn from some underlying unknown distribution, and optionally the values where they want to estimate the probability density of that distribution. The algorithm solves an optimization problem to identify variable bandwidths across the domain where the data is provided. The optimization is based on a principle of minimizing expected L2 loss function between the kernel estimate and an unknown underlying density function. An assumption is merely that samples are drawn from the density independently of each other. The locally adaptive bandwidth is obtained by iteratively computing optimal fixed-size bandwidths wihtihn local intervals. The optimal bandwidths are selected such that they are selected in the intervals that are gamma times larger than the optimal bandwidths themselves. The paramter gamma is optimized by minimizing the L2 risk estimate. Parameters ---------- x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. Default value = None. M : int, optional The number of window sizes to evaluate. Default value = 80. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y'. WinFunc : string, optional The type of window function to use in estimating local bandwidth. Choose from one of 'Boxcar', 'Laplace', 'Cauchy' and 'Gauss'. Default value = 'Gauss'. Returns ------- y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : array_like The optimal local kernel bandwidths at 't'. gs : array_like The stiffness constants of the variables bandwidths evaluated. C : array_like Cost functions associated with stiffness constraints. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample. See Also -------- sshist, sskernel References ---------- .. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 \"\"\" def CostFunction ( y_hist , N , t , dt , optws , WIN , WinFunc , g ): L = y_hist . size optwv = np . zeros (( L ,)) for k in range ( L ): gs = optws [:, k ] / WIN if g > np . max ( gs ): optwv [ k ] = np . min ( WIN ) else : if g < min ( gs ): optwv [ k ] = np . max ( WIN ) else : idx = np . max ( np . nonzero ( gs >= g )) optwv [ k ] = g * WIN [ idx ] # Nadaraya-Watson kernel regression optwp = np . zeros (( L ,)) for k in range ( L ): if WinFunc == 'Boxcar' : Z = Boxcar ( t [ k ] - t , optwv / g ) elif WinFunc == 'Laplace' : Z = Laplace ( t [ k ] - t , optwv / g ) elif WinFunc == 'Cauchy' : Z = Cauchy ( t [ k ] - t , optwv / g ) else : # WinFunc == 'Gauss' Z = Gauss ( t [ k ] - t , optwv / g ) optwp [ k ] = np . sum ( optwv * Z ) / np . sum ( Z ) # speed-optimized baloon estimator idx = y_hist . nonzero () y_hist_nz = y_hist [ idx ] t_nz = t [ idx ] yv = np . zeros (( L ,)) for k in range ( L ): yv [ k ] = np . sum ( y_hist_nz * dt * Gauss ( t [ k ] - t_nz , optwp [ k ])) yv = yv * N / np . sum ( yv * dt ) # cost function of estimated kernel cg = yv ** 2 - 2 * yv * y_hist + 2 / ( 2 * np . pi ) ** 0.5 / optwp * y_hist Cg = np . sum ( cg * dt ) return Cg , yv , optwp # set argument 't' if not provided if tin is None : T = np . max ( x ) - np . min ( x ) dx = np . sort ( np . diff ( np . sort ( x ))) dt_samp = dx [ np . nonzero ( dx )][ 0 ] tin = np . linspace ( np . min ( x ), np . max ( x ), min ( np . ceil ( T / dt_samp ), 1e3 )) t = tin x_ab = x [( x >= min ( tin )) & ( x <= max ( tin ))] else : T = np . max ( x ) - np . min ( x ) x_ab = x [( x >= min ( tin )) & ( x <= max ( tin ))] dx = np . sort ( np . diff ( np . sort ( x ))) dt_samp = dx [ np . nonzero ( dx )][ 0 ] if dt_samp > min ( np . diff ( tin )): t = np . linspace ( min ( tin ), max ( tin ), min ( np . ceil ( T / dt_samp ), 1e3 )) else : t = tin # calculate delta t dt = min ( np . diff ( t )) # create the finest histogram thist = np . concatenate (( t , ( t [ - 1 ] + dt )[ np . newaxis ])) y_hist = np . histogram ( x_ab , thist - dt / 2 )[ 0 ] / dt L = y_hist . size N = sum ( y_hist * dt ) . astype ( np . float ) # initialize window sizes W = logexp ( np . linspace ( ilogexp ( 5 * dt ), ilogexp ( T ), M )) # compute local cost functions c = np . zeros (( M , L )) for j in range ( M ): w = W [ j ] yh = fftkernel ( y_hist , w / dt ) c [ j , :] = yh ** 2 - 2 * yh * y_hist + 2 / ( 2 * np . pi ) ** 0.5 / w * y_hist # initialize optimal ws optws = np . zeros (( M , L )) for i in range ( M ): Win = W [ i ] C_local = np . zeros (( M , L )) for j in range ( M ): C_local [ j , :] = fftkernelWin ( c [ j , :], Win / dt , WinFunc ) n = np . argmin ( C_local , axis = 0 ) optws [ i , :] = W [ n ] # golden section search for stiffness parameter of variable bandwidths k = 0 gs = np . zeros (( 30 , 1 )) C = np . zeros (( 30 , 1 )) tol = 1e-5 a = 1e-12 b = 1 phi = ( 5 ** 0.5 + 1 ) / 2 c1 = ( phi - 1 ) * a + ( 2 - phi ) * b c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c1 )[ 0 ] f2 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c2 )[ 0 ] while ( np . abs ( b - a ) > tol * ( abs ( c1 ) + abs ( c2 ))) & ( k < 30 ): if f1 < f2 : b = c2 c2 = c1 c1 = ( phi - 1 ) * a + ( 2 - phi ) * b f2 = f1 f1 , yv1 , optwp1 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c1 ) yopt = yv1 / np . sum ( yv1 * dt ) optw = optwp1 else : a = c1 c1 = c2 c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 = f2 f2 , yv2 , optwp2 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c2 ) yopt = yv2 / np . sum ( yv2 * dt ) optw = optwp2 # capture estimates and increment iteration counter gs [ k ] = c1 C [ k ] = f1 k = k + 1 # discard unused entries in gs, C gs = gs [ 0 : k ] C = C [ 0 : k ] # estimate confidence intervals by bootstrapping nbs = np . asarray ( nbs ) yb = np . zeros (( nbs , tin . size )) for i in range ( nbs ): Nb = np . random . poisson ( lam = N ) idx = np . random . randint ( 0 , N , Nb ) xb = x_ab [ idx ] thist = np . concatenate (( t , ( t [ - 1 ] + dt )[ np . newaxis ])) y_histb = np . histogram ( xb , thist - dt / 2 )[ 0 ] idx = y_histb . nonzero () y_histb_nz = y_histb [ idx ] t_nz = t [ idx ] yb_buf = np . zeros (( L , )) for k in range ( L ): yb_buf [ k ] = np . sum ( y_histb_nz * Gauss ( t [ k ] - t_nz , optw [ k ])) / Nb yb_buf = yb_buf / np . sum ( yb_buf * dt ) yb [ i , :] = np . interp ( tin , t , yb_buf ) ybsort = np . sort ( yb , axis = 0 ) y95b = ybsort [ np . int ( np . floor ( 0.05 * nbs )), :] y95u = ybsort [ np . int ( np . floor ( 0.95 * nbs )), :] confb95 = np . concatenate (( y95b [ np . newaxis ], y95u [ np . newaxis ]), axis = 0 ) # return outputs y = np . interp ( tin , t , yopt ) optw = np . interp ( tin , t , optw ) t = tin return y , t , optw , gs , C , confb95 , yb sigfuncs minimum_jerk ( x , a0 = 0 , af = 1 , degree = 1 , duration = None ) A 1-D trajectory that minimizes jerk (3rd time-derivative of position). A minimum jerk trajectory is considered \"smooth\" and to be a feature of natural limb movements. https://storage.googleapis.com/wzukusers/user-31382847/documents/5a7253343814f4Iv6Hnt/minimumjerk.pdf A minimum-jerk trajectory is defined by: trajectory = a0 + (af - a0) * (10(dx^3) - 15(dx^4) + 6(dx^5)) where a0 is the resting position, and af is the finishing position. duration is assumed to be the extent of x but it may be overidden. Parameters: Name Type Description Default x ndarray required a0 0 af 1 degree 1 duration float Total duration of x in seconds. If None (default), calculated duration from x. None Returns: Type Description ndarray a0 + (af - a0) * (10 (dx.^3) - 15 (dx.^4) + 6*(dx.^5)) Source code in indl/misc/sigfuncs.py def minimum_jerk ( x : np . ndarray , a0 = 0 , af = 1 , degree = 1 , duration = None ) -> np . ndarray : r \"\"\" A 1-D trajectory that minimizes jerk (3rd time-derivative of position). A minimum jerk trajectory is considered \"smooth\" and to be a feature of natural limb movements. https://storage.googleapis.com/wzukusers/user-31382847/documents/5a7253343814f4Iv6Hnt/minimumjerk.pdf A minimum-jerk trajectory is defined by: ```math trajectory = a0 + (af - a0) * (10(dx^3) - 15(dx^4) + 6(dx^5)) ``` where a0 is the resting position, and af is the finishing position. duration is assumed to be the extent of x but it may be overidden. Args: x: a0: af: degree: duration (float): Total duration of x in seconds. If None (default), calculated duration from x. Returns: a0 + (af - a0) * (10*(dx.^3) - 15*(dx.^4) + 6*(dx.^5)) \"\"\" x = np . array ( x )[:, None ] assert ( x . size == x . shape [ 0 ]), f \"x must be 1D trajectory, found { x . shape } \" a0 = np . atleast_2d ( a0 ) af = np . atleast_2d ( af ) if duration is None : sorted_x = np . sort ( x , axis = 0 ) dx = np . diff ( x , axis = 0 ) duration = sorted_x [ - 1 ] - sorted_x [ 0 ] + np . min ( dx ) dx = x / duration if degree not in [ 1 , 2 ]: # Default - no derivative k0 = a0 x1 = 10 * dx ** 3 x2 = - 15 * dx ** 4 x3 = 6 * dx ** 5 elif degree == 1 : # Velocity k0 = np . zeros_like ( a0 ) x1 = 30 * dx ** 2 x2 = - 60 * dx ** 3 x3 = 30 * dx ** 4 elif degree == 2 : # Acceleration k0 = np . zeros_like ( a0 ) x1 = 60 * dx x2 = - 180 * dx ** 2 x3 = 120 * dx ** 3 return k0 + ( af - a0 ) * ( x1 + x2 + x3 ) sigmoid ( x , A = 0 , K = 1 , C = 1 , Q = 1 , B = 1 , v = 1 , x_offset = 0 ) Returns f(x) = A + (K - A) / ((C + Q * np.exp(-B (x - x_offset))) *(1/v)) This is a generalized logistic function. The default arguments reduce this to a simple sigmoid: f(x) = 1 / (1 + np.exp(-x)) Parameters: Name Type Description Default x np.ndarray required A float 0 K float 1 C float 1 Q float 1 B float 1 v float 1 x_offset 0 Returns: Type Description np.ndarray A + (K - A) / ((C + Q * np.exp(-B (x - x_offset))) *(1/v)) Source code in indl/misc/sigfuncs.py def sigmoid ( x , A = 0 , K = 1 , C = 1 , Q = 1 , B = 1 , v = 1 , x_offset = 0 ): \"\"\" Returns f(x) = A + (K - A) / ((C + Q * np.exp(-B*(x - x_offset)))**(1/v)) This is a generalized logistic function. The default arguments reduce this to a simple sigmoid: f(x) = 1 / (1 + np.exp(-x)) Args: x (np.ndarray): A (float): K (float): C (float): Q (float): B (float): v (float): x_offset: Returns: np.ndarray: A + (K - A) / ((C + Q * np.exp(-B*(x - x_offset)))**(1/v)) \"\"\" y = A + ( K - A ) / (( C + Q * np . exp ( - B * ( x - x_offset ))) ** ( 1 / v )) return y","title":"misc"},{"location":"API/misc/#misc","text":"","title":"misc"},{"location":"API/misc/#indl.misc.kernels","text":"","title":"kernels"},{"location":"API/misc/#indl.misc.kernels.Alpha","text":"Parameters: Name Type Description Default x ndarray required sigma float required reverse bool Reverse the direction of the kernel. False Returns: Type Description ndarray (x >= 0) * 2. * (x / sigma ** 2) * np.exp(-x * np.sqrt(2.) / sigma) Source code in indl/misc/kernels.py def Alpha ( x : np . ndarray , sigma : float , reverse : bool = False ) -> np . ndarray : \"\"\" Args: x: sigma: reverse: Reverse the direction of the kernel. Returns: ```math (x >= 0) * 2. * (x / sigma ** 2) * np.exp(-x * np.sqrt(2.) / sigma) ``` \"\"\" if reverse : return ( x <= 0 ) * - 2. * ( x / sigma ** 2 ) * np . exp ( x * np . sqrt ( 2. ) / sigma ) else : return ( x >= 0 ) * 2. * ( x / sigma ** 2 ) * np . exp ( - x * np . sqrt ( 2. ) / sigma )","title":"Alpha()"},{"location":"API/misc/#indl.misc.kernels.Boxcar","text":"Parameters: Name Type Description Default x np.ndarray required sigma float required reverse Optional[bool] unused None Returns: Type Description ndarray (0.5 / (np.sqrt(3.0) * sigma)) * (np.abs(x) < (np.sqrt(3.0) * sigma)) Source code in indl/misc/kernels.py def Boxcar ( x : np . ndarray , sigma : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x (np.ndarray): sigma: reverse: unused Returns: ```math (0.5 / (np.sqrt(3.0) * sigma)) * (np.abs(x) < (np.sqrt(3.0) * sigma)) ``` \"\"\" return ( 0.5 / ( np . sqrt ( 3.0 ) * sigma )) * ( np . abs ( x ) < ( np . sqrt ( 3.0 ) * sigma ))","title":"Boxcar()"},{"location":"API/misc/#indl.misc.kernels.Cauchy","text":"Parameters: Name Type Description Default x np.ndarray required w float required reverse Optional[bool] unused None Returns: Type Description ndarray 1 / (np.pi * w * (1 + (x / w)**2)) Source code in indl/misc/kernels.py def Cauchy ( x : np . ndarray , w : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x (np.ndarray): w: reverse: unused Returns: ```math 1 / (np.pi * w * (1 + (x / w)**2)) ``` \"\"\" return 1 / ( np . pi * w * ( 1 + ( x / w ) ** 2 ))","title":"Cauchy()"},{"location":"API/misc/#indl.misc.kernels.Exponential","text":"Parameters: Name Type Description Default x ndarray required sigma float required reverse bool False Returns: Type Description ndarray (x >= 0) * (1. / sigma) * np.exp(-x / sigma) Source code in indl/misc/kernels.py def Exponential ( x : np . ndarray , sigma : float , reverse : bool = False ) -> np . ndarray : \"\"\" Args: x: sigma: reverse: Returns: ```math (x >= 0) * (1. / sigma) * np.exp(-x / sigma) ``` \"\"\" if reverse : return ( x <= 0 ) * ( 1. / sigma ) * np . exp ( x / sigma ) else : return ( x >= 0 ) * ( 1. / sigma ) * np . exp ( - x / sigma )","title":"Exponential()"},{"location":"API/misc/#indl.misc.kernels.Gauss","text":"Parameters: Name Type Description Default x ndarray required sigma float required reverse Optional[bool] unused None Returns: Type Description ndarray (1.0 / (np.sqrt(2.0 * np.pi) * sigma)) * np.exp(-0.5 * (x / sigma) ** 2) Source code in indl/misc/kernels.py def Gauss ( x : np . ndarray , sigma : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x: sigma: reverse: unused Returns: ```math (1.0 / (np.sqrt(2.0 * np.pi) * sigma)) * np.exp(-0.5 * (x / sigma) ** 2) ``` \"\"\" return ( 1.0 / ( np . sqrt ( 2.0 * np . pi ) * sigma )) * np . exp ( - 0.5 * ( x / sigma ) ** 2 )","title":"Gauss()"},{"location":"API/misc/#indl.misc.kernels.Laplace","text":"Parameters: Name Type Description Default x np.ndarray required w float required reverse Optional[bool] unused None Returns: Type Description ndarray 1 / 2**0.5 / w * np.exp(-(2**0.5) / w / np.abs(x)) Source code in indl/misc/kernels.py def Laplace ( x : np . ndarray , w : float , reverse : Optional [ bool ] = None ) -> np . ndarray : \"\"\" Args: x (np.ndarray): w: reverse: unused Returns: ```math 1 / 2**0.5 / w * np.exp(-(2**0.5) / w / np.abs(x)) ``` \"\"\" return 1 / 2 ** 0.5 / w * np . exp ( - ( 2 ** 0.5 ) / w / np . abs ( x ))","title":"Laplace()"},{"location":"API/misc/#indl.misc.kernels.fftkernel","text":"Parameters: Name Type Description Default x ndarray required w float required Source code in indl/misc/kernels.py def fftkernel ( x : np . ndarray , w : float ) -> np . ndarray : \"\"\" Args: x: w: Returns: \"\"\" # forward padded transform L = x . size Lmax = L + 3 * w n = int ( 2 ** np . ceil ( np . log2 ( Lmax ))) X = np . fft . fft ( x , n ) # generate kernel domain f = np . linspace ( 0 , n - 1 , n ) / n f = np . concatenate (( - f [ 0 : np . int ( n / 2 + 1 )], f [ 1 : np . int ( n / 2 - 1 + 1 )][:: - 1 ])) # evaluate kernel K = np . exp ( - 0.5 * ( w * 2 * np . pi * f ) ** 2 ) # convolve and transform back from frequency domain y = np . real ( np . fft . ifft ( X * K , n )) y = y [ 0 : L ] return y","title":"fftkernel()"},{"location":"API/misc/#indl.misc.kernels.fftkernelWin","text":"Parameters: Name Type Description Default x ndarray data required w float kernel parameter required WinFunc str 'Boxcar', 'Laplace', 'Cauchy', 'Gauss' (default) required Source code in indl/misc/kernels.py def fftkernelWin ( x : np . ndarray , w : float , WinFunc : str ) -> np . ndarray : \"\"\" Args: x: data w: kernel parameter WinFunc: 'Boxcar', 'Laplace', 'Cauchy', 'Gauss' (default) Returns: \"\"\" # forward padded transform L = x . size Lmax = L + 3 * w n = 2 ** np . ceil ( np . log2 ( Lmax )) X = np . fft . fft ( x , n . astype ( np . int )) # generate kernel domain f = np . linspace ( 0 , n - 1 , n ) / n f = np . concatenate (( - f [ 0 : np . int ( n / 2 + 1 )], f [ 1 : np . int ( n / 2 - 1 + 1 )][:: - 1 ])) t = 2 * np . pi * f # determine window function - evaluate kernel if WinFunc == 'Boxcar' : a = 12 ** 0.5 * w K = 2 * np . sin ( a * t / 2 ) / ( a * t ) K [ 0 ] = 1 elif WinFunc == 'Laplace' : K = 1 / ( 1 + ( w * 2 * np . pi * f ) ** 2 / 2 ) elif WinFunc == 'Cauchy' : K = np . exp ( - w * np . abs ( 2 * np . pi * f )) else : # WinFunc == 'Gauss' K = np . exp ( - 0.5 * ( w * 2 * np . pi * f ) ** 2 ) # convolve and transform back from frequency domain y = np . real ( np . fft . ifft ( X * K , n )) y = y [ 0 : L ] return y","title":"fftkernelWin()"},{"location":"API/misc/#indl.misc.kernels.ilogexp","text":"Parameters: Name Type Description Default x ndarray required Source code in indl/misc/kernels.py def ilogexp ( x : np . ndarray ) -> np . ndarray : \"\"\" Args: x: Returns: \"\"\" # TODO: Check dtype and convert x scalars to numpy array y = np . zeros ( x . shape ) y [ x < 1e2 ] = np . log ( np . exp ( x [ x < 1e2 ]) - 1 ) y [ x >= 1e2 ] = x [ x >= 1e2 ] return y","title":"ilogexp()"},{"location":"API/misc/#indl.misc.kernels.logexp","text":"Parameters: Name Type Description Default x ndarray required Source code in indl/misc/kernels.py def logexp ( x : np . ndarray ) -> np . ndarray : \"\"\" Args: x: Returns: \"\"\" # TODO: Check dtype and convert x scalars to numpy array y = np . zeros ( x . shape ) y [ x < 1e2 ] = np . log ( 1 + np . exp ( x [ x < 1e2 ])) y [ x >= 1e2 ] = x [ x >= 1e2 ] return y","title":"logexp()"},{"location":"API/misc/#indl.misc.kernels.sshist","text":"Returns the optimal number of bins in a histogram used for density estimation. Optimization principle is to minimize expected L2 loss function between the histogram and an unknown underlying density function. An assumption made is merely that samples are drawn from the density independently each other. The optimal binwidth D* is obtained as a minimizer of the formula, (2K-V) / D^2, where K and V are mean and variance of sample counts across bins with width D. Optimal number of bins is given as (max(x) - min(x)) / D.","title":"sshist()"},{"location":"API/misc/#indl.misc.kernels.sshist--parameters","text":"x : array_like One-dimensional data to fit histogram to. N : array_like, optional Array containing number of histogram bins to evaluate for fit. Default value = 500. SN : double, optional Scalar natural number defining number of bins for shift-averaging.","title":"Parameters"},{"location":"API/misc/#indl.misc.kernels.sshist--returns","text":"optN : int Optimal number of bins to represent the data in X N : double Maximum number of bins to be evaluated. Default value = 500. C : array_like Cost function C[i] of evaluating histogram fit with N[i] bins","title":"Returns"},{"location":"API/misc/#indl.misc.kernels.sshist--see-also","text":"sskernel, ssvkernel","title":"See Also"},{"location":"API/misc/#indl.misc.kernels.sshist--references","text":".. [1] H. Shimazaki and S. Shinomoto, \"A method for selecting the bin size of a time histogram,\" in Neural Computation 19(6), 1503-1527, 2007 http://dx.doi.org/10.1162/neco.2007.19.6.1503 Source code in indl/misc/kernels.py def sshist ( x : np . ndarray , N = range ( 2 , 501 ), SN : int = 30 ) -> Tuple [ int , float , np . ndarray ]: \"\"\" Returns the optimal number of bins in a histogram used for density estimation. Optimization principle is to minimize expected L2 loss function between the histogram and an unknown underlying density function. An assumption made is merely that samples are drawn from the density independently each other. The optimal binwidth D* is obtained as a minimizer of the formula, (2K-V) / D^2, where K and V are mean and variance of sample counts across bins with width D. Optimal number of bins is given as (max(x) - min(x)) / D. Parameters ---------- x : array_like One-dimensional data to fit histogram to. N : array_like, optional Array containing number of histogram bins to evaluate for fit. Default value = 500. SN : double, optional Scalar natural number defining number of bins for shift-averaging. Returns ------- optN : int Optimal number of bins to represent the data in X N : double Maximum number of bins to be evaluated. Default value = 500. C : array_like Cost function C[i] of evaluating histogram fit with N[i] bins See Also -------- sskernel, ssvkernel References ---------- .. [1] H. Shimazaki and S. Shinomoto, \"A method for selecting the bin size of a time histogram,\" in Neural Computation 19(6), 1503-1527, 2007 http://dx.doi.org/10.1162/neco.2007.19.6.1503 \"\"\" # determine range of input 'x' x_min = np . min ( x ) x_max = np . max ( x ) # get smallest difference 'dx' between all pairwise samples buf = np . abs ( np . diff ( np . sort ( x ))) dx = min ( buf [ buf > 0 ]) # setup bins to evaluate N_MIN = 2 N_MAX = min ( np . floor (( x_max - x_min ) / ( 2 * dx )), max ( N )) N = range ( N_MIN , N_MAX + 1 ) D = ( x_max - x_min ) / N # compute cost function over each possible number of bins Cs = np . zeros (( len ( N ), SN )) for i , n in enumerate ( N ): # loop over number of bins shift = np . linspace ( 0 , D [ i ], SN ) for p , sh in enumerate ( shift ): # loop over shift window positions # define bin edges edges = np . linspace ( x_min + sh - D [ i ] / 2 , x_max + sh - D [ i ] / 2 , N [ i ] + 1 ) # count number of events in these bins ki = np . histogram ( x , edges ) # get mean and variance of events k = ki [ 0 ] . mean () v = np . sum (( ki [ 0 ] - k ) ** 2 ) / N [ i ] Cs [ i , p ] = ( 2 * k - v ) / D [ i ] ** 2 # average over shift window C = Cs . mean ( axis = 1 ) # get bin count that minimizes cost C idx = np . argmin ( C ) optN = N [ idx ] optD = D [ idx ] edges = np . linspace ( x_min , x_max , optN ) return optN , optD , edges , C , N","title":"References"},{"location":"API/misc/#indl.misc.kernels.sskernel","text":"Generates a kernel density estimate with globally-optimized bandwidth. The optimal bandwidth is obtained as a minimizer of the formula, sum_{i,j} \\int k(x - x_i) k(x - x_j) dx - 2 sum_{i~=j} k(x_i - x_j), where k(x) is the kernel function.","title":"sskernel()"},{"location":"API/misc/#indl.misc.kernels.sskernel--parameters","text":"x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. W : array_like, optional The kernel bandwidths to use in optimization. Should not be chosen smaller than the sampling resolution of 'x'. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y'","title":"Parameters"},{"location":"API/misc/#indl.misc.kernels.sskernel--returns","text":"y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : double The optimal global kernel bandwidth. W : array_like The kernel bandwidths evaluated during optimization. C : array_like The cost functions associated with the bandwidths 'W'. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample.","title":"Returns"},{"location":"API/misc/#indl.misc.kernels.sskernel--see-also","text":"sshist, ssvkernel","title":"See Also"},{"location":"API/misc/#indl.misc.kernels.sskernel--references","text":".. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 Source code in indl/misc/kernels.py def sskernel ( x : np . ndarray , tin : Optional [ np . ndarray ] = None , W : Optional [ np . ndarray ] = None , nbs : Optional [ int ] = 1e3 ) -> Tuple [ np . ndarray , np . ndarray , float , np . ndarray , np . ndarray , np . ndarray , np . ndarray ]: \"\"\" Generates a kernel density estimate with globally-optimized bandwidth. The optimal bandwidth is obtained as a minimizer of the formula, sum_{i,j} \\int k(x - x_i) k(x - x_j) dx - 2 sum_{i~=j} k(x_i - x_j), where k(x) is the kernel function. Parameters ---------- x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. W : array_like, optional The kernel bandwidths to use in optimization. Should not be chosen smaller than the sampling resolution of 'x'. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y' Returns ------- y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : double The optimal global kernel bandwidth. W : array_like The kernel bandwidths evaluated during optimization. C : array_like The cost functions associated with the bandwidths 'W'. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample. See Also -------- sshist, ssvkernel References ---------- .. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 \"\"\" def CostFunction ( y_hist , N , w , dt ): # build normal smoothing kernel yh = fftkernel ( y_hist , w / dt ) # formula for density C = np . sum ( yh ** 2 ) * dt - 2 * np . sum ( yh * y_hist ) * dt + 2 \\ / ( 2 * np . pi ) ** 0.5 / w / N C = C * N ** 2 return C , yh T = np . max ( x ) - np . min ( x ) # Total span of input spike times dx = np . sort ( np . diff ( np . sort ( x ))) # Sorted ISIs dt_samp = dx [ np . nonzero ( dx )][ 0 ] # Smallest nonzero ISI # set argument 't' if not provided if tin is None : tin = np . linspace ( np . min ( x ), np . max ( x ), int ( min ( np . ceil ( T / dt_samp ), 1e3 ))) t = tin else : if dt_samp > min ( np . diff ( tin )): t = np . linspace ( min ( tin ), max ( tin ), int ( min ( np . ceil ( T / dt_samp ), 1e3 ))) else : t = tin x_ab = x [( x >= min ( tin )) & ( x <= max ( tin ))] # Spike times that fall within tin # calculate delta t dt = min ( np . diff ( t )) # create the finest histogram thist_edges = np . r_ [ t - dt / 2 , t [ - 1 ] + dt / 2 ] y_hist , _ = np . histogram ( x_ab , thist_edges ) N = sum ( y_hist ) . astype ( np . float ) y_hist = y_hist / ( N * dt ) # density # global search if input 'W' is defined if W is not None : C = np . zeros (( 1 , len ( W ))) C_min = np . Inf for k , w in enumerate ( W ): C [ k ], yh = CostFunction ( y_hist , N , w , dt ) if ( C [ k ] < C_min ): C_min = C [ k ] optw = w y = yh else : # optimized search using golden section k = 0 C = np . zeros (( 20 , 1 )) W = np . zeros (( 20 , 1 )) Wmin = 2 * dt Wmax = np . max ( x ) - np . min ( x ) tol = 10e-5 phi = ( 5 ** 0.5 + 1 ) / 2 a = ilogexp ( Wmin ) b = ilogexp ( Wmax ) c1 = ( phi - 1 ) * a + ( 2 - phi ) * b c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 , dummy = CostFunction ( y_hist , N , logexp ( c1 ), dt ) f2 , dummy = CostFunction ( y_hist , N , logexp ( c2 ), dt ) while ( np . abs ( b - a ) > tol * ( np . abs ( c1 ) + np . abs ( c2 ))) & ( k < 20 ): if f1 < f2 : b = c2 c2 = c1 c1 = ( phi - 1 ) * a + ( 2 - phi ) * b f2 = f1 f1 , yh1 = CostFunction ( y_hist , N , logexp ( c1 ), dt ) W [ k ] = logexp ( c1 ) C [ k ] = f1 optw = logexp ( c1 ) y = yh1 / np . sum ( yh1 * dt ) else : a = c1 c1 = c2 c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 = f2 f2 , yh2 = CostFunction ( y_hist , N , logexp ( c2 ), dt ) W [ k ] = logexp ( c2 ) C [ k ] = f2 optw = logexp ( c2 ) y = yh2 / np . sum ( yh2 * dt ) # increment iteration counter k = k + 1 # discard unused entries in gs, C C = C [ 0 : k ] W = W [ 0 : k ] # estimate confidence intervals by bootstrapping yb = None confb95 = None if nbs > 0 : nbs = np . asarray ( nbs ) yb = np . zeros (( nbs , len ( tin ))) for i in range ( nbs ): idx = np . random . randint ( 0 , len ( x_ab ) - 1 , len ( x_ab )) xb = x_ab [ idx ] thist = np . concatenate (( t , ( t [ - 1 ] + dt )[ np . newaxis ])) y_histb = np . histogram ( xb , thist - dt / 2 )[ 0 ] / dt / N yb_buf = fftkernel ( y_histb , optw / dt ) yb_buf = yb_buf / np . sum ( yb_buf * dt ) yb [ i , ] = np . interp ( tin , t , yb_buf ) ybsort = np . sort ( yb , axis = 0 ) y95b = ybsort [ np . int ( np . floor ( 0.05 * nbs )), :] y95u = ybsort [ np . int ( np . floor ( 0.95 * nbs )), :] confb95 = np . concatenate (( y95b [ np . newaxis ], y95u [ np . newaxis ]), axis = 0 ) # return outputs y = np . interp ( tin , t , y ) t = tin return y , t , optw , W , C , confb95 , yb","title":"References"},{"location":"API/misc/#indl.misc.kernels.ssvkernel","text":"Generates a locally adaptive kernel-density estimate for one-dimensional data. The user provides a one-dimensional vector of samples drawn from some underlying unknown distribution, and optionally the values where they want to estimate the probability density of that distribution. The algorithm solves an optimization problem to identify variable bandwidths across the domain where the data is provided. The optimization is based on a principle of minimizing expected L2 loss function between the kernel estimate and an unknown underlying density function. An assumption is merely that samples are drawn from the density independently of each other. The locally adaptive bandwidth is obtained by iteratively computing optimal fixed-size bandwidths wihtihn local intervals. The optimal bandwidths are selected such that they are selected in the intervals that are gamma times larger than the optimal bandwidths themselves. The paramter gamma is optimized by minimizing the L2 risk estimate.","title":"ssvkernel()"},{"location":"API/misc/#indl.misc.kernels.ssvkernel--parameters","text":"x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. Default value = None. M : int, optional The number of window sizes to evaluate. Default value = 80. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y'. WinFunc : string, optional The type of window function to use in estimating local bandwidth. Choose from one of 'Boxcar', 'Laplace', 'Cauchy' and 'Gauss'. Default value = 'Gauss'.","title":"Parameters"},{"location":"API/misc/#indl.misc.kernels.ssvkernel--returns","text":"y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : array_like The optimal local kernel bandwidths at 't'. gs : array_like The stiffness constants of the variables bandwidths evaluated. C : array_like Cost functions associated with stiffness constraints. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample.","title":"Returns"},{"location":"API/misc/#indl.misc.kernels.ssvkernel--see-also","text":"sshist, sskernel","title":"See Also"},{"location":"API/misc/#indl.misc.kernels.ssvkernel--references","text":".. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 Source code in indl/misc/kernels.py def ssvkernel ( x : np . ndarray , tin : Optional [ np . ndarray ] = None , M : int = 80 , nbs : int = 1e2 , WinFunc : str = 'Boxcar' ) -> Tuple [ np . ndarray , np . ndarray , np . ndarray , np . ndarray , np . ndarray , np . ndarray , np . ndarray ]: \"\"\" Generates a locally adaptive kernel-density estimate for one-dimensional data. The user provides a one-dimensional vector of samples drawn from some underlying unknown distribution, and optionally the values where they want to estimate the probability density of that distribution. The algorithm solves an optimization problem to identify variable bandwidths across the domain where the data is provided. The optimization is based on a principle of minimizing expected L2 loss function between the kernel estimate and an unknown underlying density function. An assumption is merely that samples are drawn from the density independently of each other. The locally adaptive bandwidth is obtained by iteratively computing optimal fixed-size bandwidths wihtihn local intervals. The optimal bandwidths are selected such that they are selected in the intervals that are gamma times larger than the optimal bandwidths themselves. The paramter gamma is optimized by minimizing the L2 risk estimate. Parameters ---------- x : array_like The one-dimensional samples drawn from the underlying density tin : array_like, optional The values where the density estimate is to be evaluated in generating the output 'y'. Default value = None. M : int, optional The number of window sizes to evaluate. Default value = 80. nbs : int, optional The number of bootstrap samples to use in estimating the [0.05, 0.95] confidence interval of the output 'y'. WinFunc : string, optional The type of window function to use in estimating local bandwidth. Choose from one of 'Boxcar', 'Laplace', 'Cauchy' and 'Gauss'. Default value = 'Gauss'. Returns ------- y : array_like The estimated density, evaluated at points t / tin. t : array_like The points where the density estimate 'y' is evaluated. optw : array_like The optimal local kernel bandwidths at 't'. gs : array_like The stiffness constants of the variables bandwidths evaluated. C : array_like Cost functions associated with stiffness constraints. confb95 : array_like The 5% and 95% confidence interval of the kernel density estimate 'y'. Has dimensions 2 x len(y). confb95[0,:] corresponds to the 5% interval, and confb95[1,:] corresponds to the 95% interval. yb : array_like The bootstrap samples used in estimating confb95. Each row corresponds to one bootstrap sample. See Also -------- sshist, sskernel References ---------- .. [1] H. Shimazaki and S. Shinomoto, \"Kernel Bandwidth Optimization in Spike Rate Estimation,\" in Journal of Computational Neuroscience 29(1-2): 171\u2013182, 2010 http://dx.doi.org/10.1007/s10827-009-0180-4 \"\"\" def CostFunction ( y_hist , N , t , dt , optws , WIN , WinFunc , g ): L = y_hist . size optwv = np . zeros (( L ,)) for k in range ( L ): gs = optws [:, k ] / WIN if g > np . max ( gs ): optwv [ k ] = np . min ( WIN ) else : if g < min ( gs ): optwv [ k ] = np . max ( WIN ) else : idx = np . max ( np . nonzero ( gs >= g )) optwv [ k ] = g * WIN [ idx ] # Nadaraya-Watson kernel regression optwp = np . zeros (( L ,)) for k in range ( L ): if WinFunc == 'Boxcar' : Z = Boxcar ( t [ k ] - t , optwv / g ) elif WinFunc == 'Laplace' : Z = Laplace ( t [ k ] - t , optwv / g ) elif WinFunc == 'Cauchy' : Z = Cauchy ( t [ k ] - t , optwv / g ) else : # WinFunc == 'Gauss' Z = Gauss ( t [ k ] - t , optwv / g ) optwp [ k ] = np . sum ( optwv * Z ) / np . sum ( Z ) # speed-optimized baloon estimator idx = y_hist . nonzero () y_hist_nz = y_hist [ idx ] t_nz = t [ idx ] yv = np . zeros (( L ,)) for k in range ( L ): yv [ k ] = np . sum ( y_hist_nz * dt * Gauss ( t [ k ] - t_nz , optwp [ k ])) yv = yv * N / np . sum ( yv * dt ) # cost function of estimated kernel cg = yv ** 2 - 2 * yv * y_hist + 2 / ( 2 * np . pi ) ** 0.5 / optwp * y_hist Cg = np . sum ( cg * dt ) return Cg , yv , optwp # set argument 't' if not provided if tin is None : T = np . max ( x ) - np . min ( x ) dx = np . sort ( np . diff ( np . sort ( x ))) dt_samp = dx [ np . nonzero ( dx )][ 0 ] tin = np . linspace ( np . min ( x ), np . max ( x ), min ( np . ceil ( T / dt_samp ), 1e3 )) t = tin x_ab = x [( x >= min ( tin )) & ( x <= max ( tin ))] else : T = np . max ( x ) - np . min ( x ) x_ab = x [( x >= min ( tin )) & ( x <= max ( tin ))] dx = np . sort ( np . diff ( np . sort ( x ))) dt_samp = dx [ np . nonzero ( dx )][ 0 ] if dt_samp > min ( np . diff ( tin )): t = np . linspace ( min ( tin ), max ( tin ), min ( np . ceil ( T / dt_samp ), 1e3 )) else : t = tin # calculate delta t dt = min ( np . diff ( t )) # create the finest histogram thist = np . concatenate (( t , ( t [ - 1 ] + dt )[ np . newaxis ])) y_hist = np . histogram ( x_ab , thist - dt / 2 )[ 0 ] / dt L = y_hist . size N = sum ( y_hist * dt ) . astype ( np . float ) # initialize window sizes W = logexp ( np . linspace ( ilogexp ( 5 * dt ), ilogexp ( T ), M )) # compute local cost functions c = np . zeros (( M , L )) for j in range ( M ): w = W [ j ] yh = fftkernel ( y_hist , w / dt ) c [ j , :] = yh ** 2 - 2 * yh * y_hist + 2 / ( 2 * np . pi ) ** 0.5 / w * y_hist # initialize optimal ws optws = np . zeros (( M , L )) for i in range ( M ): Win = W [ i ] C_local = np . zeros (( M , L )) for j in range ( M ): C_local [ j , :] = fftkernelWin ( c [ j , :], Win / dt , WinFunc ) n = np . argmin ( C_local , axis = 0 ) optws [ i , :] = W [ n ] # golden section search for stiffness parameter of variable bandwidths k = 0 gs = np . zeros (( 30 , 1 )) C = np . zeros (( 30 , 1 )) tol = 1e-5 a = 1e-12 b = 1 phi = ( 5 ** 0.5 + 1 ) / 2 c1 = ( phi - 1 ) * a + ( 2 - phi ) * b c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c1 )[ 0 ] f2 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c2 )[ 0 ] while ( np . abs ( b - a ) > tol * ( abs ( c1 ) + abs ( c2 ))) & ( k < 30 ): if f1 < f2 : b = c2 c2 = c1 c1 = ( phi - 1 ) * a + ( 2 - phi ) * b f2 = f1 f1 , yv1 , optwp1 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c1 ) yopt = yv1 / np . sum ( yv1 * dt ) optw = optwp1 else : a = c1 c1 = c2 c2 = ( 2 - phi ) * a + ( phi - 1 ) * b f1 = f2 f2 , yv2 , optwp2 = CostFunction ( y_hist , N , t , dt , optws , W , WinFunc , c2 ) yopt = yv2 / np . sum ( yv2 * dt ) optw = optwp2 # capture estimates and increment iteration counter gs [ k ] = c1 C [ k ] = f1 k = k + 1 # discard unused entries in gs, C gs = gs [ 0 : k ] C = C [ 0 : k ] # estimate confidence intervals by bootstrapping nbs = np . asarray ( nbs ) yb = np . zeros (( nbs , tin . size )) for i in range ( nbs ): Nb = np . random . poisson ( lam = N ) idx = np . random . randint ( 0 , N , Nb ) xb = x_ab [ idx ] thist = np . concatenate (( t , ( t [ - 1 ] + dt )[ np . newaxis ])) y_histb = np . histogram ( xb , thist - dt / 2 )[ 0 ] idx = y_histb . nonzero () y_histb_nz = y_histb [ idx ] t_nz = t [ idx ] yb_buf = np . zeros (( L , )) for k in range ( L ): yb_buf [ k ] = np . sum ( y_histb_nz * Gauss ( t [ k ] - t_nz , optw [ k ])) / Nb yb_buf = yb_buf / np . sum ( yb_buf * dt ) yb [ i , :] = np . interp ( tin , t , yb_buf ) ybsort = np . sort ( yb , axis = 0 ) y95b = ybsort [ np . int ( np . floor ( 0.05 * nbs )), :] y95u = ybsort [ np . int ( np . floor ( 0.95 * nbs )), :] confb95 = np . concatenate (( y95b [ np . newaxis ], y95u [ np . newaxis ]), axis = 0 ) # return outputs y = np . interp ( tin , t , yopt ) optw = np . interp ( tin , t , optw ) t = tin return y , t , optw , gs , C , confb95 , yb","title":"References"},{"location":"API/misc/#indl.misc.sigfuncs","text":"","title":"sigfuncs"},{"location":"API/misc/#indl.misc.sigfuncs.minimum_jerk","text":"A 1-D trajectory that minimizes jerk (3rd time-derivative of position). A minimum jerk trajectory is considered \"smooth\" and to be a feature of natural limb movements. https://storage.googleapis.com/wzukusers/user-31382847/documents/5a7253343814f4Iv6Hnt/minimumjerk.pdf A minimum-jerk trajectory is defined by: trajectory = a0 + (af - a0) * (10(dx^3) - 15(dx^4) + 6(dx^5)) where a0 is the resting position, and af is the finishing position. duration is assumed to be the extent of x but it may be overidden. Parameters: Name Type Description Default x ndarray required a0 0 af 1 degree 1 duration float Total duration of x in seconds. If None (default), calculated duration from x. None Returns: Type Description ndarray a0 + (af - a0) * (10 (dx.^3) - 15 (dx.^4) + 6*(dx.^5)) Source code in indl/misc/sigfuncs.py def minimum_jerk ( x : np . ndarray , a0 = 0 , af = 1 , degree = 1 , duration = None ) -> np . ndarray : r \"\"\" A 1-D trajectory that minimizes jerk (3rd time-derivative of position). A minimum jerk trajectory is considered \"smooth\" and to be a feature of natural limb movements. https://storage.googleapis.com/wzukusers/user-31382847/documents/5a7253343814f4Iv6Hnt/minimumjerk.pdf A minimum-jerk trajectory is defined by: ```math trajectory = a0 + (af - a0) * (10(dx^3) - 15(dx^4) + 6(dx^5)) ``` where a0 is the resting position, and af is the finishing position. duration is assumed to be the extent of x but it may be overidden. Args: x: a0: af: degree: duration (float): Total duration of x in seconds. If None (default), calculated duration from x. Returns: a0 + (af - a0) * (10*(dx.^3) - 15*(dx.^4) + 6*(dx.^5)) \"\"\" x = np . array ( x )[:, None ] assert ( x . size == x . shape [ 0 ]), f \"x must be 1D trajectory, found { x . shape } \" a0 = np . atleast_2d ( a0 ) af = np . atleast_2d ( af ) if duration is None : sorted_x = np . sort ( x , axis = 0 ) dx = np . diff ( x , axis = 0 ) duration = sorted_x [ - 1 ] - sorted_x [ 0 ] + np . min ( dx ) dx = x / duration if degree not in [ 1 , 2 ]: # Default - no derivative k0 = a0 x1 = 10 * dx ** 3 x2 = - 15 * dx ** 4 x3 = 6 * dx ** 5 elif degree == 1 : # Velocity k0 = np . zeros_like ( a0 ) x1 = 30 * dx ** 2 x2 = - 60 * dx ** 3 x3 = 30 * dx ** 4 elif degree == 2 : # Acceleration k0 = np . zeros_like ( a0 ) x1 = 60 * dx x2 = - 180 * dx ** 2 x3 = 120 * dx ** 3 return k0 + ( af - a0 ) * ( x1 + x2 + x3 )","title":"minimum_jerk()"},{"location":"API/misc/#indl.misc.sigfuncs.sigmoid","text":"Returns f(x) = A + (K - A) / ((C + Q * np.exp(-B (x - x_offset))) *(1/v)) This is a generalized logistic function. The default arguments reduce this to a simple sigmoid: f(x) = 1 / (1 + np.exp(-x)) Parameters: Name Type Description Default x np.ndarray required A float 0 K float 1 C float 1 Q float 1 B float 1 v float 1 x_offset 0 Returns: Type Description np.ndarray A + (K - A) / ((C + Q * np.exp(-B (x - x_offset))) *(1/v)) Source code in indl/misc/sigfuncs.py def sigmoid ( x , A = 0 , K = 1 , C = 1 , Q = 1 , B = 1 , v = 1 , x_offset = 0 ): \"\"\" Returns f(x) = A + (K - A) / ((C + Q * np.exp(-B*(x - x_offset)))**(1/v)) This is a generalized logistic function. The default arguments reduce this to a simple sigmoid: f(x) = 1 / (1 + np.exp(-x)) Args: x (np.ndarray): A (float): K (float): C (float): Q (float): B (float): v (float): x_offset: Returns: np.ndarray: A + (K - A) / ((C + Q * np.exp(-B*(x - x_offset)))**(1/v)) \"\"\" y = A + ( K - A ) / (( C + Q * np . exp ( - B * ( x - x_offset ))) ** ( 1 / v )) return y","title":"sigmoid()"},{"location":"API/rnn/","text":"rnn generative GenerativeRNN ( RNN ) Generative RNN This is a wrapper around the normal RNN layer, except that it does not require an input. If an input is given, a time dimension will be added if not provided, and if the provided time dimension has length less than timesteps , it will be tile-padded with the last sample (or with zeros if tile_input=False ). If an input is not given, zeros input will be assumed; in that case the batch size may come from initial_state if provided. If neither the input nor the initial_state is provided then the batch size cannot be known, but the output would always be zeros anyway so this RNN is quite useless. If mask is provided, it is used to choose the last input sample from which the remaining input is tile-padded (or zero-padded). The output will not be masked. -Warning: mask has not been thoroughly tested. Parameters: Name Type Description Default cell recurrent cell instance instance. See tfkl.RNN for description. required timesteps integer number of timesteps to generate. 1 Args cell: timesteps: tile_input: **kwargs: required Source code in indl/rnn/generative.py class GenerativeRNN ( tfkl . RNN ): \"\"\" Generative RNN This is a wrapper around the normal RNN layer, except that it does not require an input. If an input is given, a time dimension will be added if not provided, and if the provided time dimension has length less than `timesteps`, it will be tile-padded with the last sample (or with zeros if `tile_input=False`). If an input is not given, zeros input will be assumed; in that case the batch size may come from initial_state if provided. If neither the input nor the initial_state is provided then the batch size cannot be known, but the output would always be zeros anyway so this RNN is quite useless. If mask is provided, it is used to choose the last input sample from which the remaining input is tile-padded (or zero-padded). The output will not be masked. -Warning: mask has not been thoroughly tested. Arguments: cell: recurrent cell instance instance. See tfkl.RNN for description. timesteps: integer number of timesteps to generate. See tfkl.RNN for other kwargs. Args: cell: timesteps: tile_input: **kwargs: \"\"\" def __init__ ( self , cell , timesteps = 1 , tile_input = False , # If True, it will tile the last input, else it will pad with zeros ** kwargs ): super () . __init__ ( cell , ** kwargs ) self . timesteps = timesteps self . tile_input = tile_input self . _input_has_time_dim = False self . _batch_dims : int = kwargs . pop ( 'batch_dims' , 1 ) self . _output_spec = None self . _built_with_input = False def _fixup_input_shape ( self , input_shape ): if input_shape is None : # We will make a fake input with feature length = 1 input_shape = ( None , 1 ) if isinstance ( input_shape , list ): input_shape = input_shape [ 0 ] # Check for a time dimension time_ax_ix = 0 if self . time_major else - 2 if len ( input_shape ) < 3 or input_shape [ time_ax_ix ] is None : # No time dimension provided. Add one. if self . time_major : input_shape = ( self . timesteps ,) + input_shape else : input_shape = input_shape [: - 1 ] + ( self . timesteps , input_shape [ - 1 ]) # Pretend that the time dimension has self.timesteps so that # the output gets calculated correctly. if input_shape [ time_ax_ix ] != self . timesteps : if self . time_major : input_shape = ( self . timesteps ,) + input_shape [ 1 :] else : input_shape = input_shape [: - 2 ] + ( self . timesteps , input_shape [ - 1 ]) return input_shape def get_config ( self ): config = super () . get_config () config [ 'timesteps' ] = self . timesteps return config def build_with_input ( self , inputs , * args , ** kwargs ): bd = self . _batch_dims # self._input_spec = [tf.nest.map_structure( # lambda x: tfkl.InputSpec(shape=[None] * bd + x.shape[bd:], dtype=x.dtype), inputs)] dummy_input = tf . nest . map_structure ( lambda t : tf . zeros ([ 2 ] * bd + t . shape [ bd :], t . dtype ), inputs ) dummy_output = super () . __call__ ( dummy_input , * args , ** kwargs ) self . _output_spec = tf . nest . map_structure ( lambda x : tfkl . InputSpec ( shape = [ None ] * bd + x . shape [ bd :], dtype = x . dtype ), dummy_output ) self . _built_with_input = True @property def output_spec ( self ): return self . _output_spec @output_spec . setter def output_spec ( self , value ): self . _output_spec = value @property def output_shape ( self ): assert self . output_spec is not None , 'build_with_input has not been called; output shape is not defined' return tf . nest . map_structure ( lambda x : x . shape , self . output_spec ) @property def output_dtype ( self ): assert self . output_spec is not None , 'build_with_input has not been called; output dtype is not defined' return tf . nest . map_structure ( lambda x : x . dtype , self . output_spec ) # @tf_utils.shape_type_conversion def compute_output_shape ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) if self . output_spec is None : return super () . compute_output_shape ( input_shape ) batch_shape = tf . nest . flatten ( input_shape )[ 0 ][: self . batch_dims ] return tf . nest . map_structure ( lambda x : batch_shape + x [ self . batch_dims :], self . output_shape ) def build ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) super () . build ( input_shape ) def __call__ ( self , * args , inputs = None , initial_state = None , constants = None , mask = None , ** kwargs ): inputs , initial_state , constants = _standardize_args ( inputs , initial_state , constants , self . _num_constants ) # We allow different shapes of input, even None. It doesn't really matter # because ultimately the input will be ignored except for the first step. # Nevertheless, we expand the input to have a timesteps dimension. This # is done simply for parent class calculations of output size, etc. # Allow None as an input. We will create an array of zeros of appropriate shape. if inputs is None : if initial_state is not None : # If LSTM then state might be a list. _state = initial_state [ 0 ] if isinstance ( initial_state , list ) else initial_state batch_size = _state . shape [: - 1 ] inputs = K . zeros_like ( _state [ ... , 0 ][ ... , tf . newaxis ]) # inputs = 0 * _state[..., 0][..., tf.newaxis] # Assume dim=1 input else : # Neither inputs nor initial_state provided. This likely only happens # when building/testing the layer. inputs = tf . zeros (( self . timesteps , 1 , 1 )) if self . time_major else tf . zeros (( 1 , self . timesteps , 1 )) # Allow 2D input, here reshape to 3D input if len ( K . int_shape ( inputs )) < 3 : if self . time_major : inputs = inputs [ tf . newaxis , ... ] else : inputs = inputs [ ... , tf . newaxis , :] time_ax_ix , batch_ax_ix = ( 0 , 1 ) if self . time_major else ( - 2 , 0 ) input_shape = K . int_shape ( inputs ) input_timesteps = input_shape [ time_ax_ix ] if mask is not None and K . any ( ~ mask ): mask = nest . flatten ( mask )[ 0 ] # We assume mask has a time dimension and require it is same size as input # (It doesn't make sense to use mask otherwise). mask_shape = K . int_shape ( mask ) # If the mask only has 1 item in the batch dim then tile it if mask_shape [ batch_ax_ix ] == 1 and input_shape [ batch_ax_ix ] > 1 : if self . time_major : bcast_or = tf . zeros (( 1 , input_shape [ batch_ax_ix ], 1 ), dtype = tf . bool ) else : bcast_or = tf . zeros (( input_shape [ batch_ax_ix ], 1 , 1 ), dtype = tf . bool ) mask = tf . math . logical_or ( mask , bcast_or ) if mask_shape [ time_ax_ix ] == input_timesteps : # Prepare slice parameters # For head (kept) h_sl_begin = [ 0 for _ in input_shape ] h_sl_sz = [ - 1 for _ in input_shape ] h_sl_sz [ batch_ax_ix ] = 1 # For tail (replaced) t_sl_begin = [ 0 for _ in input_shape ] t_sl_sz = [ - 1 for _ in input_shape ] t_sl_sz [ batch_ax_ix ] = 1 # Collect input replacements in list new_inputs = [] for batch_ix in range ( input_shape [ batch_ax_ix ]): samp_mask = mask [ ... , batch_ix , :] if self . time_major else mask [ batch_ix ] if K . any ( ~ samp_mask ): h_sl_begin [ batch_ax_ix ] = batch_ix t_sl_begin [ batch_ax_ix ] = batch_ix first_bad = tf . where ( ~ samp_mask )[ 0 , 0 ] h_sl_sz [ time_ax_ix ] = first_bad # sz is 1-based t_sl_begin [ time_ax_ix ] = first_bad head = tf . slice ( inputs , h_sl_begin , h_sl_sz ) tail = tf . slice ( inputs , t_sl_begin , t_sl_sz ) if self . tile_input : tile_samp = head [ - 1 ] if self . time_major else head [ ... , - 1 , :] else : tile_samp = tf . zeros (( 1 , input_shape [ - 1 ])) new_row = tf . concat (( head , tile_samp * K . ones_like ( tail )), axis = time_ax_ix ) new_inputs . append ( new_row ) inputs = tf . concat ( new_inputs , axis = batch_ax_ix ) # Fill/trim input time dimension to be self.timesteps if input_timesteps > self . timesteps : # Trim excess, if any inputs = inputs [: self . timesteps , ... ] if self . time_major else inputs [ ... , : self . timesteps , :] elif input_timesteps < self . timesteps : # Take the last timestep as our starting point for the padding data pad_sample = inputs [ - 1 ] if self . time_major else inputs [ ... , - 1 , :] if not self . tile_input : # zero out padding data if we aren't tiling pad_sample = K . zeros_like ( pad_sample ) # pad_sample = 0 * pad_sample # Add the time axis back to our pad_sample pad_sample = pad_sample [ tf . newaxis , ... ] if self . time_major else pad_sample [ ... , tf . newaxis , :] # How many more timestamps do we need? pad_timestamps = self . timesteps - K . int_shape ( inputs )[ time_ax_ix ] # Tile pad_data using broadcast-add. Does this same line work for time_major and not? pad_data = pad_sample + tf . zeros (( pad_timestamps , 1 )) inputs = tf . concat (( inputs , pad_data ), axis = time_ax_ix ) if not self . _built_with_input : self . build_with_input ( inputs , * args , initial_state = initial_state , constants = constants , mask = mask , ** kwargs ) return super () . __call__ ( inputs , initial_state = initial_state , constants = constants , ** kwargs ) output_shape property readonly Retrieves the output shape(s) of a layer. Only applicable if the layer has one output, or if all outputs have the same shape. Returns: Type Description Output shape, as an integer shape tuple (or list of shape tuples, one tuple per output tensor). Exceptions: Type Description AttributeError if the layer has no defined output shape. RuntimeError if called in Eager mode. build ( self , input_shape = None ) Creates the variables of the layer (optional, for subclass implementers). This is a method that implementers of subclasses of Layer or Model can override if they need a state-creation step in-between layer instantiation and layer call. This is typically used to create the weights of Layer subclasses. Parameters: Name Type Description Default input_shape Instance of TensorShape , or list of instances of TensorShape if the layer expects a list of inputs (one instance per input). None Source code in indl/rnn/generative.py def build ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) super () . build ( input_shape ) compute_output_shape ( self , input_shape = None ) Computes the output shape of the layer. If the layer has not been built, this method will call build on the layer. This assumes that the layer will later be used with inputs that match the input shape provided here. Parameters: Name Type Description Default input_shape Shape tuple (tuple of integers) or list of shape tuples (one per output tensor of the layer). Shape tuples can include None for free dimensions, instead of an integer. None Returns: Type Description An input shape tuple. Source code in indl/rnn/generative.py def compute_output_shape ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) if self . output_spec is None : return super () . compute_output_shape ( input_shape ) batch_shape = tf . nest . flatten ( input_shape )[ 0 ][: self . batch_dims ] return tf . nest . map_structure ( lambda x : batch_shape + x [ self . batch_dims :], self . output_shape ) get_config ( self ) Returns the config of the layer. A layer config is a Python dictionary (serializable) containing the configuration of a layer. The same layer can be reinstantiated later (without its trained weights) from this configuration. The config of a layer does not include connectivity information, nor the layer class name. These are handled by Network (one layer of abstraction above). Returns: Type Description Python dictionary. Source code in indl/rnn/generative.py def get_config ( self ): config = super () . get_config () config [ 'timesteps' ] = self . timesteps return config gru_clip GRUClipCell ( GRUCell ) Source code in indl/rnn/gru_clip.py class GRUClipCell ( tfkl . GRUCell ): # A couple differences between tfkl GRUCell and LFADS CustomGRU # * different variable names (this:LFADS) # - z:u; r:r; h:candidate # * stacking order. tfkl stacks z,r,h all in one : LFADS stacks r,u in '_gate' and c in '_candidate' # * tfkl recurrent_activation is param and defaults to hard_sigmoid : LFADS is always sigmoid def __init__ ( self , units , clip_value = np . inf , init_gate_bias_ones = True , ** kwargs ): super ( GRUClipCell , self ) . __init__ ( units , ** kwargs ) self . _clip_value = clip_value self . _init_gate_bias_ones = init_gate_bias_ones def build ( self , input_shape ): super ( GRUClipCell , self ) . build ( input_shape ) # * tfkl initializes all bias as zeros by default : LFADS inits gate's to ones and candidate's to zeros # * tfkl has separate input_bias and recurrent_bias : LFADS has recurrent_bias only if self . _init_gate_bias_ones : init_weights = self . get_weights () if not self . reset_after : init_weights [ 2 ][: 2 * self . units ] = 1. else : # separate biases for input and recurrent. We only modify recurrent. init_weights [ 2 ][ 1 ][: 2 * self . units ] = 1. self . set_weights ( init_weights ) def call ( self , inputs , states , training = None ): h , _ = super () . call ( inputs , states , training = training ) h = tf . clip_by_value ( h , - self . _clip_value , self . _clip_value ) new_state = [ h ] if nest . is_sequence ( states ) else h return h , new_state build ( self , input_shape ) Creates the variables of the layer (optional, for subclass implementers). This is a method that implementers of subclasses of Layer or Model can override if they need a state-creation step in-between layer instantiation and layer call. This is typically used to create the weights of Layer subclasses. Parameters: Name Type Description Default input_shape Instance of TensorShape , or list of instances of TensorShape if the layer expects a list of inputs (one instance per input). required Source code in indl/rnn/gru_clip.py def build ( self , input_shape ): super ( GRUClipCell , self ) . build ( input_shape ) # * tfkl initializes all bias as zeros by default : LFADS inits gate's to ones and candidate's to zeros # * tfkl has separate input_bias and recurrent_bias : LFADS has recurrent_bias only if self . _init_gate_bias_ones : init_weights = self . get_weights () if not self . reset_after : init_weights [ 2 ][: 2 * self . units ] = 1. else : # separate biases for input and recurrent. We only modify recurrent. init_weights [ 2 ][ 1 ][: 2 * self . units ] = 1. self . set_weights ( init_weights ) call ( self , inputs , states , training = None ) This is where the layer's logic lives. Note here that call() method in tf.keras is little bit different from keras API. In keras API, you can pass support masking for layers as additional arguments. Whereas tf.keras has compute_mask() method to support masking. Parameters: Name Type Description Default inputs Input tensor, or list/tuple of input tensors. required **kwargs Additional keyword arguments. Currently unused. required Returns: Type Description A tensor or list/tuple of tensors. Source code in indl/rnn/gru_clip.py def call ( self , inputs , states , training = None ): h , _ = super () . call ( inputs , states , training = training ) h = tf . clip_by_value ( h , - self . _clip_value , self . _clip_value ) new_state = [ h ] if nest . is_sequence ( states ) else h return h , new_state","title":"rnn"},{"location":"API/rnn/#rnn","text":"","title":"rnn"},{"location":"API/rnn/#indl.rnn.generative","text":"","title":"generative"},{"location":"API/rnn/#indl.rnn.generative.GenerativeRNN","text":"Generative RNN This is a wrapper around the normal RNN layer, except that it does not require an input. If an input is given, a time dimension will be added if not provided, and if the provided time dimension has length less than timesteps , it will be tile-padded with the last sample (or with zeros if tile_input=False ). If an input is not given, zeros input will be assumed; in that case the batch size may come from initial_state if provided. If neither the input nor the initial_state is provided then the batch size cannot be known, but the output would always be zeros anyway so this RNN is quite useless. If mask is provided, it is used to choose the last input sample from which the remaining input is tile-padded (or zero-padded). The output will not be masked. -Warning: mask has not been thoroughly tested. Parameters: Name Type Description Default cell recurrent cell instance instance. See tfkl.RNN for description. required timesteps integer number of timesteps to generate. 1 Args cell: timesteps: tile_input: **kwargs: required Source code in indl/rnn/generative.py class GenerativeRNN ( tfkl . RNN ): \"\"\" Generative RNN This is a wrapper around the normal RNN layer, except that it does not require an input. If an input is given, a time dimension will be added if not provided, and if the provided time dimension has length less than `timesteps`, it will be tile-padded with the last sample (or with zeros if `tile_input=False`). If an input is not given, zeros input will be assumed; in that case the batch size may come from initial_state if provided. If neither the input nor the initial_state is provided then the batch size cannot be known, but the output would always be zeros anyway so this RNN is quite useless. If mask is provided, it is used to choose the last input sample from which the remaining input is tile-padded (or zero-padded). The output will not be masked. -Warning: mask has not been thoroughly tested. Arguments: cell: recurrent cell instance instance. See tfkl.RNN for description. timesteps: integer number of timesteps to generate. See tfkl.RNN for other kwargs. Args: cell: timesteps: tile_input: **kwargs: \"\"\" def __init__ ( self , cell , timesteps = 1 , tile_input = False , # If True, it will tile the last input, else it will pad with zeros ** kwargs ): super () . __init__ ( cell , ** kwargs ) self . timesteps = timesteps self . tile_input = tile_input self . _input_has_time_dim = False self . _batch_dims : int = kwargs . pop ( 'batch_dims' , 1 ) self . _output_spec = None self . _built_with_input = False def _fixup_input_shape ( self , input_shape ): if input_shape is None : # We will make a fake input with feature length = 1 input_shape = ( None , 1 ) if isinstance ( input_shape , list ): input_shape = input_shape [ 0 ] # Check for a time dimension time_ax_ix = 0 if self . time_major else - 2 if len ( input_shape ) < 3 or input_shape [ time_ax_ix ] is None : # No time dimension provided. Add one. if self . time_major : input_shape = ( self . timesteps ,) + input_shape else : input_shape = input_shape [: - 1 ] + ( self . timesteps , input_shape [ - 1 ]) # Pretend that the time dimension has self.timesteps so that # the output gets calculated correctly. if input_shape [ time_ax_ix ] != self . timesteps : if self . time_major : input_shape = ( self . timesteps ,) + input_shape [ 1 :] else : input_shape = input_shape [: - 2 ] + ( self . timesteps , input_shape [ - 1 ]) return input_shape def get_config ( self ): config = super () . get_config () config [ 'timesteps' ] = self . timesteps return config def build_with_input ( self , inputs , * args , ** kwargs ): bd = self . _batch_dims # self._input_spec = [tf.nest.map_structure( # lambda x: tfkl.InputSpec(shape=[None] * bd + x.shape[bd:], dtype=x.dtype), inputs)] dummy_input = tf . nest . map_structure ( lambda t : tf . zeros ([ 2 ] * bd + t . shape [ bd :], t . dtype ), inputs ) dummy_output = super () . __call__ ( dummy_input , * args , ** kwargs ) self . _output_spec = tf . nest . map_structure ( lambda x : tfkl . InputSpec ( shape = [ None ] * bd + x . shape [ bd :], dtype = x . dtype ), dummy_output ) self . _built_with_input = True @property def output_spec ( self ): return self . _output_spec @output_spec . setter def output_spec ( self , value ): self . _output_spec = value @property def output_shape ( self ): assert self . output_spec is not None , 'build_with_input has not been called; output shape is not defined' return tf . nest . map_structure ( lambda x : x . shape , self . output_spec ) @property def output_dtype ( self ): assert self . output_spec is not None , 'build_with_input has not been called; output dtype is not defined' return tf . nest . map_structure ( lambda x : x . dtype , self . output_spec ) # @tf_utils.shape_type_conversion def compute_output_shape ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) if self . output_spec is None : return super () . compute_output_shape ( input_shape ) batch_shape = tf . nest . flatten ( input_shape )[ 0 ][: self . batch_dims ] return tf . nest . map_structure ( lambda x : batch_shape + x [ self . batch_dims :], self . output_shape ) def build ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) super () . build ( input_shape ) def __call__ ( self , * args , inputs = None , initial_state = None , constants = None , mask = None , ** kwargs ): inputs , initial_state , constants = _standardize_args ( inputs , initial_state , constants , self . _num_constants ) # We allow different shapes of input, even None. It doesn't really matter # because ultimately the input will be ignored except for the first step. # Nevertheless, we expand the input to have a timesteps dimension. This # is done simply for parent class calculations of output size, etc. # Allow None as an input. We will create an array of zeros of appropriate shape. if inputs is None : if initial_state is not None : # If LSTM then state might be a list. _state = initial_state [ 0 ] if isinstance ( initial_state , list ) else initial_state batch_size = _state . shape [: - 1 ] inputs = K . zeros_like ( _state [ ... , 0 ][ ... , tf . newaxis ]) # inputs = 0 * _state[..., 0][..., tf.newaxis] # Assume dim=1 input else : # Neither inputs nor initial_state provided. This likely only happens # when building/testing the layer. inputs = tf . zeros (( self . timesteps , 1 , 1 )) if self . time_major else tf . zeros (( 1 , self . timesteps , 1 )) # Allow 2D input, here reshape to 3D input if len ( K . int_shape ( inputs )) < 3 : if self . time_major : inputs = inputs [ tf . newaxis , ... ] else : inputs = inputs [ ... , tf . newaxis , :] time_ax_ix , batch_ax_ix = ( 0 , 1 ) if self . time_major else ( - 2 , 0 ) input_shape = K . int_shape ( inputs ) input_timesteps = input_shape [ time_ax_ix ] if mask is not None and K . any ( ~ mask ): mask = nest . flatten ( mask )[ 0 ] # We assume mask has a time dimension and require it is same size as input # (It doesn't make sense to use mask otherwise). mask_shape = K . int_shape ( mask ) # If the mask only has 1 item in the batch dim then tile it if mask_shape [ batch_ax_ix ] == 1 and input_shape [ batch_ax_ix ] > 1 : if self . time_major : bcast_or = tf . zeros (( 1 , input_shape [ batch_ax_ix ], 1 ), dtype = tf . bool ) else : bcast_or = tf . zeros (( input_shape [ batch_ax_ix ], 1 , 1 ), dtype = tf . bool ) mask = tf . math . logical_or ( mask , bcast_or ) if mask_shape [ time_ax_ix ] == input_timesteps : # Prepare slice parameters # For head (kept) h_sl_begin = [ 0 for _ in input_shape ] h_sl_sz = [ - 1 for _ in input_shape ] h_sl_sz [ batch_ax_ix ] = 1 # For tail (replaced) t_sl_begin = [ 0 for _ in input_shape ] t_sl_sz = [ - 1 for _ in input_shape ] t_sl_sz [ batch_ax_ix ] = 1 # Collect input replacements in list new_inputs = [] for batch_ix in range ( input_shape [ batch_ax_ix ]): samp_mask = mask [ ... , batch_ix , :] if self . time_major else mask [ batch_ix ] if K . any ( ~ samp_mask ): h_sl_begin [ batch_ax_ix ] = batch_ix t_sl_begin [ batch_ax_ix ] = batch_ix first_bad = tf . where ( ~ samp_mask )[ 0 , 0 ] h_sl_sz [ time_ax_ix ] = first_bad # sz is 1-based t_sl_begin [ time_ax_ix ] = first_bad head = tf . slice ( inputs , h_sl_begin , h_sl_sz ) tail = tf . slice ( inputs , t_sl_begin , t_sl_sz ) if self . tile_input : tile_samp = head [ - 1 ] if self . time_major else head [ ... , - 1 , :] else : tile_samp = tf . zeros (( 1 , input_shape [ - 1 ])) new_row = tf . concat (( head , tile_samp * K . ones_like ( tail )), axis = time_ax_ix ) new_inputs . append ( new_row ) inputs = tf . concat ( new_inputs , axis = batch_ax_ix ) # Fill/trim input time dimension to be self.timesteps if input_timesteps > self . timesteps : # Trim excess, if any inputs = inputs [: self . timesteps , ... ] if self . time_major else inputs [ ... , : self . timesteps , :] elif input_timesteps < self . timesteps : # Take the last timestep as our starting point for the padding data pad_sample = inputs [ - 1 ] if self . time_major else inputs [ ... , - 1 , :] if not self . tile_input : # zero out padding data if we aren't tiling pad_sample = K . zeros_like ( pad_sample ) # pad_sample = 0 * pad_sample # Add the time axis back to our pad_sample pad_sample = pad_sample [ tf . newaxis , ... ] if self . time_major else pad_sample [ ... , tf . newaxis , :] # How many more timestamps do we need? pad_timestamps = self . timesteps - K . int_shape ( inputs )[ time_ax_ix ] # Tile pad_data using broadcast-add. Does this same line work for time_major and not? pad_data = pad_sample + tf . zeros (( pad_timestamps , 1 )) inputs = tf . concat (( inputs , pad_data ), axis = time_ax_ix ) if not self . _built_with_input : self . build_with_input ( inputs , * args , initial_state = initial_state , constants = constants , mask = mask , ** kwargs ) return super () . __call__ ( inputs , initial_state = initial_state , constants = constants , ** kwargs )","title":"GenerativeRNN"},{"location":"API/rnn/#indl.rnn.generative.GenerativeRNN.output_shape","text":"Retrieves the output shape(s) of a layer. Only applicable if the layer has one output, or if all outputs have the same shape. Returns: Type Description Output shape, as an integer shape tuple (or list of shape tuples, one tuple per output tensor). Exceptions: Type Description AttributeError if the layer has no defined output shape. RuntimeError if called in Eager mode.","title":"output_shape"},{"location":"API/rnn/#indl.rnn.generative.GenerativeRNN.build","text":"Creates the variables of the layer (optional, for subclass implementers). This is a method that implementers of subclasses of Layer or Model can override if they need a state-creation step in-between layer instantiation and layer call. This is typically used to create the weights of Layer subclasses. Parameters: Name Type Description Default input_shape Instance of TensorShape , or list of instances of TensorShape if the layer expects a list of inputs (one instance per input). None Source code in indl/rnn/generative.py def build ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) super () . build ( input_shape )","title":"build()"},{"location":"API/rnn/#indl.rnn.generative.GenerativeRNN.compute_output_shape","text":"Computes the output shape of the layer. If the layer has not been built, this method will call build on the layer. This assumes that the layer will later be used with inputs that match the input shape provided here. Parameters: Name Type Description Default input_shape Shape tuple (tuple of integers) or list of shape tuples (one per output tensor of the layer). Shape tuples can include None for free dimensions, instead of an integer. None Returns: Type Description An input shape tuple. Source code in indl/rnn/generative.py def compute_output_shape ( self , input_shape = None ): input_shape = self . _fixup_input_shape ( input_shape ) if self . output_spec is None : return super () . compute_output_shape ( input_shape ) batch_shape = tf . nest . flatten ( input_shape )[ 0 ][: self . batch_dims ] return tf . nest . map_structure ( lambda x : batch_shape + x [ self . batch_dims :], self . output_shape )","title":"compute_output_shape()"},{"location":"API/rnn/#indl.rnn.generative.GenerativeRNN.get_config","text":"Returns the config of the layer. A layer config is a Python dictionary (serializable) containing the configuration of a layer. The same layer can be reinstantiated later (without its trained weights) from this configuration. The config of a layer does not include connectivity information, nor the layer class name. These are handled by Network (one layer of abstraction above). Returns: Type Description Python dictionary. Source code in indl/rnn/generative.py def get_config ( self ): config = super () . get_config () config [ 'timesteps' ] = self . timesteps return config","title":"get_config()"},{"location":"API/rnn/#indl.rnn.gru_clip","text":"","title":"gru_clip"},{"location":"API/rnn/#indl.rnn.gru_clip.GRUClipCell","text":"Source code in indl/rnn/gru_clip.py class GRUClipCell ( tfkl . GRUCell ): # A couple differences between tfkl GRUCell and LFADS CustomGRU # * different variable names (this:LFADS) # - z:u; r:r; h:candidate # * stacking order. tfkl stacks z,r,h all in one : LFADS stacks r,u in '_gate' and c in '_candidate' # * tfkl recurrent_activation is param and defaults to hard_sigmoid : LFADS is always sigmoid def __init__ ( self , units , clip_value = np . inf , init_gate_bias_ones = True , ** kwargs ): super ( GRUClipCell , self ) . __init__ ( units , ** kwargs ) self . _clip_value = clip_value self . _init_gate_bias_ones = init_gate_bias_ones def build ( self , input_shape ): super ( GRUClipCell , self ) . build ( input_shape ) # * tfkl initializes all bias as zeros by default : LFADS inits gate's to ones and candidate's to zeros # * tfkl has separate input_bias and recurrent_bias : LFADS has recurrent_bias only if self . _init_gate_bias_ones : init_weights = self . get_weights () if not self . reset_after : init_weights [ 2 ][: 2 * self . units ] = 1. else : # separate biases for input and recurrent. We only modify recurrent. init_weights [ 2 ][ 1 ][: 2 * self . units ] = 1. self . set_weights ( init_weights ) def call ( self , inputs , states , training = None ): h , _ = super () . call ( inputs , states , training = training ) h = tf . clip_by_value ( h , - self . _clip_value , self . _clip_value ) new_state = [ h ] if nest . is_sequence ( states ) else h return h , new_state","title":"GRUClipCell"},{"location":"API/rnn/#indl.rnn.gru_clip.GRUClipCell.build","text":"Creates the variables of the layer (optional, for subclass implementers). This is a method that implementers of subclasses of Layer or Model can override if they need a state-creation step in-between layer instantiation and layer call. This is typically used to create the weights of Layer subclasses. Parameters: Name Type Description Default input_shape Instance of TensorShape , or list of instances of TensorShape if the layer expects a list of inputs (one instance per input). required Source code in indl/rnn/gru_clip.py def build ( self , input_shape ): super ( GRUClipCell , self ) . build ( input_shape ) # * tfkl initializes all bias as zeros by default : LFADS inits gate's to ones and candidate's to zeros # * tfkl has separate input_bias and recurrent_bias : LFADS has recurrent_bias only if self . _init_gate_bias_ones : init_weights = self . get_weights () if not self . reset_after : init_weights [ 2 ][: 2 * self . units ] = 1. else : # separate biases for input and recurrent. We only modify recurrent. init_weights [ 2 ][ 1 ][: 2 * self . units ] = 1. self . set_weights ( init_weights )","title":"build()"},{"location":"API/rnn/#indl.rnn.gru_clip.GRUClipCell.call","text":"This is where the layer's logic lives. Note here that call() method in tf.keras is little bit different from keras API. In keras API, you can pass support masking for layers as additional arguments. Whereas tf.keras has compute_mask() method to support masking. Parameters: Name Type Description Default inputs Input tensor, or list/tuple of input tensors. required **kwargs Additional keyword arguments. Currently unused. required Returns: Type Description A tensor or list/tuple of tensors. Source code in indl/rnn/gru_clip.py def call ( self , inputs , states , training = None ): h , _ = super () . call ( inputs , states , training = training ) h = tf . clip_by_value ( h , - self . _clip_value , self . _clip_value ) new_state = [ h ] if nest . is_sequence ( states ) else h return h , new_state","title":"call()"},{"location":"API/utils/","text":"utils fileio from_neuropype_h5 ( filename , chunk_names = []) Import a Neuropype-exported HDF5 file. Parameters: Name Type Description Default filename str Name of file on disk. Opened with h5py.File. required chunk_names List[str] Limit return to a subset of the chunks in the data file. [] Returns: Type Description List[Tuple[str, dict]] A list of (name, chunk_dict) tuples. Source code in indl/utils/fileio.py def from_neuropype_h5 ( filename : str , chunk_names : List [ str ] = []) -> List [ Tuple [ str , dict ]]: \"\"\" Import a Neuropype-exported HDF5 file. Args: filename: Name of file on disk. Opened with h5py.File. chunk_names: Limit return to a subset of the chunks in the data file. Returns: A list of (name, chunk_dict) tuples. \"\"\" import numpy as np import h5py from pandas import DataFrame f = h5py . File ( filename , 'r' ) chunks = [] if 'chunks' in f . keys (): chunks_group = f [ 'chunks' ] ch_keys = [ _ for _ in chunks_group . keys () if _ in chunk_names ] for ch_key in ch_keys : chunk_group = chunks_group . get ( ch_key ) # Process data block_group = chunk_group . get ( 'block' ) data_ = block_group . get ( 'data' ) if isinstance ( data_ , h5py . Dataset ): data = data_ [()] else : # Data is a group. This only happens with sparse matrices. import scipy.sparse data = scipy . sparse . csr_matrix (( data_ [ 'data' ][:], data_ [ 'indices' ][:], data_ [ 'indptr' ][:]), data_ . attrs [ 'shape' ]) axes_group = block_group . get ( 'axes' ) axes = [] for ax_ix , axis_key in enumerate ( axes_group . keys ()): axis_group = axes_group . get ( axis_key ) ax_type = axis_group . attrs . get ( 'type' ) new_ax = { 'name' : axis_key , 'type' : ax_type } if ax_type == 'axis' : new_ax . update ( dict ( x = np . arange ( data . shape [ ax_ix ]))) elif ax_type == 'time' : nom_rate = axis_group . attrs . get ( 'nominal_rate' ) if np . isnan ( nom_rate ): nom_rate = None new_ax . update ( dict ( nominal_rate = nom_rate , times = axis_group . get ( 'times' )[()])) elif ax_type == 'frequency' : new_ax . update ( dict ( frequencies = axis_group . get ( 'frequencies' )[()])) elif ax_type == 'space' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], naming_system = axis_group . attrs [ 'naming_system' ], positions = axis_group . get ( 'positions' )[()], coordinate_system = axis_group . attrs [ 'coordinate_system' ], units = axis_group . get ( 'units' )[()])) elif ax_type == 'feature' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], units = axis_group . get ( 'units' )[()], properties = axis_group . get ( 'properties' )[()], error_distrib = axis_group . get ( 'error_distrib' )[()], sampling_distrib = axis_group . get ( 'sampling_distrib' )[()])) elif ax_type == 'instance' : new_ax . update ({ 'times' : axis_group . get ( 'times' )[()]}) if 'instance_type' in axis_group . attrs : new_ax . update ({ 'instance_type' : axis_group . attrs [ 'instance_type' ]}) _dat = axis_group . get ( 'data' )[()] if not _dat . dtype . names : new_ax . update ({ 'data' : axis_group . get ( 'data' )[()]}) else : _df = DataFrame ( _dat ) # Convert binary objects to string objects str_df = _df . select_dtypes ([ np . object ]) str_df = str_df . stack () . str . decode ( 'utf-8' ) . unstack () for col in str_df : _df [ col ] = str_df [ col ] new_ax . update ({ 'data' : _df }) elif ax_type == 'statistic' : new_ax . update ( dict ( param_types = axis_group . get ( 'param_types' )[()])) elif ax_type == 'lag' : new_ax . update ( dict ( xlags = axis_group . get ( 'lags' )[()])) if new_ax is not None : axes . append ( new_ax ) chunks . append (( ch_key , dict ( data = data , axes = axes , props = _recurse_get_dict_from_group ( chunk_group . get ( 'props' ))))) return chunks metrics dprime ( y_true , y_pred , pmarg = 0.01 , outputs = [ 'dprime' , 'bias' , 'accuracy' ]) Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Parameters: Name Type Description Default y_true array-like True labels. required y_pred array-like Predicted labels. required pmarg float 0.01 outputs List[str] list of outputs among 'dprime', 'bias', 'accuracy' ['dprime', 'bias', 'accuracy'] Returns: Type Description tuple Calculated d-prime value. Source code in indl/utils/metrics.py def dprime ( y_true , y_pred , pmarg : float = 0.01 , outputs : List [ str ] = [ 'dprime' , 'bias' , 'accuracy' ]) -> tuple : \"\"\" Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Args: y_true (array-like): True labels. y_pred (array-like): Predicted labels. pmarg: outputs: list of outputs among 'dprime', 'bias', 'accuracy' Returns: Calculated d-prime value. \"\"\" import numpy as np from scipy.stats import norm # TODO: Adapt this function for tensorflow # y_pred = ops.convert_to_tensor(y_pred) # y_true = math_ops.cast(y_true, y_pred.dtype) # return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1) # TODO: Check that true_y only has 2 classes, and test_y is entirely within true_y classes. b_true = y_pred == y_true b_pos = np . unique ( y_true , return_inverse = True )[ 1 ] . astype ( bool ) true_pos = np . sum ( np . logical_and ( b_true , b_pos )) true_neg = np . sum ( np . logical_and ( b_true , ~ b_pos )) false_pos = np . sum ( np . logical_and ( ~ b_true , b_pos )) false_neg = np . sum ( np . logical_and ( ~ b_true , ~ b_pos )) tpr = true_pos / ( true_pos + false_neg ) tpr = max ( pmarg , min ( tpr , 1 - pmarg )) fpr = false_pos / ( false_pos + true_neg ) fpr = max ( pmarg , min ( fpr , 1 - pmarg )) ztpr = norm . ppf ( tpr , loc = 0 , scale = 1 ) zfpr = norm . ppf ( fpr , loc = 0 , scale = 1 ) # Other measures of performance: # sens = tp ./ (tp+fp) # spec = tn ./ (tn+fn) # balAcc = (sens+spec)/2 # informedness = sens+spec-1 output = tuple () for out in outputs : if out == 'dprime' : dprime = ztpr - zfpr output += ( dprime ,) elif out == 'bias' : bias = - ( ztpr + zfpr ) / 2 output += ( bias ,) elif out == 'accuracy' : accuracy = 100 * ( true_pos + true_neg ) / ( true_pos + false_pos + false_neg + true_neg ) output += ( accuracy ,) return output quickplot_history ( history ) A little helper function to do a quick plot of model fit results. Parameters: Name Type Description Default history tf.keras History required Source code in indl/utils/metrics.py def quickplot_history ( history ) -> None : \"\"\" A little helper function to do a quick plot of model fit results. Args: history (tf.keras History): \"\"\" import matplotlib.pyplot as plt if hasattr ( history , 'history' ): history = history . history hist_metrics = [ _ for _ in history . keys () if not _ . startswith ( 'val_' )] for m_ix , m in enumerate ( hist_metrics ): plt . subplot ( len ( hist_metrics ), 1 , m_ix + 1 ) plt . plot ( history [ m ], label = 'Train' ) plt . plot ( history [ 'val_' + m ], label = 'Valid.' ) plt . xlabel ( 'Epoch' ) plt . ylabel ( m ) plt . legend () plt . tight_layout () plt . show () regularizers KernelLengthRegularizer ( Regularizer ) Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). Source code in indl/utils/regularizers.py class KernelLengthRegularizer ( tf . keras . regularizers . Regularizer ): \"\"\" Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). \"\"\" def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window () def rebuild_window ( self ): windows = [] for win_dim , win_len in enumerate ( self . kernel_size ): if win_len == 1 : window = np . ones (( 1 ,), dtype = np . float32 ) else : if self . window_func == 'hann' : window = 1 - tf . signal . hann_window ( win_len , periodic = False ) elif self . window_func == 'hamming' : window = 1 - tf . signal . hamming_window ( win_len , periodic = False ) else : # if window_func == 'linear': hl = win_len // 2 window = np . zeros (( win_len ,), dtype = np . float32 ) window [: hl ] = np . arange ( 1 , hl + 1 )[:: - 1 ] # Negative slope line to 0 for first half. window [ - hl :] = np . arange ( 1 , hl + 1 ) # Positive slope line from 0 for second half. window = window / hl # Scale so it's -1 -- 0 -- 1 window = window ** self . poly_exp # Exponent win_shape = [ 1 ] * ( len ( self . kernel_size ) + 2 ) win_shape [ win_dim ] = win_len window = tf . reshape ( window , win_shape ) windows . append ( window ) self . window = tf . linalg . matmul ( * windows ) self . window = self . window / tf . reduce_max ( self . window ) def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold } def __call__ ( self , weights ): weights = tf . sqrt ( tf . square ( weights )) # Differentiable abs # non_zero = tf.cast(weights > self.threshold, tf.float32) non_zero = tf . nn . sigmoid ( weights - self . threshold ) regularization = self . window_scale * self . window * non_zero # regularization = tf.reduce_max(regularization, axis=[0, 1], keepdims=True) regularization = tf . reduce_sum ( regularization ) return regularization __init__ ( self , kernel_size , window_scale = 0.01 , window_func = 'poly' , poly_exp = 2 , threshold = 1e-07 ) special Parameters: Name Type Description Default kernel_size Iterable[int] length(s) of kernel(s) required window_scale float scale factor to apply to window 0.01 window_func str 'hann', 'hamming', 'poly' (default) 'poly' poly_exp int exponent used when window_func=='poly' 2 threshold float weight threshold, below which weights will not be penalized. 1e-07 Source code in indl/utils/regularizers.py def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window () get_config ( self ) Returns the config of the regularizer. An regularizer config is a Python dictionary (serializable) containing all configuration parameters of the regularizer. The same regularizer can be reinstantiated later (without any saved state) from this configuration. This method is optional if you are just training and executing models, exporting to and from SavedModels, or using weight checkpoints. This method is required for Keras model_to_estimator , saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON. Returns: Type Description dict Python dictionary. Source code in indl/utils/regularizers.py def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold }","title":"utils"},{"location":"API/utils/#utils","text":"","title":"utils"},{"location":"API/utils/#indl.utils.fileio","text":"","title":"fileio"},{"location":"API/utils/#indl.utils.fileio.from_neuropype_h5","text":"Import a Neuropype-exported HDF5 file. Parameters: Name Type Description Default filename str Name of file on disk. Opened with h5py.File. required chunk_names List[str] Limit return to a subset of the chunks in the data file. [] Returns: Type Description List[Tuple[str, dict]] A list of (name, chunk_dict) tuples. Source code in indl/utils/fileio.py def from_neuropype_h5 ( filename : str , chunk_names : List [ str ] = []) -> List [ Tuple [ str , dict ]]: \"\"\" Import a Neuropype-exported HDF5 file. Args: filename: Name of file on disk. Opened with h5py.File. chunk_names: Limit return to a subset of the chunks in the data file. Returns: A list of (name, chunk_dict) tuples. \"\"\" import numpy as np import h5py from pandas import DataFrame f = h5py . File ( filename , 'r' ) chunks = [] if 'chunks' in f . keys (): chunks_group = f [ 'chunks' ] ch_keys = [ _ for _ in chunks_group . keys () if _ in chunk_names ] for ch_key in ch_keys : chunk_group = chunks_group . get ( ch_key ) # Process data block_group = chunk_group . get ( 'block' ) data_ = block_group . get ( 'data' ) if isinstance ( data_ , h5py . Dataset ): data = data_ [()] else : # Data is a group. This only happens with sparse matrices. import scipy.sparse data = scipy . sparse . csr_matrix (( data_ [ 'data' ][:], data_ [ 'indices' ][:], data_ [ 'indptr' ][:]), data_ . attrs [ 'shape' ]) axes_group = block_group . get ( 'axes' ) axes = [] for ax_ix , axis_key in enumerate ( axes_group . keys ()): axis_group = axes_group . get ( axis_key ) ax_type = axis_group . attrs . get ( 'type' ) new_ax = { 'name' : axis_key , 'type' : ax_type } if ax_type == 'axis' : new_ax . update ( dict ( x = np . arange ( data . shape [ ax_ix ]))) elif ax_type == 'time' : nom_rate = axis_group . attrs . get ( 'nominal_rate' ) if np . isnan ( nom_rate ): nom_rate = None new_ax . update ( dict ( nominal_rate = nom_rate , times = axis_group . get ( 'times' )[()])) elif ax_type == 'frequency' : new_ax . update ( dict ( frequencies = axis_group . get ( 'frequencies' )[()])) elif ax_type == 'space' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], naming_system = axis_group . attrs [ 'naming_system' ], positions = axis_group . get ( 'positions' )[()], coordinate_system = axis_group . attrs [ 'coordinate_system' ], units = axis_group . get ( 'units' )[()])) elif ax_type == 'feature' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], units = axis_group . get ( 'units' )[()], properties = axis_group . get ( 'properties' )[()], error_distrib = axis_group . get ( 'error_distrib' )[()], sampling_distrib = axis_group . get ( 'sampling_distrib' )[()])) elif ax_type == 'instance' : new_ax . update ({ 'times' : axis_group . get ( 'times' )[()]}) if 'instance_type' in axis_group . attrs : new_ax . update ({ 'instance_type' : axis_group . attrs [ 'instance_type' ]}) _dat = axis_group . get ( 'data' )[()] if not _dat . dtype . names : new_ax . update ({ 'data' : axis_group . get ( 'data' )[()]}) else : _df = DataFrame ( _dat ) # Convert binary objects to string objects str_df = _df . select_dtypes ([ np . object ]) str_df = str_df . stack () . str . decode ( 'utf-8' ) . unstack () for col in str_df : _df [ col ] = str_df [ col ] new_ax . update ({ 'data' : _df }) elif ax_type == 'statistic' : new_ax . update ( dict ( param_types = axis_group . get ( 'param_types' )[()])) elif ax_type == 'lag' : new_ax . update ( dict ( xlags = axis_group . get ( 'lags' )[()])) if new_ax is not None : axes . append ( new_ax ) chunks . append (( ch_key , dict ( data = data , axes = axes , props = _recurse_get_dict_from_group ( chunk_group . get ( 'props' ))))) return chunks","title":"from_neuropype_h5()"},{"location":"API/utils/#indl.utils.metrics","text":"","title":"metrics"},{"location":"API/utils/#indl.utils.metrics.dprime","text":"Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Parameters: Name Type Description Default y_true array-like True labels. required y_pred array-like Predicted labels. required pmarg float 0.01 outputs List[str] list of outputs among 'dprime', 'bias', 'accuracy' ['dprime', 'bias', 'accuracy'] Returns: Type Description tuple Calculated d-prime value. Source code in indl/utils/metrics.py def dprime ( y_true , y_pred , pmarg : float = 0.01 , outputs : List [ str ] = [ 'dprime' , 'bias' , 'accuracy' ]) -> tuple : \"\"\" Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Args: y_true (array-like): True labels. y_pred (array-like): Predicted labels. pmarg: outputs: list of outputs among 'dprime', 'bias', 'accuracy' Returns: Calculated d-prime value. \"\"\" import numpy as np from scipy.stats import norm # TODO: Adapt this function for tensorflow # y_pred = ops.convert_to_tensor(y_pred) # y_true = math_ops.cast(y_true, y_pred.dtype) # return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1) # TODO: Check that true_y only has 2 classes, and test_y is entirely within true_y classes. b_true = y_pred == y_true b_pos = np . unique ( y_true , return_inverse = True )[ 1 ] . astype ( bool ) true_pos = np . sum ( np . logical_and ( b_true , b_pos )) true_neg = np . sum ( np . logical_and ( b_true , ~ b_pos )) false_pos = np . sum ( np . logical_and ( ~ b_true , b_pos )) false_neg = np . sum ( np . logical_and ( ~ b_true , ~ b_pos )) tpr = true_pos / ( true_pos + false_neg ) tpr = max ( pmarg , min ( tpr , 1 - pmarg )) fpr = false_pos / ( false_pos + true_neg ) fpr = max ( pmarg , min ( fpr , 1 - pmarg )) ztpr = norm . ppf ( tpr , loc = 0 , scale = 1 ) zfpr = norm . ppf ( fpr , loc = 0 , scale = 1 ) # Other measures of performance: # sens = tp ./ (tp+fp) # spec = tn ./ (tn+fn) # balAcc = (sens+spec)/2 # informedness = sens+spec-1 output = tuple () for out in outputs : if out == 'dprime' : dprime = ztpr - zfpr output += ( dprime ,) elif out == 'bias' : bias = - ( ztpr + zfpr ) / 2 output += ( bias ,) elif out == 'accuracy' : accuracy = 100 * ( true_pos + true_neg ) / ( true_pos + false_pos + false_neg + true_neg ) output += ( accuracy ,) return output","title":"dprime()"},{"location":"API/utils/#indl.utils.metrics.quickplot_history","text":"A little helper function to do a quick plot of model fit results. Parameters: Name Type Description Default history tf.keras History required Source code in indl/utils/metrics.py def quickplot_history ( history ) -> None : \"\"\" A little helper function to do a quick plot of model fit results. Args: history (tf.keras History): \"\"\" import matplotlib.pyplot as plt if hasattr ( history , 'history' ): history = history . history hist_metrics = [ _ for _ in history . keys () if not _ . startswith ( 'val_' )] for m_ix , m in enumerate ( hist_metrics ): plt . subplot ( len ( hist_metrics ), 1 , m_ix + 1 ) plt . plot ( history [ m ], label = 'Train' ) plt . plot ( history [ 'val_' + m ], label = 'Valid.' ) plt . xlabel ( 'Epoch' ) plt . ylabel ( m ) plt . legend () plt . tight_layout () plt . show ()","title":"quickplot_history()"},{"location":"API/utils/#indl.utils.regularizers","text":"","title":"regularizers"},{"location":"API/utils/#indl.utils.regularizers.KernelLengthRegularizer","text":"Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). Source code in indl/utils/regularizers.py class KernelLengthRegularizer ( tf . keras . regularizers . Regularizer ): \"\"\" Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). \"\"\" def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window () def rebuild_window ( self ): windows = [] for win_dim , win_len in enumerate ( self . kernel_size ): if win_len == 1 : window = np . ones (( 1 ,), dtype = np . float32 ) else : if self . window_func == 'hann' : window = 1 - tf . signal . hann_window ( win_len , periodic = False ) elif self . window_func == 'hamming' : window = 1 - tf . signal . hamming_window ( win_len , periodic = False ) else : # if window_func == 'linear': hl = win_len // 2 window = np . zeros (( win_len ,), dtype = np . float32 ) window [: hl ] = np . arange ( 1 , hl + 1 )[:: - 1 ] # Negative slope line to 0 for first half. window [ - hl :] = np . arange ( 1 , hl + 1 ) # Positive slope line from 0 for second half. window = window / hl # Scale so it's -1 -- 0 -- 1 window = window ** self . poly_exp # Exponent win_shape = [ 1 ] * ( len ( self . kernel_size ) + 2 ) win_shape [ win_dim ] = win_len window = tf . reshape ( window , win_shape ) windows . append ( window ) self . window = tf . linalg . matmul ( * windows ) self . window = self . window / tf . reduce_max ( self . window ) def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold } def __call__ ( self , weights ): weights = tf . sqrt ( tf . square ( weights )) # Differentiable abs # non_zero = tf.cast(weights > self.threshold, tf.float32) non_zero = tf . nn . sigmoid ( weights - self . threshold ) regularization = self . window_scale * self . window * non_zero # regularization = tf.reduce_max(regularization, axis=[0, 1], keepdims=True) regularization = tf . reduce_sum ( regularization ) return regularization","title":"KernelLengthRegularizer"},{"location":"API/utils/#indl.utils.regularizers.KernelLengthRegularizer.__init__","text":"Parameters: Name Type Description Default kernel_size Iterable[int] length(s) of kernel(s) required window_scale float scale factor to apply to window 0.01 window_func str 'hann', 'hamming', 'poly' (default) 'poly' poly_exp int exponent used when window_func=='poly' 2 threshold float weight threshold, below which weights will not be penalized. 1e-07 Source code in indl/utils/regularizers.py def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window ()","title":"__init__()"},{"location":"API/utils/#indl.utils.regularizers.KernelLengthRegularizer.get_config","text":"Returns the config of the regularizer. An regularizer config is a Python dictionary (serializable) containing all configuration parameters of the regularizer. The same regularizer can be reinstantiated later (without any saved state) from this configuration. This method is optional if you are just training and executing models, exporting to and from SavedModels, or using weight checkpoints. This method is required for Keras model_to_estimator , saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON. Returns: Type Description dict Python dictionary. Source code in indl/utils/regularizers.py def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold }","title":"get_config()"},{"location":"API/model/beta_vae/","text":"model.beta_vae create_decoder ( params , zs_sample , enc_z , ext_input = None , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' , recurrent_regularizer = 'l2' ) Parameters: Name Type Description Default params dict a dict with keys. Please check 'generate_default_args' and 'generate_default_params' for definitive descriptions of each key. Required keys: 'dec_rnn_type' - The cell type of the generator RNN. 'gru_clip_value' - only required if 'dec_rnn_type' is (Bidirectional)GRUClip 'dec_rnn_units' - number of units in the generator 'zs_to_dec' - \"initial conditions\" or \"tile inputs\" 'dropout_rate' 'n_factors' required zs_sample Tensor A sample from q(f) required enc_z Tensor A sample from q(z_t) required ext_input Not supported None kernel_initializer str passed to RNN cell 'lecun_normal' bias_initializer str passed to RNN cell 'zeros' recurrent_regularizer str passed to RNN cell 'l2' Returns: Type Description Tuple[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.ops.Tensor] gen_outputs, factors Source code in indl/model/beta_vae.py def create_decoder ( params : dict , zs_sample : tf . Tensor , enc_z : tf . Tensor , ext_input = None , kernel_initializer : str = 'lecun_normal' , bias_initializer : str = 'zeros' , recurrent_regularizer : str = 'l2' ) \\ -> Tuple [ tf . Tensor , tf . Tensor ]: \"\"\" Args: params: a dict with keys. Please check 'generate_default_args' and 'generate_default_params' for definitive descriptions of each key. Required keys: 'dec_rnn_type' - The cell type of the generator RNN. 'gru_clip_value' - only required if 'dec_rnn_type' is (Bidirectional)GRUClip 'dec_rnn_units' - number of units in the generator 'zs_to_dec' - \"initial conditions\" or \"tile inputs\" 'dropout_rate' 'n_factors' zs_sample: A sample from q(f) enc_z: A sample from q(z_t) ext_input: Not supported kernel_initializer: passed to RNN cell bias_initializer: passed to RNN cell recurrent_regularizer: passed to RNN cell Returns: gen_outputs, factors \"\"\" # Generate sequences and run through Dense layer, return factors if ext_input is not None : raise ValueError ( \"Sorry, ext_input not supported yet.\" ) if params [ 'dec_rnn_type' ] . lower () . startswith ( 'complex' ): raise ValueError ( \"Please use create_generator_complex for complex cell.\" ) # Other than LFADS, the other generator implementations are simply an RNN of the provided cell type. gen_is_rnn = params [ 'dec_rnn_type' ] . startswith ( 'Bidirectional' ) \\ or ( params [ 'dec_rnn_type' ] in [ 'GRU' , 'LSTM' , 'SimpleRNN' , 'GRUClip' ]) assert gen_is_rnn , \"dec_rnn_type must be a RNN cell type, \" \\ \"possibly prefixed by 'Bidirectional'.\" rnn_kwargs = dict ( kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = 0 , # Dropout on inputs not needed. return_sequences = True ) if params [ 'dec_rnn_type' ] . endswith ( 'GRU' ): rnn_layer_cls = tfkl . GRU elif params [ 'dec_rnn_type' ] . endswith ( 'LSTM' ): rnn_layer_cls = tfkl . LSTM elif params [ 'dec_rnn_type' ] . endswith ( 'SimpleRNN' ): rnn_layer_cls = tfkl . SimpleRNN elif params [ 'dec_rnn_type' ] . endswith ( 'GRUClip' ): rnn_layer_cls = GRUClip rnn_kwargs [ 'clip_value' ] = params [ 'gru_clip_value' ] if params [ 'dec_rnn_type' ] . startswith ( 'Bidirectional' ): rnn = tfkl . Bidirectional ( rnn_layer_cls ( params [ 'dec_rnn_units' ], ** rnn_kwargs ), merge_mode = \"concat\" , name = \"gen_rnn\" ) else : rnn = rnn_layer_cls ( params [ 'dec_rnn_units' ], ** rnn_kwargs ) # The initial conditions are either a sample of q(z) or zeros. The inputs are either a sample of q(f), # or a concatenation of a sample of q(f) and a tiling of a sample of q(z) (when initial conditions are zeros). # Which input-formulation is used is in params['zs_to_dec'] # Collapse samples + batch dims -- required by LSTM # First for zs_sample sb_shape_f = tf . shape ( zs_sample )[: - 1 ] # keep a record of the (samples,) batch shape. new_f_d1 = tf . reshape ( tf . reduce_prod ( sb_shape_f ), ( 1 ,)) new_f_shape = tf . concat (( new_f_d1 , tf . shape ( zs_sample )[ - 1 :]), 0 ) zs_sample = tf . reshape ( zs_sample , new_f_shape ) # --> zs_sample shape now (samples*batch, zs_size) # Next for enc_z (which is a sample for non-LFADS) sb_shape_z = tf . shape ( enc_z )[: - 2 ] # keep a record of the (samples,) batch shape. new_z_d1 = tf . reshape ( tf . reduce_prod ( sb_shape_z ), ( 1 ,)) new_z_shape = tf . concat (( new_z_d1 , tf . shape ( enc_z )[ - 2 :]), 0 ) enc_z = tf . reshape ( enc_z , new_z_shape ) # --> enc_z shape now (samples*batch, timestamps, zd_size) if params [ 'zs_to_dec' ] . lower () . startswith ( 'init' ): _init_state = tfkl . Dense ( params [ 'dec_rnn_units' ])( zs_sample ) _gen_input = enc_z else : # params['zs_to_dec'].lower().startswith('tile') _init_state = rnn . get_initial_state () # This was trainable in LFADS! # Tile zs_sample over the timestamps dimension. dyn_steps = tf . shape ( input = enc_z )[ - 2 ] _f = zs_sample [ ... , tf . newaxis , :] + tf . zeros ([ dyn_steps , 1 ]) _gen_input = tf . concat ([ enc_z , _f ], axis =- 1 ) gen_outputs = rnn ( _gen_input , initial_state = _init_state ) # Restore samples dim with sb_shape restore_samples_shape = tf . concat (( sb_shape_z , tf . shape ( gen_outputs )[ - 2 :]), 0 ) gen_outputs = tf . reshape ( gen_outputs , restore_samples_shape ) gen_dropped = tfkl . Dropout ( params [ 'dropout_rate' ])( gen_outputs ) factors = tfkl . Dense ( params [ 'n_factors' ])( gen_dropped ) return gen_outputs , factors create_encd ( params , inputs , zs_sample = None , f_inputs_pre_z1 = True , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' , recurrent_regularizer = 'l2' ) Run the input through the Dynamic Encoder (aka LFADS' controller input encoder). Different formulations in the literature: DSAE static: z not used DSAE dynamic full: - params['encd_rnn_type'] indicates Bidirectional RNN of some cell type - params['encd_rnn2_units'] > 0 - zs_sample is a tensor, possibly with a leading 'samples' dimension. DSAE dynamic factorized: - params['encd_rnn_type'] can be None or something nonsense. - params['encd_rnn2_units'] = 0 - zs_sample = None LFADS (simple z1 only because f1-joining and z2 encoding happens in its ComplexCell): - params['encd_rnn_type'] = 'BidirectionalGRU' (any will do) - params['dec_rnn_type'] != 'Complex' - params['encd_rnn2_units'] = 0 # TODO: I want to reuse encd_rnn2_units to parameterize LFADS' complex cell's internal GRU. - zs_sample = None Parameters: Name Type Description Default params dict 'encd_rnn_type': Type of RNN. '' or 'Bidirectional' + one of ['GRU', 'LSTM', 'SimpleRNN', 'GRUClip'] (just like create_f_encoder's 'encs_rnn_type' param), OR something else to not use an RNN and just use a flat Dense layer. Do not use 'Bidirectional' prefix for causal modeling. 'gru_clip_value': Required if encd_rnn_type endswith GRUClip 'encd_rnn1_units': Number of units in the first-level z encoder layer. 'zd_lag': simulate a delay in the z1 outputs. 'encd_rnn2_units': Number of units in the second-level z encoder layer. Can be 0 to skip. z2, if used, is always a feedforward SimpleRNN. required inputs Tensor input data, probably one of the outputs from prepare_inputs . required zs_sample Optional[int] Sample from q_f. Only required if using DSAE-Full. None f_inputs_pre_z1 bool True if the zs_sample (if provided) joins as inputs to z1, otherwise it joins as inputs to z2. True kernel_initializer str See tfkl RNN docs 'lecun_normal' bias_initializer str See tfkl RNN docs 'zeros' recurrent_regularizer str See tfkl RNN docs 'l2' Returns: Type Description Tensor A Tensor (or placeholder) with shape (samples (optional), batch_size, timesteps, units), where units refers to encd_rnn2_units if encd_rnn2_units > 0, else encd_rnn1_units. Source code in indl/model/beta_vae.py def create_encd ( params : dict , inputs : tf . Tensor , zs_sample : Optional [ int ] = None , f_inputs_pre_z1 : bool = True , kernel_initializer : str = 'lecun_normal' , bias_initializer : str = 'zeros' , recurrent_regularizer : str = 'l2' ) -> tf . Tensor : \"\"\" Run the input through the Dynamic Encoder (aka LFADS' controller input encoder). Different formulations in the literature: DSAE static: z not used DSAE dynamic full: - params['encd_rnn_type'] indicates Bidirectional RNN of some cell type - params['encd_rnn2_units'] > 0 - zs_sample is a tensor, possibly with a leading 'samples' dimension. DSAE dynamic factorized: - params['encd_rnn_type'] can be None or something nonsense. - params['encd_rnn2_units'] = 0 - zs_sample = None LFADS (simple z1 only because f1-joining and z2 encoding happens in its ComplexCell): - params['encd_rnn_type'] = 'BidirectionalGRU' (any will do) - params['dec_rnn_type'] != 'Complex' - params['encd_rnn2_units'] = 0 # TODO: I want to reuse encd_rnn2_units to parameterize LFADS' complex cell's internal GRU. - zs_sample = None Args: params: - 'encd_rnn_type': Type of RNN. '' or 'Bidirectional' + one of ['GRU', 'LSTM', 'SimpleRNN', 'GRUClip'] (just like create_f_encoder's 'encs_rnn_type' param), OR something else to not use an RNN and just use a flat Dense layer. Do not use 'Bidirectional' prefix for causal modeling. - 'gru_clip_value': Required if encd_rnn_type endswith GRUClip - 'encd_rnn1_units': Number of units in the first-level z encoder layer. - 'zd_lag': simulate a delay in the z1 outputs. - 'encd_rnn2_units': Number of units in the second-level z encoder layer. Can be 0 to skip. z2, if used, is always a feedforward SimpleRNN. inputs: input data, probably one of the outputs from `prepare_inputs`. zs_sample: Sample from q_f. Only required if using DSAE-Full. f_inputs_pre_z1: True if the zs_sample (if provided) joins as inputs to z1, otherwise it joins as inputs to z2. kernel_initializer: See tfkl RNN docs bias_initializer: See tfkl RNN docs recurrent_regularizer: See tfkl RNN docs Returns: A Tensor (or placeholder) with shape (samples (optional), batch_size, timesteps, units), where units refers to encd_rnn2_units if encd_rnn2_units > 0, else encd_rnn1_units. \"\"\" if zs_sample is not None : # If zs_sample is a dist we need to transform it to a tensor. # Expand along time dimension by broadcast-add to zeros. n_times = tf . shape ( inputs )[ - 2 ] zs_sample = zs_sample [ ... , tf . newaxis , :] + tf . zeros ([ n_times , 1 ]) # Add optional f_input that we tile and concatenate onto _inputs. if zs_sample is not None and f_inputs_pre_z1 : # Highly unlikely, but just in case inputs has samples dimension(s) then we can accommodate those here broadcast_shape_f = tf . concat (( tf . shape ( inputs )[: - 3 ], [ 1 , 1 , 1 ]), 0 ) zs_sample = zs_sample + tf . zeros ( broadcast_shape_f ) # Expand inputs along sample dimension(s). broadcast_shape_inputs = tf . concat (( tf . shape ( zs_sample )[: - 3 ], [ 1 , 1 , 1 ]), 0 ) inputs = inputs + tf . zeros ( broadcast_shape_inputs ) # Concatenate inputs with zs_sample inputs = tf . concat ([ inputs , zs_sample ], axis =- 1 ) # (optional-samples, batch, timesteps, feat_dim+latent_static) z1_is_rnn = params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ) \\ or ( params [ 'encd_rnn_type' ] in [ 'GRU' , 'LSTM' , 'SimpleRNN' , 'GRUClip' ]) has_z2 = 'encd_rnn2_units' in params and params [ 'encd_rnn2_units' ] > 0 if z1_is_rnn or has_z2 : rnn_kwargs = dict ( kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = 0 , # Dropout on inputs not needed. return_sequences = True ) if params [ 'encd_rnn_type' ] . endswith ( 'GRU' ): rnn_layer_cls = tfkl . GRU elif params [ 'encd_rnn_type' ] . endswith ( 'LSTM' ): rnn_layer_cls = tfkl . LSTM elif params [ 'encd_rnn_type' ] . endswith ( 'SimpleRNN' ): rnn_layer_cls = tfkl . SimpleRNN elif params [ 'encd_rnn_type' ] . endswith ( 'GRUClip' ): rnn_layer_cls = GRUClip rnn_kwargs [ 'clip_value' ] = params [ 'gru_clip_value' ] if z1_is_rnn : # Collapse samples + batch dims -- required by LSTM sb_shape = tf . shape ( inputs )[: - 2 ] # keep a record of the (samples,) batch shape. # new_shape = tf.concat(([-1], tf.shape(inputs)[-2:]), axis=0) # Can't remember why I couldn't use -1 here. new_d1 = tf . reshape ( tf . reduce_prod ( tf . shape ( inputs )[: - 2 ]), ( 1 ,)) new_shape = tf . concat (( new_d1 , tf . shape ( inputs )[ - 2 :]), 0 ) inputs = tf . reshape ( inputs , new_shape ) # inputs shape now (samples*batch, T, feat+lat_stat) if params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ): _enc_z = tfkl . Bidirectional ( rnn_layer_cls ( params [ 'encd_rnn1_units' ], ** rnn_kwargs ), merge_mode = \"concat\" , name = \"z_rnn_1\" )( inputs ) else : _enc_z = rnn_layer_cls ( params [ 'encd_rnn1_units' ], ** rnn_kwargs )( inputs ) # Restore leading samples, batch dims. _enc_z = tf . reshape ( _enc_z , tf . concat (( sb_shape , tf . shape ( _enc_z )[ 1 :]), axis = 0 )) else : # Not RNN, just MLP _enc_z = tfkl . Dense ( params [ 'encd_rnn1_units' ])( inputs ) if params [ 'zd_lag' ] > 0 : if params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ): # Shift _fwd back, dropping the latest samples, fill front with zeros # Shift _bwd forward, dropping the earliest samples, fill tail with zeros. # _fwd = [0,0,0,...,old_fwd[-lag:]]; _bwd = [old_bwd[lag:], ..., 0, 0, 0] _fwd , _bwd = tf . split ( _enc_z , 2 , axis =- 1 ) _fwd = tf . concat ([ tf . zeros_like ( _fwd [ ... , : params [ 'zd_lag' ], :]), _fwd [ ... , : - params [ 'zd_lag' ], :]], axis =- 2 ) _bwd = tf . concat ([ _bwd [ ... , params [ 'zd_lag' ]:, :], tf . zeros_like ( _bwd [:, - params [ 'zd_lag' ]:, :])], axis =- 2 ) _enc_z = tf . concat ([ _fwd , _bwd ], axis =- 1 ) else : _enc_z = tf . concat ([ tf . zeros_like ( _enc_z [ ... , : params [ 'zd_lag' ], :]), _enc_z [ ... , : - params [ 'zd_lag' ], :]], axis =- 2 ) if params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ): # Recombine forward and backward to get merge_mode=\"sum\" _fwd , _bwd = tf . split ( _enc_z , 2 , axis =- 1 ) _enc_z = _fwd + _bwd not_lfads = ( 'dec_rnn_type' not in params ) or ( params [ 'dec_rnn_type' ] != 'Complex' ) if not_lfads and has_z2 : if zs_sample is not None and not f_inputs_pre_z1 : # Highly unlikely, but just in case _enc_z has samples dimension(s) then we can accommodate those here broadcast_shape_f = tf . concat (( tf . shape ( _enc_z )[: - 3 ], [ 1 , 1 , 1 ]), axis = 0 ) zs_sample = zs_sample + tf . zeros ( broadcast_shape_f ) # Expand _enc_z along sample dimension(s). broadcast_shape_zenc = tf . concat (( tf . shape ( zs_sample )[: - 3 ], [ 1 , 1 , 1 ]), axis = 0 ) _enc_z = _enc_z + tf . zeros ( broadcast_shape_zenc ) # Concatenate _enc_z with zs_sample _enc_z = tf . concat ([ _enc_z , zs_sample ], axis =- 1 ) # (optional-samples, batch, timesteps, feat_dim+latent_static) # TODO: LFADS does an additional dropout before input to z2 # Collapse samples + batch dims -- required by RNNs sb_shape = tf . shape ( _enc_z )[: - 2 ] # keep a record of the (samples,) batch shape. # new_shape = tf.concat(([-1], tf.shape(_enc_z)[-2:]), axis=0) # Can't remember why I couldn't use -1 here. new_d1 = tf . reshape ( tf . reduce_prod ( tf . shape ( _enc_z )[: - 2 ]), ( 1 ,)) new_shape = tf . concat (( new_d1 , tf . shape ( _enc_z )[ - 2 :]), axis = 0 ) _enc_z = tf . reshape ( _enc_z , new_shape ) # _enc_z shape now (samples*batch, T, encd_rnn1_units+lat_stat) # z2 vanilla RNN used in DSAE Full. LFADS' z2 used elsewhere. _ = rnn_kwargs . pop ( 'clip_value' , None ) _enc_z = tfkl . SimpleRNN ( params [ 'encd_rnn2_units' ], ** rnn_kwargs )( _enc_z ) # Restore leading samples, batch dims. _enc_z = tf . reshape ( _enc_z , tf . concat (( sb_shape , tf . shape ( _enc_z )[ 1 :]), axis = 0 )) return _enc_z create_encs ( params , inputs , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' , recurrent_regularizer = 'l2' ) The static arm of the encoder, aka in LFADS as the \"initial condition encoder\". Parameters: Name Type Description Default params dict required keys are 'encs_rnn_units' (int or iterable of ints), 'encs_rnn_type' (str), 'gru_clip_value' required inputs Tensor a tensor with dimensions (batch_size, timesteps, input_dim) batch_size and timesteps may be None for placeholder tensors (i.e., created by tf.keras.Input) required kernel_initializer see TF's RNN docs 'lecun_normal' bias_initializer see TF's RNN docs 'zeros' recurrent_regularizer see TF's RNN docs 'l2' Returns: Type Description Tensor statically encoded x (not variational) Source code in indl/model/beta_vae.py def create_encs ( params : dict , inputs : tf . Tensor , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' , recurrent_regularizer = 'l2' ) -> tf . Tensor : \"\"\" The static arm of the encoder, aka in LFADS as the \"initial condition encoder\". Args: params: required keys are 'encs_rnn_units' (int or iterable of ints), 'encs_rnn_type' (str), 'gru_clip_value' inputs: a tensor with dimensions (batch_size, timesteps, input_dim) batch_size and timesteps may be `None` for placeholder tensors (i.e., created by tf.keras.Input) kernel_initializer: see TF's RNN docs bias_initializer: see TF's RNN docs recurrent_regularizer: see TF's RNN docs Returns: statically encoded x (not variational) \"\"\" _encoded_s = inputs encs_rnn_units = params [ 'encs_rnn_units' ] if not isinstance ( encs_rnn_units , ( list , tuple )): encs_rnn_units = [ encs_rnn_units ] rnn_kwargs = dict ( kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = 0 , # Dropout on inputs not needed. ) if params [ 'encs_rnn_type' ] . endswith ( 'GRU' ): rnn_layer_cls = tfkl . GRU elif params [ 'encs_rnn_type' ] . endswith ( 'LSTM' ): rnn_layer_cls = tfkl . LSTM elif params [ 'encs_rnn_type' ] . endswith ( 'SimpleRNN' ): rnn_layer_cls = tfkl . SimpleRNN elif params [ 'encs_rnn_type' ] . endswith ( 'GRUClip' ): rnn_layer_cls = GRUClip rnn_kwargs [ 'clip_value' ] = params [ 'gru_clip_value' ] for ix , rnn_units in enumerate ( encs_rnn_units ): rnn_kwargs [ 'return_sequences' ] = ( ix + 1 ) < len ( encs_rnn_units ) if params [ 'encs_rnn_type' ] . startswith ( 'Bidirectional' ): _encoded_s = tfkl . Bidirectional ( rnn_layer_cls ( rnn_units , ** rnn_kwargs ), merge_mode = \"concat\" , name = \"rnn_s_\" + str ( ix ))( _encoded_s ) else : _encoded_s = rnn_layer_cls ( rnn_units , ** rnn_kwargs )( _encoded_s ) return _encoded_s create_pzd ( params ) The z_prior is a sequence of multivariate diagonal normal distributions. The parameters of the distribution at each timestep are a function of (a sample drawn from) the distribution in the previous timestep. For DSAE, the process that governs the evolution of parameters over time is a RNN. For each trial, it is initialized to zeros and the first step is a zero-input. Subsequent inputs will be samples from the previous step. The RNN parameters are learnable. See process_dist.RNNMVNGenerator For LFADS, the process that governs the evolution of parameters over time is AR1. Each dimension is an independent process. The processes variances and the processes autocorrelation time constants (taus) are both trainable parameters. See process_dist.AR1ProcessMVNGenerator We also have process_dist.TiledMVNGenerator where a single distribution is shared over all timesteps. TODO: tfp also has Autoregressive and GaussianProcess distributions which can be parameterized with trainable variables and are maybe worth investigating here. The purpose of the prior is for KL-divergence loss, and I didn't have much luck using KL-divergence as a regularizer or model loss, so we will be calculating the KL-divergence during the manual train_step. It is therefore unnecessary to return a tensor-like here. Instead, we return an instance of a class, and that instance must have a .get_dist() method that we call explicitly during train_step to get a distribution, then the distribution will be used to calculate KL divergence. Parameters: Name Type Description Default params dict required - 'pzd_process' Which process to use for the sequence-of-MVN priors on z. Valid values: 'AR1' - uses AR1ProcessMVNGenerator {rnn cell type} - including GRUClip, GRU, LSTM, RNN (not case-sensitive), uses RNNMVNGenerator 'none' - uses TiledMVNGenerator required Returns: Type Description IProcessMVNGenerator an MVNGenerator. Get a sample and dist from the generator with sample, dist = generator.get_dist(timestamps, samples=N_SAMPS, batch_size=BATCH_SIZE) In most cases, when calculating KL and the returned dist is of the same type as the latent distribution, then the analytic KL can be calculated and only the dist event_shape matters, so samples and batch_size can be set to 1. Source code in indl/model/beta_vae.py def create_pzd ( params : dict ) -> IProcessMVNGenerator : \"\"\" The z_prior is a sequence of multivariate diagonal normal distributions. The parameters of the distribution at each timestep are a function of (a sample drawn from) the distribution in the previous timestep. For DSAE, the process that governs the evolution of parameters over time is a RNN. For each trial, it is initialized to zeros and the first step is a zero-input. Subsequent inputs will be samples from the previous step. The RNN parameters are learnable. See process_dist.RNNMVNGenerator For LFADS, the process that governs the evolution of parameters over time is AR1. Each dimension is an independent process. The processes variances and the processes autocorrelation time constants (taus) are both trainable parameters. See process_dist.AR1ProcessMVNGenerator We also have process_dist.TiledMVNGenerator where a single distribution is shared over all timesteps. TODO: tfp also has Autoregressive and GaussianProcess distributions which can be parameterized with trainable variables and are maybe worth investigating here. The purpose of the prior is for KL-divergence loss, and I didn't have much luck using KL-divergence as a regularizer or model loss, so we will be calculating the KL-divergence during the manual train_step. It is therefore unnecessary to return a tensor-like here. Instead, we return an instance of a class, and that instance must have a .get_dist() method that we call explicitly during train_step to get a distribution, then the distribution will be used to calculate KL divergence. Args: params: - 'pzd_process': Which process to use for the sequence-of-MVN priors on z. Valid values: 'AR1' - uses `AR1ProcessMVNGenerator` {rnn cell type} - including GRUClip, GRU, LSTM, RNN (not case-sensitive), uses `RNNMVNGenerator` 'none' - uses `TiledMVNGenerator` Returns: an MVNGenerator. Get a sample and dist from the generator with `sample, dist = generator.get_dist(timestamps, samples=N_SAMPS, batch_size=BATCH_SIZE)` In most cases, when calculating KL and the returned dist is of the same type as the latent distribution, then the analytic KL can be calculated and only the dist event_shape matters, so samples and batch_size can be set to 1. \"\"\" if params [ 'pzd_process' ] == 'AR1' : from indl.dists.sequential import AR1ProcessMVNGenerator init_taus = [ params [ 'pzd_tau' ] for _ in range ( params [ 'zd_size' ])] init_std = [ params [ 'pzd_init_std' ] for _ in range ( params [ 'zd_size' ])] gen = AR1ProcessMVNGenerator ( init_taus , init_std = init_std , trainable_mean = params [ 'pzd_train_mean' ], trainable_tau = params [ 'pzd_train_tau' ], trainable_var = params [ 'pzd_train_var' ], offdiag = params [ 'pzd_offdiag' ]) elif params [ 'pzd_process' ] in [ 'RNN' , 'LSTM' , 'GRU' , 'GRUClip' ]: from indl.dists.sequential import RNNMVNGenerator \"\"\" units: int, out_dim: int, cell_type: str, shift_std: float = 0.1, offdiag: bool = False \"\"\" gen = RNNMVNGenerator ( params [ 'pzd_units' ], out_dim = params [ 'zd_size' ], cell_type = params [ 'pzd_process' ], shift_std = params [ 'pzd_init_std' ], offdiag = params [ 'pzd_offdiag' ]) else : from indl.dists.sequential import TiledMVNGenerator gen = TiledMVNGenerator ( params [ 'pzd_units' ], init_std = params [ 'pzd_init_std' ], trainable_mean = params [ 'pzd_train_mean' ], trainable_var = params [ 'pzd_train_var' ], offdiag = params [ 'pzd_offdiag' ]) return gen create_pzs ( params ) Make a prior with optionally trainable mean and variance. Parameters: Name Type Description Default params dict 'pzs_kappa' -- must be 0. 'zs_size' 'qzs_init_std' 'pzs_train_mean' 'pzs_train_var' 'pzs_off_diag' required Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL] Either tfd.MultivariateNormalTril if params['pzs_off_diag'] else tfd.MultivariateNormalDiag Source code in indl/model/beta_vae.py def create_pzs ( params : dict ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Make a prior with optionally trainable mean and variance. Args: params: - 'pzs_kappa' -- must be 0. - 'zs_size' - 'qzs_init_std' - 'pzs_train_mean' - 'pzs_train_var' - 'pzs_off_diag' Returns: Either tfd.MultivariateNormalTril if params['pzs_off_diag'] else tfd.MultivariateNormalDiag \"\"\" if params [ 'pzs_kappa' ] > 0 : raise NotImplementedError pzs = make_mvn_prior ( params [ 'zs_size' ], init_std = params [ 'qzs_init_std' ], trainable_mean = params [ 'pzs_train_mean' ], trainable_var = params [ 'pzs_train_var' ], offdiag = params [ 'pzs_off_diag' ]) # Old way: # prior_factory = lambda: tfd.MultivariateNormalDiag(loc=0, scale_diag=params['pzs_kappa']) # prior_factory = LearnableMultivariateNormalDiag(params['zs_size']) # prior_factory.build(input_shape=(0,)) return pzs generate_default_args () Returns: non-tunable parameters in a TestArgs object Access args with obj.arg_name or . dict ['arg_name'] Source code in indl/model/beta_vae.py def generate_default_args (): \"\"\" Returns: non-tunable parameters in a TestArgs object Access args with obj.arg_name or .__dict__['arg_name'] \"\"\" # non tunable parameters return type ( 'TestArgs' , ( object ,), dict ( random_seed = 1337 , batch_size = 16 , n_epochs = 100 , resample_X = 10 , # spike count bin size q_samples = 1 , # At some points this gets folded into the batch dim so it has to # be the same for q_f and q_z. # Encoder - Static encs_rnn_type = \"BidirectionalGRUClip\" , # Encoder RNN cell type: ('Bidirectional' or '') # + ('GRU', 'LSTM', 'SimpleRNN', 'GRUClip') encs_input_samps = 0 , # Set to > 0 to restrict f_encoder to only see this many samples # This is one of several settings required to prevent acausal modeling. qzs_off_diag = False , # If latent dist may have non-zero off diagonals # Static Latent Dist qzs_init_std = 0.1 , # (LFADS: ic_prior_var) # Static Latent Prior pzs_off_diag = False , # If latent prior may have non-zero off diagonals pzs_kappa = 0.0 , # In LFADS this is a tuned hyperparameter, ~0.1 pzs_train_mean = True , # True in LFADS pzs_train_var = True , # False in LFADS # Encoder - Dynamic encd_rnn_type = \"BidirectionalGRUClip\" , # Encoder RNN cell type # To prevent acausal modeling on the controller input, do not use Bidir zd_lag = 0 , # Time lag on the z-encoder output. # Same as LFADS' `controller_input_lag` # Dynamic Latent Dist qzd_init_std = 0.1 , # std shift when z-latent is 0, # and initial prior variance for RNN and tiled gaussian priors qzd_off_diag = False , # Dynamic Latent Prior pzd_process = \"AR1\" , # AR1 or a RNN cell type, or anything else 'none' for # simple tiled gaussian. pzd_train_mean = False , # pzd_train_var = True , # Also used for train_nvar pzd_init_std = 0.1 , # Also used for inittau pzd_offdiag = False , # pzd_units = 8 , # Number of units for RNN MVN prior (RNNMVNGenerator) pzd_tau = 10.0 , # Initial autocorrelation for AR(1) priors (AR1ProcessMVNGenerator) pzd_train_tau = True , # # Decoder dec_rnn_type = \"GRUClip\" , # Decoder generative RNN cell type. \"Complex\" is for LFADS. zs_to_dec = \"initial conditions\" , # How static latent is used in the decoder. # \"initial conditions\" or \"tile inputs\" # Output output_dist = \"Poisson\" , # Poisson or anything else for MVNDiag )) generate_default_params () Returns: tunable parameters in dictionary Source code in indl/model/beta_vae.py def generate_default_params () -> dict : \"\"\" Returns: tunable parameters in dictionary \"\"\" # tunable parameters return { \"dropout_rate\" : 1e-2 , # (1e-2) \"coordinated_dropout_rate\" : 0.1 , # \"input_factors\" : 0 , # Extra Dense layer applied to inputs. Good for multi-session. (not impl.) \"gru_clip_value\" : 5.0 , # Max value recurrent cell can take before being clipped (5.0) \"gen_l2_reg\" : 1e-4 , # (1e-4) \"learning_rate\" : 2e-3 , # (2e-3) # \"max_grad_norm\": 200.0 # Encoder - Static \"encs_rnn_units\" : [ 128 ], # Number of units in static encoder RNN. # Increase list length to add more RNN layers. (128) # Same as LFADS' `ic_enc_dim` \"zs_size\" : 10 , # Size of static latent vector zs (10) # Same as LFADS' `ic_dim` # Encoder - Dynamic \"encd_rnn1_units\" : 16 , # Number of units in dynamic encoder first RNN. # Same as LFADS `ci_enc_dim` \"encd_rnn2_units\" : 16 , # Number of units in dynamic encoder second RNN (DHSAE Full or LFADS con). # Same as LFADS `con_dim` \"zd_size\" : 4 , # Dimensionality of q_zt posterior. # Same as LFADS' `co_dim` # Decoder \"dec_rnn_units\" : 256 , # Number of RNN cells in decoder RNN (256) # Same as LFADS `gen_dim` \"n_factors\" : 10 , # Number of latent factors (24) # Same as LFADS' `factors_dim` } make_encd_variational ( params , enc_z ) Take the encoded latent sequence z (output of z1 and optionally z2) and convert it to a distribution. This isn't necessary for LFADS models because z isn't in its final encoded form until inside the Complex cell, so it's up to the complex cell to handle the formation of the distribution. Parameters: Name Type Description Default params dict required enc_z Tensor input Tensor required Returns: Type Description q_z A tfd.Distribution. - q_z.sample() will not return a prepended samples dim if params['q_samples'] == 1, else it will. - q_z.sample(N) will always return a prepended samples dim (shape N), even if N == 1. If you need to reshape so the timesteps dim isn't considered in the \"batch_shape\" but is in the \"event_shape\", then you can use tfd.Independent(q_z, reinterpreted_batch_ndims=1). Source code in indl/model/beta_vae.py def make_encd_variational ( params : dict , enc_z : tf . Tensor ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Take the encoded latent sequence z (output of z1 and optionally z2) and convert it to a distribution. This isn't necessary for LFADS models because z isn't in its final encoded form until inside the Complex cell, so it's up to the complex cell to handle the formation of the distribution. Args: params: - 'zd_size' - 'qzd_off_diag' - 'qzd_init_std' - 'q_samples' enc_z: input Tensor Returns: q_z: A tfd.Distribution. - q_z.sample() will not return a prepended samples dim if params['q_samples'] == 1, else it will. - q_z.sample(N) will always return a prepended samples dim (shape N), even if N == 1. If you need to reshape so the timesteps dim isn't considered in the \"batch_shape\" but is in the \"event_shape\", then you can use tfd.Independent(q_z, reinterpreted_batch_ndims=1). \"\"\" from indl.dists import make_variational if 'dec_rnn_type' in params : assert params [ 'dec_rnn_type' ] != \"Complex\" , \"Skip this step. LFADS complex cell handles this intrinsically.\" # Get a multivariate normal diag over each timestep. q_z = make_variational ( enc_z , params [ 'zd_size' ], init_std = params [ 'qzd_init_std' ], offdiag = params [ 'qzd_off_diag' ], samps = params [ 'q_samples' ], loc_name = \"z_loc\" , scale_name = \"z_scale\" , use_mvn_diag = True ) return q_z make_encs_variational ( params , encoded_s ) Make the output of the Static Encoder (encs) variational. Adds a dropout layer and passes through indl.model.tfp.make_variational with the correct parameters. Parameters: Name Type Description Default params dict 'dropout_rate' 'zs_size' 'qzs_off_diag' 'qzs_init_std' 'q_samples' required encoded_s Tensor required Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL] q(zs|x) Source code in indl/model/beta_vae.py def make_encs_variational ( params : dict , encoded_s : tf . Tensor ) \\ -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Make the output of the Static Encoder (encs) variational. Adds a dropout layer and passes through indl.model.tfp.make_variational with the correct parameters. Args: params: - 'dropout_rate' - 'zs_size' - 'qzs_off_diag' - 'qzs_init_std' - 'q_samples' encoded_s: Returns: q(zs|x) \"\"\" from indl.dists import make_variational encoded_s = tfkl . Dropout ( params [ 'dropout_rate' ])( encoded_s ) qzs = make_variational ( encoded_s , params [ 'zs_size' ], init_std = params [ 'qzs_init_std' ], offdiag = params [ 'qzs_off_diag' ], samps = params [ 'q_samples' ], loc_name = \"f_loc\" , scale_name = \"f_scale\" , use_mvn_diag = True ) return qzs prepare_inputs ( params , _inputs ) Prepare the data for entry into the encoder(s). This comprises several steps: dropout (optional) split off inputs to the f_encoder to prevent acausal modeling (optional) coordinated dropout (not implemented) CV mask (optional) Dense layer to read-in inputs to a common set of input factors. To keep the model flexible to inputs of varying timesteps, this model fragment does not check the size of the timestep dimension. Please make sure that params['encs_input_samps'] is less than the smallest number of timesteps in your inputs. Parameters: Name Type Description Default params dict has the following keys - 'dropout_rate' - 'encs_input_samps' - set to > 0 to split off f_encoder inputs to prevent acausal modeling. - 'coordinated_dropout_rate' - 'input_factors' required _inputs Tensor With dimensions (batch, timesteps, features) required Returns: Type Description f_enc_inputs to be used as inputs to a subsequent f_encoder. If params['encs_input_samps'] > 0 then this will simply be the leading slice off inputs unmasked, else this will be full length and masked. (In both cases it will be optionally run through Dense layer). z_enc_inputs: to be used as inputs to a subsequent z_encoder cd_kept_mask: with dtype tf.bool, to be used during decoding for \"coordinated dropout\" Source code in indl/model/beta_vae.py def prepare_inputs ( params : dict , _inputs : tf . Tensor ) -> Tuple [ tf . Tensor , tf . Tensor , tf . Tensor ]: \"\"\" Prepare the data for entry into the encoder(s). This comprises several steps: * dropout * (optional) split off inputs to the f_encoder to prevent acausal modeling * (optional) coordinated dropout * (not implemented) CV mask * (optional) Dense layer to read-in inputs to a common set of input factors. To keep the model flexible to inputs of varying timesteps, this model fragment does not check the size of the timestep dimension. Please make sure that params['encs_input_samps'] is less than the smallest number of timesteps in your inputs. Args: params: has the following keys - 'dropout_rate' - 'encs_input_samps' - set to > 0 to split off f_encoder inputs to prevent acausal modeling. - 'coordinated_dropout_rate' - 'input_factors' _inputs: With dimensions (batch, timesteps, features) Returns: f_enc_inputs: to be used as inputs to a subsequent f_encoder. If params['encs_input_samps'] > 0 then this will simply be the leading slice off inputs unmasked, else this will be full length and masked. (In both cases it will be optionally run through Dense layer). z_enc_inputs: to be used as inputs to a subsequent z_encoder cd_kept_mask: with dtype tf.bool, to be used during decoding for \"coordinated dropout\" \"\"\" _inputs = tfkl . Dropout ( params [ 'dropout_rate' ])( _inputs ) # The f-encoder takes the entire sequence and outputs a single-timestamp vector, # this vector is used as the decoder's initial condition. This has the potential # to create acausal modeling because the decoder will have knowledge of the entire # sequence from its first timestep. # We can optionally split the input to _f_enc_inputs and remaining _inputs # RNN will only see _f_enc_inputs to help prevent acausal modeling. _f_enc_inputs = _inputs [:, : params [ 'encs_input_samps' ], :] _inputs = _inputs [:, params [ 'encs_input_samps' ]:, :] # Coordinated dropout on _inputs only. # Why not _f_enc_inputs? Is it because it is likely too short to matter? _masked_inputs , cd_kept_mask = CoordinatedDropout ( params [ 'coordinated_dropout_rate' ])( _inputs ) # cd_kept_mask is part of the return so it can be used during decoding. # The z-encoder inputs will always be full length. _z_enc_inputs = tf . concat ([ _f_enc_inputs , _masked_inputs ], axis =- 2 ) if params [ 'encs_input_samps' ] == 0 : # With no encs_input_samps specification, the f_enc inputs are the full input. # Note this has coordinated dropout, whereas it wouldn't if encs_input_samps was specified. _f_enc_inputs = _masked_inputs # Note: Skipping over LFADS' CV Mask for now. if params [ 'input_factors' ] > 0 : _f_enc_inputs = tfkl . Dense ( params [ 'input_factors' ])( _f_enc_inputs ) _z_enc_inputs = tfkl . Dense ( params [ 'input_factors' ])( _z_enc_inputs ) return _f_enc_inputs , _z_enc_inputs , cd_kept_mask sample_pzd ( pzd , timesteps , params , fixed = False ) Samples from z_prior timesteps times. z_prior is a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Parameters: Name Type Description Default gen an instance of a concrete class that inherits from indl.dists.sequential.IProcessMVNGenerator , such as AR1ProcessMVNGenerator , RNNMVNGenerator or TiledMVNGenerator . required timesteps int Number of timesteps to sample for each sequence. required params dict q_samples batch_size required fixed Boolean for whether or not to share the same random sample across all sequences in batch. False Returns: Type Description Tuple[tensorflow.python.framework.ops.Tensor, tensorflow_probability.python.distributions.independent.Independent] A tuple of a sample from a distribution and the distribution itself. The tensor is of shape (samples, batch_size, timesteps, zd_size). The distribution is a tfd.Independent wrapping a multivariate normal diagonal. Source code in indl/model/beta_vae.py def sample_pzd ( pzd : IProcessMVNGenerator , timesteps : int , params : dict , fixed = False ) \\ -> Tuple [ tf . Tensor , tfd . Independent ]: \"\"\" Samples from z_prior `timesteps` times. z_prior is a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Args: gen: an instance of a concrete class that inherits from `indl.dists.sequential.IProcessMVNGenerator`, such as `AR1ProcessMVNGenerator`, `RNNMVNGenerator` or `TiledMVNGenerator`. timesteps: Number of timesteps to sample for each sequence. params: - q_samples - batch_size fixed: Boolean for whether or not to share the same random sample across all sequences in batch. Returns: A tuple of a sample from a distribution and the distribution itself. The tensor is of shape (samples, batch_size, timesteps, zd_size). The distribution is a tfd.Independent wrapping a multivariate normal diagonal. \"\"\" return pzd . get_dist ( timesteps , samples = params [ 'q_samples' ], batch_size = params [ 'batch_size' ], fixed = fixed )","title":"model.beta_vae"},{"location":"API/model/beta_vae/#modelbeta_vae","text":"","title":"model.beta_vae"},{"location":"API/model/beta_vae/#indl.model.beta_vae.create_decoder","text":"Parameters: Name Type Description Default params dict a dict with keys. Please check 'generate_default_args' and 'generate_default_params' for definitive descriptions of each key. Required keys: 'dec_rnn_type' - The cell type of the generator RNN. 'gru_clip_value' - only required if 'dec_rnn_type' is (Bidirectional)GRUClip 'dec_rnn_units' - number of units in the generator 'zs_to_dec' - \"initial conditions\" or \"tile inputs\" 'dropout_rate' 'n_factors' required zs_sample Tensor A sample from q(f) required enc_z Tensor A sample from q(z_t) required ext_input Not supported None kernel_initializer str passed to RNN cell 'lecun_normal' bias_initializer str passed to RNN cell 'zeros' recurrent_regularizer str passed to RNN cell 'l2' Returns: Type Description Tuple[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.ops.Tensor] gen_outputs, factors Source code in indl/model/beta_vae.py def create_decoder ( params : dict , zs_sample : tf . Tensor , enc_z : tf . Tensor , ext_input = None , kernel_initializer : str = 'lecun_normal' , bias_initializer : str = 'zeros' , recurrent_regularizer : str = 'l2' ) \\ -> Tuple [ tf . Tensor , tf . Tensor ]: \"\"\" Args: params: a dict with keys. Please check 'generate_default_args' and 'generate_default_params' for definitive descriptions of each key. Required keys: 'dec_rnn_type' - The cell type of the generator RNN. 'gru_clip_value' - only required if 'dec_rnn_type' is (Bidirectional)GRUClip 'dec_rnn_units' - number of units in the generator 'zs_to_dec' - \"initial conditions\" or \"tile inputs\" 'dropout_rate' 'n_factors' zs_sample: A sample from q(f) enc_z: A sample from q(z_t) ext_input: Not supported kernel_initializer: passed to RNN cell bias_initializer: passed to RNN cell recurrent_regularizer: passed to RNN cell Returns: gen_outputs, factors \"\"\" # Generate sequences and run through Dense layer, return factors if ext_input is not None : raise ValueError ( \"Sorry, ext_input not supported yet.\" ) if params [ 'dec_rnn_type' ] . lower () . startswith ( 'complex' ): raise ValueError ( \"Please use create_generator_complex for complex cell.\" ) # Other than LFADS, the other generator implementations are simply an RNN of the provided cell type. gen_is_rnn = params [ 'dec_rnn_type' ] . startswith ( 'Bidirectional' ) \\ or ( params [ 'dec_rnn_type' ] in [ 'GRU' , 'LSTM' , 'SimpleRNN' , 'GRUClip' ]) assert gen_is_rnn , \"dec_rnn_type must be a RNN cell type, \" \\ \"possibly prefixed by 'Bidirectional'.\" rnn_kwargs = dict ( kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = 0 , # Dropout on inputs not needed. return_sequences = True ) if params [ 'dec_rnn_type' ] . endswith ( 'GRU' ): rnn_layer_cls = tfkl . GRU elif params [ 'dec_rnn_type' ] . endswith ( 'LSTM' ): rnn_layer_cls = tfkl . LSTM elif params [ 'dec_rnn_type' ] . endswith ( 'SimpleRNN' ): rnn_layer_cls = tfkl . SimpleRNN elif params [ 'dec_rnn_type' ] . endswith ( 'GRUClip' ): rnn_layer_cls = GRUClip rnn_kwargs [ 'clip_value' ] = params [ 'gru_clip_value' ] if params [ 'dec_rnn_type' ] . startswith ( 'Bidirectional' ): rnn = tfkl . Bidirectional ( rnn_layer_cls ( params [ 'dec_rnn_units' ], ** rnn_kwargs ), merge_mode = \"concat\" , name = \"gen_rnn\" ) else : rnn = rnn_layer_cls ( params [ 'dec_rnn_units' ], ** rnn_kwargs ) # The initial conditions are either a sample of q(z) or zeros. The inputs are either a sample of q(f), # or a concatenation of a sample of q(f) and a tiling of a sample of q(z) (when initial conditions are zeros). # Which input-formulation is used is in params['zs_to_dec'] # Collapse samples + batch dims -- required by LSTM # First for zs_sample sb_shape_f = tf . shape ( zs_sample )[: - 1 ] # keep a record of the (samples,) batch shape. new_f_d1 = tf . reshape ( tf . reduce_prod ( sb_shape_f ), ( 1 ,)) new_f_shape = tf . concat (( new_f_d1 , tf . shape ( zs_sample )[ - 1 :]), 0 ) zs_sample = tf . reshape ( zs_sample , new_f_shape ) # --> zs_sample shape now (samples*batch, zs_size) # Next for enc_z (which is a sample for non-LFADS) sb_shape_z = tf . shape ( enc_z )[: - 2 ] # keep a record of the (samples,) batch shape. new_z_d1 = tf . reshape ( tf . reduce_prod ( sb_shape_z ), ( 1 ,)) new_z_shape = tf . concat (( new_z_d1 , tf . shape ( enc_z )[ - 2 :]), 0 ) enc_z = tf . reshape ( enc_z , new_z_shape ) # --> enc_z shape now (samples*batch, timestamps, zd_size) if params [ 'zs_to_dec' ] . lower () . startswith ( 'init' ): _init_state = tfkl . Dense ( params [ 'dec_rnn_units' ])( zs_sample ) _gen_input = enc_z else : # params['zs_to_dec'].lower().startswith('tile') _init_state = rnn . get_initial_state () # This was trainable in LFADS! # Tile zs_sample over the timestamps dimension. dyn_steps = tf . shape ( input = enc_z )[ - 2 ] _f = zs_sample [ ... , tf . newaxis , :] + tf . zeros ([ dyn_steps , 1 ]) _gen_input = tf . concat ([ enc_z , _f ], axis =- 1 ) gen_outputs = rnn ( _gen_input , initial_state = _init_state ) # Restore samples dim with sb_shape restore_samples_shape = tf . concat (( sb_shape_z , tf . shape ( gen_outputs )[ - 2 :]), 0 ) gen_outputs = tf . reshape ( gen_outputs , restore_samples_shape ) gen_dropped = tfkl . Dropout ( params [ 'dropout_rate' ])( gen_outputs ) factors = tfkl . Dense ( params [ 'n_factors' ])( gen_dropped ) return gen_outputs , factors","title":"create_decoder()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.create_encd","text":"Run the input through the Dynamic Encoder (aka LFADS' controller input encoder). Different formulations in the literature: DSAE static: z not used DSAE dynamic full: - params['encd_rnn_type'] indicates Bidirectional RNN of some cell type - params['encd_rnn2_units'] > 0 - zs_sample is a tensor, possibly with a leading 'samples' dimension. DSAE dynamic factorized: - params['encd_rnn_type'] can be None or something nonsense. - params['encd_rnn2_units'] = 0 - zs_sample = None LFADS (simple z1 only because f1-joining and z2 encoding happens in its ComplexCell): - params['encd_rnn_type'] = 'BidirectionalGRU' (any will do) - params['dec_rnn_type'] != 'Complex' - params['encd_rnn2_units'] = 0 # TODO: I want to reuse encd_rnn2_units to parameterize LFADS' complex cell's internal GRU. - zs_sample = None Parameters: Name Type Description Default params dict 'encd_rnn_type': Type of RNN. '' or 'Bidirectional' + one of ['GRU', 'LSTM', 'SimpleRNN', 'GRUClip'] (just like create_f_encoder's 'encs_rnn_type' param), OR something else to not use an RNN and just use a flat Dense layer. Do not use 'Bidirectional' prefix for causal modeling. 'gru_clip_value': Required if encd_rnn_type endswith GRUClip 'encd_rnn1_units': Number of units in the first-level z encoder layer. 'zd_lag': simulate a delay in the z1 outputs. 'encd_rnn2_units': Number of units in the second-level z encoder layer. Can be 0 to skip. z2, if used, is always a feedforward SimpleRNN. required inputs Tensor input data, probably one of the outputs from prepare_inputs . required zs_sample Optional[int] Sample from q_f. Only required if using DSAE-Full. None f_inputs_pre_z1 bool True if the zs_sample (if provided) joins as inputs to z1, otherwise it joins as inputs to z2. True kernel_initializer str See tfkl RNN docs 'lecun_normal' bias_initializer str See tfkl RNN docs 'zeros' recurrent_regularizer str See tfkl RNN docs 'l2' Returns: Type Description Tensor A Tensor (or placeholder) with shape (samples (optional), batch_size, timesteps, units), where units refers to encd_rnn2_units if encd_rnn2_units > 0, else encd_rnn1_units. Source code in indl/model/beta_vae.py def create_encd ( params : dict , inputs : tf . Tensor , zs_sample : Optional [ int ] = None , f_inputs_pre_z1 : bool = True , kernel_initializer : str = 'lecun_normal' , bias_initializer : str = 'zeros' , recurrent_regularizer : str = 'l2' ) -> tf . Tensor : \"\"\" Run the input through the Dynamic Encoder (aka LFADS' controller input encoder). Different formulations in the literature: DSAE static: z not used DSAE dynamic full: - params['encd_rnn_type'] indicates Bidirectional RNN of some cell type - params['encd_rnn2_units'] > 0 - zs_sample is a tensor, possibly with a leading 'samples' dimension. DSAE dynamic factorized: - params['encd_rnn_type'] can be None or something nonsense. - params['encd_rnn2_units'] = 0 - zs_sample = None LFADS (simple z1 only because f1-joining and z2 encoding happens in its ComplexCell): - params['encd_rnn_type'] = 'BidirectionalGRU' (any will do) - params['dec_rnn_type'] != 'Complex' - params['encd_rnn2_units'] = 0 # TODO: I want to reuse encd_rnn2_units to parameterize LFADS' complex cell's internal GRU. - zs_sample = None Args: params: - 'encd_rnn_type': Type of RNN. '' or 'Bidirectional' + one of ['GRU', 'LSTM', 'SimpleRNN', 'GRUClip'] (just like create_f_encoder's 'encs_rnn_type' param), OR something else to not use an RNN and just use a flat Dense layer. Do not use 'Bidirectional' prefix for causal modeling. - 'gru_clip_value': Required if encd_rnn_type endswith GRUClip - 'encd_rnn1_units': Number of units in the first-level z encoder layer. - 'zd_lag': simulate a delay in the z1 outputs. - 'encd_rnn2_units': Number of units in the second-level z encoder layer. Can be 0 to skip. z2, if used, is always a feedforward SimpleRNN. inputs: input data, probably one of the outputs from `prepare_inputs`. zs_sample: Sample from q_f. Only required if using DSAE-Full. f_inputs_pre_z1: True if the zs_sample (if provided) joins as inputs to z1, otherwise it joins as inputs to z2. kernel_initializer: See tfkl RNN docs bias_initializer: See tfkl RNN docs recurrent_regularizer: See tfkl RNN docs Returns: A Tensor (or placeholder) with shape (samples (optional), batch_size, timesteps, units), where units refers to encd_rnn2_units if encd_rnn2_units > 0, else encd_rnn1_units. \"\"\" if zs_sample is not None : # If zs_sample is a dist we need to transform it to a tensor. # Expand along time dimension by broadcast-add to zeros. n_times = tf . shape ( inputs )[ - 2 ] zs_sample = zs_sample [ ... , tf . newaxis , :] + tf . zeros ([ n_times , 1 ]) # Add optional f_input that we tile and concatenate onto _inputs. if zs_sample is not None and f_inputs_pre_z1 : # Highly unlikely, but just in case inputs has samples dimension(s) then we can accommodate those here broadcast_shape_f = tf . concat (( tf . shape ( inputs )[: - 3 ], [ 1 , 1 , 1 ]), 0 ) zs_sample = zs_sample + tf . zeros ( broadcast_shape_f ) # Expand inputs along sample dimension(s). broadcast_shape_inputs = tf . concat (( tf . shape ( zs_sample )[: - 3 ], [ 1 , 1 , 1 ]), 0 ) inputs = inputs + tf . zeros ( broadcast_shape_inputs ) # Concatenate inputs with zs_sample inputs = tf . concat ([ inputs , zs_sample ], axis =- 1 ) # (optional-samples, batch, timesteps, feat_dim+latent_static) z1_is_rnn = params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ) \\ or ( params [ 'encd_rnn_type' ] in [ 'GRU' , 'LSTM' , 'SimpleRNN' , 'GRUClip' ]) has_z2 = 'encd_rnn2_units' in params and params [ 'encd_rnn2_units' ] > 0 if z1_is_rnn or has_z2 : rnn_kwargs = dict ( kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = 0 , # Dropout on inputs not needed. return_sequences = True ) if params [ 'encd_rnn_type' ] . endswith ( 'GRU' ): rnn_layer_cls = tfkl . GRU elif params [ 'encd_rnn_type' ] . endswith ( 'LSTM' ): rnn_layer_cls = tfkl . LSTM elif params [ 'encd_rnn_type' ] . endswith ( 'SimpleRNN' ): rnn_layer_cls = tfkl . SimpleRNN elif params [ 'encd_rnn_type' ] . endswith ( 'GRUClip' ): rnn_layer_cls = GRUClip rnn_kwargs [ 'clip_value' ] = params [ 'gru_clip_value' ] if z1_is_rnn : # Collapse samples + batch dims -- required by LSTM sb_shape = tf . shape ( inputs )[: - 2 ] # keep a record of the (samples,) batch shape. # new_shape = tf.concat(([-1], tf.shape(inputs)[-2:]), axis=0) # Can't remember why I couldn't use -1 here. new_d1 = tf . reshape ( tf . reduce_prod ( tf . shape ( inputs )[: - 2 ]), ( 1 ,)) new_shape = tf . concat (( new_d1 , tf . shape ( inputs )[ - 2 :]), 0 ) inputs = tf . reshape ( inputs , new_shape ) # inputs shape now (samples*batch, T, feat+lat_stat) if params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ): _enc_z = tfkl . Bidirectional ( rnn_layer_cls ( params [ 'encd_rnn1_units' ], ** rnn_kwargs ), merge_mode = \"concat\" , name = \"z_rnn_1\" )( inputs ) else : _enc_z = rnn_layer_cls ( params [ 'encd_rnn1_units' ], ** rnn_kwargs )( inputs ) # Restore leading samples, batch dims. _enc_z = tf . reshape ( _enc_z , tf . concat (( sb_shape , tf . shape ( _enc_z )[ 1 :]), axis = 0 )) else : # Not RNN, just MLP _enc_z = tfkl . Dense ( params [ 'encd_rnn1_units' ])( inputs ) if params [ 'zd_lag' ] > 0 : if params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ): # Shift _fwd back, dropping the latest samples, fill front with zeros # Shift _bwd forward, dropping the earliest samples, fill tail with zeros. # _fwd = [0,0,0,...,old_fwd[-lag:]]; _bwd = [old_bwd[lag:], ..., 0, 0, 0] _fwd , _bwd = tf . split ( _enc_z , 2 , axis =- 1 ) _fwd = tf . concat ([ tf . zeros_like ( _fwd [ ... , : params [ 'zd_lag' ], :]), _fwd [ ... , : - params [ 'zd_lag' ], :]], axis =- 2 ) _bwd = tf . concat ([ _bwd [ ... , params [ 'zd_lag' ]:, :], tf . zeros_like ( _bwd [:, - params [ 'zd_lag' ]:, :])], axis =- 2 ) _enc_z = tf . concat ([ _fwd , _bwd ], axis =- 1 ) else : _enc_z = tf . concat ([ tf . zeros_like ( _enc_z [ ... , : params [ 'zd_lag' ], :]), _enc_z [ ... , : - params [ 'zd_lag' ], :]], axis =- 2 ) if params [ 'encd_rnn_type' ] . startswith ( 'Bidirectional' ): # Recombine forward and backward to get merge_mode=\"sum\" _fwd , _bwd = tf . split ( _enc_z , 2 , axis =- 1 ) _enc_z = _fwd + _bwd not_lfads = ( 'dec_rnn_type' not in params ) or ( params [ 'dec_rnn_type' ] != 'Complex' ) if not_lfads and has_z2 : if zs_sample is not None and not f_inputs_pre_z1 : # Highly unlikely, but just in case _enc_z has samples dimension(s) then we can accommodate those here broadcast_shape_f = tf . concat (( tf . shape ( _enc_z )[: - 3 ], [ 1 , 1 , 1 ]), axis = 0 ) zs_sample = zs_sample + tf . zeros ( broadcast_shape_f ) # Expand _enc_z along sample dimension(s). broadcast_shape_zenc = tf . concat (( tf . shape ( zs_sample )[: - 3 ], [ 1 , 1 , 1 ]), axis = 0 ) _enc_z = _enc_z + tf . zeros ( broadcast_shape_zenc ) # Concatenate _enc_z with zs_sample _enc_z = tf . concat ([ _enc_z , zs_sample ], axis =- 1 ) # (optional-samples, batch, timesteps, feat_dim+latent_static) # TODO: LFADS does an additional dropout before input to z2 # Collapse samples + batch dims -- required by RNNs sb_shape = tf . shape ( _enc_z )[: - 2 ] # keep a record of the (samples,) batch shape. # new_shape = tf.concat(([-1], tf.shape(_enc_z)[-2:]), axis=0) # Can't remember why I couldn't use -1 here. new_d1 = tf . reshape ( tf . reduce_prod ( tf . shape ( _enc_z )[: - 2 ]), ( 1 ,)) new_shape = tf . concat (( new_d1 , tf . shape ( _enc_z )[ - 2 :]), axis = 0 ) _enc_z = tf . reshape ( _enc_z , new_shape ) # _enc_z shape now (samples*batch, T, encd_rnn1_units+lat_stat) # z2 vanilla RNN used in DSAE Full. LFADS' z2 used elsewhere. _ = rnn_kwargs . pop ( 'clip_value' , None ) _enc_z = tfkl . SimpleRNN ( params [ 'encd_rnn2_units' ], ** rnn_kwargs )( _enc_z ) # Restore leading samples, batch dims. _enc_z = tf . reshape ( _enc_z , tf . concat (( sb_shape , tf . shape ( _enc_z )[ 1 :]), axis = 0 )) return _enc_z","title":"create_encd()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.create_encs","text":"The static arm of the encoder, aka in LFADS as the \"initial condition encoder\". Parameters: Name Type Description Default params dict required keys are 'encs_rnn_units' (int or iterable of ints), 'encs_rnn_type' (str), 'gru_clip_value' required inputs Tensor a tensor with dimensions (batch_size, timesteps, input_dim) batch_size and timesteps may be None for placeholder tensors (i.e., created by tf.keras.Input) required kernel_initializer see TF's RNN docs 'lecun_normal' bias_initializer see TF's RNN docs 'zeros' recurrent_regularizer see TF's RNN docs 'l2' Returns: Type Description Tensor statically encoded x (not variational) Source code in indl/model/beta_vae.py def create_encs ( params : dict , inputs : tf . Tensor , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' , recurrent_regularizer = 'l2' ) -> tf . Tensor : \"\"\" The static arm of the encoder, aka in LFADS as the \"initial condition encoder\". Args: params: required keys are 'encs_rnn_units' (int or iterable of ints), 'encs_rnn_type' (str), 'gru_clip_value' inputs: a tensor with dimensions (batch_size, timesteps, input_dim) batch_size and timesteps may be `None` for placeholder tensors (i.e., created by tf.keras.Input) kernel_initializer: see TF's RNN docs bias_initializer: see TF's RNN docs recurrent_regularizer: see TF's RNN docs Returns: statically encoded x (not variational) \"\"\" _encoded_s = inputs encs_rnn_units = params [ 'encs_rnn_units' ] if not isinstance ( encs_rnn_units , ( list , tuple )): encs_rnn_units = [ encs_rnn_units ] rnn_kwargs = dict ( kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = 0 , # Dropout on inputs not needed. ) if params [ 'encs_rnn_type' ] . endswith ( 'GRU' ): rnn_layer_cls = tfkl . GRU elif params [ 'encs_rnn_type' ] . endswith ( 'LSTM' ): rnn_layer_cls = tfkl . LSTM elif params [ 'encs_rnn_type' ] . endswith ( 'SimpleRNN' ): rnn_layer_cls = tfkl . SimpleRNN elif params [ 'encs_rnn_type' ] . endswith ( 'GRUClip' ): rnn_layer_cls = GRUClip rnn_kwargs [ 'clip_value' ] = params [ 'gru_clip_value' ] for ix , rnn_units in enumerate ( encs_rnn_units ): rnn_kwargs [ 'return_sequences' ] = ( ix + 1 ) < len ( encs_rnn_units ) if params [ 'encs_rnn_type' ] . startswith ( 'Bidirectional' ): _encoded_s = tfkl . Bidirectional ( rnn_layer_cls ( rnn_units , ** rnn_kwargs ), merge_mode = \"concat\" , name = \"rnn_s_\" + str ( ix ))( _encoded_s ) else : _encoded_s = rnn_layer_cls ( rnn_units , ** rnn_kwargs )( _encoded_s ) return _encoded_s","title":"create_encs()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.create_pzd","text":"The z_prior is a sequence of multivariate diagonal normal distributions. The parameters of the distribution at each timestep are a function of (a sample drawn from) the distribution in the previous timestep. For DSAE, the process that governs the evolution of parameters over time is a RNN. For each trial, it is initialized to zeros and the first step is a zero-input. Subsequent inputs will be samples from the previous step. The RNN parameters are learnable. See process_dist.RNNMVNGenerator For LFADS, the process that governs the evolution of parameters over time is AR1. Each dimension is an independent process. The processes variances and the processes autocorrelation time constants (taus) are both trainable parameters. See process_dist.AR1ProcessMVNGenerator We also have process_dist.TiledMVNGenerator where a single distribution is shared over all timesteps. TODO: tfp also has Autoregressive and GaussianProcess distributions which can be parameterized with trainable variables and are maybe worth investigating here. The purpose of the prior is for KL-divergence loss, and I didn't have much luck using KL-divergence as a regularizer or model loss, so we will be calculating the KL-divergence during the manual train_step. It is therefore unnecessary to return a tensor-like here. Instead, we return an instance of a class, and that instance must have a .get_dist() method that we call explicitly during train_step to get a distribution, then the distribution will be used to calculate KL divergence. Parameters: Name Type Description Default params dict required - 'pzd_process' Which process to use for the sequence-of-MVN priors on z. Valid values: 'AR1' - uses AR1ProcessMVNGenerator {rnn cell type} - including GRUClip, GRU, LSTM, RNN (not case-sensitive), uses RNNMVNGenerator 'none' - uses TiledMVNGenerator required Returns: Type Description IProcessMVNGenerator an MVNGenerator. Get a sample and dist from the generator with sample, dist = generator.get_dist(timestamps, samples=N_SAMPS, batch_size=BATCH_SIZE) In most cases, when calculating KL and the returned dist is of the same type as the latent distribution, then the analytic KL can be calculated and only the dist event_shape matters, so samples and batch_size can be set to 1. Source code in indl/model/beta_vae.py def create_pzd ( params : dict ) -> IProcessMVNGenerator : \"\"\" The z_prior is a sequence of multivariate diagonal normal distributions. The parameters of the distribution at each timestep are a function of (a sample drawn from) the distribution in the previous timestep. For DSAE, the process that governs the evolution of parameters over time is a RNN. For each trial, it is initialized to zeros and the first step is a zero-input. Subsequent inputs will be samples from the previous step. The RNN parameters are learnable. See process_dist.RNNMVNGenerator For LFADS, the process that governs the evolution of parameters over time is AR1. Each dimension is an independent process. The processes variances and the processes autocorrelation time constants (taus) are both trainable parameters. See process_dist.AR1ProcessMVNGenerator We also have process_dist.TiledMVNGenerator where a single distribution is shared over all timesteps. TODO: tfp also has Autoregressive and GaussianProcess distributions which can be parameterized with trainable variables and are maybe worth investigating here. The purpose of the prior is for KL-divergence loss, and I didn't have much luck using KL-divergence as a regularizer or model loss, so we will be calculating the KL-divergence during the manual train_step. It is therefore unnecessary to return a tensor-like here. Instead, we return an instance of a class, and that instance must have a .get_dist() method that we call explicitly during train_step to get a distribution, then the distribution will be used to calculate KL divergence. Args: params: - 'pzd_process': Which process to use for the sequence-of-MVN priors on z. Valid values: 'AR1' - uses `AR1ProcessMVNGenerator` {rnn cell type} - including GRUClip, GRU, LSTM, RNN (not case-sensitive), uses `RNNMVNGenerator` 'none' - uses `TiledMVNGenerator` Returns: an MVNGenerator. Get a sample and dist from the generator with `sample, dist = generator.get_dist(timestamps, samples=N_SAMPS, batch_size=BATCH_SIZE)` In most cases, when calculating KL and the returned dist is of the same type as the latent distribution, then the analytic KL can be calculated and only the dist event_shape matters, so samples and batch_size can be set to 1. \"\"\" if params [ 'pzd_process' ] == 'AR1' : from indl.dists.sequential import AR1ProcessMVNGenerator init_taus = [ params [ 'pzd_tau' ] for _ in range ( params [ 'zd_size' ])] init_std = [ params [ 'pzd_init_std' ] for _ in range ( params [ 'zd_size' ])] gen = AR1ProcessMVNGenerator ( init_taus , init_std = init_std , trainable_mean = params [ 'pzd_train_mean' ], trainable_tau = params [ 'pzd_train_tau' ], trainable_var = params [ 'pzd_train_var' ], offdiag = params [ 'pzd_offdiag' ]) elif params [ 'pzd_process' ] in [ 'RNN' , 'LSTM' , 'GRU' , 'GRUClip' ]: from indl.dists.sequential import RNNMVNGenerator \"\"\" units: int, out_dim: int, cell_type: str, shift_std: float = 0.1, offdiag: bool = False \"\"\" gen = RNNMVNGenerator ( params [ 'pzd_units' ], out_dim = params [ 'zd_size' ], cell_type = params [ 'pzd_process' ], shift_std = params [ 'pzd_init_std' ], offdiag = params [ 'pzd_offdiag' ]) else : from indl.dists.sequential import TiledMVNGenerator gen = TiledMVNGenerator ( params [ 'pzd_units' ], init_std = params [ 'pzd_init_std' ], trainable_mean = params [ 'pzd_train_mean' ], trainable_var = params [ 'pzd_train_var' ], offdiag = params [ 'pzd_offdiag' ]) return gen","title":"create_pzd()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.create_pzs","text":"Make a prior with optionally trainable mean and variance. Parameters: Name Type Description Default params dict 'pzs_kappa' -- must be 0. 'zs_size' 'qzs_init_std' 'pzs_train_mean' 'pzs_train_var' 'pzs_off_diag' required Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL] Either tfd.MultivariateNormalTril if params['pzs_off_diag'] else tfd.MultivariateNormalDiag Source code in indl/model/beta_vae.py def create_pzs ( params : dict ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Make a prior with optionally trainable mean and variance. Args: params: - 'pzs_kappa' -- must be 0. - 'zs_size' - 'qzs_init_std' - 'pzs_train_mean' - 'pzs_train_var' - 'pzs_off_diag' Returns: Either tfd.MultivariateNormalTril if params['pzs_off_diag'] else tfd.MultivariateNormalDiag \"\"\" if params [ 'pzs_kappa' ] > 0 : raise NotImplementedError pzs = make_mvn_prior ( params [ 'zs_size' ], init_std = params [ 'qzs_init_std' ], trainable_mean = params [ 'pzs_train_mean' ], trainable_var = params [ 'pzs_train_var' ], offdiag = params [ 'pzs_off_diag' ]) # Old way: # prior_factory = lambda: tfd.MultivariateNormalDiag(loc=0, scale_diag=params['pzs_kappa']) # prior_factory = LearnableMultivariateNormalDiag(params['zs_size']) # prior_factory.build(input_shape=(0,)) return pzs","title":"create_pzs()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.generate_default_args","text":"Returns: non-tunable parameters in a TestArgs object Access args with obj.arg_name or . dict ['arg_name'] Source code in indl/model/beta_vae.py def generate_default_args (): \"\"\" Returns: non-tunable parameters in a TestArgs object Access args with obj.arg_name or .__dict__['arg_name'] \"\"\" # non tunable parameters return type ( 'TestArgs' , ( object ,), dict ( random_seed = 1337 , batch_size = 16 , n_epochs = 100 , resample_X = 10 , # spike count bin size q_samples = 1 , # At some points this gets folded into the batch dim so it has to # be the same for q_f and q_z. # Encoder - Static encs_rnn_type = \"BidirectionalGRUClip\" , # Encoder RNN cell type: ('Bidirectional' or '') # + ('GRU', 'LSTM', 'SimpleRNN', 'GRUClip') encs_input_samps = 0 , # Set to > 0 to restrict f_encoder to only see this many samples # This is one of several settings required to prevent acausal modeling. qzs_off_diag = False , # If latent dist may have non-zero off diagonals # Static Latent Dist qzs_init_std = 0.1 , # (LFADS: ic_prior_var) # Static Latent Prior pzs_off_diag = False , # If latent prior may have non-zero off diagonals pzs_kappa = 0.0 , # In LFADS this is a tuned hyperparameter, ~0.1 pzs_train_mean = True , # True in LFADS pzs_train_var = True , # False in LFADS # Encoder - Dynamic encd_rnn_type = \"BidirectionalGRUClip\" , # Encoder RNN cell type # To prevent acausal modeling on the controller input, do not use Bidir zd_lag = 0 , # Time lag on the z-encoder output. # Same as LFADS' `controller_input_lag` # Dynamic Latent Dist qzd_init_std = 0.1 , # std shift when z-latent is 0, # and initial prior variance for RNN and tiled gaussian priors qzd_off_diag = False , # Dynamic Latent Prior pzd_process = \"AR1\" , # AR1 or a RNN cell type, or anything else 'none' for # simple tiled gaussian. pzd_train_mean = False , # pzd_train_var = True , # Also used for train_nvar pzd_init_std = 0.1 , # Also used for inittau pzd_offdiag = False , # pzd_units = 8 , # Number of units for RNN MVN prior (RNNMVNGenerator) pzd_tau = 10.0 , # Initial autocorrelation for AR(1) priors (AR1ProcessMVNGenerator) pzd_train_tau = True , # # Decoder dec_rnn_type = \"GRUClip\" , # Decoder generative RNN cell type. \"Complex\" is for LFADS. zs_to_dec = \"initial conditions\" , # How static latent is used in the decoder. # \"initial conditions\" or \"tile inputs\" # Output output_dist = \"Poisson\" , # Poisson or anything else for MVNDiag ))","title":"generate_default_args()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.generate_default_params","text":"Returns: tunable parameters in dictionary Source code in indl/model/beta_vae.py def generate_default_params () -> dict : \"\"\" Returns: tunable parameters in dictionary \"\"\" # tunable parameters return { \"dropout_rate\" : 1e-2 , # (1e-2) \"coordinated_dropout_rate\" : 0.1 , # \"input_factors\" : 0 , # Extra Dense layer applied to inputs. Good for multi-session. (not impl.) \"gru_clip_value\" : 5.0 , # Max value recurrent cell can take before being clipped (5.0) \"gen_l2_reg\" : 1e-4 , # (1e-4) \"learning_rate\" : 2e-3 , # (2e-3) # \"max_grad_norm\": 200.0 # Encoder - Static \"encs_rnn_units\" : [ 128 ], # Number of units in static encoder RNN. # Increase list length to add more RNN layers. (128) # Same as LFADS' `ic_enc_dim` \"zs_size\" : 10 , # Size of static latent vector zs (10) # Same as LFADS' `ic_dim` # Encoder - Dynamic \"encd_rnn1_units\" : 16 , # Number of units in dynamic encoder first RNN. # Same as LFADS `ci_enc_dim` \"encd_rnn2_units\" : 16 , # Number of units in dynamic encoder second RNN (DHSAE Full or LFADS con). # Same as LFADS `con_dim` \"zd_size\" : 4 , # Dimensionality of q_zt posterior. # Same as LFADS' `co_dim` # Decoder \"dec_rnn_units\" : 256 , # Number of RNN cells in decoder RNN (256) # Same as LFADS `gen_dim` \"n_factors\" : 10 , # Number of latent factors (24) # Same as LFADS' `factors_dim` }","title":"generate_default_params()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.make_encd_variational","text":"Take the encoded latent sequence z (output of z1 and optionally z2) and convert it to a distribution. This isn't necessary for LFADS models because z isn't in its final encoded form until inside the Complex cell, so it's up to the complex cell to handle the formation of the distribution. Parameters: Name Type Description Default params dict required enc_z Tensor input Tensor required Returns: Type Description q_z A tfd.Distribution. - q_z.sample() will not return a prepended samples dim if params['q_samples'] == 1, else it will. - q_z.sample(N) will always return a prepended samples dim (shape N), even if N == 1. If you need to reshape so the timesteps dim isn't considered in the \"batch_shape\" but is in the \"event_shape\", then you can use tfd.Independent(q_z, reinterpreted_batch_ndims=1). Source code in indl/model/beta_vae.py def make_encd_variational ( params : dict , enc_z : tf . Tensor ) -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Take the encoded latent sequence z (output of z1 and optionally z2) and convert it to a distribution. This isn't necessary for LFADS models because z isn't in its final encoded form until inside the Complex cell, so it's up to the complex cell to handle the formation of the distribution. Args: params: - 'zd_size' - 'qzd_off_diag' - 'qzd_init_std' - 'q_samples' enc_z: input Tensor Returns: q_z: A tfd.Distribution. - q_z.sample() will not return a prepended samples dim if params['q_samples'] == 1, else it will. - q_z.sample(N) will always return a prepended samples dim (shape N), even if N == 1. If you need to reshape so the timesteps dim isn't considered in the \"batch_shape\" but is in the \"event_shape\", then you can use tfd.Independent(q_z, reinterpreted_batch_ndims=1). \"\"\" from indl.dists import make_variational if 'dec_rnn_type' in params : assert params [ 'dec_rnn_type' ] != \"Complex\" , \"Skip this step. LFADS complex cell handles this intrinsically.\" # Get a multivariate normal diag over each timestep. q_z = make_variational ( enc_z , params [ 'zd_size' ], init_std = params [ 'qzd_init_std' ], offdiag = params [ 'qzd_off_diag' ], samps = params [ 'q_samples' ], loc_name = \"z_loc\" , scale_name = \"z_scale\" , use_mvn_diag = True ) return q_z","title":"make_encd_variational()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.make_encs_variational","text":"Make the output of the Static Encoder (encs) variational. Adds a dropout layer and passes through indl.model.tfp.make_variational with the correct parameters. Parameters: Name Type Description Default params dict 'dropout_rate' 'zs_size' 'qzs_off_diag' 'qzs_init_std' 'q_samples' required encoded_s Tensor required Returns: Type Description Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL] q(zs|x) Source code in indl/model/beta_vae.py def make_encs_variational ( params : dict , encoded_s : tf . Tensor ) \\ -> Union [ tfd . MultivariateNormalDiag , tfd . MultivariateNormalTriL ]: \"\"\" Make the output of the Static Encoder (encs) variational. Adds a dropout layer and passes through indl.model.tfp.make_variational with the correct parameters. Args: params: - 'dropout_rate' - 'zs_size' - 'qzs_off_diag' - 'qzs_init_std' - 'q_samples' encoded_s: Returns: q(zs|x) \"\"\" from indl.dists import make_variational encoded_s = tfkl . Dropout ( params [ 'dropout_rate' ])( encoded_s ) qzs = make_variational ( encoded_s , params [ 'zs_size' ], init_std = params [ 'qzs_init_std' ], offdiag = params [ 'qzs_off_diag' ], samps = params [ 'q_samples' ], loc_name = \"f_loc\" , scale_name = \"f_scale\" , use_mvn_diag = True ) return qzs","title":"make_encs_variational()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.prepare_inputs","text":"Prepare the data for entry into the encoder(s). This comprises several steps: dropout (optional) split off inputs to the f_encoder to prevent acausal modeling (optional) coordinated dropout (not implemented) CV mask (optional) Dense layer to read-in inputs to a common set of input factors. To keep the model flexible to inputs of varying timesteps, this model fragment does not check the size of the timestep dimension. Please make sure that params['encs_input_samps'] is less than the smallest number of timesteps in your inputs. Parameters: Name Type Description Default params dict has the following keys - 'dropout_rate' - 'encs_input_samps' - set to > 0 to split off f_encoder inputs to prevent acausal modeling. - 'coordinated_dropout_rate' - 'input_factors' required _inputs Tensor With dimensions (batch, timesteps, features) required Returns: Type Description f_enc_inputs to be used as inputs to a subsequent f_encoder. If params['encs_input_samps'] > 0 then this will simply be the leading slice off inputs unmasked, else this will be full length and masked. (In both cases it will be optionally run through Dense layer). z_enc_inputs: to be used as inputs to a subsequent z_encoder cd_kept_mask: with dtype tf.bool, to be used during decoding for \"coordinated dropout\" Source code in indl/model/beta_vae.py def prepare_inputs ( params : dict , _inputs : tf . Tensor ) -> Tuple [ tf . Tensor , tf . Tensor , tf . Tensor ]: \"\"\" Prepare the data for entry into the encoder(s). This comprises several steps: * dropout * (optional) split off inputs to the f_encoder to prevent acausal modeling * (optional) coordinated dropout * (not implemented) CV mask * (optional) Dense layer to read-in inputs to a common set of input factors. To keep the model flexible to inputs of varying timesteps, this model fragment does not check the size of the timestep dimension. Please make sure that params['encs_input_samps'] is less than the smallest number of timesteps in your inputs. Args: params: has the following keys - 'dropout_rate' - 'encs_input_samps' - set to > 0 to split off f_encoder inputs to prevent acausal modeling. - 'coordinated_dropout_rate' - 'input_factors' _inputs: With dimensions (batch, timesteps, features) Returns: f_enc_inputs: to be used as inputs to a subsequent f_encoder. If params['encs_input_samps'] > 0 then this will simply be the leading slice off inputs unmasked, else this will be full length and masked. (In both cases it will be optionally run through Dense layer). z_enc_inputs: to be used as inputs to a subsequent z_encoder cd_kept_mask: with dtype tf.bool, to be used during decoding for \"coordinated dropout\" \"\"\" _inputs = tfkl . Dropout ( params [ 'dropout_rate' ])( _inputs ) # The f-encoder takes the entire sequence and outputs a single-timestamp vector, # this vector is used as the decoder's initial condition. This has the potential # to create acausal modeling because the decoder will have knowledge of the entire # sequence from its first timestep. # We can optionally split the input to _f_enc_inputs and remaining _inputs # RNN will only see _f_enc_inputs to help prevent acausal modeling. _f_enc_inputs = _inputs [:, : params [ 'encs_input_samps' ], :] _inputs = _inputs [:, params [ 'encs_input_samps' ]:, :] # Coordinated dropout on _inputs only. # Why not _f_enc_inputs? Is it because it is likely too short to matter? _masked_inputs , cd_kept_mask = CoordinatedDropout ( params [ 'coordinated_dropout_rate' ])( _inputs ) # cd_kept_mask is part of the return so it can be used during decoding. # The z-encoder inputs will always be full length. _z_enc_inputs = tf . concat ([ _f_enc_inputs , _masked_inputs ], axis =- 2 ) if params [ 'encs_input_samps' ] == 0 : # With no encs_input_samps specification, the f_enc inputs are the full input. # Note this has coordinated dropout, whereas it wouldn't if encs_input_samps was specified. _f_enc_inputs = _masked_inputs # Note: Skipping over LFADS' CV Mask for now. if params [ 'input_factors' ] > 0 : _f_enc_inputs = tfkl . Dense ( params [ 'input_factors' ])( _f_enc_inputs ) _z_enc_inputs = tfkl . Dense ( params [ 'input_factors' ])( _z_enc_inputs ) return _f_enc_inputs , _z_enc_inputs , cd_kept_mask","title":"prepare_inputs()"},{"location":"API/model/beta_vae/#indl.model.beta_vae.sample_pzd","text":"Samples from z_prior timesteps times. z_prior is a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Parameters: Name Type Description Default gen an instance of a concrete class that inherits from indl.dists.sequential.IProcessMVNGenerator , such as AR1ProcessMVNGenerator , RNNMVNGenerator or TiledMVNGenerator . required timesteps int Number of timesteps to sample for each sequence. required params dict q_samples batch_size required fixed Boolean for whether or not to share the same random sample across all sequences in batch. False Returns: Type Description Tuple[tensorflow.python.framework.ops.Tensor, tensorflow_probability.python.distributions.independent.Independent] A tuple of a sample from a distribution and the distribution itself. The tensor is of shape (samples, batch_size, timesteps, zd_size). The distribution is a tfd.Independent wrapping a multivariate normal diagonal. Source code in indl/model/beta_vae.py def sample_pzd ( pzd : IProcessMVNGenerator , timesteps : int , params : dict , fixed = False ) \\ -> Tuple [ tf . Tensor , tfd . Independent ]: \"\"\" Samples from z_prior `timesteps` times. z_prior is a multivariate normal diagonal distribution for each timestep. We collect each timestep-dist's params (loc and scale), then use them to create the return value: a single MVN diag dist that has a dimension for timesteps. The cell returns a full dist for each timestep so that we can 'sample' it. If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent to doing a generative RNN (init state = zeros, return_sequences=True) then passing those values through a pair of Dense layers to parameterize a single MVNDiag. Args: gen: an instance of a concrete class that inherits from `indl.dists.sequential.IProcessMVNGenerator`, such as `AR1ProcessMVNGenerator`, `RNNMVNGenerator` or `TiledMVNGenerator`. timesteps: Number of timesteps to sample for each sequence. params: - q_samples - batch_size fixed: Boolean for whether or not to share the same random sample across all sequences in batch. Returns: A tuple of a sample from a distribution and the distribution itself. The tensor is of shape (samples, batch_size, timesteps, zd_size). The distribution is a tfd.Independent wrapping a multivariate normal diagonal. \"\"\" return pzd . get_dist ( timesteps , samples = params [ 'q_samples' ], batch_size = params [ 'batch_size' ], fixed = fixed )","title":"sample_pzd()"},{"location":"API/model/lfads/","text":"lfads create_generator_lfads ( params ) units_gen, units_con, factors_dim, co_dim, ext_input_dim, inject_ext_input_to_gen, Source code in indl/model/lfads/__init__.py def create_generator_lfads ( params ): \"\"\" units_gen, units_con, factors_dim, co_dim, ext_input_dim, inject_ext_input_to_gen, \"\"\" from indl.model.lfads.complex import ComplexCell # TODO: Sample/Mean from $q(f)$. This will replace the first element in generator init_states # TODO: need a custom function for sample-during-train-mean-during-test. See nn.dropout for inspiration. # TODO: Sample from $q(z_t)$, and optionally concat with ext_input, to build generator inputs. # TODO: continue generator from lfads-cd/lfadslite.py start at 495 custom_cell = ComplexCell ( params [ 'gen_dim' ], # Units in generator GRU con_hidden_state_dim , # Units in controller GRU params [ 'factors_dim' ], params [ 'co_dim' ], params [ 'ext_input_dim' ], True , ) generator = tfkl . RNN ( custom_cell , return_sequences = True , # recurrent_regularizer=tf.keras.regularizers.l2(l=gen_l2_reg), name = 'gen_rnn' ) init_states = generator . get_initial_state ( gen_input ) gen_output = generator ( gen_input , initial_state = init_states ) factors = gen_output [ - 1 ] return factors complex ComplexCell ( AbstractRNNCell ) Source code in indl/model/lfads/complex.py class ComplexCell ( tfkl . AbstractRNNCell ): _BIAS_VARIABLE_NAME = \"bias\" _WEIGHTS_VARIABLE_NAME = \"kernel\" \"\"\"Cell class for the LFADS Generative GRU + Controller Input This cell uses two GRUClipCells: One for the Generator and one for the Controller. The Controller - This is equivalent to the \"z2\" RNN layer in the other disentangling AE formulations. - Optional -- only used if z2_units (LFADS: con_dim) > 0 - inputs: the concatenation of (a) the encoded controller inputs and (b) the generator cell's state from the previous iteration transformed through the factor dense layer. (on the zeroth step, b starts with f-encoded latents) The encoded controller inputs are themselves the output of an RNN with dim size z1_units, or 'ci_enc_dim' in LFADS - initial state: in LFADS -- a **learnable Variable** of zeros. The Generator - inputs: the output of the Controller cell and optionally 'external' inputs. - initial state: in LFADS -- a sample of a posterior distribution that is parameterized by an encoder. The two cells share the same initialization parameters (activations, initializers, bias, dropout, regularizer, etc.) except for the number of units. Arguments: units_gen: Positive integer, number of units in generator RNN cell. z2_units: Positive integer, number of units in controller RNN cell. (units_con in LFADS) factors_dim: Number of units in Dense layer for factors output. This layer would normally be external to the RNN. However, in LFADS, the factors dense layer is also used to transform the t-1 generator cell state which becomes part of the _inputs_ to the controller cell. z_latent_size: Dimensionality of variational posterior from controller output --> inputs to controller RNN (LFADS: co_dim) ext_input_dim: Size of external input. The cell input will be split into encoded_z and ext_input depending on this value. Can be 0. inject_ext_input_to_gen: Only makes sense if ext_input_dim is > 0, and `False` is not implemented. activation: Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass None, no activation is applied (ie. \"linear\" activation: `a(x) = x`). recurrent_activation: Activation function to use for the recurrent step. Default: hard sigmoid (`hard_sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`). Note: LFADS uses normal sigmoid. use_bias: Boolean, whether the layer uses a bias vector. kernel_initializer: Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: lecun_normal Vanilla tensorflow default is glorot_uniform. recurrent_initializer: Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state. Default: orthogonal LFADS uses lecun_normal bias_initializer: Initializer for the bias vector. Default: zeros Note: LFADS uses ones for gate bias and zeros for candidate bias kernel_regularizer: Regularizer function applied to the `kernel` weights matrix. Default: None recurrent_regularizer: Regularizer function applied to the `recurrent_kernel` weights matrix. Default: 'l2' at 0.01 Note: LFADS uses L2 regularization with per-cell scaling. Default for generator is 2000., and for controller is 0. (sum(v*v)*scale*0.5) / numel bias_regularizer: Regularizer function applied to the bias vector. Default: None kernel_constraint: Constraint function applied to the `kernel` weights matrix. Default: None recurrent_constraint: Constraint function applied to the `recurrent_kernel` weights matrix. Default: None bias_constraint: Constraint function applied to the bias vector. Default: None dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.05 recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.0 implementation: Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations. These modes will have different performance profiles on different hardware and for different applications. Note: This applies to the sub-cells. reset_after: GRU convention (whether to apply reset gate after or before matrix multiplication). False = \"before\" (default), True = \"after\" (CuDNN compatible). clip_value: Value at which to clip the GRU cell output. Default: np.inf (no clipping) Call arguments: inputs: A 2D tensor, composed of the following (concatenated together). - Encoded Z1 (LFADS: \"controller inputs\", other frameworks: half way through dynamic or z-encoding). - (Optional) External Input. Set size with `ext_input_dim`, can be 0. states: List of state tensors corresponding to the previous timestep. - gen_cell: Generator cell state, of size `units_gen`. Typically initialized from a sample of the f-latent distribution q(f) (LFADS: \"encoded initial conditions\"; others: \"static\"). - z2_cell: Z2 cell state of size `z2_units`. Initialized with Variable inited to zeros. (LFADS: controller input) - z_latent x 3: Output only for tracking purposes and external KL loss. Not fed back to next iteration. Controller output means, variances, and sampled output (same as means during *testing*) - factors: The main output. Not fed back to next iteration. training: Python boolean indicating whether the layer should behave in training mode or in inference mode. Only relevant when `dropout` or `recurrent_dropout` is used. \"\"\" def __init__ ( self , units_gen , z2_units , factors_dim , z_latent_size , ext_input_dim , inject_ext_input_to_gen = True , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' , recurrent_regularizer = 'l2' , dropout = 0.05 , clip_value = np . inf , ** kwargs ): self . units_gen = units_gen self . z2_units = z2_units self . factors_dim = factors_dim self . z_latent_size = z_latent_size self . ext_input_dim = ext_input_dim self . inject_ext_input_to_gen = inject_ext_input_to_gen self . units = z2_units + units_gen + 3 * z_latent_size + factors_dim super () . __init__ ( ** kwargs ) self . dropout = tfkl . Dropout ( dropout ) self . fac_lin = tfkl . Dense ( self . factors_dim , use_bias = False , kernel_initializer = 'lecun_normal' , # stdev = 1 / np.sqrt(in_size) kernel_constraint = 'unit_norm' ) # w / sqrt(sum(w**2)) # Note, we use norm constraint whereas LFADS uses norm on init only. from indl.rnn.gru_clip import GRUClipCell if self . z2_units > 0 : self . z2_cell = GRUClipCell ( self . z2_units , kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = dropout , clip_value = clip_value , ** kwargs ) else : self . z2_cell = None self . mean_lin = tfkl . Dense ( self . z_latent_size , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' ) self . logvar_lin = tfkl . Dense ( self . z_latent_size , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' ) self . gen_cell = GRUClipCell ( self . units_gen , kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = dropout , clip_value = clip_value , ** kwargs ) @property def state_size ( self ): # [gen_s_new, z2_state, z_latent_mean, z_latent_logvar, q_z_sample, factors_new] state_sizes = [ self . gen_cell . state_size ] if self . z2_units > 0 : state_sizes . append ( self . z2_cell . state_size ) return tuple ( state_sizes ) + ( self . z_latent_size ,) * 3 + ( self . factors_dim ,) @property def output_size ( self ): return self . z2_units + self . units_gen + 3 * self . z_latent_size + self . factors_dim @tf_utils . shape_type_conversion def build ( self , input_shape ): input_dim = input_shape [ - 1 ] if self . z2_units > 0 : self . z2_cell . build ( input_dim + self . factors_dim + self . ext_input_dim ) self . gen_cell . build ( self . z_latent_size + self . ext_input_dim ) self . built = ( self . z2_units == 0 or self . z2_cell . built ) and self . gen_cell . built def get_config ( self ): config = { 'units_gen' : self . units_gen , 'z2_units' : self . z2_units , 'factors_dim' : self . factors_dim , 'z_latent_size' : self . z_latent_size , 'ext_input_dim' : self . ext_input_dim , 'inject_ext_input_to_gen' : self . inject_ext_input_to_gen } base_config = super () . get_config () gru_config = self . gen_cell . get_config () return dict ( list ( base_config . items ()) + list ( gru_config . items ()) + list ( config . items ())) def get_initial_state ( self , inputs = None , batch_size = None , dtype = None , make_K_tensors = True ): init_state = [ self . gen_cell . get_initial_state ( inputs = inputs , batch_size = batch_size , dtype = dtype )] if self . z2_units > 0 : init_state += [ self . z2_cell . get_initial_state ( inputs = inputs , batch_size = batch_size , dtype = dtype )] from tensorflow.python.keras.layers.recurrent import _generate_zero_filled_state if inputs is not None : batch_size = tf . shape ( inputs )[ 0 ] init_state += [ _generate_zero_filled_state ( batch_size , self . z_latent_size , dtype ) for _ in range ( 3 )] init_state += [ _generate_zero_filled_state ( batch_size , self . factors_dim , dtype )] if make_K_tensors : # import tensorflow.keras.backend as K # K.is_tensor(init_state[0]) init_state = [ tfkl . Lambda ( lambda x : x )( _ ) for _ in init_state ] return tuple ( init_state ) def call ( self , inputs , states , training = None ): if training is None : training = K . learning_phase () # if external inputs are used split the inputs if self . ext_input_dim > 0 : z1 = inputs [:, : - self . ext_input_dim ] ext_inputs = inputs [:, - self . ext_input_dim :] else : z1 = inputs ext_inputs = None gen_state , z2_state = states [: 2 ] if self . z_latent_size > 0 : # if controller is used # input to the controller is (con_i and previous step's factors) prev_gen_dropped = self . dropout ( gen_state , training = training ) prev_fac = self . fac_lin ( prev_gen_dropped ) z2_inputs = tf . concat ([ z1 , prev_fac ], axis = 1 ) z2_inputs = self . dropout ( z2_inputs , training = training ) # controller GRU recursion, get new state z2_outputs , z2_state = self . z2_cell ( z2_inputs , z2_state , training = training ) # calculate the inputs to the generator # transformation to mean and logvar of the posterior # TODO: use make_variational(params, z2_state) z_latent_mean = self . mean_lin ( z2_state ) z_latent_logvar = self . logvar_lin ( z2_state ) z_latent_dist = DiagonalGaussianFromExisting ( z_latent_mean , z_latent_logvar ) if training : # TODO: (training or \"posterior_sample_and_average\"), whatever the latter is. q_z_sample = z_latent_dist . sample else : q_z_sample = z_latent_dist . mean else : # pass zeros (0-dim) as inputs to generator q_z_sample = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) z2_state = z_latent_mean = z_latent_logvar = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) # generator's inputs if self . ext_input_dim > 0 and self . inject_ext_input_to_gen : # passing external inputs along with controller output as generator's input gen_inputs = tf . concat ([ q_z_sample , ext_inputs ], axis = 1 ) elif self . ext_input_dim > 0 and not self . inject_ext_input_to_gen : assert 0 , \"Not Implemented!\" else : # using only controller output as generator's input gen_inputs = q_z_sample # generator GRU recursion, get the new state gen_outputs , gen_s_new = self . gen_cell ( gen_inputs , gen_state , training = training ) # calculate the factors gen_s_new_dropped = self . dropout ( gen_s_new , training = training ) factors_new = self . fac_lin ( gen_s_new_dropped ) # Output the states and other values to make them available after RNN new_state = [ gen_s_new , z2_state , z_latent_mean , z_latent_logvar , q_z_sample , factors_new ] return new_state , new_state output_size property readonly Integer or TensorShape: size of outputs produced by this cell. state_size property readonly size(s) of state(s) used by this cell. It can be represented by an Integer, a TensorShape or a tuple of Integers or TensorShapes. call ( self , inputs , states , training = None ) The function that contains the logic for one RNN step calculation. Parameters: Name Type Description Default inputs the input tensor, which is a slide from the overall RNN input by the time dimension (usually the second dimension). required states the state tensor from previous step, which has the same shape as (batch, state_size) . In the case of timestep 0, it will be the initial state user specified, or zero filled tensor otherwise. required Returns: Type Description A tuple of two tensors output tensor for the current timestep, with size output_size . state tensor for next step, which has the shape of state_size . Source code in indl/model/lfads/complex.py def call ( self , inputs , states , training = None ): if training is None : training = K . learning_phase () # if external inputs are used split the inputs if self . ext_input_dim > 0 : z1 = inputs [:, : - self . ext_input_dim ] ext_inputs = inputs [:, - self . ext_input_dim :] else : z1 = inputs ext_inputs = None gen_state , z2_state = states [: 2 ] if self . z_latent_size > 0 : # if controller is used # input to the controller is (con_i and previous step's factors) prev_gen_dropped = self . dropout ( gen_state , training = training ) prev_fac = self . fac_lin ( prev_gen_dropped ) z2_inputs = tf . concat ([ z1 , prev_fac ], axis = 1 ) z2_inputs = self . dropout ( z2_inputs , training = training ) # controller GRU recursion, get new state z2_outputs , z2_state = self . z2_cell ( z2_inputs , z2_state , training = training ) # calculate the inputs to the generator # transformation to mean and logvar of the posterior # TODO: use make_variational(params, z2_state) z_latent_mean = self . mean_lin ( z2_state ) z_latent_logvar = self . logvar_lin ( z2_state ) z_latent_dist = DiagonalGaussianFromExisting ( z_latent_mean , z_latent_logvar ) if training : # TODO: (training or \"posterior_sample_and_average\"), whatever the latter is. q_z_sample = z_latent_dist . sample else : q_z_sample = z_latent_dist . mean else : # pass zeros (0-dim) as inputs to generator q_z_sample = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) z2_state = z_latent_mean = z_latent_logvar = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) # generator's inputs if self . ext_input_dim > 0 and self . inject_ext_input_to_gen : # passing external inputs along with controller output as generator's input gen_inputs = tf . concat ([ q_z_sample , ext_inputs ], axis = 1 ) elif self . ext_input_dim > 0 and not self . inject_ext_input_to_gen : assert 0 , \"Not Implemented!\" else : # using only controller output as generator's input gen_inputs = q_z_sample # generator GRU recursion, get the new state gen_outputs , gen_s_new = self . gen_cell ( gen_inputs , gen_state , training = training ) # calculate the factors gen_s_new_dropped = self . dropout ( gen_s_new , training = training ) factors_new = self . fac_lin ( gen_s_new_dropped ) # Output the states and other values to make them available after RNN new_state = [ gen_s_new , z2_state , z_latent_mean , z_latent_logvar , q_z_sample , factors_new ] return new_state , new_state get_config ( self ) Returns the config of the layer. A layer config is a Python dictionary (serializable) containing the configuration of a layer. The same layer can be reinstantiated later (without its trained weights) from this configuration. The config of a layer does not include connectivity information, nor the layer class name. These are handled by Network (one layer of abstraction above). Returns: Type Description Python dictionary. Source code in indl/model/lfads/complex.py def get_config ( self ): config = { 'units_gen' : self . units_gen , 'z2_units' : self . z2_units , 'factors_dim' : self . factors_dim , 'z_latent_size' : self . z_latent_size , 'ext_input_dim' : self . ext_input_dim , 'inject_ext_input_to_gen' : self . inject_ext_input_to_gen } base_config = super () . get_config () gru_config = self . gen_cell . get_config () return dict ( list ( base_config . items ()) + list ( gru_config . items ()) + list ( config . items ())) dists DiagonalGaussianFromExisting ( Gaussian ) Diagonal Gaussian with different constant mean and variances in each dimension. Source code in indl/model/lfads/dists.py class DiagonalGaussianFromExisting ( Gaussian ): \"\"\" Diagonal Gaussian with different constant mean and variances in each dimension. \"\"\" def __init__ ( self , mean_bxn , logvar_bxn , var_min = 0.0 ): self . mean_bxn = mean_bxn if var_min > 0.0 : logvar_bxn = tf . math . log ( tf . exp ( logvar_bxn ) + var_min ) # logvar_bxn = tf.nn.relu(logvar_bxn) + tf.math.log(var_min) self . logvar_bxn = logvar_bxn self . noise_bxn = noise_bxn = tf . random . normal ( tf . shape ( input = logvar_bxn )) #self.noise_bxn.set_shape([None, z_size]) self . sample_bxn = mean_bxn + tf . exp ( 0.5 * logvar_bxn ) * noise_bxn def logp ( self , z = None ): \"\"\"Compute the log-likelihood under the distribution. Args: z (optional): value to compute likelihood for, if None, use sample. Returns: The likelihood of z under the model. \"\"\" if z is None : z = self . sample # This is needed to make sure that the gradients are simple. # The value of the function shouldn't change. if z == self . sample_bxn : return gaussian_pos_log_likelihood ( self . mean_bxn , self . logvar_bxn , self . noise_bxn ) return diag_gaussian_log_likelihood ( z , self . mean_bxn , self . logvar_bxn ) logp ( self , z = None ) Compute the log-likelihood under the distribution. Parameters: Name Type Description Default z optional value to compute likelihood for, if None, use sample. None Returns: Type Description The likelihood of z under the model. Source code in indl/model/lfads/dists.py def logp ( self , z = None ): \"\"\"Compute the log-likelihood under the distribution. Args: z (optional): value to compute likelihood for, if None, use sample. Returns: The likelihood of z under the model. \"\"\" if z is None : z = self . sample # This is needed to make sure that the gradients are simple. # The value of the function shouldn't change. if z == self . sample_bxn : return gaussian_pos_log_likelihood ( self . mean_bxn , self . logvar_bxn , self . noise_bxn ) return diag_gaussian_log_likelihood ( z , self . mean_bxn , self . logvar_bxn ) Gaussian Base class for Gaussian distribution classes. Source code in indl/model/lfads/dists.py class Gaussian ( object ): \"\"\"Base class for Gaussian distribution classes.\"\"\" @property def mean ( self ): return self . mean_bxn @property def logvar ( self ): return self . logvar_bxn @property def noise ( self ): return tf . random . normal ( tf . shape ( input = self . logvar )) @property def sample ( self ): # return self.mean + tf.exp(0.5 * self.logvar) * self.noise return self . sample_bxn KLCost_GaussianGaussianProcessSampled log p(x|z) + KL(q||p) terms for Gaussian posterior and Gaussian process prior via sampling. The log p(x|z) term is the reconstruction error under the model. The KL term represents the penalty for passing information from the encoder to the decoder. To sample KL(q||p), we simply sample ln q - ln p by drawing samples from q and averaging. Source code in indl/model/lfads/dists.py class KLCost_GaussianGaussianProcessSampled ( object ): \"\"\" log p(x|z) + KL(q||p) terms for Gaussian posterior and Gaussian process prior via sampling. The log p(x|z) term is the reconstruction error under the model. The KL term represents the penalty for passing information from the encoder to the decoder. To sample KL(q||p), we simply sample ln q - ln p by drawing samples from q and averaging. \"\"\" def __init__ ( self , post_zs , prior_z_process ): \"\"\"Create a lower bound in three parts, normalized reconstruction cost, normalized KL divergence cost, and their sum. Args: post_zs: posterior z ~ q(z|x) prior_z_process: prior AR(1) process \"\"\" # assert len(post_zs) > 1, \"GP is for time, need more than 1 time step.\" # assert isinstance(prior_z_process, GaussianProcess), \"Must use GP.\" # L = -KL + log p(x|z), to maximize bound on likelihood # -L = KL - log p(x|z), to minimize bound on NLL # so 'KL cost' is postive KL divergence # sample from the posterior for all time points and dimensions post_zs_sampled = post_zs . sample # sum KL over time and dimension axis logq_bxu = tf . reduce_sum ( input_tensor = post_zs . logp ( post_zs_sampled ), axis = [ 1 , 2 ]) logp_bxu = 0 num_steps = post_zs . mean . get_shape ()[ 1 ] for i in range ( num_steps ): # posterior is independent in time, prior is not if i == 0 : z_tm1_bxu = None else : z_tm1_bxu = post_zs_sampled [:, i - 1 , :] logp_bxu += tf . reduce_sum ( input_tensor = prior_z_process . logp_t ( post_zs_sampled [:, i , :], z_tm1_bxu ), axis = [ 1 ]) kl_b = logq_bxu - logp_bxu self . kl_cost_b = kl_b __init__ ( self , post_zs , prior_z_process ) special Create a lower bound in three parts, normalized reconstruction cost, normalized KL divergence cost, and their sum. Parameters: Name Type Description Default post_zs posterior z ~ q(z|x) required prior_z_process prior AR(1) process required Source code in indl/model/lfads/dists.py def __init__ ( self , post_zs , prior_z_process ): \"\"\"Create a lower bound in three parts, normalized reconstruction cost, normalized KL divergence cost, and their sum. Args: post_zs: posterior z ~ q(z|x) prior_z_process: prior AR(1) process \"\"\" # assert len(post_zs) > 1, \"GP is for time, need more than 1 time step.\" # assert isinstance(prior_z_process, GaussianProcess), \"Must use GP.\" # L = -KL + log p(x|z), to maximize bound on likelihood # -L = KL - log p(x|z), to minimize bound on NLL # so 'KL cost' is postive KL divergence # sample from the posterior for all time points and dimensions post_zs_sampled = post_zs . sample # sum KL over time and dimension axis logq_bxu = tf . reduce_sum ( input_tensor = post_zs . logp ( post_zs_sampled ), axis = [ 1 , 2 ]) logp_bxu = 0 num_steps = post_zs . mean . get_shape ()[ 1 ] for i in range ( num_steps ): # posterior is independent in time, prior is not if i == 0 : z_tm1_bxu = None else : z_tm1_bxu = post_zs_sampled [:, i - 1 , :] logp_bxu += tf . reduce_sum ( input_tensor = prior_z_process . logp_t ( post_zs_sampled [:, i , :], z_tm1_bxu ), axis = [ 1 ]) kl_b = logq_bxu - logp_bxu self . kl_cost_b = kl_b LearnableAutoRegressive1Prior AR(1) model where autocorrelation and process variance are learned parameters. Assumed zero mean. Source code in indl/model/lfads/dists.py class LearnableAutoRegressive1Prior ( object ): \"\"\" AR(1) model where autocorrelation and process variance are learned parameters. Assumed zero mean. \"\"\" def __init__ ( self , batch_size , z_size , autocorrelation_taus , noise_variances , do_train_prior_ar_atau , do_train_prior_ar_nvar , name ): \"\"\"Create a learnable autoregressive (1) process. Args: batch_size: The size of the batch, i.e. 0th dim in 2D tensor of samples. z_size: The dimension of the distribution, i.e. 1st dim in 2D tensor. autocorrelation_taus: The auto correlation time constant of the AR(1) process. A value of 0 is uncorrelated gaussian noise. noise_variances: The variance of the additive noise, *not* the process variance. do_train_prior_ar_atau: Train or leave as constant, the autocorrelation? do_train_prior_ar_nvar: Train or leave as constant, the noise variance? num_steps: Number of steps to run the process. name: The name to prefix to learned TF variables. \"\"\" # Note the use of the plural in all of these quantities. This is intended # to mark that even though a sample z_t from the posterior is thought of a # single sample of a multidimensional gaussian, the prior is actually # thought of as U AR(1) processes, where U is the dimension of the inferred # input. size_bx1 = tf . stack ([ batch_size , 1 ]) size__xu = [ None , z_size ] # process variance, the variance at time t over all instantiations of AR(1) # with these parameters. log_evar_inits_1xu = tf . expand_dims ( tf . math . log ( noise_variances ), 0 ) self . logevars_1xu = logevars_1xu = \\ tf . Variable ( log_evar_inits_1xu , name = name + \"/logevars\" , dtype = tf . float32 , trainable = do_train_prior_ar_nvar ) self . logevars_bxu = logevars_bxu = tf . tile ( logevars_1xu , size_bx1 ) logevars_bxu . set_shape ( size__xu ) # tile loses shape # \\tau, which is the autocorrelation time constant of the AR(1) process log_atau_inits_1xu = tf . expand_dims ( tf . math . log ( autocorrelation_taus ), 0 ) self . logataus_1xu = logataus_1xu = \\ tf . Variable ( log_atau_inits_1xu , name = name + \"/logatau\" , dtype = tf . float32 , trainable = do_train_prior_ar_atau ) # phi in x_t = \\mu + phi x_tm1 + \\eps # phi = exp(-1/tau) # phi = exp(-1/exp(logtau)) # phi = exp(-exp(-logtau)) phis_1xu = tf . exp ( - tf . exp ( - logataus_1xu )) self . phis_bxu = phis_bxu = tf . tile ( phis_1xu , size_bx1 ) phis_bxu . set_shape ( size__xu ) # process noise # pvar = evar / (1- phi^2) # logpvar = log ( exp(logevar) / (1 - phi^2) ) # logpvar = logevar - log(1-phi^2) # logpvar = logevar - (log(1-phi) + log(1+phi)) self . logpvars_1xu = \\ logevars_1xu - tf . math . log ( 1.0 - phis_1xu ) - tf . math . log ( 1.0 + phis_1xu ) self . logpvars_bxu = logpvars_bxu = tf . tile ( self . logpvars_1xu , size_bx1 ) logpvars_bxu . set_shape ( size__xu ) # process mean (zero but included in for completeness) self . pmeans_bxu = pmeans_bxu = tf . zeros_like ( phis_bxu ) def logp_t ( self , z_t_bxu , z_tm1_bxu = None ): \"\"\"Compute the log-likelihood under the distribution for a given time t, not the whole sequence. Args: z_t_bxu: sample to compute likelihood for at time t. z_tm1_bxu (optional): sample condition probability of z_t upon. Returns: The likelihood of p_t under the model at time t. i.e. p(z_t|z_tm1_bxu) = N(z_tm1_bxu * phis, eps^2) \"\"\" if z_tm1_bxu is None : logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , self . pmeans_bxu , self . logpvars_bxu ) else : means_t_bxu = self . pmeans_bxu + self . phis_bxu * z_tm1_bxu logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , means_t_bxu , self . logevars_bxu ) return logp_tgtm1_bxu __init__ ( self , batch_size , z_size , autocorrelation_taus , noise_variances , do_train_prior_ar_atau , do_train_prior_ar_nvar , name ) special Create a learnable autoregressive (1) process. Parameters: Name Type Description Default batch_size The size of the batch, i.e. 0th dim in 2D tensor of samples. required z_size The dimension of the distribution, i.e. 1st dim in 2D tensor. required autocorrelation_taus The auto correlation time constant of the AR(1) required noise_variances The variance of the additive noise, not the process variance. required do_train_prior_ar_atau Train or leave as constant, the autocorrelation? required do_train_prior_ar_nvar Train or leave as constant, the noise variance? required num_steps Number of steps to run the process. required name The name to prefix to learned TF variables. required Source code in indl/model/lfads/dists.py def __init__ ( self , batch_size , z_size , autocorrelation_taus , noise_variances , do_train_prior_ar_atau , do_train_prior_ar_nvar , name ): \"\"\"Create a learnable autoregressive (1) process. Args: batch_size: The size of the batch, i.e. 0th dim in 2D tensor of samples. z_size: The dimension of the distribution, i.e. 1st dim in 2D tensor. autocorrelation_taus: The auto correlation time constant of the AR(1) process. A value of 0 is uncorrelated gaussian noise. noise_variances: The variance of the additive noise, *not* the process variance. do_train_prior_ar_atau: Train or leave as constant, the autocorrelation? do_train_prior_ar_nvar: Train or leave as constant, the noise variance? num_steps: Number of steps to run the process. name: The name to prefix to learned TF variables. \"\"\" # Note the use of the plural in all of these quantities. This is intended # to mark that even though a sample z_t from the posterior is thought of a # single sample of a multidimensional gaussian, the prior is actually # thought of as U AR(1) processes, where U is the dimension of the inferred # input. size_bx1 = tf . stack ([ batch_size , 1 ]) size__xu = [ None , z_size ] # process variance, the variance at time t over all instantiations of AR(1) # with these parameters. log_evar_inits_1xu = tf . expand_dims ( tf . math . log ( noise_variances ), 0 ) self . logevars_1xu = logevars_1xu = \\ tf . Variable ( log_evar_inits_1xu , name = name + \"/logevars\" , dtype = tf . float32 , trainable = do_train_prior_ar_nvar ) self . logevars_bxu = logevars_bxu = tf . tile ( logevars_1xu , size_bx1 ) logevars_bxu . set_shape ( size__xu ) # tile loses shape # \\tau, which is the autocorrelation time constant of the AR(1) process log_atau_inits_1xu = tf . expand_dims ( tf . math . log ( autocorrelation_taus ), 0 ) self . logataus_1xu = logataus_1xu = \\ tf . Variable ( log_atau_inits_1xu , name = name + \"/logatau\" , dtype = tf . float32 , trainable = do_train_prior_ar_atau ) # phi in x_t = \\mu + phi x_tm1 + \\eps # phi = exp(-1/tau) # phi = exp(-1/exp(logtau)) # phi = exp(-exp(-logtau)) phis_1xu = tf . exp ( - tf . exp ( - logataus_1xu )) self . phis_bxu = phis_bxu = tf . tile ( phis_1xu , size_bx1 ) phis_bxu . set_shape ( size__xu ) # process noise # pvar = evar / (1- phi^2) # logpvar = log ( exp(logevar) / (1 - phi^2) ) # logpvar = logevar - log(1-phi^2) # logpvar = logevar - (log(1-phi) + log(1+phi)) self . logpvars_1xu = \\ logevars_1xu - tf . math . log ( 1.0 - phis_1xu ) - tf . math . log ( 1.0 + phis_1xu ) self . logpvars_bxu = logpvars_bxu = tf . tile ( self . logpvars_1xu , size_bx1 ) logpvars_bxu . set_shape ( size__xu ) # process mean (zero but included in for completeness) self . pmeans_bxu = pmeans_bxu = tf . zeros_like ( phis_bxu ) logp_t ( self , z_t_bxu , z_tm1_bxu = None ) Compute the log-likelihood under the distribution for a given time t, not the whole sequence. Parameters: Name Type Description Default z_t_bxu sample to compute likelihood for at time t. required z_tm1_bxu optional sample condition probability of z_t upon. None Returns: Type Description The likelihood of p_t under the model at time t. i.e. p(z_t|z_tm1_bxu) = N(z_tm1_bxu * phis, eps^2) Source code in indl/model/lfads/dists.py def logp_t ( self , z_t_bxu , z_tm1_bxu = None ): \"\"\"Compute the log-likelihood under the distribution for a given time t, not the whole sequence. Args: z_t_bxu: sample to compute likelihood for at time t. z_tm1_bxu (optional): sample condition probability of z_t upon. Returns: The likelihood of p_t under the model at time t. i.e. p(z_t|z_tm1_bxu) = N(z_tm1_bxu * phis, eps^2) \"\"\" if z_tm1_bxu is None : logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , self . pmeans_bxu , self . logpvars_bxu ) else : means_t_bxu = self . pmeans_bxu + self . phis_bxu * z_tm1_bxu logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , means_t_bxu , self . logevars_bxu ) return logp_tgtm1_bxu LearnableDiagonalGaussian ( Gaussian ) Diagonal Gaussian with different means and variances in each dimension. Means and variances are optionally trainable. For LFADS ics prior, trainable_mean=True, trainable_var=False (both default). For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True Source code in indl/model/lfads/dists.py class LearnableDiagonalGaussian ( Gaussian ): \"\"\" Diagonal Gaussian with different means and variances in each dimension. Means and variances are optionally trainable. For LFADS ics prior, trainable_mean=True, trainable_var=False (both default). For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True \"\"\" def __init__ ( self , batch_size , z_size , name , var , trainable_mean = True , trainable_var = False ): # MRK's fix, letting the mean of the prior to be trainable mean_init = 0.0 num_steps = z_size [ 0 ] num_dim = z_size [ 1 ] z_mean_1xn = tf . compat . v1 . get_variable ( name = name + \"/mean\" , shape = [ 1 , 1 , num_dim ], initializer = tf . compat . v1 . constant_initializer ( mean_init ), trainable = trainable_mean ) self . mean_bxn = tf . tile ( z_mean_1xn , tf . stack ([ batch_size , num_steps , 1 ])) self . mean_bxn . set_shape ([ None ] + z_size ) # MRK, make Var trainable (for Controller prior) var_init = np . log ( var ) z_logvar_1xn = tf . compat . v1 . get_variable ( name = name + \"/logvar\" , shape = [ 1 , 1 , num_dim ], initializer = tf . compat . v1 . constant_initializer ( var_init ), trainable = trainable_var ) self . logvar_bxn = tf . tile ( z_logvar_1xn , tf . stack ([ batch_size , num_steps , 1 ])) self . logvar_bxn . set_shape ([ None ] + z_size ) # remove time axis if 1 (used for ICs) if num_steps == 1 : self . mean_bxn = tf . squeeze ( self . mean_bxn , axis = 1 ) self . logvar_bxn = tf . squeeze ( self . logvar_bxn , axis = 1 ) self . noise_bxn = tf . random . normal ( tf . shape ( input = self . logvar_bxn )) diag_gaussian_log_likelihood ( z , mu = 0.0 , logvar = 0.0 ) Log-likelihood under a Gaussian distribution with diagonal covariance. Returns the log-likelihood for each dimension. One should sum the results for the log-likelihood under the full multidimensional model. Parameters: Name Type Description Default z The value to compute the log-likelihood. required mu The mean of the Gaussian 0.0 logvar The log variance of the Gaussian. 0.0 Returns: Type Description The log-likelihood under the Gaussian model. Source code in indl/model/lfads/dists.py def diag_gaussian_log_likelihood ( z , mu = 0.0 , logvar = 0.0 ): \"\"\"Log-likelihood under a Gaussian distribution with diagonal covariance. Returns the log-likelihood for each dimension. One should sum the results for the log-likelihood under the full multidimensional model. Args: z: The value to compute the log-likelihood. mu: The mean of the Gaussian logvar: The log variance of the Gaussian. Returns: The log-likelihood under the Gaussian model. \"\"\" return - 0.5 * ( logvar + np . log ( 2 * np . pi ) + \\ tf . square (( z - mu ) / tf . exp ( 0.5 * logvar ))) gaussian_pos_log_likelihood ( unused_mean , logvar , noise ) Gaussian log-likelihood function for a posterior in VAE Note: This function is specialized for a posterior distribution, that has the form of z = mean + sigma * noise. Parameters: Name Type Description Default unused_mean ignore required logvar The log variance of the distribution required noise The noise used in the sampling of the posterior. required Returns: Type Description The log-likelihood under the Gaussian model. Source code in indl/model/lfads/dists.py def gaussian_pos_log_likelihood ( unused_mean , logvar , noise ): \"\"\"Gaussian log-likelihood function for a posterior in VAE Note: This function is specialized for a posterior distribution, that has the form of z = mean + sigma * noise. Args: unused_mean: ignore logvar: The log variance of the distribution noise: The noise used in the sampling of the posterior. Returns: The log-likelihood under the Gaussian model. \"\"\" # ln N(z; mean, sigma) = - ln(sigma) - 0.5 ln 2pi - noise^2 / 2 return - 0.5 * ( logvar + np . log ( 2 * np . pi ) + tf . square ( noise ))","title":"lfads"},{"location":"API/model/lfads/#lfads","text":"","title":"lfads"},{"location":"API/model/lfads/#indl.model.lfads.create_generator_lfads","text":"units_gen, units_con, factors_dim, co_dim, ext_input_dim, inject_ext_input_to_gen, Source code in indl/model/lfads/__init__.py def create_generator_lfads ( params ): \"\"\" units_gen, units_con, factors_dim, co_dim, ext_input_dim, inject_ext_input_to_gen, \"\"\" from indl.model.lfads.complex import ComplexCell # TODO: Sample/Mean from $q(f)$. This will replace the first element in generator init_states # TODO: need a custom function for sample-during-train-mean-during-test. See nn.dropout for inspiration. # TODO: Sample from $q(z_t)$, and optionally concat with ext_input, to build generator inputs. # TODO: continue generator from lfads-cd/lfadslite.py start at 495 custom_cell = ComplexCell ( params [ 'gen_dim' ], # Units in generator GRU con_hidden_state_dim , # Units in controller GRU params [ 'factors_dim' ], params [ 'co_dim' ], params [ 'ext_input_dim' ], True , ) generator = tfkl . RNN ( custom_cell , return_sequences = True , # recurrent_regularizer=tf.keras.regularizers.l2(l=gen_l2_reg), name = 'gen_rnn' ) init_states = generator . get_initial_state ( gen_input ) gen_output = generator ( gen_input , initial_state = init_states ) factors = gen_output [ - 1 ] return factors","title":"create_generator_lfads()"},{"location":"API/model/lfads/#indl.model.lfads.complex","text":"","title":"complex"},{"location":"API/model/lfads/#indl.model.lfads.complex.ComplexCell","text":"Source code in indl/model/lfads/complex.py class ComplexCell ( tfkl . AbstractRNNCell ): _BIAS_VARIABLE_NAME = \"bias\" _WEIGHTS_VARIABLE_NAME = \"kernel\" \"\"\"Cell class for the LFADS Generative GRU + Controller Input This cell uses two GRUClipCells: One for the Generator and one for the Controller. The Controller - This is equivalent to the \"z2\" RNN layer in the other disentangling AE formulations. - Optional -- only used if z2_units (LFADS: con_dim) > 0 - inputs: the concatenation of (a) the encoded controller inputs and (b) the generator cell's state from the previous iteration transformed through the factor dense layer. (on the zeroth step, b starts with f-encoded latents) The encoded controller inputs are themselves the output of an RNN with dim size z1_units, or 'ci_enc_dim' in LFADS - initial state: in LFADS -- a **learnable Variable** of zeros. The Generator - inputs: the output of the Controller cell and optionally 'external' inputs. - initial state: in LFADS -- a sample of a posterior distribution that is parameterized by an encoder. The two cells share the same initialization parameters (activations, initializers, bias, dropout, regularizer, etc.) except for the number of units. Arguments: units_gen: Positive integer, number of units in generator RNN cell. z2_units: Positive integer, number of units in controller RNN cell. (units_con in LFADS) factors_dim: Number of units in Dense layer for factors output. This layer would normally be external to the RNN. However, in LFADS, the factors dense layer is also used to transform the t-1 generator cell state which becomes part of the _inputs_ to the controller cell. z_latent_size: Dimensionality of variational posterior from controller output --> inputs to controller RNN (LFADS: co_dim) ext_input_dim: Size of external input. The cell input will be split into encoded_z and ext_input depending on this value. Can be 0. inject_ext_input_to_gen: Only makes sense if ext_input_dim is > 0, and `False` is not implemented. activation: Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass None, no activation is applied (ie. \"linear\" activation: `a(x) = x`). recurrent_activation: Activation function to use for the recurrent step. Default: hard sigmoid (`hard_sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`). Note: LFADS uses normal sigmoid. use_bias: Boolean, whether the layer uses a bias vector. kernel_initializer: Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: lecun_normal Vanilla tensorflow default is glorot_uniform. recurrent_initializer: Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state. Default: orthogonal LFADS uses lecun_normal bias_initializer: Initializer for the bias vector. Default: zeros Note: LFADS uses ones for gate bias and zeros for candidate bias kernel_regularizer: Regularizer function applied to the `kernel` weights matrix. Default: None recurrent_regularizer: Regularizer function applied to the `recurrent_kernel` weights matrix. Default: 'l2' at 0.01 Note: LFADS uses L2 regularization with per-cell scaling. Default for generator is 2000., and for controller is 0. (sum(v*v)*scale*0.5) / numel bias_regularizer: Regularizer function applied to the bias vector. Default: None kernel_constraint: Constraint function applied to the `kernel` weights matrix. Default: None recurrent_constraint: Constraint function applied to the `recurrent_kernel` weights matrix. Default: None bias_constraint: Constraint function applied to the bias vector. Default: None dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0.05 recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0.0 implementation: Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations. These modes will have different performance profiles on different hardware and for different applications. Note: This applies to the sub-cells. reset_after: GRU convention (whether to apply reset gate after or before matrix multiplication). False = \"before\" (default), True = \"after\" (CuDNN compatible). clip_value: Value at which to clip the GRU cell output. Default: np.inf (no clipping) Call arguments: inputs: A 2D tensor, composed of the following (concatenated together). - Encoded Z1 (LFADS: \"controller inputs\", other frameworks: half way through dynamic or z-encoding). - (Optional) External Input. Set size with `ext_input_dim`, can be 0. states: List of state tensors corresponding to the previous timestep. - gen_cell: Generator cell state, of size `units_gen`. Typically initialized from a sample of the f-latent distribution q(f) (LFADS: \"encoded initial conditions\"; others: \"static\"). - z2_cell: Z2 cell state of size `z2_units`. Initialized with Variable inited to zeros. (LFADS: controller input) - z_latent x 3: Output only for tracking purposes and external KL loss. Not fed back to next iteration. Controller output means, variances, and sampled output (same as means during *testing*) - factors: The main output. Not fed back to next iteration. training: Python boolean indicating whether the layer should behave in training mode or in inference mode. Only relevant when `dropout` or `recurrent_dropout` is used. \"\"\" def __init__ ( self , units_gen , z2_units , factors_dim , z_latent_size , ext_input_dim , inject_ext_input_to_gen = True , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' , recurrent_regularizer = 'l2' , dropout = 0.05 , clip_value = np . inf , ** kwargs ): self . units_gen = units_gen self . z2_units = z2_units self . factors_dim = factors_dim self . z_latent_size = z_latent_size self . ext_input_dim = ext_input_dim self . inject_ext_input_to_gen = inject_ext_input_to_gen self . units = z2_units + units_gen + 3 * z_latent_size + factors_dim super () . __init__ ( ** kwargs ) self . dropout = tfkl . Dropout ( dropout ) self . fac_lin = tfkl . Dense ( self . factors_dim , use_bias = False , kernel_initializer = 'lecun_normal' , # stdev = 1 / np.sqrt(in_size) kernel_constraint = 'unit_norm' ) # w / sqrt(sum(w**2)) # Note, we use norm constraint whereas LFADS uses norm on init only. from indl.rnn.gru_clip import GRUClipCell if self . z2_units > 0 : self . z2_cell = GRUClipCell ( self . z2_units , kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = dropout , clip_value = clip_value , ** kwargs ) else : self . z2_cell = None self . mean_lin = tfkl . Dense ( self . z_latent_size , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' ) self . logvar_lin = tfkl . Dense ( self . z_latent_size , kernel_initializer = 'lecun_normal' , bias_initializer = 'zeros' ) self . gen_cell = GRUClipCell ( self . units_gen , kernel_initializer = kernel_initializer , bias_initializer = bias_initializer , recurrent_regularizer = recurrent_regularizer , dropout = dropout , clip_value = clip_value , ** kwargs ) @property def state_size ( self ): # [gen_s_new, z2_state, z_latent_mean, z_latent_logvar, q_z_sample, factors_new] state_sizes = [ self . gen_cell . state_size ] if self . z2_units > 0 : state_sizes . append ( self . z2_cell . state_size ) return tuple ( state_sizes ) + ( self . z_latent_size ,) * 3 + ( self . factors_dim ,) @property def output_size ( self ): return self . z2_units + self . units_gen + 3 * self . z_latent_size + self . factors_dim @tf_utils . shape_type_conversion def build ( self , input_shape ): input_dim = input_shape [ - 1 ] if self . z2_units > 0 : self . z2_cell . build ( input_dim + self . factors_dim + self . ext_input_dim ) self . gen_cell . build ( self . z_latent_size + self . ext_input_dim ) self . built = ( self . z2_units == 0 or self . z2_cell . built ) and self . gen_cell . built def get_config ( self ): config = { 'units_gen' : self . units_gen , 'z2_units' : self . z2_units , 'factors_dim' : self . factors_dim , 'z_latent_size' : self . z_latent_size , 'ext_input_dim' : self . ext_input_dim , 'inject_ext_input_to_gen' : self . inject_ext_input_to_gen } base_config = super () . get_config () gru_config = self . gen_cell . get_config () return dict ( list ( base_config . items ()) + list ( gru_config . items ()) + list ( config . items ())) def get_initial_state ( self , inputs = None , batch_size = None , dtype = None , make_K_tensors = True ): init_state = [ self . gen_cell . get_initial_state ( inputs = inputs , batch_size = batch_size , dtype = dtype )] if self . z2_units > 0 : init_state += [ self . z2_cell . get_initial_state ( inputs = inputs , batch_size = batch_size , dtype = dtype )] from tensorflow.python.keras.layers.recurrent import _generate_zero_filled_state if inputs is not None : batch_size = tf . shape ( inputs )[ 0 ] init_state += [ _generate_zero_filled_state ( batch_size , self . z_latent_size , dtype ) for _ in range ( 3 )] init_state += [ _generate_zero_filled_state ( batch_size , self . factors_dim , dtype )] if make_K_tensors : # import tensorflow.keras.backend as K # K.is_tensor(init_state[0]) init_state = [ tfkl . Lambda ( lambda x : x )( _ ) for _ in init_state ] return tuple ( init_state ) def call ( self , inputs , states , training = None ): if training is None : training = K . learning_phase () # if external inputs are used split the inputs if self . ext_input_dim > 0 : z1 = inputs [:, : - self . ext_input_dim ] ext_inputs = inputs [:, - self . ext_input_dim :] else : z1 = inputs ext_inputs = None gen_state , z2_state = states [: 2 ] if self . z_latent_size > 0 : # if controller is used # input to the controller is (con_i and previous step's factors) prev_gen_dropped = self . dropout ( gen_state , training = training ) prev_fac = self . fac_lin ( prev_gen_dropped ) z2_inputs = tf . concat ([ z1 , prev_fac ], axis = 1 ) z2_inputs = self . dropout ( z2_inputs , training = training ) # controller GRU recursion, get new state z2_outputs , z2_state = self . z2_cell ( z2_inputs , z2_state , training = training ) # calculate the inputs to the generator # transformation to mean and logvar of the posterior # TODO: use make_variational(params, z2_state) z_latent_mean = self . mean_lin ( z2_state ) z_latent_logvar = self . logvar_lin ( z2_state ) z_latent_dist = DiagonalGaussianFromExisting ( z_latent_mean , z_latent_logvar ) if training : # TODO: (training or \"posterior_sample_and_average\"), whatever the latter is. q_z_sample = z_latent_dist . sample else : q_z_sample = z_latent_dist . mean else : # pass zeros (0-dim) as inputs to generator q_z_sample = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) z2_state = z_latent_mean = z_latent_logvar = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) # generator's inputs if self . ext_input_dim > 0 and self . inject_ext_input_to_gen : # passing external inputs along with controller output as generator's input gen_inputs = tf . concat ([ q_z_sample , ext_inputs ], axis = 1 ) elif self . ext_input_dim > 0 and not self . inject_ext_input_to_gen : assert 0 , \"Not Implemented!\" else : # using only controller output as generator's input gen_inputs = q_z_sample # generator GRU recursion, get the new state gen_outputs , gen_s_new = self . gen_cell ( gen_inputs , gen_state , training = training ) # calculate the factors gen_s_new_dropped = self . dropout ( gen_s_new , training = training ) factors_new = self . fac_lin ( gen_s_new_dropped ) # Output the states and other values to make them available after RNN new_state = [ gen_s_new , z2_state , z_latent_mean , z_latent_logvar , q_z_sample , factors_new ] return new_state , new_state","title":"ComplexCell"},{"location":"API/model/lfads/#indl.model.lfads.complex.ComplexCell.output_size","text":"Integer or TensorShape: size of outputs produced by this cell.","title":"output_size"},{"location":"API/model/lfads/#indl.model.lfads.complex.ComplexCell.state_size","text":"size(s) of state(s) used by this cell. It can be represented by an Integer, a TensorShape or a tuple of Integers or TensorShapes.","title":"state_size"},{"location":"API/model/lfads/#indl.model.lfads.complex.ComplexCell.call","text":"The function that contains the logic for one RNN step calculation. Parameters: Name Type Description Default inputs the input tensor, which is a slide from the overall RNN input by the time dimension (usually the second dimension). required states the state tensor from previous step, which has the same shape as (batch, state_size) . In the case of timestep 0, it will be the initial state user specified, or zero filled tensor otherwise. required Returns: Type Description A tuple of two tensors output tensor for the current timestep, with size output_size . state tensor for next step, which has the shape of state_size . Source code in indl/model/lfads/complex.py def call ( self , inputs , states , training = None ): if training is None : training = K . learning_phase () # if external inputs are used split the inputs if self . ext_input_dim > 0 : z1 = inputs [:, : - self . ext_input_dim ] ext_inputs = inputs [:, - self . ext_input_dim :] else : z1 = inputs ext_inputs = None gen_state , z2_state = states [: 2 ] if self . z_latent_size > 0 : # if controller is used # input to the controller is (con_i and previous step's factors) prev_gen_dropped = self . dropout ( gen_state , training = training ) prev_fac = self . fac_lin ( prev_gen_dropped ) z2_inputs = tf . concat ([ z1 , prev_fac ], axis = 1 ) z2_inputs = self . dropout ( z2_inputs , training = training ) # controller GRU recursion, get new state z2_outputs , z2_state = self . z2_cell ( z2_inputs , z2_state , training = training ) # calculate the inputs to the generator # transformation to mean and logvar of the posterior # TODO: use make_variational(params, z2_state) z_latent_mean = self . mean_lin ( z2_state ) z_latent_logvar = self . logvar_lin ( z2_state ) z_latent_dist = DiagonalGaussianFromExisting ( z_latent_mean , z_latent_logvar ) if training : # TODO: (training or \"posterior_sample_and_average\"), whatever the latter is. q_z_sample = z_latent_dist . sample else : q_z_sample = z_latent_dist . mean else : # pass zeros (0-dim) as inputs to generator q_z_sample = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) z2_state = z_latent_mean = z_latent_logvar = tf . zeros ([ tf . shape ( input = gen_state )[ 0 ], 0 ]) # generator's inputs if self . ext_input_dim > 0 and self . inject_ext_input_to_gen : # passing external inputs along with controller output as generator's input gen_inputs = tf . concat ([ q_z_sample , ext_inputs ], axis = 1 ) elif self . ext_input_dim > 0 and not self . inject_ext_input_to_gen : assert 0 , \"Not Implemented!\" else : # using only controller output as generator's input gen_inputs = q_z_sample # generator GRU recursion, get the new state gen_outputs , gen_s_new = self . gen_cell ( gen_inputs , gen_state , training = training ) # calculate the factors gen_s_new_dropped = self . dropout ( gen_s_new , training = training ) factors_new = self . fac_lin ( gen_s_new_dropped ) # Output the states and other values to make them available after RNN new_state = [ gen_s_new , z2_state , z_latent_mean , z_latent_logvar , q_z_sample , factors_new ] return new_state , new_state","title":"call()"},{"location":"API/model/lfads/#indl.model.lfads.complex.ComplexCell.get_config","text":"Returns the config of the layer. A layer config is a Python dictionary (serializable) containing the configuration of a layer. The same layer can be reinstantiated later (without its trained weights) from this configuration. The config of a layer does not include connectivity information, nor the layer class name. These are handled by Network (one layer of abstraction above). Returns: Type Description Python dictionary. Source code in indl/model/lfads/complex.py def get_config ( self ): config = { 'units_gen' : self . units_gen , 'z2_units' : self . z2_units , 'factors_dim' : self . factors_dim , 'z_latent_size' : self . z_latent_size , 'ext_input_dim' : self . ext_input_dim , 'inject_ext_input_to_gen' : self . inject_ext_input_to_gen } base_config = super () . get_config () gru_config = self . gen_cell . get_config () return dict ( list ( base_config . items ()) + list ( gru_config . items ()) + list ( config . items ()))","title":"get_config()"},{"location":"API/model/lfads/#indl.model.lfads.dists","text":"","title":"dists"},{"location":"API/model/lfads/#indl.model.lfads.dists.DiagonalGaussianFromExisting","text":"Diagonal Gaussian with different constant mean and variances in each dimension. Source code in indl/model/lfads/dists.py class DiagonalGaussianFromExisting ( Gaussian ): \"\"\" Diagonal Gaussian with different constant mean and variances in each dimension. \"\"\" def __init__ ( self , mean_bxn , logvar_bxn , var_min = 0.0 ): self . mean_bxn = mean_bxn if var_min > 0.0 : logvar_bxn = tf . math . log ( tf . exp ( logvar_bxn ) + var_min ) # logvar_bxn = tf.nn.relu(logvar_bxn) + tf.math.log(var_min) self . logvar_bxn = logvar_bxn self . noise_bxn = noise_bxn = tf . random . normal ( tf . shape ( input = logvar_bxn )) #self.noise_bxn.set_shape([None, z_size]) self . sample_bxn = mean_bxn + tf . exp ( 0.5 * logvar_bxn ) * noise_bxn def logp ( self , z = None ): \"\"\"Compute the log-likelihood under the distribution. Args: z (optional): value to compute likelihood for, if None, use sample. Returns: The likelihood of z under the model. \"\"\" if z is None : z = self . sample # This is needed to make sure that the gradients are simple. # The value of the function shouldn't change. if z == self . sample_bxn : return gaussian_pos_log_likelihood ( self . mean_bxn , self . logvar_bxn , self . noise_bxn ) return diag_gaussian_log_likelihood ( z , self . mean_bxn , self . logvar_bxn )","title":"DiagonalGaussianFromExisting"},{"location":"API/model/lfads/#indl.model.lfads.dists.DiagonalGaussianFromExisting.logp","text":"Compute the log-likelihood under the distribution. Parameters: Name Type Description Default z optional value to compute likelihood for, if None, use sample. None Returns: Type Description The likelihood of z under the model. Source code in indl/model/lfads/dists.py def logp ( self , z = None ): \"\"\"Compute the log-likelihood under the distribution. Args: z (optional): value to compute likelihood for, if None, use sample. Returns: The likelihood of z under the model. \"\"\" if z is None : z = self . sample # This is needed to make sure that the gradients are simple. # The value of the function shouldn't change. if z == self . sample_bxn : return gaussian_pos_log_likelihood ( self . mean_bxn , self . logvar_bxn , self . noise_bxn ) return diag_gaussian_log_likelihood ( z , self . mean_bxn , self . logvar_bxn )","title":"logp()"},{"location":"API/model/lfads/#indl.model.lfads.dists.Gaussian","text":"Base class for Gaussian distribution classes. Source code in indl/model/lfads/dists.py class Gaussian ( object ): \"\"\"Base class for Gaussian distribution classes.\"\"\" @property def mean ( self ): return self . mean_bxn @property def logvar ( self ): return self . logvar_bxn @property def noise ( self ): return tf . random . normal ( tf . shape ( input = self . logvar )) @property def sample ( self ): # return self.mean + tf.exp(0.5 * self.logvar) * self.noise return self . sample_bxn","title":"Gaussian"},{"location":"API/model/lfads/#indl.model.lfads.dists.KLCost_GaussianGaussianProcessSampled","text":"log p(x|z) + KL(q||p) terms for Gaussian posterior and Gaussian process prior via sampling. The log p(x|z) term is the reconstruction error under the model. The KL term represents the penalty for passing information from the encoder to the decoder. To sample KL(q||p), we simply sample ln q - ln p by drawing samples from q and averaging. Source code in indl/model/lfads/dists.py class KLCost_GaussianGaussianProcessSampled ( object ): \"\"\" log p(x|z) + KL(q||p) terms for Gaussian posterior and Gaussian process prior via sampling. The log p(x|z) term is the reconstruction error under the model. The KL term represents the penalty for passing information from the encoder to the decoder. To sample KL(q||p), we simply sample ln q - ln p by drawing samples from q and averaging. \"\"\" def __init__ ( self , post_zs , prior_z_process ): \"\"\"Create a lower bound in three parts, normalized reconstruction cost, normalized KL divergence cost, and their sum. Args: post_zs: posterior z ~ q(z|x) prior_z_process: prior AR(1) process \"\"\" # assert len(post_zs) > 1, \"GP is for time, need more than 1 time step.\" # assert isinstance(prior_z_process, GaussianProcess), \"Must use GP.\" # L = -KL + log p(x|z), to maximize bound on likelihood # -L = KL - log p(x|z), to minimize bound on NLL # so 'KL cost' is postive KL divergence # sample from the posterior for all time points and dimensions post_zs_sampled = post_zs . sample # sum KL over time and dimension axis logq_bxu = tf . reduce_sum ( input_tensor = post_zs . logp ( post_zs_sampled ), axis = [ 1 , 2 ]) logp_bxu = 0 num_steps = post_zs . mean . get_shape ()[ 1 ] for i in range ( num_steps ): # posterior is independent in time, prior is not if i == 0 : z_tm1_bxu = None else : z_tm1_bxu = post_zs_sampled [:, i - 1 , :] logp_bxu += tf . reduce_sum ( input_tensor = prior_z_process . logp_t ( post_zs_sampled [:, i , :], z_tm1_bxu ), axis = [ 1 ]) kl_b = logq_bxu - logp_bxu self . kl_cost_b = kl_b","title":"KLCost_GaussianGaussianProcessSampled"},{"location":"API/model/lfads/#indl.model.lfads.dists.KLCost_GaussianGaussianProcessSampled.__init__","text":"Create a lower bound in three parts, normalized reconstruction cost, normalized KL divergence cost, and their sum. Parameters: Name Type Description Default post_zs posterior z ~ q(z|x) required prior_z_process prior AR(1) process required Source code in indl/model/lfads/dists.py def __init__ ( self , post_zs , prior_z_process ): \"\"\"Create a lower bound in three parts, normalized reconstruction cost, normalized KL divergence cost, and their sum. Args: post_zs: posterior z ~ q(z|x) prior_z_process: prior AR(1) process \"\"\" # assert len(post_zs) > 1, \"GP is for time, need more than 1 time step.\" # assert isinstance(prior_z_process, GaussianProcess), \"Must use GP.\" # L = -KL + log p(x|z), to maximize bound on likelihood # -L = KL - log p(x|z), to minimize bound on NLL # so 'KL cost' is postive KL divergence # sample from the posterior for all time points and dimensions post_zs_sampled = post_zs . sample # sum KL over time and dimension axis logq_bxu = tf . reduce_sum ( input_tensor = post_zs . logp ( post_zs_sampled ), axis = [ 1 , 2 ]) logp_bxu = 0 num_steps = post_zs . mean . get_shape ()[ 1 ] for i in range ( num_steps ): # posterior is independent in time, prior is not if i == 0 : z_tm1_bxu = None else : z_tm1_bxu = post_zs_sampled [:, i - 1 , :] logp_bxu += tf . reduce_sum ( input_tensor = prior_z_process . logp_t ( post_zs_sampled [:, i , :], z_tm1_bxu ), axis = [ 1 ]) kl_b = logq_bxu - logp_bxu self . kl_cost_b = kl_b","title":"__init__()"},{"location":"API/model/lfads/#indl.model.lfads.dists.LearnableAutoRegressive1Prior","text":"AR(1) model where autocorrelation and process variance are learned parameters. Assumed zero mean. Source code in indl/model/lfads/dists.py class LearnableAutoRegressive1Prior ( object ): \"\"\" AR(1) model where autocorrelation and process variance are learned parameters. Assumed zero mean. \"\"\" def __init__ ( self , batch_size , z_size , autocorrelation_taus , noise_variances , do_train_prior_ar_atau , do_train_prior_ar_nvar , name ): \"\"\"Create a learnable autoregressive (1) process. Args: batch_size: The size of the batch, i.e. 0th dim in 2D tensor of samples. z_size: The dimension of the distribution, i.e. 1st dim in 2D tensor. autocorrelation_taus: The auto correlation time constant of the AR(1) process. A value of 0 is uncorrelated gaussian noise. noise_variances: The variance of the additive noise, *not* the process variance. do_train_prior_ar_atau: Train or leave as constant, the autocorrelation? do_train_prior_ar_nvar: Train or leave as constant, the noise variance? num_steps: Number of steps to run the process. name: The name to prefix to learned TF variables. \"\"\" # Note the use of the plural in all of these quantities. This is intended # to mark that even though a sample z_t from the posterior is thought of a # single sample of a multidimensional gaussian, the prior is actually # thought of as U AR(1) processes, where U is the dimension of the inferred # input. size_bx1 = tf . stack ([ batch_size , 1 ]) size__xu = [ None , z_size ] # process variance, the variance at time t over all instantiations of AR(1) # with these parameters. log_evar_inits_1xu = tf . expand_dims ( tf . math . log ( noise_variances ), 0 ) self . logevars_1xu = logevars_1xu = \\ tf . Variable ( log_evar_inits_1xu , name = name + \"/logevars\" , dtype = tf . float32 , trainable = do_train_prior_ar_nvar ) self . logevars_bxu = logevars_bxu = tf . tile ( logevars_1xu , size_bx1 ) logevars_bxu . set_shape ( size__xu ) # tile loses shape # \\tau, which is the autocorrelation time constant of the AR(1) process log_atau_inits_1xu = tf . expand_dims ( tf . math . log ( autocorrelation_taus ), 0 ) self . logataus_1xu = logataus_1xu = \\ tf . Variable ( log_atau_inits_1xu , name = name + \"/logatau\" , dtype = tf . float32 , trainable = do_train_prior_ar_atau ) # phi in x_t = \\mu + phi x_tm1 + \\eps # phi = exp(-1/tau) # phi = exp(-1/exp(logtau)) # phi = exp(-exp(-logtau)) phis_1xu = tf . exp ( - tf . exp ( - logataus_1xu )) self . phis_bxu = phis_bxu = tf . tile ( phis_1xu , size_bx1 ) phis_bxu . set_shape ( size__xu ) # process noise # pvar = evar / (1- phi^2) # logpvar = log ( exp(logevar) / (1 - phi^2) ) # logpvar = logevar - log(1-phi^2) # logpvar = logevar - (log(1-phi) + log(1+phi)) self . logpvars_1xu = \\ logevars_1xu - tf . math . log ( 1.0 - phis_1xu ) - tf . math . log ( 1.0 + phis_1xu ) self . logpvars_bxu = logpvars_bxu = tf . tile ( self . logpvars_1xu , size_bx1 ) logpvars_bxu . set_shape ( size__xu ) # process mean (zero but included in for completeness) self . pmeans_bxu = pmeans_bxu = tf . zeros_like ( phis_bxu ) def logp_t ( self , z_t_bxu , z_tm1_bxu = None ): \"\"\"Compute the log-likelihood under the distribution for a given time t, not the whole sequence. Args: z_t_bxu: sample to compute likelihood for at time t. z_tm1_bxu (optional): sample condition probability of z_t upon. Returns: The likelihood of p_t under the model at time t. i.e. p(z_t|z_tm1_bxu) = N(z_tm1_bxu * phis, eps^2) \"\"\" if z_tm1_bxu is None : logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , self . pmeans_bxu , self . logpvars_bxu ) else : means_t_bxu = self . pmeans_bxu + self . phis_bxu * z_tm1_bxu logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , means_t_bxu , self . logevars_bxu ) return logp_tgtm1_bxu","title":"LearnableAutoRegressive1Prior"},{"location":"API/model/lfads/#indl.model.lfads.dists.LearnableAutoRegressive1Prior.__init__","text":"Create a learnable autoregressive (1) process. Parameters: Name Type Description Default batch_size The size of the batch, i.e. 0th dim in 2D tensor of samples. required z_size The dimension of the distribution, i.e. 1st dim in 2D tensor. required autocorrelation_taus The auto correlation time constant of the AR(1) required noise_variances The variance of the additive noise, not the process variance. required do_train_prior_ar_atau Train or leave as constant, the autocorrelation? required do_train_prior_ar_nvar Train or leave as constant, the noise variance? required num_steps Number of steps to run the process. required name The name to prefix to learned TF variables. required Source code in indl/model/lfads/dists.py def __init__ ( self , batch_size , z_size , autocorrelation_taus , noise_variances , do_train_prior_ar_atau , do_train_prior_ar_nvar , name ): \"\"\"Create a learnable autoregressive (1) process. Args: batch_size: The size of the batch, i.e. 0th dim in 2D tensor of samples. z_size: The dimension of the distribution, i.e. 1st dim in 2D tensor. autocorrelation_taus: The auto correlation time constant of the AR(1) process. A value of 0 is uncorrelated gaussian noise. noise_variances: The variance of the additive noise, *not* the process variance. do_train_prior_ar_atau: Train or leave as constant, the autocorrelation? do_train_prior_ar_nvar: Train or leave as constant, the noise variance? num_steps: Number of steps to run the process. name: The name to prefix to learned TF variables. \"\"\" # Note the use of the plural in all of these quantities. This is intended # to mark that even though a sample z_t from the posterior is thought of a # single sample of a multidimensional gaussian, the prior is actually # thought of as U AR(1) processes, where U is the dimension of the inferred # input. size_bx1 = tf . stack ([ batch_size , 1 ]) size__xu = [ None , z_size ] # process variance, the variance at time t over all instantiations of AR(1) # with these parameters. log_evar_inits_1xu = tf . expand_dims ( tf . math . log ( noise_variances ), 0 ) self . logevars_1xu = logevars_1xu = \\ tf . Variable ( log_evar_inits_1xu , name = name + \"/logevars\" , dtype = tf . float32 , trainable = do_train_prior_ar_nvar ) self . logevars_bxu = logevars_bxu = tf . tile ( logevars_1xu , size_bx1 ) logevars_bxu . set_shape ( size__xu ) # tile loses shape # \\tau, which is the autocorrelation time constant of the AR(1) process log_atau_inits_1xu = tf . expand_dims ( tf . math . log ( autocorrelation_taus ), 0 ) self . logataus_1xu = logataus_1xu = \\ tf . Variable ( log_atau_inits_1xu , name = name + \"/logatau\" , dtype = tf . float32 , trainable = do_train_prior_ar_atau ) # phi in x_t = \\mu + phi x_tm1 + \\eps # phi = exp(-1/tau) # phi = exp(-1/exp(logtau)) # phi = exp(-exp(-logtau)) phis_1xu = tf . exp ( - tf . exp ( - logataus_1xu )) self . phis_bxu = phis_bxu = tf . tile ( phis_1xu , size_bx1 ) phis_bxu . set_shape ( size__xu ) # process noise # pvar = evar / (1- phi^2) # logpvar = log ( exp(logevar) / (1 - phi^2) ) # logpvar = logevar - log(1-phi^2) # logpvar = logevar - (log(1-phi) + log(1+phi)) self . logpvars_1xu = \\ logevars_1xu - tf . math . log ( 1.0 - phis_1xu ) - tf . math . log ( 1.0 + phis_1xu ) self . logpvars_bxu = logpvars_bxu = tf . tile ( self . logpvars_1xu , size_bx1 ) logpvars_bxu . set_shape ( size__xu ) # process mean (zero but included in for completeness) self . pmeans_bxu = pmeans_bxu = tf . zeros_like ( phis_bxu )","title":"__init__()"},{"location":"API/model/lfads/#indl.model.lfads.dists.LearnableAutoRegressive1Prior.logp_t","text":"Compute the log-likelihood under the distribution for a given time t, not the whole sequence. Parameters: Name Type Description Default z_t_bxu sample to compute likelihood for at time t. required z_tm1_bxu optional sample condition probability of z_t upon. None Returns: Type Description The likelihood of p_t under the model at time t. i.e. p(z_t|z_tm1_bxu) = N(z_tm1_bxu * phis, eps^2) Source code in indl/model/lfads/dists.py def logp_t ( self , z_t_bxu , z_tm1_bxu = None ): \"\"\"Compute the log-likelihood under the distribution for a given time t, not the whole sequence. Args: z_t_bxu: sample to compute likelihood for at time t. z_tm1_bxu (optional): sample condition probability of z_t upon. Returns: The likelihood of p_t under the model at time t. i.e. p(z_t|z_tm1_bxu) = N(z_tm1_bxu * phis, eps^2) \"\"\" if z_tm1_bxu is None : logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , self . pmeans_bxu , self . logpvars_bxu ) else : means_t_bxu = self . pmeans_bxu + self . phis_bxu * z_tm1_bxu logp_tgtm1_bxu = diag_gaussian_log_likelihood ( z_t_bxu , means_t_bxu , self . logevars_bxu ) return logp_tgtm1_bxu","title":"logp_t()"},{"location":"API/model/lfads/#indl.model.lfads.dists.LearnableDiagonalGaussian","text":"Diagonal Gaussian with different means and variances in each dimension. Means and variances are optionally trainable. For LFADS ics prior, trainable_mean=True, trainable_var=False (both default). For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True Source code in indl/model/lfads/dists.py class LearnableDiagonalGaussian ( Gaussian ): \"\"\" Diagonal Gaussian with different means and variances in each dimension. Means and variances are optionally trainable. For LFADS ics prior, trainable_mean=True, trainable_var=False (both default). For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True \"\"\" def __init__ ( self , batch_size , z_size , name , var , trainable_mean = True , trainable_var = False ): # MRK's fix, letting the mean of the prior to be trainable mean_init = 0.0 num_steps = z_size [ 0 ] num_dim = z_size [ 1 ] z_mean_1xn = tf . compat . v1 . get_variable ( name = name + \"/mean\" , shape = [ 1 , 1 , num_dim ], initializer = tf . compat . v1 . constant_initializer ( mean_init ), trainable = trainable_mean ) self . mean_bxn = tf . tile ( z_mean_1xn , tf . stack ([ batch_size , num_steps , 1 ])) self . mean_bxn . set_shape ([ None ] + z_size ) # MRK, make Var trainable (for Controller prior) var_init = np . log ( var ) z_logvar_1xn = tf . compat . v1 . get_variable ( name = name + \"/logvar\" , shape = [ 1 , 1 , num_dim ], initializer = tf . compat . v1 . constant_initializer ( var_init ), trainable = trainable_var ) self . logvar_bxn = tf . tile ( z_logvar_1xn , tf . stack ([ batch_size , num_steps , 1 ])) self . logvar_bxn . set_shape ([ None ] + z_size ) # remove time axis if 1 (used for ICs) if num_steps == 1 : self . mean_bxn = tf . squeeze ( self . mean_bxn , axis = 1 ) self . logvar_bxn = tf . squeeze ( self . logvar_bxn , axis = 1 ) self . noise_bxn = tf . random . normal ( tf . shape ( input = self . logvar_bxn ))","title":"LearnableDiagonalGaussian"},{"location":"API/model/lfads/#indl.model.lfads.dists.diag_gaussian_log_likelihood","text":"Log-likelihood under a Gaussian distribution with diagonal covariance. Returns the log-likelihood for each dimension. One should sum the results for the log-likelihood under the full multidimensional model. Parameters: Name Type Description Default z The value to compute the log-likelihood. required mu The mean of the Gaussian 0.0 logvar The log variance of the Gaussian. 0.0 Returns: Type Description The log-likelihood under the Gaussian model. Source code in indl/model/lfads/dists.py def diag_gaussian_log_likelihood ( z , mu = 0.0 , logvar = 0.0 ): \"\"\"Log-likelihood under a Gaussian distribution with diagonal covariance. Returns the log-likelihood for each dimension. One should sum the results for the log-likelihood under the full multidimensional model. Args: z: The value to compute the log-likelihood. mu: The mean of the Gaussian logvar: The log variance of the Gaussian. Returns: The log-likelihood under the Gaussian model. \"\"\" return - 0.5 * ( logvar + np . log ( 2 * np . pi ) + \\ tf . square (( z - mu ) / tf . exp ( 0.5 * logvar )))","title":"diag_gaussian_log_likelihood()"},{"location":"API/model/lfads/#indl.model.lfads.dists.gaussian_pos_log_likelihood","text":"Gaussian log-likelihood function for a posterior in VAE Note: This function is specialized for a posterior distribution, that has the form of z = mean + sigma * noise. Parameters: Name Type Description Default unused_mean ignore required logvar The log variance of the distribution required noise The noise used in the sampling of the posterior. required Returns: Type Description The log-likelihood under the Gaussian model. Source code in indl/model/lfads/dists.py def gaussian_pos_log_likelihood ( unused_mean , logvar , noise ): \"\"\"Gaussian log-likelihood function for a posterior in VAE Note: This function is specialized for a posterior distribution, that has the form of z = mean + sigma * noise. Args: unused_mean: ignore logvar: The log variance of the distribution noise: The noise used in the sampling of the posterior. Returns: The log-likelihood under the Gaussian model. \"\"\" # ln N(z; mean, sigma) = - ln(sigma) - 0.5 ln 2pi - noise^2 / 2 return - 0.5 * ( logvar + np . log ( 2 * np . pi ) + tf . square ( noise ))","title":"gaussian_pos_log_likelihood()"},{"location":"API/utils/fileio/","text":"fileio from_neuropype_h5 ( filename , chunk_names = []) Import a Neuropype-exported HDF5 file. Parameters: Name Type Description Default filename str Name of file on disk. Opened with h5py.File. required chunk_names List[str] Limit return to a subset of the chunks in the data file. [] Returns: Type Description List[Tuple[str, dict]] A list of (name, chunk_dict) tuples. Source code in indl/utils/fileio.py def from_neuropype_h5 ( filename : str , chunk_names : List [ str ] = []) -> List [ Tuple [ str , dict ]]: \"\"\" Import a Neuropype-exported HDF5 file. Args: filename: Name of file on disk. Opened with h5py.File. chunk_names: Limit return to a subset of the chunks in the data file. Returns: A list of (name, chunk_dict) tuples. \"\"\" import numpy as np import h5py from pandas import DataFrame f = h5py . File ( filename , 'r' ) chunks = [] if 'chunks' in f . keys (): chunks_group = f [ 'chunks' ] ch_keys = [ _ for _ in chunks_group . keys () if _ in chunk_names ] for ch_key in ch_keys : chunk_group = chunks_group . get ( ch_key ) # Process data block_group = chunk_group . get ( 'block' ) data_ = block_group . get ( 'data' ) if isinstance ( data_ , h5py . Dataset ): data = data_ [()] else : # Data is a group. This only happens with sparse matrices. import scipy.sparse data = scipy . sparse . csr_matrix (( data_ [ 'data' ][:], data_ [ 'indices' ][:], data_ [ 'indptr' ][:]), data_ . attrs [ 'shape' ]) axes_group = block_group . get ( 'axes' ) axes = [] for ax_ix , axis_key in enumerate ( axes_group . keys ()): axis_group = axes_group . get ( axis_key ) ax_type = axis_group . attrs . get ( 'type' ) new_ax = { 'name' : axis_key , 'type' : ax_type } if ax_type == 'axis' : new_ax . update ( dict ( x = np . arange ( data . shape [ ax_ix ]))) elif ax_type == 'time' : nom_rate = axis_group . attrs . get ( 'nominal_rate' ) if np . isnan ( nom_rate ): nom_rate = None new_ax . update ( dict ( nominal_rate = nom_rate , times = axis_group . get ( 'times' )[()])) elif ax_type == 'frequency' : new_ax . update ( dict ( frequencies = axis_group . get ( 'frequencies' )[()])) elif ax_type == 'space' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], naming_system = axis_group . attrs [ 'naming_system' ], positions = axis_group . get ( 'positions' )[()], coordinate_system = axis_group . attrs [ 'coordinate_system' ], units = axis_group . get ( 'units' )[()])) elif ax_type == 'feature' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], units = axis_group . get ( 'units' )[()], properties = axis_group . get ( 'properties' )[()], error_distrib = axis_group . get ( 'error_distrib' )[()], sampling_distrib = axis_group . get ( 'sampling_distrib' )[()])) elif ax_type == 'instance' : new_ax . update ({ 'times' : axis_group . get ( 'times' )[()]}) if 'instance_type' in axis_group . attrs : new_ax . update ({ 'instance_type' : axis_group . attrs [ 'instance_type' ]}) _dat = axis_group . get ( 'data' )[()] if not _dat . dtype . names : new_ax . update ({ 'data' : axis_group . get ( 'data' )[()]}) else : _df = DataFrame ( _dat ) # Convert binary objects to string objects str_df = _df . select_dtypes ([ np . object ]) str_df = str_df . stack () . str . decode ( 'utf-8' ) . unstack () for col in str_df : _df [ col ] = str_df [ col ] new_ax . update ({ 'data' : _df }) elif ax_type == 'statistic' : new_ax . update ( dict ( param_types = axis_group . get ( 'param_types' )[()])) elif ax_type == 'lag' : new_ax . update ( dict ( xlags = axis_group . get ( 'lags' )[()])) if new_ax is not None : axes . append ( new_ax ) chunks . append (( ch_key , dict ( data = data , axes = axes , props = _recurse_get_dict_from_group ( chunk_group . get ( 'props' ))))) return chunks","title":"fileio"},{"location":"API/utils/fileio/#fileio","text":"","title":"fileio"},{"location":"API/utils/fileio/#indl.utils.fileio.from_neuropype_h5","text":"Import a Neuropype-exported HDF5 file. Parameters: Name Type Description Default filename str Name of file on disk. Opened with h5py.File. required chunk_names List[str] Limit return to a subset of the chunks in the data file. [] Returns: Type Description List[Tuple[str, dict]] A list of (name, chunk_dict) tuples. Source code in indl/utils/fileio.py def from_neuropype_h5 ( filename : str , chunk_names : List [ str ] = []) -> List [ Tuple [ str , dict ]]: \"\"\" Import a Neuropype-exported HDF5 file. Args: filename: Name of file on disk. Opened with h5py.File. chunk_names: Limit return to a subset of the chunks in the data file. Returns: A list of (name, chunk_dict) tuples. \"\"\" import numpy as np import h5py from pandas import DataFrame f = h5py . File ( filename , 'r' ) chunks = [] if 'chunks' in f . keys (): chunks_group = f [ 'chunks' ] ch_keys = [ _ for _ in chunks_group . keys () if _ in chunk_names ] for ch_key in ch_keys : chunk_group = chunks_group . get ( ch_key ) # Process data block_group = chunk_group . get ( 'block' ) data_ = block_group . get ( 'data' ) if isinstance ( data_ , h5py . Dataset ): data = data_ [()] else : # Data is a group. This only happens with sparse matrices. import scipy.sparse data = scipy . sparse . csr_matrix (( data_ [ 'data' ][:], data_ [ 'indices' ][:], data_ [ 'indptr' ][:]), data_ . attrs [ 'shape' ]) axes_group = block_group . get ( 'axes' ) axes = [] for ax_ix , axis_key in enumerate ( axes_group . keys ()): axis_group = axes_group . get ( axis_key ) ax_type = axis_group . attrs . get ( 'type' ) new_ax = { 'name' : axis_key , 'type' : ax_type } if ax_type == 'axis' : new_ax . update ( dict ( x = np . arange ( data . shape [ ax_ix ]))) elif ax_type == 'time' : nom_rate = axis_group . attrs . get ( 'nominal_rate' ) if np . isnan ( nom_rate ): nom_rate = None new_ax . update ( dict ( nominal_rate = nom_rate , times = axis_group . get ( 'times' )[()])) elif ax_type == 'frequency' : new_ax . update ( dict ( frequencies = axis_group . get ( 'frequencies' )[()])) elif ax_type == 'space' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], naming_system = axis_group . attrs [ 'naming_system' ], positions = axis_group . get ( 'positions' )[()], coordinate_system = axis_group . attrs [ 'coordinate_system' ], units = axis_group . get ( 'units' )[()])) elif ax_type == 'feature' : new_ax . update ( dict ( names = axis_group . get ( 'names' )[()], units = axis_group . get ( 'units' )[()], properties = axis_group . get ( 'properties' )[()], error_distrib = axis_group . get ( 'error_distrib' )[()], sampling_distrib = axis_group . get ( 'sampling_distrib' )[()])) elif ax_type == 'instance' : new_ax . update ({ 'times' : axis_group . get ( 'times' )[()]}) if 'instance_type' in axis_group . attrs : new_ax . update ({ 'instance_type' : axis_group . attrs [ 'instance_type' ]}) _dat = axis_group . get ( 'data' )[()] if not _dat . dtype . names : new_ax . update ({ 'data' : axis_group . get ( 'data' )[()]}) else : _df = DataFrame ( _dat ) # Convert binary objects to string objects str_df = _df . select_dtypes ([ np . object ]) str_df = str_df . stack () . str . decode ( 'utf-8' ) . unstack () for col in str_df : _df [ col ] = str_df [ col ] new_ax . update ({ 'data' : _df }) elif ax_type == 'statistic' : new_ax . update ( dict ( param_types = axis_group . get ( 'param_types' )[()])) elif ax_type == 'lag' : new_ax . update ( dict ( xlags = axis_group . get ( 'lags' )[()])) if new_ax is not None : axes . append ( new_ax ) chunks . append (( ch_key , dict ( data = data , axes = axes , props = _recurse_get_dict_from_group ( chunk_group . get ( 'props' ))))) return chunks","title":"from_neuropype_h5()"},{"location":"API/utils/metrics/","text":"metrics dprime ( y_true , y_pred , pmarg = 0.01 , outputs = [ 'dprime' , 'bias' , 'accuracy' ]) Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Parameters: Name Type Description Default y_true array-like True labels. required y_pred array-like Predicted labels. required pmarg float 0.01 outputs List[str] list of outputs among 'dprime', 'bias', 'accuracy' ['dprime', 'bias', 'accuracy'] Returns: Type Description tuple Calculated d-prime value. Source code in indl/utils/metrics.py def dprime ( y_true , y_pred , pmarg : float = 0.01 , outputs : List [ str ] = [ 'dprime' , 'bias' , 'accuracy' ]) -> tuple : \"\"\" Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Args: y_true (array-like): True labels. y_pred (array-like): Predicted labels. pmarg: outputs: list of outputs among 'dprime', 'bias', 'accuracy' Returns: Calculated d-prime value. \"\"\" import numpy as np from scipy.stats import norm # TODO: Adapt this function for tensorflow # y_pred = ops.convert_to_tensor(y_pred) # y_true = math_ops.cast(y_true, y_pred.dtype) # return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1) # TODO: Check that true_y only has 2 classes, and test_y is entirely within true_y classes. b_true = y_pred == y_true b_pos = np . unique ( y_true , return_inverse = True )[ 1 ] . astype ( bool ) true_pos = np . sum ( np . logical_and ( b_true , b_pos )) true_neg = np . sum ( np . logical_and ( b_true , ~ b_pos )) false_pos = np . sum ( np . logical_and ( ~ b_true , b_pos )) false_neg = np . sum ( np . logical_and ( ~ b_true , ~ b_pos )) tpr = true_pos / ( true_pos + false_neg ) tpr = max ( pmarg , min ( tpr , 1 - pmarg )) fpr = false_pos / ( false_pos + true_neg ) fpr = max ( pmarg , min ( fpr , 1 - pmarg )) ztpr = norm . ppf ( tpr , loc = 0 , scale = 1 ) zfpr = norm . ppf ( fpr , loc = 0 , scale = 1 ) # Other measures of performance: # sens = tp ./ (tp+fp) # spec = tn ./ (tn+fn) # balAcc = (sens+spec)/2 # informedness = sens+spec-1 output = tuple () for out in outputs : if out == 'dprime' : dprime = ztpr - zfpr output += ( dprime ,) elif out == 'bias' : bias = - ( ztpr + zfpr ) / 2 output += ( bias ,) elif out == 'accuracy' : accuracy = 100 * ( true_pos + true_neg ) / ( true_pos + false_pos + false_neg + true_neg ) output += ( accuracy ,) return output quickplot_history ( history ) A little helper function to do a quick plot of model fit results. Parameters: Name Type Description Default history tf.keras History required Source code in indl/utils/metrics.py def quickplot_history ( history ) -> None : \"\"\" A little helper function to do a quick plot of model fit results. Args: history (tf.keras History): \"\"\" import matplotlib.pyplot as plt if hasattr ( history , 'history' ): history = history . history hist_metrics = [ _ for _ in history . keys () if not _ . startswith ( 'val_' )] for m_ix , m in enumerate ( hist_metrics ): plt . subplot ( len ( hist_metrics ), 1 , m_ix + 1 ) plt . plot ( history [ m ], label = 'Train' ) plt . plot ( history [ 'val_' + m ], label = 'Valid.' ) plt . xlabel ( 'Epoch' ) plt . ylabel ( m ) plt . legend () plt . tight_layout () plt . show ()","title":"metrics"},{"location":"API/utils/metrics/#metrics","text":"","title":"metrics"},{"location":"API/utils/metrics/#indl.utils.metrics.dprime","text":"Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Parameters: Name Type Description Default y_true array-like True labels. required y_pred array-like Predicted labels. required pmarg float 0.01 outputs List[str] list of outputs among 'dprime', 'bias', 'accuracy' ['dprime', 'bias', 'accuracy'] Returns: Type Description tuple Calculated d-prime value. Source code in indl/utils/metrics.py def dprime ( y_true , y_pred , pmarg : float = 0.01 , outputs : List [ str ] = [ 'dprime' , 'bias' , 'accuracy' ]) -> tuple : \"\"\" Calculate D-Prime for binary data. 70% for both classes is d=1.0488. Highest possible is 6.93, but effectively 4.65 for 99% http://www.birmingham.ac.uk/Documents/college-les/psych/vision-laboratory/sdtintro.pdf This function is not designed to behave as a valid 'Tensorflow metric'. Args: y_true (array-like): True labels. y_pred (array-like): Predicted labels. pmarg: outputs: list of outputs among 'dprime', 'bias', 'accuracy' Returns: Calculated d-prime value. \"\"\" import numpy as np from scipy.stats import norm # TODO: Adapt this function for tensorflow # y_pred = ops.convert_to_tensor(y_pred) # y_true = math_ops.cast(y_true, y_pred.dtype) # return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1) # TODO: Check that true_y only has 2 classes, and test_y is entirely within true_y classes. b_true = y_pred == y_true b_pos = np . unique ( y_true , return_inverse = True )[ 1 ] . astype ( bool ) true_pos = np . sum ( np . logical_and ( b_true , b_pos )) true_neg = np . sum ( np . logical_and ( b_true , ~ b_pos )) false_pos = np . sum ( np . logical_and ( ~ b_true , b_pos )) false_neg = np . sum ( np . logical_and ( ~ b_true , ~ b_pos )) tpr = true_pos / ( true_pos + false_neg ) tpr = max ( pmarg , min ( tpr , 1 - pmarg )) fpr = false_pos / ( false_pos + true_neg ) fpr = max ( pmarg , min ( fpr , 1 - pmarg )) ztpr = norm . ppf ( tpr , loc = 0 , scale = 1 ) zfpr = norm . ppf ( fpr , loc = 0 , scale = 1 ) # Other measures of performance: # sens = tp ./ (tp+fp) # spec = tn ./ (tn+fn) # balAcc = (sens+spec)/2 # informedness = sens+spec-1 output = tuple () for out in outputs : if out == 'dprime' : dprime = ztpr - zfpr output += ( dprime ,) elif out == 'bias' : bias = - ( ztpr + zfpr ) / 2 output += ( bias ,) elif out == 'accuracy' : accuracy = 100 * ( true_pos + true_neg ) / ( true_pos + false_pos + false_neg + true_neg ) output += ( accuracy ,) return output","title":"dprime()"},{"location":"API/utils/metrics/#indl.utils.metrics.quickplot_history","text":"A little helper function to do a quick plot of model fit results. Parameters: Name Type Description Default history tf.keras History required Source code in indl/utils/metrics.py def quickplot_history ( history ) -> None : \"\"\" A little helper function to do a quick plot of model fit results. Args: history (tf.keras History): \"\"\" import matplotlib.pyplot as plt if hasattr ( history , 'history' ): history = history . history hist_metrics = [ _ for _ in history . keys () if not _ . startswith ( 'val_' )] for m_ix , m in enumerate ( hist_metrics ): plt . subplot ( len ( hist_metrics ), 1 , m_ix + 1 ) plt . plot ( history [ m ], label = 'Train' ) plt . plot ( history [ 'val_' + m ], label = 'Valid.' ) plt . xlabel ( 'Epoch' ) plt . ylabel ( m ) plt . legend () plt . tight_layout () plt . show ()","title":"quickplot_history()"},{"location":"API/utils/regularizers/","text":"regularizers KernelLengthRegularizer ( Regularizer ) Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). Source code in indl/utils/regularizers.py class KernelLengthRegularizer ( tf . keras . regularizers . Regularizer ): \"\"\" Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). \"\"\" def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window () def rebuild_window ( self ): windows = [] for win_dim , win_len in enumerate ( self . kernel_size ): if win_len == 1 : window = np . ones (( 1 ,), dtype = np . float32 ) else : if self . window_func == 'hann' : window = 1 - tf . signal . hann_window ( win_len , periodic = False ) elif self . window_func == 'hamming' : window = 1 - tf . signal . hamming_window ( win_len , periodic = False ) else : # if window_func == 'linear': hl = win_len // 2 window = np . zeros (( win_len ,), dtype = np . float32 ) window [: hl ] = np . arange ( 1 , hl + 1 )[:: - 1 ] # Negative slope line to 0 for first half. window [ - hl :] = np . arange ( 1 , hl + 1 ) # Positive slope line from 0 for second half. window = window / hl # Scale so it's -1 -- 0 -- 1 window = window ** self . poly_exp # Exponent win_shape = [ 1 ] * ( len ( self . kernel_size ) + 2 ) win_shape [ win_dim ] = win_len window = tf . reshape ( window , win_shape ) windows . append ( window ) self . window = tf . linalg . matmul ( * windows ) self . window = self . window / tf . reduce_max ( self . window ) def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold } def __call__ ( self , weights ): weights = tf . sqrt ( tf . square ( weights )) # Differentiable abs # non_zero = tf.cast(weights > self.threshold, tf.float32) non_zero = tf . nn . sigmoid ( weights - self . threshold ) regularization = self . window_scale * self . window * non_zero # regularization = tf.reduce_max(regularization, axis=[0, 1], keepdims=True) regularization = tf . reduce_sum ( regularization ) return regularization __init__ ( self , kernel_size , window_scale = 0.01 , window_func = 'poly' , poly_exp = 2 , threshold = 1e-07 ) special Parameters: Name Type Description Default kernel_size Iterable[int] length(s) of kernel(s) required window_scale float scale factor to apply to window 0.01 window_func str 'hann', 'hamming', 'poly' (default) 'poly' poly_exp int exponent used when window_func=='poly' 2 threshold float weight threshold, below which weights will not be penalized. 1e-07 Source code in indl/utils/regularizers.py def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window () get_config ( self ) Returns the config of the regularizer. An regularizer config is a Python dictionary (serializable) containing all configuration parameters of the regularizer. The same regularizer can be reinstantiated later (without any saved state) from this configuration. This method is optional if you are just training and executing models, exporting to and from SavedModels, or using weight checkpoints. This method is required for Keras model_to_estimator , saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON. Returns: Type Description dict Python dictionary. Source code in indl/utils/regularizers.py def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold }","title":"regularizers"},{"location":"API/utils/regularizers/#regularizers","text":"","title":"regularizers"},{"location":"API/utils/regularizers/#indl.utils.regularizers.KernelLengthRegularizer","text":"Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). Source code in indl/utils/regularizers.py class KernelLengthRegularizer ( tf . keras . regularizers . Regularizer ): \"\"\" Regularize a kernel by its length. Added loss is a int mask of 1s where abs(weight) is above threshold, and 0s otherwise, multiplied by a window. The window is typically shaped to penalize the presence of non-zero weights further away from the middle of the kernel. Use this regularizer if you want to try to find a minimal-length kernel. (after training, kernel can be shortened for faster inference). \"\"\" def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window () def rebuild_window ( self ): windows = [] for win_dim , win_len in enumerate ( self . kernel_size ): if win_len == 1 : window = np . ones (( 1 ,), dtype = np . float32 ) else : if self . window_func == 'hann' : window = 1 - tf . signal . hann_window ( win_len , periodic = False ) elif self . window_func == 'hamming' : window = 1 - tf . signal . hamming_window ( win_len , periodic = False ) else : # if window_func == 'linear': hl = win_len // 2 window = np . zeros (( win_len ,), dtype = np . float32 ) window [: hl ] = np . arange ( 1 , hl + 1 )[:: - 1 ] # Negative slope line to 0 for first half. window [ - hl :] = np . arange ( 1 , hl + 1 ) # Positive slope line from 0 for second half. window = window / hl # Scale so it's -1 -- 0 -- 1 window = window ** self . poly_exp # Exponent win_shape = [ 1 ] * ( len ( self . kernel_size ) + 2 ) win_shape [ win_dim ] = win_len window = tf . reshape ( window , win_shape ) windows . append ( window ) self . window = tf . linalg . matmul ( * windows ) self . window = self . window / tf . reduce_max ( self . window ) def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold } def __call__ ( self , weights ): weights = tf . sqrt ( tf . square ( weights )) # Differentiable abs # non_zero = tf.cast(weights > self.threshold, tf.float32) non_zero = tf . nn . sigmoid ( weights - self . threshold ) regularization = self . window_scale * self . window * non_zero # regularization = tf.reduce_max(regularization, axis=[0, 1], keepdims=True) regularization = tf . reduce_sum ( regularization ) return regularization","title":"KernelLengthRegularizer"},{"location":"API/utils/regularizers/#indl.utils.regularizers.KernelLengthRegularizer.__init__","text":"Parameters: Name Type Description Default kernel_size Iterable[int] length(s) of kernel(s) required window_scale float scale factor to apply to window 0.01 window_func str 'hann', 'hamming', 'poly' (default) 'poly' poly_exp int exponent used when window_func=='poly' 2 threshold float weight threshold, below which weights will not be penalized. 1e-07 Source code in indl/utils/regularizers.py def __init__ ( self , kernel_size : Iterable [ int ], window_scale : float = 1e-2 , window_func : str = 'poly' , poly_exp : int = 2 , threshold : float = tf . keras . backend . epsilon ()): \"\"\" Args: kernel_size: length(s) of kernel(s) window_scale: scale factor to apply to window window_func: 'hann', 'hamming', 'poly' (default) poly_exp: exponent used when window_func=='poly' threshold: weight threshold, below which weights will not be penalized. \"\"\" self . kernel_size = kernel_size self . window_scale = window_scale self . window_func = window_func self . poly_exp = poly_exp self . threshold = threshold self . rebuild_window ()","title":"__init__()"},{"location":"API/utils/regularizers/#indl.utils.regularizers.KernelLengthRegularizer.get_config","text":"Returns the config of the regularizer. An regularizer config is a Python dictionary (serializable) containing all configuration parameters of the regularizer. The same regularizer can be reinstantiated later (without any saved state) from this configuration. This method is optional if you are just training and executing models, exporting to and from SavedModels, or using weight checkpoints. This method is required for Keras model_to_estimator , saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON. Returns: Type Description dict Python dictionary. Source code in indl/utils/regularizers.py def get_config ( self ) -> dict : return { 'kernel_size' : self . kernel_size , 'window_scale' : self . window_scale , 'window_func' : self . window_func , 'poly_exp' : self . poly_exp , 'threshold' : self . threshold }","title":"get_config()"},{"location":"DSAE/dsae/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); \\(\\beta\\) Variational Autoencoders to Disentangle Multi-channel Neural Timeseries Data In this notebook we first outline the motivation for applying autoencoders to neural timeseries, then we demonstrate how to use the indl library to implement variational sequential autoencoders to disentangle neural timeseries data, with extra attention spent on comparing different approaches to promote disentanglement. Autoencoders for Neural Data Many more neurons modulate their activity during a set of behaviours than are strictly necessary for a minimal representation of those behaviours. (I'm using the term 'behaviour' very loosely here; it could equally apply to stimulus perception or movement.) Similarly, each neuron participates in many different behaviours, and it is sometimes difficult to predict how a neuron will modulate during a behaviour based on its modulation during other behaviours, or even other phases of the same behaviour; this is known as \"mixed selectivity\". These phenomena of redundancy and mixed selectivity necessitated a shift in neuroscience away from the \"neuron doctrine\" toward the \"neural population doctrine\" ( Saxena and Cunningham, Current Opinion in Neurobiology, 2019 ). Neurons are highly correlated -- as one would expect due to their physical connections -- and the description of the correlation structure can similarly describe the population information coding capacity ( Kohn et al., Ann. Rev Neuro, 2016 ). The unit of computation in the brain is not the single neuron but the ensemble of covarying neurons, and computation happens in a low-dimensional manifold within the neural population space ( Ruff et al., Ann. Review of Neuroscience, 2018 ). Dimensionality reduction techniques have become increasingly important tools in our understanding of brain function ( Hurwitz et al., arXiv 2021 , Cunningham and Yu, Nature Neuroscience, 2014 ), even motivating a recent neural latents benchmark . Generally, the main goal of dimensionality reduction is to reduce high dimensional data into a lower dimensional representation that is more tractable and more intuitive. If the low-dimensional representation of neural data is semantically meaningful then it can help provide insight into what contextual information and stimulus parameters are important for computation in the brain. For example, in a stimulus-driven task, the latent variables driving the observed spiking data might represent upstream encoding of task-relevant features, and might facilitate understanding of learning processes when these features are assigned new meaning experimentally. Another less-informal goal of dimensionality reduction is that low-dimensional representations should \"make it easier to extract useful information when building classifiers or other predictors\" (Bengio et al., 2013), which could lead to better performing and more generalizable brain-computer interfaces (BCIs). The autoencoder model architecture has been applied to the problem of finding latent representations of neural data ( Pandarinath et al., LFADS ) and denoising ( Altan et al., \u201cJoint Autoencoder\u201d, bioRxiv 2020 ). I admit that the definition of variational autoencoders I provide in the following text is not very approachable. I really like this description of VAEs by Joseph Rocca . It has wonderful images, and it begins by orienting the reader from the perspective of dimensionality reduction like PCA, which is likely familiar to people who work with neural data. If you aren't already familiar with VAEs then please begin there. I chose the approach that I did because it will facilitate description of some of the more complicated models later. Dimensionality reduction is often implemented as the solution to a generative model. We assume that observed high-dimensional neural data \\(x\\) -- recorded with many electrodes -- is the result of a decoder process \\(d(z)\\) driven by unobservable lower-dimensional latent variables \\(z\\) , sometimes called neural modes. If we treat the process as deterministic then we get \\(x = d(z)\\) . If the deterministic model has sufficient capacity (i.e., \\(d(z)\\) has many parameters) then it can severely overfit the data and simply memorize the transformation from any latent value -- such as a trial index -- to the observation associated with that latent value. When this happens, the latent variable has no meaning and offers no insight. To help make the latent variables meaningful, a variational autoencoder (VAE) represents the latent variables as a multivariate distribution from which we draw samples to get the inputs to the decoder process, and the VAE training regularizes the latent distributions to help fill the latent space and make its dimensions more meaningful. From \"Understanding VAEs\" by Joseph Rocca. We thus recast the decoder from deterministic to probabilistic. First, the latent representation \\(z\\) is a sample from a prior distribution \\(p(z)\\) . Second, the output of the decoder is also probabilistic, defined by \\(p(x|z)\\) , from which a sample draw of x is likely. The model has the following structure: \\[ p(x,z) = p(x|z)p(z) \\] That is, the joint distribution of the observed and latents is the product of the 'observed conditioned on the latents' and the latents themselves. In practice, \\(z\\) is usually sampled from an approximation \\(q(z)\\) . \\(q(z)\\) is regularized to resemble the prior \\(p(z)\\) which we can define to be anything, but typically we use a multivariate Gaussian with zero-mean with no covariance (i.e., the off-diagonal elements of the covariance matrix are all 0). Note that this is, in a way, a redefinition of \\(p(z)\\) compared to above. Originally \\(p(z)\\) was taken to mean a prior on the true latents; now \\(p(z)\\) is a prior that we use to regularization the latent space. Recall that we are interested in understanding the latent variables \\(z\\) in our data. So far we've described how \\(x\\) can come from the variational approximation of \\(z\\) : \\(q(z)\\) , but we still don't have a way to get \\(q(z)\\) . We can infer \\(z\\) 's distribution from the encoding process \\(e(x)\\) to get \\(p(z|x)\\) . These distributions can be linked with Bayes' theorem: \\[ p( {z|x} ) = \\frac{{p( {x|z} )p( z )}}{{p( x )}}\\label{eqn:1} \\] In practice, the output of the encoder \\(e(x)\\) is the parameterization of the distribution. So in the case of a Gaussian this is its mean \\(\\mu\\) and standard deviation \\(\\sigma\\) . We approximate \\(p(z|x)\\) with \\(q(z|x)\\) . We use variational inference to estimate the unknown distributions. $$ \\begin{align} &\\underset{e ,d }{\\mathrm{arg\\,min}}(KL( {q(z|x)||p(z|x)})) \\label{eqn:2} \\ =&\\underset{e ,d }{\\mathrm{arg\\,max}}({E_{q(z|x)}}\\log p(x|z) - KL({q(z|x)||p(z)}))\\label{eqn:3} \\end{align} $$ That is, we find the parameterization of \\(e(x)\\) and \\(d(z)\\) that minimizes the KL-divergence between \\(q(z|x)\\) and \\(p(z|x)\\) . The derivation is beyond the scope of this document, but this is equivalent to finding the parameterization that maximizes the log-likelihood of \\(p(x|z)\\) and minimizes the KL divergence between \\(q(z|x)\\) and \\(p(z)\\) . We use the negative of these two terms in the maximization problem, depicted as the pink double-ended arrows in the above figure, as our loss when training the model with gradient descent. Disentangling Autoencoder We can control how much the KL-divergence contributes to the loss by a scaling factor \\(\\beta\\) . And, when \\(p(z)\\) is a Gaussian with mean 0, unit standard deviation, and no covariance, then we get \\(\\underset{e*,d*}{\\mathrm{arg\\,max}}({E_{q(z|x)}}\\log p(x|z) - \\beta KL({q(z|x)||N(0,1)}))\\label{eqn:4}\\) The \\(\\beta\\) parameter can be modified via a schedule during training. Initially it is zero or near zero to allow the reconstruction loss to dominate and not end up in a pathological state where all inputs lead to \\(N(0,1)\\) . Over epochs, \\(\\beta\\) is increased to regularize the latent space. This is known as a \\(\\beta\\) -VAE ( Higgins et al., 2016 ). When the prior has diagonal covariance and \\(\\beta\\) is allowed to grow large, the latent dimensions are forced to be uncorrelated. In practice, forcing uncorrelated latent dimensions can often lead to the latent dimensions representing interpretable features that we would consider to be independent attributes. For example, in pictures of faces, gender is independent of hair colour is independent of darkness of glasses. When this happens, the latent dimensions are said to be disentangled . Indeed, a \\(\\beta\\) -VAE is the most common and possibly the simplest form of a Disentangling Autoencoder. This concept of disentangling is distinct from untangling used by Russo et al., Neuron 2018 . The latter is specific to sequences, and has to do with the average derivative neural trajectories through latent space: if the trajectories that pass through a particular location in latent space have a consistent orientation then the average of their derivatives will have a large magnitude and be considered untangled . Conversely, if different trajectories traverse a common space with different orientations then the average derivative will be near zero, and this region is highly tangled. If a neural state is in untangled space then the path through that space is deterministic and robust to perturbations, as one might see in a neural trajectory from motor cortex executing a learned movement. Conversely, a neural state in a highly tangled space could be redirected easily by a small amount of noise, as one might see in a decision-making process when there is little evidence. Impossibility and Identifiability \\(\\beta\\) -VAEs and their extensions aim to disentangle the latent variables, but there is no guarantee that the inferred latent variables are the correct solution just because they are disentangled. Indeed, if the function from latent to observed variables is not linear then the problem is ill-posed, and one cannot recover the true independent latents from the observed variables alone. Two related lines of research describe how unsupervised learning of disentangled representations is fundamentally impossible unless there is a strong inductive bias ( Locatello et al., 2020 ; Locatello et al., 2019 ), or the model is identifiable ( Khemakhem et al., arXiv 2020 ; pwc ). Identifiability, an idea from nonlinear ICA, can occur when using a latent prior that has a factorized distribution that is conditioned on additionally observed variables, such as a class label, time index, previous data points in a time series, or almost any further observation, \\(u\\) . This family of models is called identifiable VIA (iVAE). \\[ p(x,z|u)=p_{d}(x|z)p(z|u) \\] They make a few assumptions: * the noise in \\(x\\) is independent of \\(z\\) or \\(d\\) . * \\(p(z|u)\\) is conditionally factorial, where each element of \\(z\\) has a univariate (exponential family) distribution given conditioning variable \\(u\\) . Conditioning is through an arbitrary function \\(\\lambda(u)\\) , such as a recurrent neural network. As we will see, all of the disentangling sequential autoencoder models we will encounter implement a variation of this idea. Disentangling-(sequential)-VAEs in practice Whether or not they were explicitly informed by the above studies, every disentangling-VAE variant I've encountered that is designed for sequence data has implemented a solution that factorizes the latent distribution conditioned on additional variables. The most trivial additional variable is the timestep, which conditions a low-dimensional time-varying latent (which we call \\(z_d\\) ) to represent dynamic \"content\", while the more typical high-dimensional yet static latent (which we call \\(z_s\\) ) is left to represent the \"style\". For example in a speech autoencoder, z_d would represent the words and z_s would represent something identifiable about the speaker. We have identified several different disentangling-VAE architectures that have taken this approach: LFADS ( Keshtkaran, ..., Pandarinath, 2021 ) DSAE ( Li and Mandt, ICML 2018 ) - \"Full\" model. DSAE - \"Factorized' model FHVAE ( Hsu and Glass ). FDMM , drived from FHVAE, models state transition probabilities in the prior. iLQR-VAE ( Schimel, ..., Hennequin, 2021 ) From these we identify a general abstraction of the disentangling-sequential-VAE (DSAE) architecture. TODO: Image of general architecture The below table provides the major differences between the models. LFADS DSAE full DSAE factorized FHVAE FDMM \\(z_s\\) initial conditions f f z2 y \\(z_d\\) controller input z z z1 z \\(e_{z_s}\\) \\(BiGRU(x)\\) BiLSTM(x) ?? LSTM->LSTM \\(BiLSTM(x)\\) \\(e_{z_d}\\) A: \\(BiGRU(x)\\) , B: \\(GRU(A, z_d)\\) RNN(x, tile(z_d)) \\(MLP(x_t)\\) LSTM((x, tile(z_d)))->LSTM A: Backward RNN, B: \"combiner\" \\(p(z_s)\\) \\(\\mathcal{N}(0,\\kappa I)\\) \\(\\mathcal{N}(\\mu_z,\\sigma_zI)\\) ?? \\(\\mathcal{N}(\\mu_2,0.5^2I)\\) ?? \\(p(z_d)\\) LearnableAutoRegressive1Prior LSTM(0) ?? \\(\\mathcal{N}(0,I)\\) \"gated transition\" decoder Complex w/ GRU RNN CNN? CNN? LSTM x2 Linear DNN RNN input0 \\(0 / z1\\) ?? ?? concat(z_stat, z_dyn) ?? RNN state0 \\(z2\\) ?? ?? 0 ?? RNN output -MLP-> fac -MLP-> rates ?? ?? (x_mu, x_logvar) ?? Decoder loss -log(p spike|Poisson(rates)) ?? ?? sparse sce with logits ?? Learning rate 1e-2 decay 0.95 every 6 ?? ?? ?? ?? There are additional differences in implementation details between the models, any of which can be used in any of the models. These include the optimizer, learning rate, where to insert dropout and how much, etc. Further improvements to \\(\\beta\\) -VAE Recent \\(\\beta\\) -VAE extensions add augmentations that separate the KL-divergence between the latents and the latent-prior into I(x;z) + KL(q(z)||p(z)) , where I is mutual information among inputs (x) and latents (z), and they penalize the KL term to promote disentangling without penalizing I which would harm reconstruction. FactorVAE Kim and Mnih, 2018 No official repo for FactorVAE, but here's one using TF2 \\(\\beta\\) -TCVAE Chen et al., 2019 . beta-TCVAE has an official repo using pytorch, but here is one using TF2 that is for some reason not in the Papers With Code list and has some extras. The Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations paper Locatello et al., 2019 examines these and other advances to VAEs, and has TF1 code for these augmentations and metrics. TODO: Also add one of their disentangling metrics. A repo comparing 5 different VAE losses using pytorch here . Also has a really nice explanation of the different losses at the end of the README. Add SRU++ cell type Add a discriminator for real vs fake reconstructions when keeping dynamic latent constant but swapping static latent from another trial. Swapping Autoencoder for Deep Image Manipulation by Park et al., 2020 with pytorch implementation . Getting Started with DSAEs in indl This indl library defines a series of model-builder functions. Each function takes params , a dictionary of hyperparameters, and inputs containing one or more Keras tensors, and each returns the model outputs and other intermediate variables that need to be tracked. The model-builder functions are mostly defined in indl.model.beta_vae , and that module makes extensive use of other indl modules. The functions are designed to be modular such that they can be used to build different VAE implementations when provided with the correct parameterization. Hyperparameters We separate our hyperparameters into non-tunable 'arguments' and tunable 'parameters'. This helps with the hyperparameter optimization framework. Both are defined at the top of indl.model.beta_vae . import tensorflow as tf from indl.model.beta_vae import generate_default_args , generate_default_params _params = generate_default_params () _args = generate_default_args () j_params = { ** _params , ** _args . __dict__ } Prepare inputs The first step is to prepare the inputs for entry into the encoder(s). This comprises several steps: dropout (optional) split off inputs to the f_encoder to prevent acausal modeling (optional) coordinated dropout (not implemented) CV mask (optional) Dense layer to read-in inputs to a common set of input factors. from tensorflow.keras import backend as K from indl.model.beta_vae import prepare_inputs n_times = 246 n_sensors = 36 K . clear_session () inputs = tf . keras . Input ( shape = ( n_times , n_sensors )) f_enc_inputs , z_enc_inputs , cd_mask = prepare_inputs ( j_params , inputs ) print ( \"inputs: \" , inputs ) print ( \"inputs to f-encoder: \" , f_enc_inputs ) print ( \"inputs to z-encoder: \" , z_enc_inputs ) print ( \"coordinated dropout mask: \" , cd_mask ) inputs: Tensor(\"input_1:0\", shape=(None, 246, 36), dtype=float32) inputs to f-encoder: Tensor(\"coordinated_dropout/Identity:0\", shape=(None, 246, 36), dtype=float32) inputs to z-encoder: Tensor(\"concat:0\", shape=(None, 246, 36), dtype=float32) coordinated dropout mask: Tensor(\"coordinated_dropout/Identity_1:0\", shape=(None, 246, 36), dtype=bool) f -Encoder Transform full sequence of \"features\" ( inputs or ReadIn(inputs) ) through (1) RNN then (2) affine to yield parameters of latent posterior distribution: \\( \\(q(f | x_{1:T})\\) \\) This distribution is a multivariate normal, optionally with off-diagonal elements allowed. from indl.model.beta_vae import create_f_encoder , make_f_variational enc_f = create_f_encoder ( j_params , f_enc_inputs ) q_f = make_f_variational ( j_params , enc_f ) print ( \"encoded f latents: \" , enc_f ) print ( \"q(f) - latents as distributions: \" , q_f ) WARNING:tensorflow:From /home/chad/miniconda3/envs/indl/lib/python3.8/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:159: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version. Instructions for updating: Do not pass `graph_parents`. They will no longer be used. encoded f latents: Tensor(\"f_rnn_0/Identity:0\", shape=(None, 256), dtype=float32) q(f) - latents as distributions: tfp.distributions.MultivariateNormalDiag(\"distribution_lambda_MultivariateNormalDiag\", event_shape=[10], dtype=float32) f -Prior Model loss will include the KL divergence between the q_f posterior and a prior. The prior is a learnable multivariate normal diagonal. The prior is initialized with a mean of 0 and a stddev of 0.1 but these are trainable by default. (In LFADS, only the mean is trainable). from indl.model.beta_vae import create_f_prior f_prior = create_f_prior ( j_params ) # Use during training with: # f_kl = tfd.kl_divergence(q_f, f_prior) print ( \"Prior on q(f): \" , f_prior ) Prior on q(f): tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[], event_shape=[10], dtype=float32) z -Encoder \\(q(z_t | x_{1:T})\\) I have also seen this called the \"Dynamic Encoder\", or in LFADS the \"Controller Input\" encoder. The z -Encoder varies quite a bit between the different Disentangling/ \\(\\beta\\) Variational Autoencoder implementations. Indeed, in some formulations it isn't used at all, such as the LFADS model without inferred controller input. Where it is used, in general: The inputs are the original data sequences ( \\(x_t\\) ). Unlike the f -encoder, here we output full sequences. The output sequences parameterize a multivariate normal distribution at each timestep , sometimes with constraints on the temporal evolution (e.g., RNN or AR(1)). The encoder itself has as its first layer a RNN (LSTM, GRU), often bidirectional, or a simple MLP as in the DSAE Factorized model If the first layer is an RNN then there is usually a second layer forward-only RNN. Extra Details - DSAE Full The inputs are concatenated with a tiled sample from \\(q(f)\\) . We've added a parameter to choose if \\(q(f)\\) is concatenated on the inputs into the first or second RNN, though there isn't a precedent for concatenating on the second. Extra Details - LFADS Like its f-Encoder, the RNN cells are a GRU with clipping. The secondary RNN input is the output from the primary RNN concatenated with the decoder RNN's previous step + transformed through the factor Dense layer . Because the LFADS secondary RNN is so complicated, it is integrated into the decoder RNN itself in a \"complex cell\". The complex cell includes the z2 cell, makes the z2 outputs variational in \\(q(z_t)\\) , samples \\(q(z_t)\\) for the inputs to the generative RNN cell, passes the output of the generative RNN step through a Dense to-factors layer, and finally uses that output as one of the inputs to the z2 cell. If params['gen_cell_type'] is \"Complex\" , then we assume that LFADS is being used and we skip the second RNN in create_z_encoder , and we skip making the latents variational in make_z_variational . from indl.model.beta_vae import create_z_encoder , make_z_variational # Note: For f_sample, you can pass in q_f dist itself, or pass q_f.sample(N_SAMPLES) or even q_f.mean() # The former will use the default `convert_to_tensor_fn` which uses params['q_f_samples']. enc_z = create_z_encoder ( j_params , z_enc_inputs , f_sample = q_f ) q_z = make_z_variational ( j_params , enc_z ) print ( \"encoded z: \" , enc_z ) print ( \"q(z|x_t): \" , q_z ) encoded z: Tensor(\"Reshape_5:0\", shape=(None, 246, 16), dtype=float32) q(z|x_t): tfp.distributions.MultivariateNormalDiag(\"distribution_lambda_1_MultivariateNormalDiag\", event_shape=[4], dtype=float32) Z Prior Model loss will include the KL divergence between the q_z posterior and a prior. There are several versions of the Z prior. DSAE Full: An LSTM with a low-ish hidden size. It is used to generate an output sequence with length equal to q_z timesteps dim. The output sequence is then used to parameterize a MVNDiag distribution of equal dimensionality to q_z. (Implementation note: LSTM is initialized with zero-state and zero-input for sample 0, but subsequent samples are drawn from the previous step's dist .) DSAE Factorized: I'm not sure, maybe the same as above? LFADS: Two options. First seems unused: MVNDiag with zero-mean and trainable var. Second: Learnable AR1 process. from indl.model.beta_vae import create_z_prior # TODO! Generator (Decoder part 1) \\(p(x_t | z_t, f)\\) The generator takes in the encoded latents contributing to the inputs and/or initial state, and outputs full sequences. The generator layer is typically an RNN, though in some applications (e.g. video) it can be a CNN. The encoded latents comprise a single-timestep latent vector ( f ) and optionally a low-dimensional sequence ( \\(z_t\\) ). Note that these latents are distributions, and therefore must be sampled from to get the initial state and/or the inputs to the generative RNN. The q_f sample and the q_z sample may be combined in different ways to become the generator inputs. In LFADS, the generator is in the \"ComplexCell\", which also includes the z2 cell and the . Therein, the q_f sample is used as the generator's initial state and the q_z sample is used as the inputs. In DVAE, the q_z sample is used as an input to the generator RNN. The q_f sample can either be used as the initial condition to the generator, or it can be tiled and concated with q_z. The generative RNN outputs a sequence. The next step after the sequence is typically a Dense layer to transform into \"factors\". Because the LFADS ComplexCell includes this step, as is required so that the factors can be fed-back to the z2_encoder step-by-step, we also include the Dense layer in our generator for easier interoperability. factors = create_generator ( f_sample , z_sample ) Probabilistic Reconstructed Input (Decoder part 2) The factors are passed through a Dense layer and the outputs are the same dimensionality as the inputs, but instead of reconstructing the inputs, they parameterize a distribution representing the inputs. This distribution can be Gaussian or Poisson, with the latter being more appropriate for (binned) spike counts.","title":"Dsae"},{"location":"DSAE/dsae/#beta-variational-autoencoders-to-disentangle-multi-channel-neural-timeseries-data","text":"In this notebook we first outline the motivation for applying autoencoders to neural timeseries, then we demonstrate how to use the indl library to implement variational sequential autoencoders to disentangle neural timeseries data, with extra attention spent on comparing different approaches to promote disentanglement.","title":"\\(\\beta\\) Variational Autoencoders to Disentangle Multi-channel Neural Timeseries  Data"},{"location":"DSAE/dsae/#autoencoders-for-neural-data","text":"Many more neurons modulate their activity during a set of behaviours than are strictly necessary for a minimal representation of those behaviours. (I'm using the term 'behaviour' very loosely here; it could equally apply to stimulus perception or movement.) Similarly, each neuron participates in many different behaviours, and it is sometimes difficult to predict how a neuron will modulate during a behaviour based on its modulation during other behaviours, or even other phases of the same behaviour; this is known as \"mixed selectivity\". These phenomena of redundancy and mixed selectivity necessitated a shift in neuroscience away from the \"neuron doctrine\" toward the \"neural population doctrine\" ( Saxena and Cunningham, Current Opinion in Neurobiology, 2019 ). Neurons are highly correlated -- as one would expect due to their physical connections -- and the description of the correlation structure can similarly describe the population information coding capacity ( Kohn et al., Ann. Rev Neuro, 2016 ). The unit of computation in the brain is not the single neuron but the ensemble of covarying neurons, and computation happens in a low-dimensional manifold within the neural population space ( Ruff et al., Ann. Review of Neuroscience, 2018 ). Dimensionality reduction techniques have become increasingly important tools in our understanding of brain function ( Hurwitz et al., arXiv 2021 , Cunningham and Yu, Nature Neuroscience, 2014 ), even motivating a recent neural latents benchmark . Generally, the main goal of dimensionality reduction is to reduce high dimensional data into a lower dimensional representation that is more tractable and more intuitive. If the low-dimensional representation of neural data is semantically meaningful then it can help provide insight into what contextual information and stimulus parameters are important for computation in the brain. For example, in a stimulus-driven task, the latent variables driving the observed spiking data might represent upstream encoding of task-relevant features, and might facilitate understanding of learning processes when these features are assigned new meaning experimentally. Another less-informal goal of dimensionality reduction is that low-dimensional representations should \"make it easier to extract useful information when building classifiers or other predictors\" (Bengio et al., 2013), which could lead to better performing and more generalizable brain-computer interfaces (BCIs). The autoencoder model architecture has been applied to the problem of finding latent representations of neural data ( Pandarinath et al., LFADS ) and denoising ( Altan et al., \u201cJoint Autoencoder\u201d, bioRxiv 2020 ). I admit that the definition of variational autoencoders I provide in the following text is not very approachable. I really like this description of VAEs by Joseph Rocca . It has wonderful images, and it begins by orienting the reader from the perspective of dimensionality reduction like PCA, which is likely familiar to people who work with neural data. If you aren't already familiar with VAEs then please begin there. I chose the approach that I did because it will facilitate description of some of the more complicated models later. Dimensionality reduction is often implemented as the solution to a generative model. We assume that observed high-dimensional neural data \\(x\\) -- recorded with many electrodes -- is the result of a decoder process \\(d(z)\\) driven by unobservable lower-dimensional latent variables \\(z\\) , sometimes called neural modes. If we treat the process as deterministic then we get \\(x = d(z)\\) . If the deterministic model has sufficient capacity (i.e., \\(d(z)\\) has many parameters) then it can severely overfit the data and simply memorize the transformation from any latent value -- such as a trial index -- to the observation associated with that latent value. When this happens, the latent variable has no meaning and offers no insight. To help make the latent variables meaningful, a variational autoencoder (VAE) represents the latent variables as a multivariate distribution from which we draw samples to get the inputs to the decoder process, and the VAE training regularizes the latent distributions to help fill the latent space and make its dimensions more meaningful. From \"Understanding VAEs\" by Joseph Rocca. We thus recast the decoder from deterministic to probabilistic. First, the latent representation \\(z\\) is a sample from a prior distribution \\(p(z)\\) . Second, the output of the decoder is also probabilistic, defined by \\(p(x|z)\\) , from which a sample draw of x is likely. The model has the following structure: \\[ p(x,z) = p(x|z)p(z) \\] That is, the joint distribution of the observed and latents is the product of the 'observed conditioned on the latents' and the latents themselves. In practice, \\(z\\) is usually sampled from an approximation \\(q(z)\\) . \\(q(z)\\) is regularized to resemble the prior \\(p(z)\\) which we can define to be anything, but typically we use a multivariate Gaussian with zero-mean with no covariance (i.e., the off-diagonal elements of the covariance matrix are all 0). Note that this is, in a way, a redefinition of \\(p(z)\\) compared to above. Originally \\(p(z)\\) was taken to mean a prior on the true latents; now \\(p(z)\\) is a prior that we use to regularization the latent space. Recall that we are interested in understanding the latent variables \\(z\\) in our data. So far we've described how \\(x\\) can come from the variational approximation of \\(z\\) : \\(q(z)\\) , but we still don't have a way to get \\(q(z)\\) . We can infer \\(z\\) 's distribution from the encoding process \\(e(x)\\) to get \\(p(z|x)\\) . These distributions can be linked with Bayes' theorem: \\[ p( {z|x} ) = \\frac{{p( {x|z} )p( z )}}{{p( x )}}\\label{eqn:1} \\] In practice, the output of the encoder \\(e(x)\\) is the parameterization of the distribution. So in the case of a Gaussian this is its mean \\(\\mu\\) and standard deviation \\(\\sigma\\) . We approximate \\(p(z|x)\\) with \\(q(z|x)\\) . We use variational inference to estimate the unknown distributions. $$ \\begin{align} &\\underset{e ,d }{\\mathrm{arg\\,min}}(KL( {q(z|x)||p(z|x)})) \\label{eqn:2} \\ =&\\underset{e ,d }{\\mathrm{arg\\,max}}({E_{q(z|x)}}\\log p(x|z) - KL({q(z|x)||p(z)}))\\label{eqn:3} \\end{align} $$ That is, we find the parameterization of \\(e(x)\\) and \\(d(z)\\) that minimizes the KL-divergence between \\(q(z|x)\\) and \\(p(z|x)\\) . The derivation is beyond the scope of this document, but this is equivalent to finding the parameterization that maximizes the log-likelihood of \\(p(x|z)\\) and minimizes the KL divergence between \\(q(z|x)\\) and \\(p(z)\\) . We use the negative of these two terms in the maximization problem, depicted as the pink double-ended arrows in the above figure, as our loss when training the model with gradient descent.","title":"Autoencoders for Neural Data"},{"location":"DSAE/dsae/#disentangling-autoencoder","text":"We can control how much the KL-divergence contributes to the loss by a scaling factor \\(\\beta\\) . And, when \\(p(z)\\) is a Gaussian with mean 0, unit standard deviation, and no covariance, then we get \\(\\underset{e*,d*}{\\mathrm{arg\\,max}}({E_{q(z|x)}}\\log p(x|z) - \\beta KL({q(z|x)||N(0,1)}))\\label{eqn:4}\\) The \\(\\beta\\) parameter can be modified via a schedule during training. Initially it is zero or near zero to allow the reconstruction loss to dominate and not end up in a pathological state where all inputs lead to \\(N(0,1)\\) . Over epochs, \\(\\beta\\) is increased to regularize the latent space. This is known as a \\(\\beta\\) -VAE ( Higgins et al., 2016 ). When the prior has diagonal covariance and \\(\\beta\\) is allowed to grow large, the latent dimensions are forced to be uncorrelated. In practice, forcing uncorrelated latent dimensions can often lead to the latent dimensions representing interpretable features that we would consider to be independent attributes. For example, in pictures of faces, gender is independent of hair colour is independent of darkness of glasses. When this happens, the latent dimensions are said to be disentangled . Indeed, a \\(\\beta\\) -VAE is the most common and possibly the simplest form of a Disentangling Autoencoder. This concept of disentangling is distinct from untangling used by Russo et al., Neuron 2018 . The latter is specific to sequences, and has to do with the average derivative neural trajectories through latent space: if the trajectories that pass through a particular location in latent space have a consistent orientation then the average of their derivatives will have a large magnitude and be considered untangled . Conversely, if different trajectories traverse a common space with different orientations then the average derivative will be near zero, and this region is highly tangled. If a neural state is in untangled space then the path through that space is deterministic and robust to perturbations, as one might see in a neural trajectory from motor cortex executing a learned movement. Conversely, a neural state in a highly tangled space could be redirected easily by a small amount of noise, as one might see in a decision-making process when there is little evidence.","title":"Disentangling Autoencoder"},{"location":"DSAE/dsae/#impossibility-and-identifiability","text":"\\(\\beta\\) -VAEs and their extensions aim to disentangle the latent variables, but there is no guarantee that the inferred latent variables are the correct solution just because they are disentangled. Indeed, if the function from latent to observed variables is not linear then the problem is ill-posed, and one cannot recover the true independent latents from the observed variables alone. Two related lines of research describe how unsupervised learning of disentangled representations is fundamentally impossible unless there is a strong inductive bias ( Locatello et al., 2020 ; Locatello et al., 2019 ), or the model is identifiable ( Khemakhem et al., arXiv 2020 ; pwc ). Identifiability, an idea from nonlinear ICA, can occur when using a latent prior that has a factorized distribution that is conditioned on additionally observed variables, such as a class label, time index, previous data points in a time series, or almost any further observation, \\(u\\) . This family of models is called identifiable VIA (iVAE). \\[ p(x,z|u)=p_{d}(x|z)p(z|u) \\] They make a few assumptions: * the noise in \\(x\\) is independent of \\(z\\) or \\(d\\) . * \\(p(z|u)\\) is conditionally factorial, where each element of \\(z\\) has a univariate (exponential family) distribution given conditioning variable \\(u\\) . Conditioning is through an arbitrary function \\(\\lambda(u)\\) , such as a recurrent neural network. As we will see, all of the disentangling sequential autoencoder models we will encounter implement a variation of this idea.","title":"Impossibility and Identifiability"},{"location":"DSAE/dsae/#disentangling-sequential-vaes-in-practice","text":"Whether or not they were explicitly informed by the above studies, every disentangling-VAE variant I've encountered that is designed for sequence data has implemented a solution that factorizes the latent distribution conditioned on additional variables. The most trivial additional variable is the timestep, which conditions a low-dimensional time-varying latent (which we call \\(z_d\\) ) to represent dynamic \"content\", while the more typical high-dimensional yet static latent (which we call \\(z_s\\) ) is left to represent the \"style\". For example in a speech autoencoder, z_d would represent the words and z_s would represent something identifiable about the speaker. We have identified several different disentangling-VAE architectures that have taken this approach: LFADS ( Keshtkaran, ..., Pandarinath, 2021 ) DSAE ( Li and Mandt, ICML 2018 ) - \"Full\" model. DSAE - \"Factorized' model FHVAE ( Hsu and Glass ). FDMM , drived from FHVAE, models state transition probabilities in the prior. iLQR-VAE ( Schimel, ..., Hennequin, 2021 ) From these we identify a general abstraction of the disentangling-sequential-VAE (DSAE) architecture. TODO: Image of general architecture The below table provides the major differences between the models. LFADS DSAE full DSAE factorized FHVAE FDMM \\(z_s\\) initial conditions f f z2 y \\(z_d\\) controller input z z z1 z \\(e_{z_s}\\) \\(BiGRU(x)\\) BiLSTM(x) ?? LSTM->LSTM \\(BiLSTM(x)\\) \\(e_{z_d}\\) A: \\(BiGRU(x)\\) , B: \\(GRU(A, z_d)\\) RNN(x, tile(z_d)) \\(MLP(x_t)\\) LSTM((x, tile(z_d)))->LSTM A: Backward RNN, B: \"combiner\" \\(p(z_s)\\) \\(\\mathcal{N}(0,\\kappa I)\\) \\(\\mathcal{N}(\\mu_z,\\sigma_zI)\\) ?? \\(\\mathcal{N}(\\mu_2,0.5^2I)\\) ?? \\(p(z_d)\\) LearnableAutoRegressive1Prior LSTM(0) ?? \\(\\mathcal{N}(0,I)\\) \"gated transition\" decoder Complex w/ GRU RNN CNN? CNN? LSTM x2 Linear DNN RNN input0 \\(0 / z1\\) ?? ?? concat(z_stat, z_dyn) ?? RNN state0 \\(z2\\) ?? ?? 0 ?? RNN output -MLP-> fac -MLP-> rates ?? ?? (x_mu, x_logvar) ?? Decoder loss -log(p spike|Poisson(rates)) ?? ?? sparse sce with logits ?? Learning rate 1e-2 decay 0.95 every 6 ?? ?? ?? ?? There are additional differences in implementation details between the models, any of which can be used in any of the models. These include the optimizer, learning rate, where to insert dropout and how much, etc.","title":"Disentangling-(sequential)-VAEs in practice"},{"location":"DSAE/dsae/#further-improvements-to-beta-vae","text":"Recent \\(\\beta\\) -VAE extensions add augmentations that separate the KL-divergence between the latents and the latent-prior into I(x;z) + KL(q(z)||p(z)) , where I is mutual information among inputs (x) and latents (z), and they penalize the KL term to promote disentangling without penalizing I which would harm reconstruction. FactorVAE Kim and Mnih, 2018 No official repo for FactorVAE, but here's one using TF2 \\(\\beta\\) -TCVAE Chen et al., 2019 . beta-TCVAE has an official repo using pytorch, but here is one using TF2 that is for some reason not in the Papers With Code list and has some extras. The Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations paper Locatello et al., 2019 examines these and other advances to VAEs, and has TF1 code for these augmentations and metrics. TODO: Also add one of their disentangling metrics. A repo comparing 5 different VAE losses using pytorch here . Also has a really nice explanation of the different losses at the end of the README. Add SRU++ cell type Add a discriminator for real vs fake reconstructions when keeping dynamic latent constant but swapping static latent from another trial. Swapping Autoencoder for Deep Image Manipulation by Park et al., 2020 with pytorch implementation .","title":"Further improvements to \\(\\beta\\)-VAE"},{"location":"DSAE/dsae/#getting-started-with-dsaes-in-indl","text":"This indl library defines a series of model-builder functions. Each function takes params , a dictionary of hyperparameters, and inputs containing one or more Keras tensors, and each returns the model outputs and other intermediate variables that need to be tracked. The model-builder functions are mostly defined in indl.model.beta_vae , and that module makes extensive use of other indl modules. The functions are designed to be modular such that they can be used to build different VAE implementations when provided with the correct parameterization.","title":"Getting Started with DSAEs in indl"},{"location":"DSAE/dsae/#hyperparameters","text":"We separate our hyperparameters into non-tunable 'arguments' and tunable 'parameters'. This helps with the hyperparameter optimization framework. Both are defined at the top of indl.model.beta_vae . import tensorflow as tf from indl.model.beta_vae import generate_default_args , generate_default_params _params = generate_default_params () _args = generate_default_args () j_params = { ** _params , ** _args . __dict__ }","title":"Hyperparameters"},{"location":"DSAE/dsae/#prepare-inputs","text":"The first step is to prepare the inputs for entry into the encoder(s). This comprises several steps: dropout (optional) split off inputs to the f_encoder to prevent acausal modeling (optional) coordinated dropout (not implemented) CV mask (optional) Dense layer to read-in inputs to a common set of input factors. from tensorflow.keras import backend as K from indl.model.beta_vae import prepare_inputs n_times = 246 n_sensors = 36 K . clear_session () inputs = tf . keras . Input ( shape = ( n_times , n_sensors )) f_enc_inputs , z_enc_inputs , cd_mask = prepare_inputs ( j_params , inputs ) print ( \"inputs: \" , inputs ) print ( \"inputs to f-encoder: \" , f_enc_inputs ) print ( \"inputs to z-encoder: \" , z_enc_inputs ) print ( \"coordinated dropout mask: \" , cd_mask ) inputs: Tensor(\"input_1:0\", shape=(None, 246, 36), dtype=float32) inputs to f-encoder: Tensor(\"coordinated_dropout/Identity:0\", shape=(None, 246, 36), dtype=float32) inputs to z-encoder: Tensor(\"concat:0\", shape=(None, 246, 36), dtype=float32) coordinated dropout mask: Tensor(\"coordinated_dropout/Identity_1:0\", shape=(None, 246, 36), dtype=bool)","title":"Prepare inputs"},{"location":"DSAE/dsae/#f-encoder","text":"Transform full sequence of \"features\" ( inputs or ReadIn(inputs) ) through (1) RNN then (2) affine to yield parameters of latent posterior distribution: \\( \\(q(f | x_{1:T})\\) \\) This distribution is a multivariate normal, optionally with off-diagonal elements allowed. from indl.model.beta_vae import create_f_encoder , make_f_variational enc_f = create_f_encoder ( j_params , f_enc_inputs ) q_f = make_f_variational ( j_params , enc_f ) print ( \"encoded f latents: \" , enc_f ) print ( \"q(f) - latents as distributions: \" , q_f ) WARNING:tensorflow:From /home/chad/miniconda3/envs/indl/lib/python3.8/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:159: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version. Instructions for updating: Do not pass `graph_parents`. They will no longer be used. encoded f latents: Tensor(\"f_rnn_0/Identity:0\", shape=(None, 256), dtype=float32) q(f) - latents as distributions: tfp.distributions.MultivariateNormalDiag(\"distribution_lambda_MultivariateNormalDiag\", event_shape=[10], dtype=float32)","title":"f-Encoder"},{"location":"DSAE/dsae/#f-prior","text":"Model loss will include the KL divergence between the q_f posterior and a prior. The prior is a learnable multivariate normal diagonal. The prior is initialized with a mean of 0 and a stddev of 0.1 but these are trainable by default. (In LFADS, only the mean is trainable). from indl.model.beta_vae import create_f_prior f_prior = create_f_prior ( j_params ) # Use during training with: # f_kl = tfd.kl_divergence(q_f, f_prior) print ( \"Prior on q(f): \" , f_prior ) Prior on q(f): tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[], event_shape=[10], dtype=float32)","title":"f-Prior"},{"location":"DSAE/dsae/#z-encoder","text":"\\(q(z_t | x_{1:T})\\) I have also seen this called the \"Dynamic Encoder\", or in LFADS the \"Controller Input\" encoder. The z -Encoder varies quite a bit between the different Disentangling/ \\(\\beta\\) Variational Autoencoder implementations. Indeed, in some formulations it isn't used at all, such as the LFADS model without inferred controller input. Where it is used, in general: The inputs are the original data sequences ( \\(x_t\\) ). Unlike the f -encoder, here we output full sequences. The output sequences parameterize a multivariate normal distribution at each timestep , sometimes with constraints on the temporal evolution (e.g., RNN or AR(1)). The encoder itself has as its first layer a RNN (LSTM, GRU), often bidirectional, or a simple MLP as in the DSAE Factorized model If the first layer is an RNN then there is usually a second layer forward-only RNN.","title":"z-Encoder"},{"location":"DSAE/dsae/#extra-details-dsae-full","text":"The inputs are concatenated with a tiled sample from \\(q(f)\\) . We've added a parameter to choose if \\(q(f)\\) is concatenated on the inputs into the first or second RNN, though there isn't a precedent for concatenating on the second.","title":"Extra Details - DSAE Full"},{"location":"DSAE/dsae/#extra-details-lfads","text":"Like its f-Encoder, the RNN cells are a GRU with clipping. The secondary RNN input is the output from the primary RNN concatenated with the decoder RNN's previous step + transformed through the factor Dense layer . Because the LFADS secondary RNN is so complicated, it is integrated into the decoder RNN itself in a \"complex cell\". The complex cell includes the z2 cell, makes the z2 outputs variational in \\(q(z_t)\\) , samples \\(q(z_t)\\) for the inputs to the generative RNN cell, passes the output of the generative RNN step through a Dense to-factors layer, and finally uses that output as one of the inputs to the z2 cell. If params['gen_cell_type'] is \"Complex\" , then we assume that LFADS is being used and we skip the second RNN in create_z_encoder , and we skip making the latents variational in make_z_variational . from indl.model.beta_vae import create_z_encoder , make_z_variational # Note: For f_sample, you can pass in q_f dist itself, or pass q_f.sample(N_SAMPLES) or even q_f.mean() # The former will use the default `convert_to_tensor_fn` which uses params['q_f_samples']. enc_z = create_z_encoder ( j_params , z_enc_inputs , f_sample = q_f ) q_z = make_z_variational ( j_params , enc_z ) print ( \"encoded z: \" , enc_z ) print ( \"q(z|x_t): \" , q_z ) encoded z: Tensor(\"Reshape_5:0\", shape=(None, 246, 16), dtype=float32) q(z|x_t): tfp.distributions.MultivariateNormalDiag(\"distribution_lambda_1_MultivariateNormalDiag\", event_shape=[4], dtype=float32)","title":"Extra Details - LFADS"},{"location":"DSAE/dsae/#z-prior","text":"Model loss will include the KL divergence between the q_z posterior and a prior. There are several versions of the Z prior. DSAE Full: An LSTM with a low-ish hidden size. It is used to generate an output sequence with length equal to q_z timesteps dim. The output sequence is then used to parameterize a MVNDiag distribution of equal dimensionality to q_z. (Implementation note: LSTM is initialized with zero-state and zero-input for sample 0, but subsequent samples are drawn from the previous step's dist .) DSAE Factorized: I'm not sure, maybe the same as above? LFADS: Two options. First seems unused: MVNDiag with zero-mean and trainable var. Second: Learnable AR1 process. from indl.model.beta_vae import create_z_prior # TODO!","title":"Z Prior"},{"location":"DSAE/dsae/#generator-decoder-part-1","text":"\\(p(x_t | z_t, f)\\) The generator takes in the encoded latents contributing to the inputs and/or initial state, and outputs full sequences. The generator layer is typically an RNN, though in some applications (e.g. video) it can be a CNN. The encoded latents comprise a single-timestep latent vector ( f ) and optionally a low-dimensional sequence ( \\(z_t\\) ). Note that these latents are distributions, and therefore must be sampled from to get the initial state and/or the inputs to the generative RNN. The q_f sample and the q_z sample may be combined in different ways to become the generator inputs. In LFADS, the generator is in the \"ComplexCell\", which also includes the z2 cell and the . Therein, the q_f sample is used as the generator's initial state and the q_z sample is used as the inputs. In DVAE, the q_z sample is used as an input to the generator RNN. The q_f sample can either be used as the initial condition to the generator, or it can be tiled and concated with q_z. The generative RNN outputs a sequence. The next step after the sequence is typically a Dense layer to transform into \"factors\". Because the LFADS ComplexCell includes this step, as is required so that the factors can be fed-back to the z2_encoder step-by-step, we also include the Dense layer in our generator for easier interoperability. factors = create_generator ( f_sample , z_sample )","title":"Generator (Decoder part 1)"},{"location":"DSAE/dsae/#probabilistic-reconstructed-input-decoder-part-2","text":"The factors are passed through a Dense layer and the outputs are the same dimensionality as the inputs, but instead of reconstructing the inputs, they parameterize a distribution representing the inputs. This distribution can be Gaussian or Poisson, with the latter being more appropriate for (binned) spike counts.","title":"Probabilistic Reconstructed Input (Decoder part 2)"},{"location":"DSAE/recurrent_layers/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Custom Recurrent Layers A bit of a mess. Also check out tfp_utils, lfads_utils, and lfads_complex_cell. Test GenerativeRNN N_IN = 8 N_UNITS = 24 N_OUT_TIMESTEPS = 115 cell = tfkl.GRUCell # LSTMCell or GRUCell # Test regular RNN with zeros input reg_rnn_layer = tfkl.RNN(cell(N_UNITS), return_state=True, return_sequences=True) in_ = tf.zeros((1, 115, 16)) x_ = reg_rnn_layer(in_) print(K.any(x_[0])) # Just to remind myself that input zeros and state zeros will yield output zeros. tf.Tensor(False, shape=(), dtype=bool) # Test placeholder tensor with no timesteps K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) in_ = tfkl.Input(shape=(N_IN,)) x_, cell_state_ = gen_rnn_layer(in_) print(\"Test placeholder tensor\") model = tf.keras.Model(inputs=in_, outputs=x_) model.summary() Test placeholder tensor Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 8)] 0 __________________________________________________________________________________________________ tf_op_layer_strided_slice (Tens [(None, 1, 8)] 0 input_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_1 (Te [(None, 8)] 0 tf_op_layer_strided_slice[0][0] __________________________________________________________________________________________________ tf_op_layer_ZerosLike (TensorFl [(None, 8)] 0 tf_op_layer_strided_slice_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_2 (Te [(None, 1, 8)] 0 tf_op_layer_ZerosLike[0][0] __________________________________________________________________________________________________ tf_op_layer_AddV2 (TensorFlowOp [(None, 114, 8)] 0 tf_op_layer_strided_slice_2[0][0] __________________________________________________________________________________________________ tf_op_layer_concat (TensorFlowO [(None, 115, 8)] 0 tf_op_layer_strided_slice[0][0] tf_op_layer_AddV2[0][0] __________________________________________________________________________________________________ generative_rnn (GenerativeRNN) [(None, 115, 24), (N 2448 tf_op_layer_concat[0][0] ================================================================================================== Total params: 2,448 Trainable params: 2,448 Non-trainable params: 0 __________________________________________________________________________________________________ # Test placeholder tensor with no timesteps as initial state K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) in_ = tfkl.Input(shape=(N_UNITS,)) x_, cell_state_ = gen_rnn_layer(None, initial_state=in_) print(\"Test placeholder tensor\") model = tf.keras.Model(inputs=in_, outputs=x_) model.summary() Test placeholder tensor Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 24)] 0 __________________________________________________________________________________________________ tf_op_layer_strided_slice (Tens [(None,)] 0 input_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_1 (Te [(None, 1)] 0 tf_op_layer_strided_slice[0][0] __________________________________________________________________________________________________ tf_op_layer_ZerosLike (TensorFl [(None, 1)] 0 tf_op_layer_strided_slice_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_2 (Te [(None, 1, 1)] 0 tf_op_layer_ZerosLike[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_3 (Te [(None, 1)] 0 tf_op_layer_strided_slice_2[0][0] __________________________________________________________________________________________________ tf_op_layer_ZerosLike_1 (Tensor [(None, 1)] 0 tf_op_layer_strided_slice_3[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_4 (Te [(None, 1, 1)] 0 tf_op_layer_ZerosLike_1[0][0] __________________________________________________________________________________________________ tf_op_layer_AddV2 (TensorFlowOp [(None, 114, 1)] 0 tf_op_layer_strided_slice_4[0][0] __________________________________________________________________________________________________ tf_op_layer_concat (TensorFlowO [(None, 115, 1)] 0 tf_op_layer_strided_slice_2[0][0] tf_op_layer_AddV2[0][0] __________________________________________________________________________________________________ generative_rnn (GenerativeRNN) [(None, 115, 24), (N 1944 tf_op_layer_concat[0][0] input_1[0][0] ================================================================================================== Total params: 1,944 Trainable params: 1,944 Non-trainable params: 0 __________________________________________________________________________________________________ # Test None input --> uses zeros K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) print(\"Test None input\") x_, cell_state_ = gen_rnn_layer() print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? Test None input (1, 115, 24) (1, 24) tf.Tensor(False, shape=(), dtype=bool) tf.Tensor(False, shape=(), dtype=bool) # Test random input K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) in_ = tf.random.uniform((1, 8, N_UNITS), minval=-1.0, maxval=1.0) print(\"Test zeros input\") x_, cell_state_ = gen_rnn_layer(in_) print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? Test zeros input (1, 115, 24) (1, 24) tf.Tensor(True, shape=(), dtype=bool) tf.Tensor(True, shape=(), dtype=bool) # Test random states K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) print(gen_rnn_layer.compute_output_shape()) init_states = [tf.random.uniform((1, N_UNITS), minval=-1.0, maxval=1.0) for _ in range(1)] x_, cell_states_ = gen_rnn_layer(initial_state=init_states) print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? [TensorShape([None, 115, 24]), TensorShape([None, 24])] (1, 115, 24) (1, 24) tf.Tensor(True, shape=(), dtype=bool) tf.Tensor(True, shape=(), dtype=bool) # Test masking K.clear_session() tmp = tf.range(N_OUT_TIMESTEPS)[tf.newaxis, :, tf.newaxis] mask = tf.math.logical_or(tmp < 5, tmp > 100) gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS, tile_input=True) in_ = tf.random.uniform((5, N_OUT_TIMESTEPS, N_UNITS), minval=-1.0, maxval=1.0) x_, cell_state_ = gen_rnn_layer(in_, mask=mask) print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? (5, 115, 24) (5, 24) tf.Tensor(True, shape=(), dtype=bool) tf.Tensor(True, shape=(), dtype=bool) # Garbage code I don't want to throw out yet. if False: def call(self, inputs, mask=None, training=None, initial_state=None, constants=None): assert(mask is None), \"mask not supported.\" # First part copied from super call() # The input should be dense, padded with zeros. If a ragged input is fed # into the layer, it is padded and the row lengths are used for masking. inputs, row_lengths = K.convert_inputs_if_ragged(inputs) is_ragged_input = (row_lengths is not None) self._validate_args_if_ragged(is_ragged_input, mask) # Get initial_state. Merge provided initial_state and preserved if self.stateful, # otherwise use provided or zeros if provided is None. inputs, initial_state, constants = self._process_inputs( inputs, initial_state, constants) self._maybe_reset_cell_dropout_mask(self.cell) if isinstance(self.cell, tfkl.StackedRNNCells): for cell in self.cell.cells: self._maybe_reset_cell_dropout_mask(cell) kwargs = {} if generic_utils.has_arg(self.cell.call, 'training'): kwargs['training'] = training # TF RNN cells expect single tensor as state instead of list wrapped tensor. is_tf_rnn_cell = getattr(self.cell, '_is_tf_rnn_cell', None) is not None if constants: if not generic_utils.has_arg(self.cell.call, 'constants'): raise ValueError('RNN cell does not support constants') def step(inputs, states): constants = states[-self._num_constants:] # pylint: disable=invalid-unary-operand-type states = states[:-self._num_constants] # pylint: disable=invalid-unary-operand-type states = states[0] if len(states) == 1 and is_tf_rnn_cell else states output, new_states = self.cell.call( inputs, states, constants=constants, **kwargs) if not nest.is_sequence(new_states): new_states = [new_states] return output, new_states else: def step(inputs, states): states = states[0] if len(states) == 1 and is_tf_rnn_cell else states output, new_states = self.cell.call(inputs, states, **kwargs) if not nest.is_sequence(new_states): new_states = [new_states] return output, new_states # Begin deviation from super call() # ##################################### # We do not do K.rnn because it does not support feeding the output back as the input to the next step. def _process_single_input_t(input_t): input_t = tf.unstack(input_t, axis=-2) # unstack for time_step dim if self.go_backwards: input_t.reverse() return input_t if nest.is_sequence(inputs): processed_input = nest.map_structure(_process_single_input_t, inputs) else: processed_input = (_process_single_input_t(inputs),) cell_input = nest.pack_sequence_as(inputs, [_[0] for _ in processed_input]) cell_state = tuple(initial_state) out_states = [] out_inputs = [] for step_ix in range(self.timesteps): cell_input, new_states = step(cell_input, cell_state) flat_new_states = nest.flatten(new_states) cell_state = nest.pack_sequence_as(cell_state, flat_new_states) out_states.append(cell_state) out_inputs.append(cell_input) out_inputs = tf.stack(out_inputs, axis=-2) # if cell outputs a distribution, then we might do the following, but base class # would have to change. if False: if hasattr(out_inputs[0], 'parameters') and 'distribution' in out_inputs[0].parameters: dist0_parms = out_inputs[0].parameters['distribution'].parameters coll_parms = {} for p_name, p_val in dist0_parms.items(): if K.tensor_util.is_tensor(p_val): coll_parms[p_name] = [] for dist in out_inputs: for p_name in coll_parms.keys(): coll_parms[p_name].append(dist.parameters['distribution'].parameters[p_name]) for p_name in coll_parms.keys(): coll_parms[p_name] = tf.stack(coll_parms[p_name], axis=-2) dist_class = out_inputs[0].parameters['distribution'].__class__ out_inputs = dist_class(**coll_parms) # Warning! time dimension lost in batch with None out_inputs = tfp.distributions.Independent(out_inputs, reinterpreted_batch_ndims=1) out_states = tf.stack(out_states, axis=-2) out_states = tf.unstack(out_states, axis=0) if not hasattr(self.cell.state_size, '__len__'): out_states = out_states[0] if not self.return_sequences: out_inputs = out_inputs[..., -1, :] out_states = [_[..., -1, :] for _ in out_states] if isinstance(out_states, list) else out_states[..., -1, :] if self.return_state: return out_inputs, out_states return out_inputs","title":"Recurrent layers"},{"location":"DSAE/recurrent_layers/#custom-recurrent-layers","text":"A bit of a mess. Also check out tfp_utils, lfads_utils, and lfads_complex_cell.","title":"Custom Recurrent Layers"},{"location":"DSAE/recurrent_layers/#test-generativernn","text":"N_IN = 8 N_UNITS = 24 N_OUT_TIMESTEPS = 115 cell = tfkl.GRUCell # LSTMCell or GRUCell # Test regular RNN with zeros input reg_rnn_layer = tfkl.RNN(cell(N_UNITS), return_state=True, return_sequences=True) in_ = tf.zeros((1, 115, 16)) x_ = reg_rnn_layer(in_) print(K.any(x_[0])) # Just to remind myself that input zeros and state zeros will yield output zeros. tf.Tensor(False, shape=(), dtype=bool) # Test placeholder tensor with no timesteps K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) in_ = tfkl.Input(shape=(N_IN,)) x_, cell_state_ = gen_rnn_layer(in_) print(\"Test placeholder tensor\") model = tf.keras.Model(inputs=in_, outputs=x_) model.summary() Test placeholder tensor Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 8)] 0 __________________________________________________________________________________________________ tf_op_layer_strided_slice (Tens [(None, 1, 8)] 0 input_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_1 (Te [(None, 8)] 0 tf_op_layer_strided_slice[0][0] __________________________________________________________________________________________________ tf_op_layer_ZerosLike (TensorFl [(None, 8)] 0 tf_op_layer_strided_slice_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_2 (Te [(None, 1, 8)] 0 tf_op_layer_ZerosLike[0][0] __________________________________________________________________________________________________ tf_op_layer_AddV2 (TensorFlowOp [(None, 114, 8)] 0 tf_op_layer_strided_slice_2[0][0] __________________________________________________________________________________________________ tf_op_layer_concat (TensorFlowO [(None, 115, 8)] 0 tf_op_layer_strided_slice[0][0] tf_op_layer_AddV2[0][0] __________________________________________________________________________________________________ generative_rnn (GenerativeRNN) [(None, 115, 24), (N 2448 tf_op_layer_concat[0][0] ================================================================================================== Total params: 2,448 Trainable params: 2,448 Non-trainable params: 0 __________________________________________________________________________________________________ # Test placeholder tensor with no timesteps as initial state K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) in_ = tfkl.Input(shape=(N_UNITS,)) x_, cell_state_ = gen_rnn_layer(None, initial_state=in_) print(\"Test placeholder tensor\") model = tf.keras.Model(inputs=in_, outputs=x_) model.summary() Test placeholder tensor Model: \"model\" __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 24)] 0 __________________________________________________________________________________________________ tf_op_layer_strided_slice (Tens [(None,)] 0 input_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_1 (Te [(None, 1)] 0 tf_op_layer_strided_slice[0][0] __________________________________________________________________________________________________ tf_op_layer_ZerosLike (TensorFl [(None, 1)] 0 tf_op_layer_strided_slice_1[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_2 (Te [(None, 1, 1)] 0 tf_op_layer_ZerosLike[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_3 (Te [(None, 1)] 0 tf_op_layer_strided_slice_2[0][0] __________________________________________________________________________________________________ tf_op_layer_ZerosLike_1 (Tensor [(None, 1)] 0 tf_op_layer_strided_slice_3[0][0] __________________________________________________________________________________________________ tf_op_layer_strided_slice_4 (Te [(None, 1, 1)] 0 tf_op_layer_ZerosLike_1[0][0] __________________________________________________________________________________________________ tf_op_layer_AddV2 (TensorFlowOp [(None, 114, 1)] 0 tf_op_layer_strided_slice_4[0][0] __________________________________________________________________________________________________ tf_op_layer_concat (TensorFlowO [(None, 115, 1)] 0 tf_op_layer_strided_slice_2[0][0] tf_op_layer_AddV2[0][0] __________________________________________________________________________________________________ generative_rnn (GenerativeRNN) [(None, 115, 24), (N 1944 tf_op_layer_concat[0][0] input_1[0][0] ================================================================================================== Total params: 1,944 Trainable params: 1,944 Non-trainable params: 0 __________________________________________________________________________________________________ # Test None input --> uses zeros K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) print(\"Test None input\") x_, cell_state_ = gen_rnn_layer() print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? Test None input (1, 115, 24) (1, 24) tf.Tensor(False, shape=(), dtype=bool) tf.Tensor(False, shape=(), dtype=bool) # Test random input K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) in_ = tf.random.uniform((1, 8, N_UNITS), minval=-1.0, maxval=1.0) print(\"Test zeros input\") x_, cell_state_ = gen_rnn_layer(in_) print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? Test zeros input (1, 115, 24) (1, 24) tf.Tensor(True, shape=(), dtype=bool) tf.Tensor(True, shape=(), dtype=bool) # Test random states K.clear_session() gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS) print(gen_rnn_layer.compute_output_shape()) init_states = [tf.random.uniform((1, N_UNITS), minval=-1.0, maxval=1.0) for _ in range(1)] x_, cell_states_ = gen_rnn_layer(initial_state=init_states) print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? [TensorShape([None, 115, 24]), TensorShape([None, 24])] (1, 115, 24) (1, 24) tf.Tensor(True, shape=(), dtype=bool) tf.Tensor(True, shape=(), dtype=bool) # Test masking K.clear_session() tmp = tf.range(N_OUT_TIMESTEPS)[tf.newaxis, :, tf.newaxis] mask = tf.math.logical_or(tmp < 5, tmp > 100) gen_rnn_layer = GenerativeRNN(cell(N_UNITS), return_sequences=True, return_state=True, timesteps=N_OUT_TIMESTEPS, tile_input=True) in_ = tf.random.uniform((5, N_OUT_TIMESTEPS, N_UNITS), minval=-1.0, maxval=1.0) x_, cell_state_ = gen_rnn_layer(in_, mask=mask) print(x_.shape, cell_state_.shape) print(K.any(x_), K.any(cell_state_)) # <- any non-zero values? (5, 115, 24) (5, 24) tf.Tensor(True, shape=(), dtype=bool) tf.Tensor(True, shape=(), dtype=bool) # Garbage code I don't want to throw out yet. if False: def call(self, inputs, mask=None, training=None, initial_state=None, constants=None): assert(mask is None), \"mask not supported.\" # First part copied from super call() # The input should be dense, padded with zeros. If a ragged input is fed # into the layer, it is padded and the row lengths are used for masking. inputs, row_lengths = K.convert_inputs_if_ragged(inputs) is_ragged_input = (row_lengths is not None) self._validate_args_if_ragged(is_ragged_input, mask) # Get initial_state. Merge provided initial_state and preserved if self.stateful, # otherwise use provided or zeros if provided is None. inputs, initial_state, constants = self._process_inputs( inputs, initial_state, constants) self._maybe_reset_cell_dropout_mask(self.cell) if isinstance(self.cell, tfkl.StackedRNNCells): for cell in self.cell.cells: self._maybe_reset_cell_dropout_mask(cell) kwargs = {} if generic_utils.has_arg(self.cell.call, 'training'): kwargs['training'] = training # TF RNN cells expect single tensor as state instead of list wrapped tensor. is_tf_rnn_cell = getattr(self.cell, '_is_tf_rnn_cell', None) is not None if constants: if not generic_utils.has_arg(self.cell.call, 'constants'): raise ValueError('RNN cell does not support constants') def step(inputs, states): constants = states[-self._num_constants:] # pylint: disable=invalid-unary-operand-type states = states[:-self._num_constants] # pylint: disable=invalid-unary-operand-type states = states[0] if len(states) == 1 and is_tf_rnn_cell else states output, new_states = self.cell.call( inputs, states, constants=constants, **kwargs) if not nest.is_sequence(new_states): new_states = [new_states] return output, new_states else: def step(inputs, states): states = states[0] if len(states) == 1 and is_tf_rnn_cell else states output, new_states = self.cell.call(inputs, states, **kwargs) if not nest.is_sequence(new_states): new_states = [new_states] return output, new_states # Begin deviation from super call() # ##################################### # We do not do K.rnn because it does not support feeding the output back as the input to the next step. def _process_single_input_t(input_t): input_t = tf.unstack(input_t, axis=-2) # unstack for time_step dim if self.go_backwards: input_t.reverse() return input_t if nest.is_sequence(inputs): processed_input = nest.map_structure(_process_single_input_t, inputs) else: processed_input = (_process_single_input_t(inputs),) cell_input = nest.pack_sequence_as(inputs, [_[0] for _ in processed_input]) cell_state = tuple(initial_state) out_states = [] out_inputs = [] for step_ix in range(self.timesteps): cell_input, new_states = step(cell_input, cell_state) flat_new_states = nest.flatten(new_states) cell_state = nest.pack_sequence_as(cell_state, flat_new_states) out_states.append(cell_state) out_inputs.append(cell_input) out_inputs = tf.stack(out_inputs, axis=-2) # if cell outputs a distribution, then we might do the following, but base class # would have to change. if False: if hasattr(out_inputs[0], 'parameters') and 'distribution' in out_inputs[0].parameters: dist0_parms = out_inputs[0].parameters['distribution'].parameters coll_parms = {} for p_name, p_val in dist0_parms.items(): if K.tensor_util.is_tensor(p_val): coll_parms[p_name] = [] for dist in out_inputs: for p_name in coll_parms.keys(): coll_parms[p_name].append(dist.parameters['distribution'].parameters[p_name]) for p_name in coll_parms.keys(): coll_parms[p_name] = tf.stack(coll_parms[p_name], axis=-2) dist_class = out_inputs[0].parameters['distribution'].__class__ out_inputs = dist_class(**coll_parms) # Warning! time dimension lost in batch with None out_inputs = tfp.distributions.Independent(out_inputs, reinterpreted_batch_ndims=1) out_states = tf.stack(out_states, axis=-2) out_states = tf.unstack(out_states, axis=0) if not hasattr(self.cell.state_size, '__len__'): out_states = out_states[0] if not self.return_sequences: out_inputs = out_inputs[..., -1, :] out_states = [_[..., -1, :] for _ in out_states] if isinstance(out_states, list) else out_states[..., -1, :] if self.return_state: return out_inputs, out_states return out_inputs","title":"Test GenerativeRNN"},{"location":"DSAE/tfp_notes/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Notes on using tensorflow-probability in bVAE These notes are a little bit outdated now. I need to review. Tensorflow-probability (tfp) provides a few tools that simplify writing a VAE. In the VAE using vanilla tensorflow, the input to our decoder uses a a trick that mimics drawing a sample from a distribution parameterized by our latent vector. With tfp, we can make our latent vector an actual distribution. No trick needed! tfp provides the ability to apply KL-regularization directly on our latent distributions. We can make the reconstructed signal a distribution, and the reconstruction loss is the negative log-likelihood of the input given the reconstruction distribution. Resources TF Probability homepage (within link to VAE blog post ). TF Probability example of disentangled VAE from Li and Mandt, ICML 2018 . A Note About TFP Distribution Shapes Event shape describes the shape of a single draw from the distribution; it may be dependent across dimensions. For scalar distributions, the event shape is [] . For a bivariate, it is [2] , and for a 5-dimensional MultivariateNormal, the event shape is [5] . Batch shape describes independent, not identically distributed draws, aka a \"batch\" of distributions. Sample shape describes independent, identically distributed draws of batches from the distribution family. Define the latent prior What distribution do we assume the latent variables should follow? In the case of variational autoencoders we typically assume that the latents are (a) Guassian, (b) have mean=0, and (c) have diagonal covariance. The following demonstrates multiple ways to create such a distribution, with fixed parameters. Prior - Off-diagonal covariance? I guess that depends on if the latent posterior variables should be regularized against having off-diagonals. If the goal is for the latents to describe an orthonormal space, at least as much as possible without sacrificing model quality, then the prior should not have any off-diagonal covariances. Indeed, I have never seen a prior that was not set to be diagonal. If the posterior is not allowed off-diagonals then definitely do not put off-diagonals in the prior. Prior - Fixed or Learnable? Do we want to enforce these static priors? Or do we want to allow the priors to update as the model trains? The answer depends primarily on if we think that we have a good prior. There is a small discussion about this in the tfp regression tutorial in Case 3: Note that in this example we are training both P(w) ( prior ) and Q(w) ( posterior ). This training corresponds to using Empirical Bayes or Type-II Maximum Likelihood. We used this method so that we wouldn\u2019t need to specify the location of the prior for the slope and intercept parameters, which can be tough to get right if we do not have prior knowledge about the problem. Moreover, if you set the priors very far from their true values, then the posterior may be unduly affected by this choice. A caveat of using Type-II Maximum Likelihood is that you lose some of the regularization benefits over the weights. If you wanted to do a proper Bayesian treatment of uncertainty (if you had some prior knowledge, or a more sophisticated prior), you could use a non-trainable prior (see Appendix B). The prior is fixed in many of the TFP introductory examples. This is because the intro examples meet conditions under which it doesn't matter if the prior is trainable. See here for more info. The next cell, in the last example, implements a learnable multivariate normal distribution. tfp.util.TransformedVariable : Variable tracking object which applies function upon convert_to_tensor tfp.bijectors.FillScaleTriL : Transforms unconstrained vectors to TriL matrices with positive diagonal. I have also seen this implemented as a custom class . Or as a callable that returns another callable to be passed to tfpl.DenseVariational 's make_prior_fn argument. Encoder The input is transformed into some lower dimensional latent variable. In this case we use a Bidirectional(LSTM) . This may not be the right layer for you. We use it here because it is similar to what is used in the disentangled_vae example in the tfp source code. Then the latent variables are used to parameterize a distribution. It's arguable whether the distribution is part of the encoder, the decoder, or something in between, but we will put it in the encoder. Off-diagonal covariance in latent? In the tfp example VAE scripts , all the latents were MultivariateNormalDiag , i.e. no off-diagonal covariances. However, in the VAE with TFP blog post , the encoded latents used MultivariateNormalTriL , and thus were allowed off-diagonals (though the prior did not). Allowing off-diagonals also increases the number of the parameters in the model which might increase the number of samples of data needed. Mixture of distributions or single distributions? While this applies to different distribution families as well, we are using Normal distributions. Each independent latent can be modeled as a single Normal or a mixture of Normals. When using a mixture, analytic KL divergence won't work, and more data is required to fit the additional parameters. I have never used mixture of Gaussians, but the below snippet is a demonstration of how that might work: tfd . MixtureSameFamily ( components_distribution = tfd . MultivariateNormalDiag ( loc = tf . Variable ( mixture_components , latent_size ), scale_diag = tf . nn . softplus ( tf . Variable ( mixture_components , latent_size ))), mixture_distribution = tfd . Categorical ( logits = Variable ( mixture_components )), name = \"prior\" ) tfp . layers . MixtureNormal ( num_components , event_shape = ( LATENT_DIM ,)) Additional transform on covariance For the Normal distributions, the initialized value for the mean ( loc ) is typically centered on 0.0 , and the value for the std ( scale ) is typically centered on 1.0 . When these values are changing with training (from previous layer or tf.Variable in the case of a trainable prior), care should be taken so that the learnable variables are centered around their expected initial values and are of similar magnitude. I believe the training machinery works better under these conditions. For the loc there is nothing to do because it is already centred at 0 and there are no requirements for it to be positive. For the scale , we want the loss to update values that are by default centered on 0, but when the distribution is sampled, the stddev is centered around 1. Also, we have to be careful that the stddev doesn't go negative. Scale can be transformed to meet the requirements by adding a bias to the scale and transforming it through Softplus . Thus, the inputs to the distribution's scale argument are around 0 (at least initially), then shifted by np.log(np.exp(1) - 1) ( =softplus_inverse(1.0) ~ 0.55 ), then softplus transformed, and finally shifted by 1e-5 (to force > 0) to yield the value that will parameterize the dist stddev. _loc = tfkl . Dense ( LATENT_DIM )( _features ) _scale_diag = tfkl . Dense ( LATENT_DIM )( _features ) _scale_diag = _scale_diag + np . log ( np . exp ( 1 ) - 1 ) _scale_diag = tf . math . softplus ( _scale_diag ) + 1e-5 _static_sample = tfpl . DistributionLambda ( make_distribution_fn = lambda t : tfd . Independent ( tfd . Normal ( loc = t [ 0 ], scale = t [ 1 ]) ), )([ _loc , _scale_diag ]) In the case of a trainable prior , we can initialize the tf.TransformedVariable for the scale to be around 1 and use a bijector tf.nn.softplus(_ + np.log(np.exp(1) - 1)) + 1e-5 before sampling. It's a little confusing that the TransformedVariable should be initialized to its transformed value, and the stored variable value (i.e., the one subject to training) is inverse transforming the initialization value through the bijector. See the make_mvn_prior function definition for an example. Number of samples from distributions? For any given pass through the model, the distributions can be sampled multiples times. For example, on the output distribution, we can get N_SAMPLES different reconstructions, but then we must calculate the error for each sample (e.g., using 'mse') and take the average error, or we can calculate the probability for each sample and take the average probability: tf.reduce_logsumexp(elbo) - tf.math.log(n_samples) . _static_sample = tfpl . DistributionLambda ( make_distribution_fn = lambda t : tfd . Independent ( tfd . Normal ( loc = t [ 0 ], scale = t [ 1 ])), convert_to_tensor_fn = lambda s : s . sample ( N_SAMPLES ) )([ _loc , _scale_diag ]) KL Divergence The latent posterior distribution is regularized to resemble the prior distribution by penalizing the KL divergence between the posterior and the prior. There are several ways to do this. Add the latent distribution to the model outputs then use loss functions for each output to penalize KL divergence from the prior. While the reconstructions's loss function will remain -recon_dist.log_prob(expected_recon) , the latent dist can use Analytic KL: lambda _, latent_dist: tfd.kl_divergence(latent_dist, prior) Quantitative KL: Need a func that accepts (true_x, latent_dist), samples latent_dist to get latent_sample, and returns latent_dist.log_prob(latent_sample) - prior.log_prob(latent_sample) . Add KL regularizer directly to latent distribution (my preferred approach): posterior = tfpl . SomeLayer ( ... , activity_regularizer = tfpl . KLDivergenceRegularizer ( prior , weight = KL_WEIGHT ) ) Using tfpl.KLDivergenceAddLoss(prior) . This currently does not work; see here . Add KL divergence loss manually kl_loss = tfd.kl_divergence(latent, prior) model.add_loss(weight * kl_loss, axis=0) # Might be necessary to reduce_mean depending on shapes. Calculate KL loss in custom training calculation. See custom training in this notebook. Analytic KL (or kl_exact ) works only when the latent and prior dists are of the same type, and not for mixture models. In this notebook I demonstrate 1, 2, and 5. 1 has weight=0 so it isn't actually used, but nevertheless it is still convenient to have Keras print out its values during training. 5 is coded but the custom training loop is commented out. Ultimately, 2 is what is used to update the latent. Weighting by number of samples If we allow the KL divergence loss to be weighted too heavily then the model will prioritize matching the prior more than solving the output objective. This is especially problematic when we do not have a learnable prior. I looked to available examples to see what the conventions were. But this left me more confused. In Regression blog post and accompanying google colab : rv_y.variational_loss(y, kl_weight=np.array(batch_size, x.dtype) / x.shape[0]) In vae blog post: activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=1.0)) In vae example script: weighted_elbo = tf.reduce_logsumexp(elbo) - tf.math.log(n_samples) But the above is not used. If it were: loss = -tf.reduce_mean(weighted_elbo) In kernel_divergence_fn kwarg for tfpl.DenseFlipout in logistic_regression example : kernel_divergence_fn=lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(num_samples, dtype=tf.float32) In API docs for tfpl.KLDivergenceRegularizer or tfpl.KLDivergenceAddLoss , example code sets weight=num_train_samples . Isn't this the opposite of the other examples? In disentangled vae example: Not done! In LFADS : \"normalized only by batch size, not by dimension or by time steps\" - implicit in tf.reduce_mean() . In my confusion I posted a question to the TensorFlow Probability mailing list. Someone answered pointing me to other similar conversations. As best as I can understand, it seems that the conventional scaling to apply to the KL divergence term is (batch_size / number_of_samples) . Upon further inspection, I think that depends on which of the above methods of adding KL Divergence loss KL annealing Sometimes units can become inactive and stay inactive if they become trapped in a local minimum when the KL distance is near 0. Therefore, it is often beneficial to drastically deprioritize the prior at training outset then gradually increase the KL weight as training progresses. This is well described in section 2.3 of the Ladder VAE paper . We can alo make the beta term cyclical which provides other benefits as described here . For this to work with the Keras training syntax, we need the weight to be a non-trainable variable that changes during a callback. You can find an example implementation here Decoder Which distribution? The output distribution should, as much as possible, make sense for the type of data being generated. Some examples: binarized pixels -- independent bernoulli spike counts -- independent Poisson Any aggregate of many small-scale processes -- Normal (Gaussian) Biological signals sometimes follow Gaussian distributions. When they don't, it's usually a good idea to transform them so that they do, because many data science tools work best with Gaussian data. For similar reasons, it's quite common to scale the data so that they have a standard deviation of 1.0. What about covariances? This should be considered separately for every dataset. For the present data, the signals were created by mixing latents, so it is expected that signals with contributions from the same latents will covary, and therefore we should generate outputs with covariances. But in practice it doesn't matter here and it slows down training so we'll go with diagonal-only. Model To the model's outputs= kwarg we pass a tuple of both the latent distribution and the output distribution. We do this for one reason only: to monitor the KL divergence loss during training. If you recall, the dataset Y was mapped to (zeros, x) tuple to give us 2 outputs. The compiled model has 2 loss functions: the first calculates the KL divergence of the latent from the prior, and the second calculates the -log-likelihood of the data on the output distribution. The first loss has a weight of 0.0 and is thus not used in updating the model variables. It is not needed because the KL-divergence for updating the model variables is calculated in the activity_regularizer for the prior distribution in the encoder model. Yet, Keras' model.fit will still print out the KL loss (here called \"q_z_loss\"). If we didn't want to monitor the KL-loss, we could simplify things a little by removing the first output from the model, changing the dataset from outputting (zeros, x) to only output x, removing the first loss-fn from the loss kwarg in model.compile, and getting rid of the loss_weights kwarg.","title":"Tfp notes"},{"location":"DSAE/tfp_notes/#notes-on-using-tensorflow-probability-in-bvae","text":"These notes are a little bit outdated now. I need to review. Tensorflow-probability (tfp) provides a few tools that simplify writing a VAE. In the VAE using vanilla tensorflow, the input to our decoder uses a a trick that mimics drawing a sample from a distribution parameterized by our latent vector. With tfp, we can make our latent vector an actual distribution. No trick needed! tfp provides the ability to apply KL-regularization directly on our latent distributions. We can make the reconstructed signal a distribution, and the reconstruction loss is the negative log-likelihood of the input given the reconstruction distribution.","title":"Notes on using tensorflow-probability in bVAE"},{"location":"DSAE/tfp_notes/#resources","text":"TF Probability homepage (within link to VAE blog post ). TF Probability example of disentangled VAE from Li and Mandt, ICML 2018 .","title":"Resources"},{"location":"DSAE/tfp_notes/#a-note-about-tfp-distribution-shapes","text":"Event shape describes the shape of a single draw from the distribution; it may be dependent across dimensions. For scalar distributions, the event shape is [] . For a bivariate, it is [2] , and for a 5-dimensional MultivariateNormal, the event shape is [5] . Batch shape describes independent, not identically distributed draws, aka a \"batch\" of distributions. Sample shape describes independent, identically distributed draws of batches from the distribution family.","title":"A Note About TFP Distribution Shapes"},{"location":"DSAE/tfp_notes/#define-the-latent-prior","text":"What distribution do we assume the latent variables should follow? In the case of variational autoencoders we typically assume that the latents are (a) Guassian, (b) have mean=0, and (c) have diagonal covariance. The following demonstrates multiple ways to create such a distribution, with fixed parameters.","title":"Define the latent prior"},{"location":"DSAE/tfp_notes/#prior-off-diagonal-covariance","text":"I guess that depends on if the latent posterior variables should be regularized against having off-diagonals. If the goal is for the latents to describe an orthonormal space, at least as much as possible without sacrificing model quality, then the prior should not have any off-diagonal covariances. Indeed, I have never seen a prior that was not set to be diagonal. If the posterior is not allowed off-diagonals then definitely do not put off-diagonals in the prior.","title":"Prior - Off-diagonal covariance?"},{"location":"DSAE/tfp_notes/#prior-fixed-or-learnable","text":"Do we want to enforce these static priors? Or do we want to allow the priors to update as the model trains? The answer depends primarily on if we think that we have a good prior. There is a small discussion about this in the tfp regression tutorial in Case 3: Note that in this example we are training both P(w) ( prior ) and Q(w) ( posterior ). This training corresponds to using Empirical Bayes or Type-II Maximum Likelihood. We used this method so that we wouldn\u2019t need to specify the location of the prior for the slope and intercept parameters, which can be tough to get right if we do not have prior knowledge about the problem. Moreover, if you set the priors very far from their true values, then the posterior may be unduly affected by this choice. A caveat of using Type-II Maximum Likelihood is that you lose some of the regularization benefits over the weights. If you wanted to do a proper Bayesian treatment of uncertainty (if you had some prior knowledge, or a more sophisticated prior), you could use a non-trainable prior (see Appendix B). The prior is fixed in many of the TFP introductory examples. This is because the intro examples meet conditions under which it doesn't matter if the prior is trainable. See here for more info. The next cell, in the last example, implements a learnable multivariate normal distribution. tfp.util.TransformedVariable : Variable tracking object which applies function upon convert_to_tensor tfp.bijectors.FillScaleTriL : Transforms unconstrained vectors to TriL matrices with positive diagonal. I have also seen this implemented as a custom class . Or as a callable that returns another callable to be passed to tfpl.DenseVariational 's make_prior_fn argument.","title":"Prior - Fixed or Learnable?"},{"location":"DSAE/tfp_notes/#encoder","text":"The input is transformed into some lower dimensional latent variable. In this case we use a Bidirectional(LSTM) . This may not be the right layer for you. We use it here because it is similar to what is used in the disentangled_vae example in the tfp source code. Then the latent variables are used to parameterize a distribution. It's arguable whether the distribution is part of the encoder, the decoder, or something in between, but we will put it in the encoder.","title":"Encoder"},{"location":"DSAE/tfp_notes/#off-diagonal-covariance-in-latent","text":"In the tfp example VAE scripts , all the latents were MultivariateNormalDiag , i.e. no off-diagonal covariances. However, in the VAE with TFP blog post , the encoded latents used MultivariateNormalTriL , and thus were allowed off-diagonals (though the prior did not). Allowing off-diagonals also increases the number of the parameters in the model which might increase the number of samples of data needed.","title":"Off-diagonal covariance in latent?"},{"location":"DSAE/tfp_notes/#mixture-of-distributions-or-single-distributions","text":"While this applies to different distribution families as well, we are using Normal distributions. Each independent latent can be modeled as a single Normal or a mixture of Normals. When using a mixture, analytic KL divergence won't work, and more data is required to fit the additional parameters. I have never used mixture of Gaussians, but the below snippet is a demonstration of how that might work: tfd . MixtureSameFamily ( components_distribution = tfd . MultivariateNormalDiag ( loc = tf . Variable ( mixture_components , latent_size ), scale_diag = tf . nn . softplus ( tf . Variable ( mixture_components , latent_size ))), mixture_distribution = tfd . Categorical ( logits = Variable ( mixture_components )), name = \"prior\" ) tfp . layers . MixtureNormal ( num_components , event_shape = ( LATENT_DIM ,))","title":"Mixture of distributions or single distributions?"},{"location":"DSAE/tfp_notes/#additional-transform-on-covariance","text":"For the Normal distributions, the initialized value for the mean ( loc ) is typically centered on 0.0 , and the value for the std ( scale ) is typically centered on 1.0 . When these values are changing with training (from previous layer or tf.Variable in the case of a trainable prior), care should be taken so that the learnable variables are centered around their expected initial values and are of similar magnitude. I believe the training machinery works better under these conditions. For the loc there is nothing to do because it is already centred at 0 and there are no requirements for it to be positive. For the scale , we want the loss to update values that are by default centered on 0, but when the distribution is sampled, the stddev is centered around 1. Also, we have to be careful that the stddev doesn't go negative. Scale can be transformed to meet the requirements by adding a bias to the scale and transforming it through Softplus . Thus, the inputs to the distribution's scale argument are around 0 (at least initially), then shifted by np.log(np.exp(1) - 1) ( =softplus_inverse(1.0) ~ 0.55 ), then softplus transformed, and finally shifted by 1e-5 (to force > 0) to yield the value that will parameterize the dist stddev. _loc = tfkl . Dense ( LATENT_DIM )( _features ) _scale_diag = tfkl . Dense ( LATENT_DIM )( _features ) _scale_diag = _scale_diag + np . log ( np . exp ( 1 ) - 1 ) _scale_diag = tf . math . softplus ( _scale_diag ) + 1e-5 _static_sample = tfpl . DistributionLambda ( make_distribution_fn = lambda t : tfd . Independent ( tfd . Normal ( loc = t [ 0 ], scale = t [ 1 ]) ), )([ _loc , _scale_diag ]) In the case of a trainable prior , we can initialize the tf.TransformedVariable for the scale to be around 1 and use a bijector tf.nn.softplus(_ + np.log(np.exp(1) - 1)) + 1e-5 before sampling. It's a little confusing that the TransformedVariable should be initialized to its transformed value, and the stored variable value (i.e., the one subject to training) is inverse transforming the initialization value through the bijector. See the make_mvn_prior function definition for an example.","title":"Additional transform on covariance"},{"location":"DSAE/tfp_notes/#number-of-samples-from-distributions","text":"For any given pass through the model, the distributions can be sampled multiples times. For example, on the output distribution, we can get N_SAMPLES different reconstructions, but then we must calculate the error for each sample (e.g., using 'mse') and take the average error, or we can calculate the probability for each sample and take the average probability: tf.reduce_logsumexp(elbo) - tf.math.log(n_samples) . _static_sample = tfpl . DistributionLambda ( make_distribution_fn = lambda t : tfd . Independent ( tfd . Normal ( loc = t [ 0 ], scale = t [ 1 ])), convert_to_tensor_fn = lambda s : s . sample ( N_SAMPLES ) )([ _loc , _scale_diag ])","title":"Number of samples from distributions?"},{"location":"DSAE/tfp_notes/#kl-divergence","text":"The latent posterior distribution is regularized to resemble the prior distribution by penalizing the KL divergence between the posterior and the prior. There are several ways to do this. Add the latent distribution to the model outputs then use loss functions for each output to penalize KL divergence from the prior. While the reconstructions's loss function will remain -recon_dist.log_prob(expected_recon) , the latent dist can use Analytic KL: lambda _, latent_dist: tfd.kl_divergence(latent_dist, prior) Quantitative KL: Need a func that accepts (true_x, latent_dist), samples latent_dist to get latent_sample, and returns latent_dist.log_prob(latent_sample) - prior.log_prob(latent_sample) . Add KL regularizer directly to latent distribution (my preferred approach): posterior = tfpl . SomeLayer ( ... , activity_regularizer = tfpl . KLDivergenceRegularizer ( prior , weight = KL_WEIGHT ) ) Using tfpl.KLDivergenceAddLoss(prior) . This currently does not work; see here . Add KL divergence loss manually kl_loss = tfd.kl_divergence(latent, prior) model.add_loss(weight * kl_loss, axis=0) # Might be necessary to reduce_mean depending on shapes. Calculate KL loss in custom training calculation. See custom training in this notebook. Analytic KL (or kl_exact ) works only when the latent and prior dists are of the same type, and not for mixture models. In this notebook I demonstrate 1, 2, and 5. 1 has weight=0 so it isn't actually used, but nevertheless it is still convenient to have Keras print out its values during training. 5 is coded but the custom training loop is commented out. Ultimately, 2 is what is used to update the latent.","title":"KL Divergence"},{"location":"DSAE/tfp_notes/#weighting-by-number-of-samples","text":"If we allow the KL divergence loss to be weighted too heavily then the model will prioritize matching the prior more than solving the output objective. This is especially problematic when we do not have a learnable prior. I looked to available examples to see what the conventions were. But this left me more confused. In Regression blog post and accompanying google colab : rv_y.variational_loss(y, kl_weight=np.array(batch_size, x.dtype) / x.shape[0]) In vae blog post: activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=1.0)) In vae example script: weighted_elbo = tf.reduce_logsumexp(elbo) - tf.math.log(n_samples) But the above is not used. If it were: loss = -tf.reduce_mean(weighted_elbo) In kernel_divergence_fn kwarg for tfpl.DenseFlipout in logistic_regression example : kernel_divergence_fn=lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(num_samples, dtype=tf.float32) In API docs for tfpl.KLDivergenceRegularizer or tfpl.KLDivergenceAddLoss , example code sets weight=num_train_samples . Isn't this the opposite of the other examples? In disentangled vae example: Not done! In LFADS : \"normalized only by batch size, not by dimension or by time steps\" - implicit in tf.reduce_mean() . In my confusion I posted a question to the TensorFlow Probability mailing list. Someone answered pointing me to other similar conversations. As best as I can understand, it seems that the conventional scaling to apply to the KL divergence term is (batch_size / number_of_samples) . Upon further inspection, I think that depends on which of the above methods of adding KL Divergence loss","title":"Weighting by number of samples"},{"location":"DSAE/tfp_notes/#kl-annealing","text":"Sometimes units can become inactive and stay inactive if they become trapped in a local minimum when the KL distance is near 0. Therefore, it is often beneficial to drastically deprioritize the prior at training outset then gradually increase the KL weight as training progresses. This is well described in section 2.3 of the Ladder VAE paper . We can alo make the beta term cyclical which provides other benefits as described here . For this to work with the Keras training syntax, we need the weight to be a non-trainable variable that changes during a callback. You can find an example implementation here","title":"KL annealing"},{"location":"DSAE/tfp_notes/#decoder","text":"","title":"Decoder"},{"location":"DSAE/tfp_notes/#which-distribution","text":"The output distribution should, as much as possible, make sense for the type of data being generated. Some examples: binarized pixels -- independent bernoulli spike counts -- independent Poisson Any aggregate of many small-scale processes -- Normal (Gaussian) Biological signals sometimes follow Gaussian distributions. When they don't, it's usually a good idea to transform them so that they do, because many data science tools work best with Gaussian data. For similar reasons, it's quite common to scale the data so that they have a standard deviation of 1.0. What about covariances? This should be considered separately for every dataset. For the present data, the signals were created by mixing latents, so it is expected that signals with contributions from the same latents will covary, and therefore we should generate outputs with covariances. But in practice it doesn't matter here and it slows down training so we'll go with diagonal-only.","title":"Which distribution?"},{"location":"DSAE/tfp_notes/#model","text":"To the model's outputs= kwarg we pass a tuple of both the latent distribution and the output distribution. We do this for one reason only: to monitor the KL divergence loss during training. If you recall, the dataset Y was mapped to (zeros, x) tuple to give us 2 outputs. The compiled model has 2 loss functions: the first calculates the KL divergence of the latent from the prior, and the second calculates the -log-likelihood of the data on the output distribution. The first loss has a weight of 0.0 and is thus not used in updating the model variables. It is not needed because the KL-divergence for updating the model variables is calculated in the activity_regularizer for the prior distribution in the encoder model. Yet, Keras' model.fit will still print out the KL loss (here called \"q_z_loss\"). If we didn't want to monitor the KL-loss, we could simplify things a little by removing the first output from the model, changing the dataset from outputting (zeros, x) to only output x, removing the first loss-fn from the loss kwarg in model.compile, and getting rid of the loss_weights kwarg.","title":"Model"},{"location":"DSAE/tfp_utils/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Tensorflow Probability Utilities This notebook is a bit of a mess after the refactor. Its code has all been moved to indl.model.tfp and indl.model.tfp.dsae Many of the tests have been moved to the unit tests. import numpy as np import tensorflow as tf import tensorflow.keras.layers as tfkl from tensorflow.keras import backend as K import tensorflow_probability as tfp tfd = tfp . distributions tfpl = tfp . layers tfb = tfp . bijectors scale_shift = np . log ( np . exp ( 1 ) - 1 ) . astype ( np . float32 ) from indl.model.tfp.devae import * from indl.model.tfp import * # An example of how this would work in a variational autoencoder. N_TIMES = 10 N_SENSORS = 8 N_SAMPLES = 2 N_HIDDEN = 5 KL_WEIGHT = 0.05 t_vec = tf . range ( N_TIMES , dtype = tf . float32 ) / N_TIMES sig_vec = 1 + tf . exp ( - 10 * ( t_vec - 0.5 )) def make_model ( prior ): input_ = tfkl . Input ( shape = ( LATENT_SIZE ,)) # Encoder make_latent_dist_fn , latent_params = make_mvn_dist_fn ( input_ , LATENT_SIZE , offdiag = True , loc_name = \"latent_loc\" ) q_latent = tfpl . DistributionLambda ( name = \"q_latent\" , make_distribution_fn = make_latent_dist_fn , convert_to_tensor_fn = lambda s : s . sample ( N_SAMPLES ), activity_regularizer = tfpl . KLDivergenceRegularizer ( prior , use_exact_kl = True , weight = KL_WEIGHT ) )( latent_params ) # Decoder y_ = q_latent [ ... , tf . newaxis , :] / sig_vec [:, tf . newaxis ] # broadcast-add zeros to restore timesteps #y_ = q_latent[..., tf.newaxis, :] + tf.zeros([N_TIMES, 1]) #y_ = tf.reshape(y_, [-1, N_TIMES, LATENT_SIZE]) #y_ = tfkl.LSTM(N_HIDDEN, return_sequences=True)(y_) #y_ = tf.reshape(y_, [N_SAMPLES, -1, N_TIMES, N_HIDDEN]) make_out_dist_fn , out_dist_params = make_mvn_dist_fn ( y_ , N_SENSORS , loc_name = \"out_loc\" ) p_out = tfpl . DistributionLambda ( make_distribution_fn = make_out_dist_fn , name = \"p_out\" )( out_dist_params ) # no prior on the output. # Model model = tf . keras . Model ( inputs = input_ , outputs = [ q_latent , p_out ]) return model # Create a fake dataset to train the model. LATENT_SIZE = 4 BATCH_SIZE = 6 # The latents are sampled from a distribution with known parameters. true_dist = tfd . MultivariateNormalDiag ( loc = [ - 1. , 1. , 5 , - 5 ], # must have length == LATENT_SIZE scale_diag = [ 0.5 , 0.5 , 0.9 , 0.2 ] ) # They parameterize sigmoid end points, from indl.misc.sigfuncs import sigmoid from functools import partial t_vec = ( np . arange ( N_TIMES , dtype = np . float32 ) / N_TIMES )[ None , :] f_sig = partial ( sigmoid , t_vec , B = 10 , x_offset = 0.5 ) # which are then mixed with a known mixing matrix mix_mat = np . array ([ [ - 0.3 , - .28 , - 0.38 , - 0.45 , - 0.02 , - 0.12 , - 0.05 , - 0.48 ], [ 0.27 , 0.29 , - 0.34 , 0.2 , 0.41 , 0.08 , 0.11 , 0.13 ], [ - 0.14 , 0.26 , - 0.28 , - 0.14 , 0.1 , - 0.2 , 0.4 , 0.11 ], [ - 0.05 , - 0.12 , 0.28 , 0.49 , - 0.12 , 0.1 , 0.17 , 0.22 ] ], dtype = np . float32 ) . T #mix_mat = tf.convert_to_tensor(mix_mat) def gen_ds ( n_iters = 1e2 , latent_size = LATENT_SIZE ): iter_ix = 0 while iter_ix < n_iters : _input = tf . ones (( latent_size ,), dtype = tf . float32 ) latent = true_dist . sample () . numpy () _y = np . reshape ( latent , [ latent_size , 1 ]) _y = f_sig ( K = _y ) _y = mix_mat @ _y _y = _y . T yield _input , _y iter_ix += 1 ds = tf . data . Dataset . from_generator ( gen_ds , args = [ 1e2 ], output_types = ( tf . float32 , tf . float32 ), output_shapes = (( LATENT_SIZE ,), ( N_TIMES , N_SENSORS ))) ds = ds . map ( lambda x , y : ( x , ( tf . zeros ( 0 , dtype = tf . float32 ), y ))) . batch ( BATCH_SIZE ) # Train the model. # Try playing around with the 2nd loss_weights (below) and KL_WEIGHT (above). N_EPOCHS = 100 K . clear_session () prior = make_mvn_prior ( LATENT_SIZE , trainable_mean = True , trainable_var = True , offdiag = False ) model_ = make_model ( prior ) model_ . compile ( optimizer = 'adam' , loss = [ lambda _ , model_latent : tfd . kl_divergence ( model_latent , prior ), lambda y_true , model_out : - model_out . log_prob ( y_true )], loss_weights = [ 0.0 , 1.0 ]) hist = model_ . fit ( ds , epochs = N_EPOCHS , verbose = 2 ) Epoch 1/100 17/17 - 0s - loss: 91.9389 - q_latent_loss: 4.6523 - p_out_loss: 90.5613 Epoch 2/100 17/17 - 0s - loss: 11531.2471 - q_latent_loss: 4.3536 - p_out_loss: 11529.9590 Epoch 3/100 17/17 - 0s - loss: 743.5315 - q_latent_loss: 4.1376 - p_out_loss: 742.3065 Epoch 4/100 17/17 - 0s - loss: 137048.2969 - q_latent_loss: 3.9767 - p_out_loss: 137047.1250 Epoch 5/100 17/17 - 0s - loss: 113.2025 - q_latent_loss: 3.8272 - p_out_loss: 112.0695 Epoch 6/100 17/17 - 0s - loss: 74.9116 - q_latent_loss: 3.7352 - p_out_loss: 73.8058 Epoch 7/100 17/17 - 0s - loss: 79.9207 - q_latent_loss: 3.6573 - p_out_loss: 78.8380 Epoch 8/100 17/17 - 0s - loss: 372.0323 - q_latent_loss: 3.5850 - p_out_loss: 370.9711 Epoch 9/100 17/17 - 0s - loss: 60.3690 - q_latent_loss: 3.5167 - p_out_loss: 59.3279 Epoch 10/100 17/17 - 0s - loss: 7418.3252 - q_latent_loss: 3.4512 - p_out_loss: 7417.3027 Epoch 11/100 17/17 - 0s - loss: 3513.5659 - q_latent_loss: 3.3824 - p_out_loss: 3512.5649 Epoch 12/100 17/17 - 0s - loss: 53.7796 - q_latent_loss: 3.3220 - p_out_loss: 52.7962 Epoch 13/100 17/17 - 0s - loss: 20.4849 - q_latent_loss: 3.2672 - p_out_loss: 19.5177 Epoch 14/100 17/17 - 0s - loss: 1562.3738 - q_latent_loss: 3.2157 - p_out_loss: 1561.4218 Epoch 15/100 17/17 - 0s - loss: 963.6710 - q_latent_loss: 3.1652 - p_out_loss: 962.7339 Epoch 16/100 17/17 - 0s - loss: 2838.6292 - q_latent_loss: 3.1165 - p_out_loss: 2837.7068 Epoch 17/100 17/17 - 0s - loss: 35.5000 - q_latent_loss: 3.0708 - p_out_loss: 34.5910 Epoch 18/100 17/17 - 0s - loss: 706.3328 - q_latent_loss: 3.0287 - p_out_loss: 705.4363 Epoch 19/100 17/17 - 0s - loss: 52.2510 - q_latent_loss: 2.9887 - p_out_loss: 51.3663 Epoch 20/100 17/17 - 0s - loss: 7950.6792 - q_latent_loss: 2.9512 - p_out_loss: 7949.8062 Epoch 21/100 17/17 - 0s - loss: 190.5290 - q_latent_loss: 2.9112 - p_out_loss: 189.6672 Epoch 22/100 17/17 - 0s - loss: 27.1404 - q_latent_loss: 2.8756 - p_out_loss: 26.2891 Epoch 23/100 17/17 - 0s - loss: 222.1122 - q_latent_loss: 2.8434 - p_out_loss: 221.2705 Epoch 24/100 17/17 - 0s - loss: 26.6817 - q_latent_loss: 2.8132 - p_out_loss: 25.8489 Epoch 25/100 17/17 - 0s - loss: 301.0465 - q_latent_loss: 2.7844 - p_out_loss: 300.2223 Epoch 26/100 17/17 - 0s - loss: 17.3472 - q_latent_loss: 2.7568 - p_out_loss: 16.5312 Epoch 27/100 17/17 - 0s - loss: 47.1069 - q_latent_loss: 2.7306 - p_out_loss: 46.2986 Epoch 28/100 17/17 - 0s - loss: 34.0318 - q_latent_loss: 2.7057 - p_out_loss: 33.2309 Epoch 29/100 17/17 - 0s - loss: 25.4790 - q_latent_loss: 2.6819 - p_out_loss: 24.6851 Epoch 30/100 17/17 - 0s - loss: 35.2237 - q_latent_loss: 2.6592 - p_out_loss: 34.4365 Epoch 31/100 17/17 - 0s - loss: 17.7497 - q_latent_loss: 2.6375 - p_out_loss: 16.9690 Epoch 32/100 17/17 - 0s - loss: 19.0096 - q_latent_loss: 2.6168 - p_out_loss: 18.2350 Epoch 33/100 17/17 - 0s - loss: 17.3889 - q_latent_loss: 2.5969 - p_out_loss: 16.6202 Epoch 34/100 17/17 - 0s - loss: 3164.2163 - q_latent_loss: 2.5783 - p_out_loss: 3163.4539 Epoch 35/100 17/17 - 0s - loss: 318.1325 - q_latent_loss: 2.5614 - p_out_loss: 317.3743 Epoch 36/100 17/17 - 0s - loss: 496.7764 - q_latent_loss: 2.5442 - p_out_loss: 496.0233 Epoch 37/100 17/17 - 0s - loss: 43.8554 - q_latent_loss: 2.5274 - p_out_loss: 43.1073 Epoch 38/100 17/17 - 0s - loss: 127.4449 - q_latent_loss: 2.5114 - p_out_loss: 126.7015 Epoch 39/100 17/17 - 0s - loss: 34.3881 - q_latent_loss: 2.4962 - p_out_loss: 33.6492 Epoch 40/100 17/17 - 0s - loss: 92.4194 - q_latent_loss: 2.4816 - p_out_loss: 91.6848 Epoch 41/100 17/17 - 0s - loss: 2711.8994 - q_latent_loss: 2.4669 - p_out_loss: 2711.1697 Epoch 42/100 17/17 - 0s - loss: 32.7170 - q_latent_loss: 2.4484 - p_out_loss: 31.9922 Epoch 43/100 17/17 - 0s - loss: 368.3795 - q_latent_loss: 2.4338 - p_out_loss: 367.6590 Epoch 44/100 17/17 - 0s - loss: 185.1732 - q_latent_loss: 2.4207 - p_out_loss: 184.4566 Epoch 45/100 17/17 - 0s - loss: 1496.3325 - q_latent_loss: 2.4090 - p_out_loss: 1495.6195 Epoch 46/100 17/17 - 0s - loss: 40.2950 - q_latent_loss: 2.3979 - p_out_loss: 39.5852 Epoch 47/100 17/17 - 0s - loss: 3341.2693 - q_latent_loss: 2.3869 - p_out_loss: 3340.5627 Epoch 48/100 17/17 - 0s - loss: 317.7818 - q_latent_loss: 2.3705 - p_out_loss: 317.0801 Epoch 49/100 17/17 - 0s - loss: 129.0085 - q_latent_loss: 2.3577 - p_out_loss: 128.3107 Epoch 50/100 17/17 - 0s - loss: 677.0181 - q_latent_loss: 2.3475 - p_out_loss: 676.3232 Epoch 51/100 17/17 - 0s - loss: 44.6301 - q_latent_loss: 2.3379 - p_out_loss: 43.9381 Epoch 52/100 17/17 - 0s - loss: 13.6527 - q_latent_loss: 2.3290 - p_out_loss: 12.9633 Epoch 53/100 17/17 - 0s - loss: 2174.0337 - q_latent_loss: 2.3206 - p_out_loss: 2173.3469 Epoch 54/100 17/17 - 0s - loss: 85.2265 - q_latent_loss: 2.3118 - p_out_loss: 84.5422 Epoch 55/100 17/17 - 0s - loss: 13.3743 - q_latent_loss: 2.3037 - p_out_loss: 12.6924 Epoch 56/100 17/17 - 0s - loss: 46996.4805 - q_latent_loss: 2.2929 - p_out_loss: 46995.8008 Epoch 57/100 17/17 - 0s - loss: 23.0730 - q_latent_loss: 2.2527 - p_out_loss: 22.4061 Epoch 58/100 17/17 - 0s - loss: 11.3692 - q_latent_loss: 2.2361 - p_out_loss: 10.7074 Epoch 59/100 17/17 - 0s - loss: 25.0329 - q_latent_loss: 2.2285 - p_out_loss: 24.3733 Epoch 60/100 17/17 - 0s - loss: 17.7706 - q_latent_loss: 2.2227 - p_out_loss: 17.1126 Epoch 61/100 17/17 - 0s - loss: 10.4981 - q_latent_loss: 2.2176 - p_out_loss: 9.8417 Epoch 62/100 17/17 - 0s - loss: 32.7279 - q_latent_loss: 2.2127 - p_out_loss: 32.0729 Epoch 63/100 17/17 - 0s - loss: 30.3548 - q_latent_loss: 2.2081 - p_out_loss: 29.7012 Epoch 64/100 17/17 - 0s - loss: 30.8280 - q_latent_loss: 2.2037 - p_out_loss: 30.1757 Epoch 65/100 17/17 - 0s - loss: 41.9700 - q_latent_loss: 2.1996 - p_out_loss: 41.3189 Epoch 66/100 17/17 - 0s - loss: 54.7435 - q_latent_loss: 2.1956 - p_out_loss: 54.0936 Epoch 67/100 17/17 - 0s - loss: 43.0750 - q_latent_loss: 2.1918 - p_out_loss: 42.4262 Epoch 68/100 17/17 - 0s - loss: 243.1561 - q_latent_loss: 2.1882 - p_out_loss: 242.5083 Epoch 69/100 17/17 - 0s - loss: 22.0350 - q_latent_loss: 2.1842 - p_out_loss: 21.3885 Epoch 70/100 17/17 - 0s - loss: 99.8952 - q_latent_loss: 2.1805 - p_out_loss: 99.2498 Epoch 71/100 17/17 - 0s - loss: 31.7489 - q_latent_loss: 2.1772 - p_out_loss: 31.1044 Epoch 72/100 17/17 - 0s - loss: 10.3156 - q_latent_loss: 2.1741 - p_out_loss: 9.6721 Epoch 73/100 17/17 - 0s - loss: 10.8083 - q_latent_loss: 2.1710 - p_out_loss: 10.1656 Epoch 74/100 17/17 - 0s - loss: 149.1215 - q_latent_loss: 2.1682 - p_out_loss: 148.4797 Epoch 75/100 17/17 - 0s - loss: 11.4474 - q_latent_loss: 2.1655 - p_out_loss: 10.8064 Epoch 76/100 17/17 - 0s - loss: 11.3532 - q_latent_loss: 2.1629 - p_out_loss: 10.7130 Epoch 77/100 17/17 - 0s - loss: 9.8263 - q_latent_loss: 2.1603 - p_out_loss: 9.1868 Epoch 78/100 17/17 - 0s - loss: 12.8481 - q_latent_loss: 2.1578 - p_out_loss: 12.2094 Epoch 79/100 17/17 - 0s - loss: 10.0819 - q_latent_loss: 2.1554 - p_out_loss: 9.4439 Epoch 80/100 17/17 - 0s - loss: 9.9589 - q_latent_loss: 2.1531 - p_out_loss: 9.3216 Epoch 81/100 17/17 - 0s - loss: 148.1879 - q_latent_loss: 2.1508 - p_out_loss: 147.5513 Epoch 82/100 17/17 - 0s - loss: 13.6919 - q_latent_loss: 2.1483 - p_out_loss: 13.0560 Epoch 83/100 17/17 - 0s - loss: 11.4130 - q_latent_loss: 2.1462 - p_out_loss: 10.7777 Epoch 84/100 17/17 - 0s - loss: 62.1876 - q_latent_loss: 2.1442 - p_out_loss: 61.5529 Epoch 85/100 17/17 - 0s - loss: 37.1363 - q_latent_loss: 2.1424 - p_out_loss: 36.5021 Epoch 86/100 17/17 - 0s - loss: 9.0239 - q_latent_loss: 2.1406 - p_out_loss: 8.3903 Epoch 87/100 17/17 - 0s - loss: 9.6573 - q_latent_loss: 2.1389 - p_out_loss: 9.0242 Epoch 88/100 17/17 - 0s - loss: 16.5087 - q_latent_loss: 2.1371 - p_out_loss: 15.8761 Epoch 89/100 17/17 - 0s - loss: 9.0933 - q_latent_loss: 2.1355 - p_out_loss: 8.4612 Epoch 90/100 17/17 - 0s - loss: 11.1045 - q_latent_loss: 2.1339 - p_out_loss: 10.4729 Epoch 91/100 17/17 - 0s - loss: 14.6627 - q_latent_loss: 2.1323 - p_out_loss: 14.0315 Epoch 92/100 17/17 - 0s - loss: 12.7246 - q_latent_loss: 2.1308 - p_out_loss: 12.0939 Epoch 93/100 17/17 - 0s - loss: 18.2482 - q_latent_loss: 2.1294 - p_out_loss: 17.6179 Epoch 94/100 17/17 - 0s - loss: 12.0889 - q_latent_loss: 2.1280 - p_out_loss: 11.4590 Epoch 95/100 17/17 - 0s - loss: 35.7015 - q_latent_loss: 2.1267 - p_out_loss: 35.0720 Epoch 96/100 17/17 - 0s - loss: 156.0881 - q_latent_loss: 2.1253 - p_out_loss: 155.4590 Epoch 97/100 17/17 - 0s - loss: 8.8568 - q_latent_loss: 2.1240 - p_out_loss: 8.2280 Epoch 98/100 17/17 - 0s - loss: 10.9563 - q_latent_loss: 2.1228 - p_out_loss: 10.3279 Epoch 99/100 17/17 - 0s - loss: 10.1586 - q_latent_loss: 2.1217 - p_out_loss: 9.5306 Epoch 100/100 17/17 - 0s - loss: 14.0194 - q_latent_loss: 2.1206 - p_out_loss: 13.3917 lat_wts = model_ . get_layer ( \"latent_loc\" ) . weights lat_locs = np . ones (( 1 , LATENT_SIZE )) @ lat_wts [ 0 ] . numpy () + lat_wts [ 1 ] . numpy () mix_wts = model_ . get_layer ( \"out_loc\" ) . weights model_out = lat_locs @ mix_wts [ 0 ] . numpy () + mix_wts [ 1 ] . numpy () true_out = mix_mat @ true_dist . mean () . numpy () print ( f \"Model est lat: { lat_locs } \" ) print ( f \"Model est out: { model_out } \" ) print ( f \"prior mean: { prior . mean () . numpy () } \" ) print ( f \"true lat: { true_dist . mean () . numpy () } \" ) print ( f \"true out: { true_out . T } \" ) Model est lat: [[ 0.51195845 -1.02728739 0.67845761 -0.11073773]] Model est out: [[ 0.10048061 1.36010552 0.30864524 -0.09840383 1.17217551 -0.67099368 0.95406085 0.03414997]] prior mean: [ 0.5117957 -0.8991166 0.66152537 -0.11197621] true lat: [-1. 1. 5. -5.] true out: [ 0.12000006 2.4699998 -2.76 -2.5 1.53 -1.3 1.31 0.05999994] # test LearnableMultivariateNormalDiag prior_factory = LearnableMultivariateNormalDiag ( LATENT_SIZE ) learnable_prior = prior_factory () sample = learnable_prior . sample (( 100 , 64 )) print ( sample . shape ) print ( learnable_prior . trainable_variables ) (100, 64, 4) (<tf.Variable 'learnable_multivariate_normal_diag_2/mean:0' shape=(4,) dtype=float32, numpy=array([ 0.16748714, -0.1799583 , 0.0387747 , 0.11378615], dtype=float32)>, <tf.Variable 'learnable_multivariate_normal_diag_2/transformed_scale:0' shape=(4,) dtype=float32, numpy=array([-0.11407143, 0.06062925, 0.02439827, -0.01735771], dtype=float32)>) K . clear_session () model_ = make_model ( learnable_prior ) model_ . compile ( optimizer = 'adam' , loss = [ lambda _ , model_latent : tfd . kl_divergence ( model_latent , learnable_prior ), lambda y_true , model_out : - model_out . log_prob ( y_true )], loss_weights = [ 0.0 , 1.0 ]) print ( learnable_prior . trainable_variables ) print ([ _ . name for _ in model_ . trainable_variables ]) hist = model_ . fit ( ds , epochs = N_EPOCHS , verbose = 2 ) lat_wts = model_ . get_layer ( \"latent_loc\" ) . weights lat_locs = np . ones (( 1 , LATENT_SIZE )) @ lat_wts [ 0 ] . numpy () + lat_wts [ 1 ] . numpy () mix_wts = model_ . get_layer ( \"out_loc\" ) . weights model_out = lat_locs @ mix_wts [ 0 ] . numpy () + mix_wts [ 1 ] . numpy () true_out = mix_mat @ true_dist . mean () . numpy () print ( f \"Model est lat: { lat_locs } \" ) print ( f \"Model est out: { model_out } \" ) print ( f \"prior mean: { learnable_prior . mean () . numpy () } \" ) print ( f \"true lat: { true_dist . mean () . numpy () } \" ) print ( f \"true out: { true_out . T } \" ) (<tf.Variable 'learnable_multivariate_normal_diag_2/mean:0' shape=(4,) dtype=float32, numpy=array([ 0.16748714, -0.1799583 , 0.0387747 , 0.11378615], dtype=float32)>, <tf.Variable 'learnable_multivariate_normal_diag_2/transformed_scale:0' shape=(4,) dtype=float32, numpy=array([-0.11407143, 0.06062925, 0.02439827, -0.01735771], dtype=float32)>) ['dense/kernel:0', 'dense/bias:0', 'latent_loc/kernel:0', 'latent_loc/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'out_loc/kernel:0', 'out_loc/bias:0', 'learnable_multivariate_normal_diag_2/mean:0', 'learnable_multivariate_normal_diag_2/transformed_scale:0'] Epoch 1/100 17/17 - 0s - loss: 266.6295 - q_latent_loss: 6.5640 - p_out_loss: 264.6859 Epoch 2/100 17/17 - 0s - loss: 2032.0966 - q_latent_loss: 6.2853 - p_out_loss: 2030.2358 Epoch 3/100 17/17 - 0s - loss: 83.5799 - q_latent_loss: 6.0718 - p_out_loss: 81.7824 Epoch 4/100 17/17 - 0s - loss: 82.7522 - q_latent_loss: 5.8942 - p_out_loss: 81.0072 Epoch 5/100 17/17 - 0s - loss: 59.2224 - q_latent_loss: 5.7269 - p_out_loss: 57.5269 Epoch 6/100 17/17 - 0s - loss: 38.8948 - q_latent_loss: 5.5706 - p_out_loss: 37.2456 Epoch 7/100 17/17 - 0s - loss: 47.8537 - q_latent_loss: 5.4227 - p_out_loss: 46.2483 Epoch 8/100 17/17 - 0s - loss: 60.9186 - q_latent_loss: 5.2828 - p_out_loss: 59.3546 Epoch 9/100 17/17 - 0s - loss: 80.7008 - q_latent_loss: 5.1479 - p_out_loss: 79.1768 Epoch 10/100 17/17 - 0s - loss: 29.5548 - q_latent_loss: 5.0204 - p_out_loss: 28.0686 Epoch 11/100 17/17 - 0s - loss: 100.5337 - q_latent_loss: 4.9013 - p_out_loss: 99.0827 Epoch 12/100 17/17 - 0s - loss: 208.5356 - q_latent_loss: 4.7856 - p_out_loss: 207.1189 Epoch 13/100 17/17 - 0s - loss: 47.4895 - q_latent_loss: 4.6692 - p_out_loss: 46.1072 Epoch 14/100 17/17 - 0s - loss: 51.8070 - q_latent_loss: 4.5624 - p_out_loss: 50.4563 Epoch 15/100 17/17 - 0s - loss: 49.2825 - q_latent_loss: 4.4640 - p_out_loss: 47.9610 Epoch 16/100 17/17 - 0s - loss: 63.7341 - q_latent_loss: 4.3716 - p_out_loss: 62.4399 Epoch 17/100 17/17 - 0s - loss: 35.2299 - q_latent_loss: 4.2837 - p_out_loss: 33.9617 Epoch 18/100 17/17 - 0s - loss: 45.8432 - q_latent_loss: 4.2006 - p_out_loss: 44.5997 Epoch 19/100 17/17 - 0s - loss: 25.7876 - q_latent_loss: 4.1215 - p_out_loss: 24.5675 Epoch 20/100 17/17 - 0s - loss: 268.8558 - q_latent_loss: 4.0396 - p_out_loss: 267.6599 Epoch 21/100 17/17 - 0s - loss: 45.2869 - q_latent_loss: 3.9513 - p_out_loss: 44.1171 Epoch 22/100 17/17 - 0s - loss: 30.1766 - q_latent_loss: 3.8787 - p_out_loss: 29.0284 Epoch 23/100 17/17 - 0s - loss: 32.2969 - q_latent_loss: 3.8108 - p_out_loss: 31.1688 Epoch 24/100 17/17 - 0s - loss: 64.0437 - q_latent_loss: 3.7457 - p_out_loss: 62.9348 Epoch 25/100 17/17 - 0s - loss: 39.9464 - q_latent_loss: 3.6825 - p_out_loss: 38.8562 Epoch 26/100 17/17 - 0s - loss: 33.5094 - q_latent_loss: 3.6220 - p_out_loss: 32.4372 Epoch 27/100 17/17 - 0s - loss: 31.4306 - q_latent_loss: 3.5643 - p_out_loss: 30.3755 Epoch 28/100 17/17 - 0s - loss: 27.8061 - q_latent_loss: 3.5087 - p_out_loss: 26.7674 Epoch 29/100 17/17 - 0s - loss: 65.8272 - q_latent_loss: 3.4540 - p_out_loss: 64.8047 Epoch 30/100 17/17 - 0s - loss: 25.9475 - q_latent_loss: 3.4009 - p_out_loss: 24.9408 Epoch 31/100 17/17 - 0s - loss: 30.2780 - q_latent_loss: 3.3515 - p_out_loss: 29.2859 Epoch 32/100 17/17 - 0s - loss: 21.8850 - q_latent_loss: 3.3044 - p_out_loss: 20.9068 Epoch 33/100 17/17 - 0s - loss: 36.6851 - q_latent_loss: 3.2587 - p_out_loss: 35.7204 Epoch 34/100 17/17 - 0s - loss: 25.5569 - q_latent_loss: 3.2120 - p_out_loss: 24.6061 Epoch 35/100 17/17 - 0s - loss: 24.6902 - q_latent_loss: 3.1682 - p_out_loss: 23.7523 Epoch 36/100 17/17 - 0s - loss: 116.0450 - q_latent_loss: 3.1269 - p_out_loss: 115.1194 Epoch 37/100 17/17 - 0s - loss: 20.0418 - q_latent_loss: 3.0908 - p_out_loss: 19.1268 Epoch 38/100 17/17 - 0s - loss: 56.1398 - q_latent_loss: 3.0497 - p_out_loss: 55.2370 Epoch 39/100 17/17 - 0s - loss: 27.5171 - q_latent_loss: 3.0067 - p_out_loss: 26.6270 Epoch 40/100 17/17 - 0s - loss: 20.7006 - q_latent_loss: 2.9684 - p_out_loss: 19.8219 Epoch 41/100 17/17 - 0s - loss: 26.9046 - q_latent_loss: 2.9328 - p_out_loss: 26.0364 Epoch 42/100 17/17 - 0s - loss: 18.7693 - q_latent_loss: 2.8996 - p_out_loss: 17.9110 Epoch 43/100 17/17 - 0s - loss: 22.3650 - q_latent_loss: 2.8670 - p_out_loss: 21.5163 Epoch 44/100 17/17 - 0s - loss: 32.9155 - q_latent_loss: 2.8352 - p_out_loss: 32.0763 Epoch 45/100 17/17 - 0s - loss: 19.9130 - q_latent_loss: 2.8037 - p_out_loss: 19.0830 Epoch 46/100 17/17 - 0s - loss: 19.9001 - q_latent_loss: 2.7740 - p_out_loss: 19.0789 Epoch 47/100 17/17 - 0s - loss: 25.4838 - q_latent_loss: 2.7436 - p_out_loss: 24.6716 Epoch 48/100 17/17 - 0s - loss: 23.9622 - q_latent_loss: 2.7135 - p_out_loss: 23.1589 Epoch 49/100 17/17 - 0s - loss: 20.7703 - q_latent_loss: 2.6849 - p_out_loss: 19.9756 Epoch 50/100 17/17 - 0s - loss: 19.6302 - q_latent_loss: 2.6576 - p_out_loss: 18.8435 Epoch 51/100 17/17 - 0s - loss: 18.7125 - q_latent_loss: 2.6321 - p_out_loss: 17.9334 Epoch 52/100 17/17 - 0s - loss: 21.4065 - q_latent_loss: 2.6073 - p_out_loss: 20.6347 Epoch 53/100 17/17 - 0s - loss: 37.3685 - q_latent_loss: 2.5831 - p_out_loss: 36.6039 Epoch 54/100 17/17 - 0s - loss: 15.8975 - q_latent_loss: 2.5606 - p_out_loss: 15.1395 Epoch 55/100 17/17 - 0s - loss: 15.6574 - q_latent_loss: 2.5387 - p_out_loss: 14.9059 Epoch 56/100 17/17 - 0s - loss: 28.7901 - q_latent_loss: 2.5174 - p_out_loss: 28.0449 Epoch 57/100 17/17 - 0s - loss: 99.3240 - q_latent_loss: 2.4972 - p_out_loss: 98.5848 Epoch 58/100 17/17 - 0s - loss: 19.6783 - q_latent_loss: 2.4761 - p_out_loss: 18.9453 Epoch 59/100 17/17 - 0s - loss: 18.9958 - q_latent_loss: 2.4563 - p_out_loss: 18.2688 Epoch 60/100 17/17 - 0s - loss: 21.3663 - q_latent_loss: 2.4364 - p_out_loss: 20.6451 Epoch 61/100 17/17 - 0s - loss: 26.8008 - q_latent_loss: 2.4179 - p_out_loss: 26.0850 Epoch 62/100 17/17 - 0s - loss: 13.9355 - q_latent_loss: 2.3984 - p_out_loss: 13.2256 Epoch 63/100 17/17 - 0s - loss: 14.0786 - q_latent_loss: 2.3803 - p_out_loss: 13.3740 Epoch 64/100 17/17 - 0s - loss: 20.6991 - q_latent_loss: 2.3634 - p_out_loss: 19.9995 Epoch 65/100 17/17 - 0s - loss: 33.9438 - q_latent_loss: 2.3476 - p_out_loss: 33.2488 Epoch 66/100 17/17 - 0s - loss: 19.5023 - q_latent_loss: 2.3325 - p_out_loss: 18.8118 Epoch 67/100 17/17 - 0s - loss: 16.1214 - q_latent_loss: 2.3179 - p_out_loss: 15.4353 Epoch 68/100 17/17 - 0s - loss: 33.3983 - q_latent_loss: 2.3044 - p_out_loss: 32.7162 Epoch 69/100 17/17 - 0s - loss: 14.1833 - q_latent_loss: 2.2933 - p_out_loss: 13.5045 Epoch 70/100 17/17 - 0s - loss: 33.0913 - q_latent_loss: 2.2802 - p_out_loss: 32.4163 Epoch 71/100 17/17 - 0s - loss: 15.5565 - q_latent_loss: 2.2661 - p_out_loss: 14.8857 Epoch 72/100 17/17 - 0s - loss: 23.7552 - q_latent_loss: 2.2522 - p_out_loss: 23.0885 Epoch 73/100 17/17 - 0s - loss: 15.8186 - q_latent_loss: 2.2402 - p_out_loss: 15.1554 Epoch 74/100 17/17 - 0s - loss: 15.8109 - q_latent_loss: 2.2277 - p_out_loss: 15.1514 Epoch 75/100 17/17 - 0s - loss: 23.2216 - q_latent_loss: 2.2153 - p_out_loss: 22.5659 Epoch 76/100 17/17 - 0s - loss: 17.1244 - q_latent_loss: 2.2021 - p_out_loss: 16.4725 Epoch 77/100 17/17 - 0s - loss: 20.2818 - q_latent_loss: 2.1875 - p_out_loss: 19.6343 Epoch 78/100 17/17 - 0s - loss: 20.1146 - q_latent_loss: 2.1751 - p_out_loss: 19.4708 Epoch 79/100 17/17 - 0s - loss: 12.0626 - q_latent_loss: 2.1647 - p_out_loss: 11.4218 Epoch 80/100 17/17 - 0s - loss: 17.5959 - q_latent_loss: 2.1547 - p_out_loss: 16.9580 Epoch 81/100 17/17 - 0s - loss: 46.9798 - q_latent_loss: 2.1428 - p_out_loss: 46.3454 Epoch 82/100 17/17 - 0s - loss: 20.0080 - q_latent_loss: 2.1244 - p_out_loss: 19.3792 Epoch 83/100 17/17 - 0s - loss: 11.8902 - q_latent_loss: 2.1120 - p_out_loss: 11.2651 Epoch 84/100 17/17 - 0s - loss: 17.5359 - q_latent_loss: 2.1015 - p_out_loss: 16.9139 Epoch 85/100 17/17 - 0s - loss: 14.8084 - q_latent_loss: 2.0917 - p_out_loss: 14.1892 Epoch 86/100 17/17 - 0s - loss: 9.6016 - q_latent_loss: 2.0823 - p_out_loss: 8.9852 Epoch 87/100 17/17 - 0s - loss: 13.4432 - q_latent_loss: 2.0736 - p_out_loss: 12.8294 Epoch 88/100 17/17 - 0s - loss: 16.5978 - q_latent_loss: 2.0652 - p_out_loss: 15.9865 Epoch 89/100 17/17 - 0s - loss: 21.3484 - q_latent_loss: 2.0557 - p_out_loss: 20.7399 Epoch 90/100 17/17 - 0s - loss: 11.3400 - q_latent_loss: 2.0439 - p_out_loss: 10.7350 Epoch 91/100 17/17 - 0s - loss: 14.2551 - q_latent_loss: 2.0345 - p_out_loss: 13.6529 Epoch 92/100 17/17 - 0s - loss: 14.2384 - q_latent_loss: 2.0268 - p_out_loss: 13.6385 Epoch 93/100 17/17 - 0s - loss: 16.3489 - q_latent_loss: 2.0194 - p_out_loss: 15.7511 Epoch 94/100 17/17 - 0s - loss: 14.2265 - q_latent_loss: 2.0118 - p_out_loss: 13.6310 Epoch 95/100 17/17 - 0s - loss: 11.5992 - q_latent_loss: 2.0041 - p_out_loss: 11.0060 Epoch 96/100 17/17 - 0s - loss: 11.7333 - q_latent_loss: 1.9971 - p_out_loss: 11.1421 Epoch 97/100 17/17 - 0s - loss: 12.1329 - q_latent_loss: 1.9904 - p_out_loss: 11.5438 Epoch 98/100 17/17 - 0s - loss: 13.7211 - q_latent_loss: 1.9832 - p_out_loss: 13.1341 Epoch 99/100 17/17 - 0s - loss: 37.2112 - q_latent_loss: 1.9745 - p_out_loss: 36.6267 Epoch 100/100 17/17 - 0s - loss: 9.3972 - q_latent_loss: 1.9630 - p_out_loss: 8.8161 Model est lat: [[ 2.51292503 -1.26424221 -1.11180196 -0.02588509]] Model est out: [[-0.27425705 2.39304429 -2.49596335 0.29950965 1.37276651 -0.43098222 -0.45473986 0.07839915]] prior mean: [ 1.3514248 -1.2266612 -0.8751619 -0.03475915] true lat: [-1. 1. 5. -5.] true out: [ 0.12000006 2.4699998 -2.76 -2.5 1.53 -1.3 1.31 0.05999994] Latent Dynamic Factor # Return 3 outputs, the first 2 are null #ds_dyn = ds.map(lambda x, y: (x, (y[0], y[0], y[1]))) ds_dyn = ds . map ( lambda x , y : ( x , y [ 1 ])) KL_WEIGHT = 0.001 LATENT_SIZE_DYNAMIC = 1 # Integer dimensionality of each dynamic, time-variant latent variable `z_t`. K . clear_session () tmp = LearnableMultivariateNormalDiagCell ( 3 , 4 ) #tmp.build((None, 10, 5)) #tmp.summary() # test DynamicEncoder and LearnableMultivariateNormalDiagCell K . clear_session () dynamic_encoder = DynamicEncoder ( N_HIDDEN , N_TIMES , LATENT_SIZE_DYNAMIC ) sample , dynamic_prior = dynamic_encoder . sample_dynamic_prior ( N_TIMES , samples = N_SAMPLES , batches = 1 ) print ( sample . shape ) print ( \"mean:\" , np . squeeze ( dynamic_prior . mean ())) print ( \"stddev:\" , np . squeeze ( dynamic_prior . stddev ())) print ([ _ . name for _ in dynamic_encoder . trainable_variables ]) (2, 1, 10, 1) mean: [[ 0. 0.42388976 0.45631832 0.365768 0.20130846 0.37873474 0.31262326 0.26073667 0.15399611 0.14049806] [ 0. 0.08804662 0.0361465 -0.03267653 -0.08733355 0.19941618 0.30335566 0.3730844 0.2744042 0.17948757]] stddev: [[1.00001 0.929902 0.9554563 0.99371654 1.0142238 0.97018814 1.0006421 1.0033575 1.0105829 1.0065393 ] [1.00001 0.9952911 1.0008274 1.0000954 0.99874425 0.98230976 0.9771384 0.9683764 1.000174 1.0049998 ]] ['learnable_multivariate_normal_diag_cell/mvndiagcell_lstm/kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_lstm/recurrent_kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_lstm/bias:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_loc/kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_loc/bias:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_scale/kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_scale/bias:0'] K . clear_session () f_model = FactorizedAutoEncoder ( N_HIDDEN , N_TIMES , LATENT_SIZE , LATENT_SIZE_DYNAMIC , N_SENSORS ) # Most of the trainable variables don't present themselves until the model pieces are called. print ([ _ . name for _ in f_model . static_encoder . trainable_variables ]) print ([ _ . name for _ in f_model . dynamic_encoder . trainable_variables ]) print ([ _ . name for _ in f_model . decoder . trainable_variables ]) [] ['learnable_multivariate_normal_diag/mean:0', 'learnable_multivariate_normal_diag/untransformed_stddev:0'] [] [] N_EPOCHS = 200 if False : f_model . compile ( optimizer = 'adam' , loss = lambda y_true , model_out : - model_out . log_prob ( y_true )) hist = f_model . fit ( ds_dyn , epochs = N_EPOCHS , verbose = 2 ) else : @tf . function def grad ( model , inputs , preds ): with tf . GradientTape () as tape : q_f = model . static_encoder ( inputs ) q_z = model . dynamic_encoder ( inputs ) p_full = model . decoder ([ tf . convert_to_tensor ( q_f ), tf . convert_to_tensor ( q_z )]) # Reconstruction log-likelihood: p(output|input) recon_post_log_prob = p_full . log_prob ( preds ) recon_post_log_prob = tf . reduce_sum ( recon_post_log_prob , axis =- 1 ) # Sum over time axis recon_post_log_prob = tf . reduce_mean ( recon_post_log_prob ) # KL Divergence - analytical # Static static_prior = model . static_encoder . static_prior_factory () stat_kl = tfd . kl_divergence ( q_f , static_prior ) stat_kl = KL_WEIGHT * stat_kl stat_kl = tf . reduce_mean ( stat_kl ) # Dynamic _ , dynamic_prior = model . dynamic_encoder . sample_dynamic_prior ( N_TIMES , samples = 1 , batches = 1 ) dyn_kl = tfd . kl_divergence ( q_z , dynamic_prior ) dyn_kl = tf . reduce_sum ( dyn_kl , axis =- 1 ) dyn_kl = tf . squeeze ( dyn_kl ) dyn_kl = KL_WEIGHT * dyn_kl dyn_kl = tf . reduce_mean ( dyn_kl ) loss = - recon_post_log_prob + stat_kl + dyn_kl grads = tape . gradient ( loss , model . trainable_variables ) return loss , grads , ( - recon_post_log_prob , stat_kl , dyn_kl ) optim = tf . keras . optimizers . Adam ( learning_rate = 1e-3 ) for epoch_ix in range ( N_EPOCHS ): for step_ix , batch in enumerate ( ds_dyn ): inputs , preds = batch loss , grads , loss_comps = grad ( f_model , inputs , preds ) optim . apply_gradients ( zip ( grads , f_model . trainable_variables )) if ( step_ix % 200 ) == 0 : print ( '.' ) print ( f \"Epoch { epoch_ix } / { N_EPOCHS } : \\t loss= { loss : .3f } ; \" f \"Losses: { [ _ . numpy () for _ in loss_comps ] } \" ) . Epoch 0/200: loss=3777.438; Losses: [3777.3972, 0.0028260916, 0.03819199] . Epoch 1/200: loss=908.620; Losses: [908.5834, 0.002681077, 0.034407526] . Epoch 2/200: loss=682.733; Losses: [682.7001, 0.0025911012, 0.030505255] . Epoch 3/200: loss=317.985; Losses: [317.9555, 0.0024803109, 0.027142774] . Epoch 4/200: loss=737.753; Losses: [737.7305, 0.0024128703, 0.019867169] . Epoch 5/200: loss=293.983; Losses: [293.9585, 0.0023704215, 0.022514882] . Epoch 6/200: loss=412.075; Losses: [412.0592, 0.002335041, 0.013460781] . Epoch 7/200: loss=306.618; Losses: [306.60327, 0.002284743, 0.012861049] . Epoch 8/200: loss=215.916; Losses: [215.9029, 0.0022479186, 0.0111077] . Epoch 9/200: loss=223.136; Losses: [223.12366, 0.0022122823, 0.010420884] . Epoch 10/200: loss=300.156; Losses: [300.14383, 0.0021807426, 0.009667382] . Epoch 11/200: loss=179.766; Losses: [179.75607, 0.0021481065, 0.007676568] . Epoch 12/200: loss=215.981; Losses: [215.97124, 0.0021149626, 0.008112778] . Epoch 13/200: loss=208.054; Losses: [208.04565, 0.0020882282, 0.006530414] . Epoch 14/200: loss=207.146; Losses: [207.13806, 0.0020594192, 0.0063194335] . Epoch 15/200: loss=261.805; Losses: [261.7982, 0.0020306753, 0.0045144106] . Epoch 16/200: loss=178.393; Losses: [178.38637, 0.0020005947, 0.0045015276] . Epoch 17/200: loss=284.872; Losses: [284.86642, 0.0019730518, 0.003997615] . Epoch 18/200: loss=212.054; Losses: [212.04866, 0.0019469936, 0.0034680453] . Epoch 19/200: loss=145.862; Losses: [145.85641, 0.001922644, 0.004011639] . Epoch 20/200: loss=182.153; Losses: [182.14563, 0.0018981744, 0.0059485184] . Epoch 21/200: loss=154.575; Losses: [154.56941, 0.0018728755, 0.0038126395] . Epoch 22/200: loss=214.752; Losses: [214.74734, 0.0018469194, 0.003135754] . Epoch 23/200: loss=179.347; Losses: [179.34248, 0.001825613, 0.0029100403] . Epoch 24/200: loss=354.274; Losses: [354.26898, 0.0018005224, 0.0028155171] . Epoch 25/200: loss=181.006; Losses: [181.0021, 0.0017763268, 0.0022955306] . Epoch 26/200: loss=142.006; Losses: [142.00166, 0.0017520584, 0.0022001117] . Epoch 27/200: loss=158.932; Losses: [158.92723, 0.0017273662, 0.0026816982] . Epoch 28/200: loss=175.159; Losses: [175.15494, 0.0017028436, 0.0019087334] . Epoch 29/200: loss=167.915; Losses: [167.91084, 0.0016797789, 0.002798946] . Epoch 30/200: loss=152.785; Losses: [152.78006, 0.001658167, 0.0029456303] . Epoch 31/200: loss=158.407; Losses: [158.40344, 0.0016350556, 0.0018697139] . Epoch 32/200: loss=151.065; Losses: [151.06094, 0.0016126116, 0.00282249] . Epoch 33/200: loss=181.075; Losses: [181.07072, 0.0015892526, 0.0025259533] . Epoch 34/200: loss=157.210; Losses: [157.20605, 0.0015682159, 0.0026225548] . Epoch 35/200: loss=151.200; Losses: [151.19623, 0.0015464819, 0.0017979483] . Epoch 36/200: loss=157.111; Losses: [157.10796, 0.0015237778, 0.0016808716] . Epoch 37/200: loss=160.398; Losses: [160.39449, 0.0015015532, 0.0018031715] . Epoch 38/200: loss=133.418; Losses: [133.41472, 0.0014805306, 0.0017712188] . Epoch 39/200: loss=161.662; Losses: [161.65845, 0.0014592485, 0.0018676165] . Epoch 40/200: loss=181.789; Losses: [181.78532, 0.0014379938, 0.0023018767] . Epoch 41/200: loss=183.568; Losses: [183.56451, 0.00142015, 0.001671126] . Epoch 42/200: loss=211.679; Losses: [211.67618, 0.0014024411, 0.001817507] . Epoch 43/200: loss=235.384; Losses: [235.38095, 0.0013794828, 0.0018946148] . Epoch 44/200: loss=139.088; Losses: [139.08447, 0.0013571468, 0.0019089653] . Epoch 45/200: loss=160.254; Losses: [160.25092, 0.0013359843, 0.0013933791] . Epoch 46/200: loss=142.206; Losses: [142.20291, 0.0013167453, 0.0014015753] . Epoch 47/200: loss=138.814; Losses: [138.8115, 0.0012925405, 0.0014298331] . Epoch 48/200: loss=130.677; Losses: [130.67343, 0.0012679367, 0.0021604125] . Epoch 49/200: loss=145.296; Losses: [145.29306, 0.0012432866, 0.0013332999] . Epoch 50/200: loss=133.338; Losses: [133.33516, 0.0012180805, 0.0012685797] . Epoch 51/200: loss=138.212; Losses: [138.20908, 0.0011976506, 0.0017989981] . Epoch 52/200: loss=136.139; Losses: [136.13644, 0.0011768966, 0.001470595] . Epoch 53/200: loss=141.839; Losses: [141.83646, 0.0011539405, 0.0017275128] . Epoch 54/200: loss=159.297; Losses: [159.29402, 0.0011311076, 0.0017414299] . Epoch 55/200: loss=125.919; Losses: [125.91669, 0.0011091225, 0.0013509693] . Epoch 56/200: loss=135.710; Losses: [135.7079, 0.0010871431, 0.0010571101] . Epoch 57/200: loss=124.548; Losses: [124.545654, 0.0010660599, 0.0011921946] . Epoch 58/200: loss=128.607; Losses: [128.60472, 0.0010461143, 0.0010578154] . Epoch 59/200: loss=200.879; Losses: [200.87674, 0.0010245068, 0.0014237395] . Epoch 60/200: loss=181.939; Losses: [181.93698, 0.0010024481, 0.0010916217] . Epoch 61/200: loss=161.069; Losses: [161.06737, 0.0009815091, 0.0009930782] . Epoch 62/200: loss=129.661; Losses: [129.65881, 0.0009596758, 0.001090972] . Epoch 63/200: loss=342.733; Losses: [342.73068, 0.000939325, 0.001181667] . Epoch 64/200: loss=160.802; Losses: [160.8003, 0.00091621274, 0.0012079075] . Epoch 65/200: loss=123.200; Losses: [123.19836, 0.00089694076, 0.0009983401] . Epoch 66/200: loss=134.465; Losses: [134.46295, 0.00087896077, 0.0009002821] . Epoch 67/200: loss=205.839; Losses: [205.83714, 0.0008604548, 0.001061962] . Epoch 68/200: loss=144.191; Losses: [144.18906, 0.0008421927, 0.0011492949] . Epoch 69/200: loss=164.397; Losses: [164.39539, 0.0008238552, 0.0010998722] . Epoch 70/200: loss=131.024; Losses: [131.02272, 0.00080561615, 0.000867295] . Epoch 71/200: loss=130.408; Losses: [130.40652, 0.0007878286, 0.0009589862] . Epoch 72/200: loss=120.511; Losses: [120.509705, 0.0007217523, 0.0008722847] . Epoch 73/200: loss=122.388; Losses: [122.38655, 0.00069110864, 0.00080618635] . Epoch 74/200: loss=123.200; Losses: [123.198654, 0.0006731994, 0.0008244566] . Epoch 75/200: loss=117.884; Losses: [117.88217, 0.00065816526, 0.00086460914] . Epoch 76/200: loss=123.508; Losses: [123.50694, 0.0006448629, 0.0008477152] . Epoch 77/200: loss=121.749; Losses: [121.74744, 0.0006321136, 0.0008150753] . Epoch 78/200: loss=145.549; Losses: [145.5473, 0.00061951997, 0.00082959904] . Epoch 79/200: loss=135.341; Losses: [135.33992, 0.00060778105, 0.0007312283] . Epoch 80/200: loss=131.476; Losses: [131.47452, 0.0005965105, 0.0008391714] . Epoch 81/200: loss=123.978; Losses: [123.976944, 0.00058624754, 0.0008059401] . Epoch 82/200: loss=136.084; Losses: [136.08298, 0.0005766748, 0.0007252015] . Epoch 83/200: loss=137.815; Losses: [137.81375, 0.00056776253, 0.0009108439] . Epoch 84/200: loss=116.955; Losses: [116.95401, 0.0005592232, 0.0008040637] . Epoch 85/200: loss=131.525; Losses: [131.52376, 0.00055153086, 0.0007604256] . Epoch 86/200: loss=135.716; Losses: [135.71432, 0.00054452394, 0.0006871256] . Epoch 87/200: loss=191.940; Losses: [191.93927, 0.0005378095, 0.0006448448] . Epoch 88/200: loss=170.746; Losses: [170.74509, 0.00053181086, 0.0006591724] . Epoch 89/200: loss=121.373; Losses: [121.37161, 0.00052640436, 0.00079500565] . Epoch 90/200: loss=126.909; Losses: [126.90761, 0.0005213883, 0.0006021685] . Epoch 91/200: loss=122.121; Losses: [122.120255, 0.0005157513, 0.0006873938] . Epoch 92/200: loss=129.156; Losses: [129.15442, 0.0005111307, 0.00064897194] . Epoch 93/200: loss=113.183; Losses: [113.18219, 0.0005073488, 0.000602577] . Epoch 94/200: loss=146.389; Losses: [146.38794, 0.00050397916, 0.0005585851] . Epoch 95/200: loss=130.446; Losses: [130.44531, 0.0005009744, 0.00056175387] . Epoch 96/200: loss=118.884; Losses: [118.88327, 0.0004950377, 0.0005437781] . Epoch 97/200: loss=114.319; Losses: [114.3183, 0.0004938163, 0.0006134198] . Epoch 98/200: loss=134.747; Losses: [134.74594, 0.0004912615, 0.0005468172] . Epoch 99/200: loss=127.224; Losses: [127.22336, 0.0004886875, 0.00050384714] . Epoch 100/200: loss=123.007; Losses: [123.00618, 0.0004862357, 0.00056520273] . Epoch 101/200: loss=130.374; Losses: [130.3726, 0.0004841056, 0.0005738659] . Epoch 102/200: loss=120.120; Losses: [120.11898, 0.00048118114, 0.00054365897] . Epoch 103/200: loss=107.167; Losses: [107.16606, 0.00047940924, 0.0004886348] . Epoch 104/200: loss=112.270; Losses: [112.268585, 0.00047771176, 0.0004745159] . Epoch 105/200: loss=125.537; Losses: [125.53565, 0.0004758754, 0.00047247266] . Epoch 106/200: loss=109.324; Losses: [109.32308, 0.00047426036, 0.00046340926] . Epoch 107/200: loss=113.328; Losses: [113.327286, 0.0004729222, 0.00046490182] . Epoch 108/200: loss=117.106; Losses: [117.10452, 0.000471713, 0.00062898267] . Epoch 109/200: loss=122.371; Losses: [122.37039, 0.0004705812, 0.00051386596] . Epoch 110/200: loss=119.422; Losses: [119.42122, 0.0004696009, 0.0005573735] . Epoch 111/200: loss=131.784; Losses: [131.78348, 0.000468354, 0.00041559048] . Epoch 112/200: loss=124.476; Losses: [124.475006, 0.00046699354, 0.00041292777] . Epoch 113/200: loss=104.487; Losses: [104.486534, 0.00046530017, 0.00042556314] . Epoch 114/200: loss=119.418; Losses: [119.41684, 0.0004641684, 0.00039730535] . Epoch 115/200: loss=117.776; Losses: [117.77547, 0.00046339296, 0.00056288636] . Epoch 116/200: loss=112.189; Losses: [112.18817, 0.0004628609, 0.00045002214] . Epoch 117/200: loss=116.317; Losses: [116.31613, 0.0004616853, 0.00036934114] . Epoch 118/200: loss=159.105; Losses: [159.10422, 0.00046110825, 0.0003716088] . Epoch 119/200: loss=116.958; Losses: [116.95712, 0.00045984008, 0.0003543413] . Epoch 120/200: loss=108.100; Losses: [108.09944, 0.00045923653, 0.00045118056] . Epoch 121/200: loss=107.565; Losses: [107.56447, 0.00045848632, 0.00033903003] . Epoch 122/200: loss=117.631; Losses: [117.62992, 0.0004574218, 0.00033954927] . Epoch 123/200: loss=116.075; Losses: [116.07385, 0.0004564249, 0.00036835673] . Epoch 124/200: loss=106.798; Losses: [106.79701, 0.0004566427, 0.00032678706] . Epoch 125/200: loss=113.363; Losses: [113.36252, 0.0004562596, 0.00042438688] . Epoch 126/200: loss=118.104; Losses: [118.10279, 0.00045581322, 0.00032525152] . Epoch 127/200: loss=113.516; Losses: [113.51486, 0.00045547614, 0.0005056638] . Epoch 128/200: loss=117.624; Losses: [117.62353, 0.00045549794, 0.00034517745] . Epoch 129/200: loss=112.273; Losses: [112.272316, 0.00045538746, 0.00029629772] . Epoch 130/200: loss=113.328; Losses: [113.32768, 0.0004549961, 0.0003071945] . Epoch 131/200: loss=111.756; Losses: [111.75513, 0.00045427072, 0.00032724047] . Epoch 132/200: loss=107.796; Losses: [107.795494, 0.00045377907, 0.00027464304] . Epoch 133/200: loss=150.595; Losses: [150.59428, 0.00045307074, 0.0003010978] . Epoch 134/200: loss=120.134; Losses: [120.13356, 0.00045292114, 0.00029552256] . Epoch 135/200: loss=120.130; Losses: [120.12947, 0.00045320712, 0.0002585037] . Epoch 136/200: loss=117.070; Losses: [117.06926, 0.0004533619, 0.00026611943] . Epoch 137/200: loss=111.006; Losses: [111.00518, 0.00045333267, 0.0002824646] . Epoch 138/200: loss=115.901; Losses: [115.90064, 0.00045347284, 0.00030576388] . Epoch 139/200: loss=111.147; Losses: [111.146286, 0.000453111, 0.0002558468] . Epoch 140/200: loss=103.128; Losses: [103.12687, 0.0004522237, 0.00038727812] . Epoch 141/200: loss=115.025; Losses: [115.024475, 0.00045187408, 0.0002339398] . Epoch 142/200: loss=117.170; Losses: [117.16969, 0.0004520767, 0.00023050333] . Epoch 143/200: loss=105.315; Losses: [105.31448, 0.0004517807, 0.00026579303] . Epoch 144/200: loss=114.114; Losses: [114.113625, 0.00045176974, 0.0002442702] . Epoch 145/200: loss=108.179; Losses: [108.178154, 0.00045183185, 0.00022483827] . Epoch 146/200: loss=119.408; Losses: [119.407074, 0.0004509559, 0.00021656642] . Epoch 147/200: loss=116.504; Losses: [116.50336, 0.000450821, 0.00021879328] . Epoch 148/200: loss=108.465; Losses: [108.464005, 0.0004506137, 0.00031175395] . Epoch 149/200: loss=99.284; Losses: [99.28293, 0.00045024417, 0.00022024836] . Epoch 150/200: loss=105.143; Losses: [105.14198, 0.00044986696, 0.00024956765] . Epoch 151/200: loss=107.015; Losses: [107.01389, 0.0004503439, 0.00019209863] . Epoch 152/200: loss=109.961; Losses: [109.96058, 0.00045052002, 0.00036505712] . Epoch 153/200: loss=110.943; Losses: [110.94235, 0.00045058262, 0.00019362733] . Epoch 154/200: loss=105.146; Losses: [105.14586, 0.0004505078, 0.00018350873] . Epoch 155/200: loss=153.239; Losses: [153.23862, 0.00045094165, 0.00018688777] . Epoch 156/200: loss=97.193; Losses: [97.192276, 0.0004497521, 0.0002643012] . Epoch 157/200: loss=116.076; Losses: [116.075356, 0.00044927179, 0.00018770616] . Epoch 158/200: loss=99.644; Losses: [99.64349, 0.00044897772, 0.00019957994] . Epoch 159/200: loss=101.686; Losses: [101.68573, 0.00044913022, 0.0001649716] . Epoch 160/200: loss=114.998; Losses: [114.99737, 0.00044872603, 0.0001598363] . Epoch 161/200: loss=126.449; Losses: [126.44795, 0.00044798924, 0.00017636445] . Epoch 162/200: loss=99.323; Losses: [99.32204, 0.00044971833, 0.0001718228] . Epoch 163/200: loss=118.403; Losses: [118.402115, 0.0004499098, 0.00016231032] . Epoch 164/200: loss=101.217; Losses: [101.21654, 0.00044922353, 0.00015090306] . Epoch 165/200: loss=132.002; Losses: [132.0016, 0.0004491811, 0.00018679435] . Epoch 166/200: loss=103.262; Losses: [103.26103, 0.00044870118, 0.00014671378] . Epoch 167/200: loss=98.593; Losses: [98.592026, 0.0004482735, 0.00017167021] . Epoch 168/200: loss=102.641; Losses: [102.64062, 0.00044823167, 0.0001966377] . Epoch 169/200: loss=110.199; Losses: [110.19867, 0.00044768318, 0.00014072815] . Epoch 170/200: loss=98.456; Losses: [98.45533, 0.00044640992, 0.00013351238] . Epoch 171/200: loss=107.700; Losses: [107.698944, 0.00044608887, 0.000128763] . Epoch 172/200: loss=110.314; Losses: [110.31317, 0.0004454155, 0.00015472547] . Epoch 173/200: loss=101.824; Losses: [101.82384, 0.00044520054, 0.00012376827] . Epoch 174/200: loss=100.615; Losses: [100.61448, 0.00044518447, 0.00012106997] . Epoch 175/200: loss=99.010; Losses: [99.00989, 0.00044499052, 0.0001265088] . Epoch 176/200: loss=104.999; Losses: [104.99841, 0.0004448745, 0.00017745573] . Epoch 177/200: loss=98.012; Losses: [98.0118, 0.0004448767, 0.00016406355] . Epoch 178/200: loss=99.610; Losses: [99.60982, 0.0004446858, 0.00011498472] . Epoch 179/200: loss=108.899; Losses: [108.89821, 0.00044491427, 0.00010847509] . Epoch 180/200: loss=118.136; Losses: [118.13521, 0.00044519745, 0.00010489453] . Epoch 181/200: loss=98.810; Losses: [98.80894, 0.000445671, 0.00012609128] . Epoch 182/200: loss=96.406; Losses: [96.40544, 0.0004462903, 0.00010188887] . Epoch 183/200: loss=98.501; Losses: [98.50068, 0.00044781342, 9.952572e-05] . Epoch 184/200: loss=97.149; Losses: [97.14829, 0.00044934792, 0.00010874969] . Epoch 185/200: loss=100.637; Losses: [100.63678, 0.00044996737, 9.560937e-05] . Epoch 186/200: loss=97.202; Losses: [97.201294, 0.00045056257, 9.1939364e-05] . Epoch 187/200: loss=99.839; Losses: [99.83876, 0.0004511009, 8.99044e-05] . Epoch 188/200: loss=118.457; Losses: [118.45691, 0.00045174357, 9.007633e-05] . Epoch 189/200: loss=102.419; Losses: [102.41877, 0.00045339097, 9.094182e-05] . Epoch 190/200: loss=110.813; Losses: [110.812386, 0.00045527803, 8.5699685e-05] . Epoch 191/200: loss=99.384; Losses: [99.38332, 0.000456504, 8.375079e-05] . Epoch 192/200: loss=103.581; Losses: [103.58075, 0.0004564843, 9.893996e-05] . Epoch 193/200: loss=97.621; Losses: [97.62078, 0.00045904273, 8.179152e-05] . Epoch 194/200: loss=94.909; Losses: [94.90842, 0.00046064917, 7.898855e-05] . Epoch 195/200: loss=100.840; Losses: [100.83898, 0.0004623049, 8.4420986e-05] . Epoch 196/200: loss=98.157; Losses: [98.15616, 0.00046370056, 8.1935854e-05] . Epoch 197/200: loss=95.283; Losses: [95.28199, 0.00046543585, 7.4171934e-05] . Epoch 198/200: loss=98.005; Losses: [98.00419, 0.0004669357, 7.385877e-05] . Epoch 199/200: loss=103.609; Losses: [103.608406, 0.00046879202, 7.1431816e-05] _ , dyn_prior = f_model . dynamic_encoder . sample_dynamic_prior ( 10 ) np . squeeze ( dyn_prior . mean () . numpy ()) array([-1.6796231, -2.5568666, -2.4644861, -2.4013069, -2.3772488, -2.3707619, -2.377105 , -2.332031 , -2.3327737, -2.360692 ], dtype=float32) K . clear_session () dynamic_prior = RNNMultivariateNormalDiag ( VariationalLSTMCell ( N_HIDDEN , output_dim = LATENT_SIZE_DYNAMIC ), n_timesteps = N_TIMES , output_dim = LATENT_SIZE_DYNAMIC ) sample = dynamic_prior . sample (( N_SAMPLES , BATCH_SIZE )) print ( sample . shape ) print ( dynamic_prior . mean ()) (2, 6, 10, 1) tf.Tensor( [[ 0. ] [ 0.04328619] [ 0.08498121] [-0.17377347] [-0.09743058] [-0.30255282] [-0.22110605] [-0.36379734] [-0.30933833] [-0.13590682]], shape=(10, 1), dtype=float32)","title":"Tfp utils"},{"location":"DSAE/tfp_utils/#tensorflow-probability-utilities","text":"This notebook is a bit of a mess after the refactor. Its code has all been moved to indl.model.tfp and indl.model.tfp.dsae Many of the tests have been moved to the unit tests. import numpy as np import tensorflow as tf import tensorflow.keras.layers as tfkl from tensorflow.keras import backend as K import tensorflow_probability as tfp tfd = tfp . distributions tfpl = tfp . layers tfb = tfp . bijectors scale_shift = np . log ( np . exp ( 1 ) - 1 ) . astype ( np . float32 ) from indl.model.tfp.devae import * from indl.model.tfp import * # An example of how this would work in a variational autoencoder. N_TIMES = 10 N_SENSORS = 8 N_SAMPLES = 2 N_HIDDEN = 5 KL_WEIGHT = 0.05 t_vec = tf . range ( N_TIMES , dtype = tf . float32 ) / N_TIMES sig_vec = 1 + tf . exp ( - 10 * ( t_vec - 0.5 )) def make_model ( prior ): input_ = tfkl . Input ( shape = ( LATENT_SIZE ,)) # Encoder make_latent_dist_fn , latent_params = make_mvn_dist_fn ( input_ , LATENT_SIZE , offdiag = True , loc_name = \"latent_loc\" ) q_latent = tfpl . DistributionLambda ( name = \"q_latent\" , make_distribution_fn = make_latent_dist_fn , convert_to_tensor_fn = lambda s : s . sample ( N_SAMPLES ), activity_regularizer = tfpl . KLDivergenceRegularizer ( prior , use_exact_kl = True , weight = KL_WEIGHT ) )( latent_params ) # Decoder y_ = q_latent [ ... , tf . newaxis , :] / sig_vec [:, tf . newaxis ] # broadcast-add zeros to restore timesteps #y_ = q_latent[..., tf.newaxis, :] + tf.zeros([N_TIMES, 1]) #y_ = tf.reshape(y_, [-1, N_TIMES, LATENT_SIZE]) #y_ = tfkl.LSTM(N_HIDDEN, return_sequences=True)(y_) #y_ = tf.reshape(y_, [N_SAMPLES, -1, N_TIMES, N_HIDDEN]) make_out_dist_fn , out_dist_params = make_mvn_dist_fn ( y_ , N_SENSORS , loc_name = \"out_loc\" ) p_out = tfpl . DistributionLambda ( make_distribution_fn = make_out_dist_fn , name = \"p_out\" )( out_dist_params ) # no prior on the output. # Model model = tf . keras . Model ( inputs = input_ , outputs = [ q_latent , p_out ]) return model # Create a fake dataset to train the model. LATENT_SIZE = 4 BATCH_SIZE = 6 # The latents are sampled from a distribution with known parameters. true_dist = tfd . MultivariateNormalDiag ( loc = [ - 1. , 1. , 5 , - 5 ], # must have length == LATENT_SIZE scale_diag = [ 0.5 , 0.5 , 0.9 , 0.2 ] ) # They parameterize sigmoid end points, from indl.misc.sigfuncs import sigmoid from functools import partial t_vec = ( np . arange ( N_TIMES , dtype = np . float32 ) / N_TIMES )[ None , :] f_sig = partial ( sigmoid , t_vec , B = 10 , x_offset = 0.5 ) # which are then mixed with a known mixing matrix mix_mat = np . array ([ [ - 0.3 , - .28 , - 0.38 , - 0.45 , - 0.02 , - 0.12 , - 0.05 , - 0.48 ], [ 0.27 , 0.29 , - 0.34 , 0.2 , 0.41 , 0.08 , 0.11 , 0.13 ], [ - 0.14 , 0.26 , - 0.28 , - 0.14 , 0.1 , - 0.2 , 0.4 , 0.11 ], [ - 0.05 , - 0.12 , 0.28 , 0.49 , - 0.12 , 0.1 , 0.17 , 0.22 ] ], dtype = np . float32 ) . T #mix_mat = tf.convert_to_tensor(mix_mat) def gen_ds ( n_iters = 1e2 , latent_size = LATENT_SIZE ): iter_ix = 0 while iter_ix < n_iters : _input = tf . ones (( latent_size ,), dtype = tf . float32 ) latent = true_dist . sample () . numpy () _y = np . reshape ( latent , [ latent_size , 1 ]) _y = f_sig ( K = _y ) _y = mix_mat @ _y _y = _y . T yield _input , _y iter_ix += 1 ds = tf . data . Dataset . from_generator ( gen_ds , args = [ 1e2 ], output_types = ( tf . float32 , tf . float32 ), output_shapes = (( LATENT_SIZE ,), ( N_TIMES , N_SENSORS ))) ds = ds . map ( lambda x , y : ( x , ( tf . zeros ( 0 , dtype = tf . float32 ), y ))) . batch ( BATCH_SIZE ) # Train the model. # Try playing around with the 2nd loss_weights (below) and KL_WEIGHT (above). N_EPOCHS = 100 K . clear_session () prior = make_mvn_prior ( LATENT_SIZE , trainable_mean = True , trainable_var = True , offdiag = False ) model_ = make_model ( prior ) model_ . compile ( optimizer = 'adam' , loss = [ lambda _ , model_latent : tfd . kl_divergence ( model_latent , prior ), lambda y_true , model_out : - model_out . log_prob ( y_true )], loss_weights = [ 0.0 , 1.0 ]) hist = model_ . fit ( ds , epochs = N_EPOCHS , verbose = 2 ) Epoch 1/100 17/17 - 0s - loss: 91.9389 - q_latent_loss: 4.6523 - p_out_loss: 90.5613 Epoch 2/100 17/17 - 0s - loss: 11531.2471 - q_latent_loss: 4.3536 - p_out_loss: 11529.9590 Epoch 3/100 17/17 - 0s - loss: 743.5315 - q_latent_loss: 4.1376 - p_out_loss: 742.3065 Epoch 4/100 17/17 - 0s - loss: 137048.2969 - q_latent_loss: 3.9767 - p_out_loss: 137047.1250 Epoch 5/100 17/17 - 0s - loss: 113.2025 - q_latent_loss: 3.8272 - p_out_loss: 112.0695 Epoch 6/100 17/17 - 0s - loss: 74.9116 - q_latent_loss: 3.7352 - p_out_loss: 73.8058 Epoch 7/100 17/17 - 0s - loss: 79.9207 - q_latent_loss: 3.6573 - p_out_loss: 78.8380 Epoch 8/100 17/17 - 0s - loss: 372.0323 - q_latent_loss: 3.5850 - p_out_loss: 370.9711 Epoch 9/100 17/17 - 0s - loss: 60.3690 - q_latent_loss: 3.5167 - p_out_loss: 59.3279 Epoch 10/100 17/17 - 0s - loss: 7418.3252 - q_latent_loss: 3.4512 - p_out_loss: 7417.3027 Epoch 11/100 17/17 - 0s - loss: 3513.5659 - q_latent_loss: 3.3824 - p_out_loss: 3512.5649 Epoch 12/100 17/17 - 0s - loss: 53.7796 - q_latent_loss: 3.3220 - p_out_loss: 52.7962 Epoch 13/100 17/17 - 0s - loss: 20.4849 - q_latent_loss: 3.2672 - p_out_loss: 19.5177 Epoch 14/100 17/17 - 0s - loss: 1562.3738 - q_latent_loss: 3.2157 - p_out_loss: 1561.4218 Epoch 15/100 17/17 - 0s - loss: 963.6710 - q_latent_loss: 3.1652 - p_out_loss: 962.7339 Epoch 16/100 17/17 - 0s - loss: 2838.6292 - q_latent_loss: 3.1165 - p_out_loss: 2837.7068 Epoch 17/100 17/17 - 0s - loss: 35.5000 - q_latent_loss: 3.0708 - p_out_loss: 34.5910 Epoch 18/100 17/17 - 0s - loss: 706.3328 - q_latent_loss: 3.0287 - p_out_loss: 705.4363 Epoch 19/100 17/17 - 0s - loss: 52.2510 - q_latent_loss: 2.9887 - p_out_loss: 51.3663 Epoch 20/100 17/17 - 0s - loss: 7950.6792 - q_latent_loss: 2.9512 - p_out_loss: 7949.8062 Epoch 21/100 17/17 - 0s - loss: 190.5290 - q_latent_loss: 2.9112 - p_out_loss: 189.6672 Epoch 22/100 17/17 - 0s - loss: 27.1404 - q_latent_loss: 2.8756 - p_out_loss: 26.2891 Epoch 23/100 17/17 - 0s - loss: 222.1122 - q_latent_loss: 2.8434 - p_out_loss: 221.2705 Epoch 24/100 17/17 - 0s - loss: 26.6817 - q_latent_loss: 2.8132 - p_out_loss: 25.8489 Epoch 25/100 17/17 - 0s - loss: 301.0465 - q_latent_loss: 2.7844 - p_out_loss: 300.2223 Epoch 26/100 17/17 - 0s - loss: 17.3472 - q_latent_loss: 2.7568 - p_out_loss: 16.5312 Epoch 27/100 17/17 - 0s - loss: 47.1069 - q_latent_loss: 2.7306 - p_out_loss: 46.2986 Epoch 28/100 17/17 - 0s - loss: 34.0318 - q_latent_loss: 2.7057 - p_out_loss: 33.2309 Epoch 29/100 17/17 - 0s - loss: 25.4790 - q_latent_loss: 2.6819 - p_out_loss: 24.6851 Epoch 30/100 17/17 - 0s - loss: 35.2237 - q_latent_loss: 2.6592 - p_out_loss: 34.4365 Epoch 31/100 17/17 - 0s - loss: 17.7497 - q_latent_loss: 2.6375 - p_out_loss: 16.9690 Epoch 32/100 17/17 - 0s - loss: 19.0096 - q_latent_loss: 2.6168 - p_out_loss: 18.2350 Epoch 33/100 17/17 - 0s - loss: 17.3889 - q_latent_loss: 2.5969 - p_out_loss: 16.6202 Epoch 34/100 17/17 - 0s - loss: 3164.2163 - q_latent_loss: 2.5783 - p_out_loss: 3163.4539 Epoch 35/100 17/17 - 0s - loss: 318.1325 - q_latent_loss: 2.5614 - p_out_loss: 317.3743 Epoch 36/100 17/17 - 0s - loss: 496.7764 - q_latent_loss: 2.5442 - p_out_loss: 496.0233 Epoch 37/100 17/17 - 0s - loss: 43.8554 - q_latent_loss: 2.5274 - p_out_loss: 43.1073 Epoch 38/100 17/17 - 0s - loss: 127.4449 - q_latent_loss: 2.5114 - p_out_loss: 126.7015 Epoch 39/100 17/17 - 0s - loss: 34.3881 - q_latent_loss: 2.4962 - p_out_loss: 33.6492 Epoch 40/100 17/17 - 0s - loss: 92.4194 - q_latent_loss: 2.4816 - p_out_loss: 91.6848 Epoch 41/100 17/17 - 0s - loss: 2711.8994 - q_latent_loss: 2.4669 - p_out_loss: 2711.1697 Epoch 42/100 17/17 - 0s - loss: 32.7170 - q_latent_loss: 2.4484 - p_out_loss: 31.9922 Epoch 43/100 17/17 - 0s - loss: 368.3795 - q_latent_loss: 2.4338 - p_out_loss: 367.6590 Epoch 44/100 17/17 - 0s - loss: 185.1732 - q_latent_loss: 2.4207 - p_out_loss: 184.4566 Epoch 45/100 17/17 - 0s - loss: 1496.3325 - q_latent_loss: 2.4090 - p_out_loss: 1495.6195 Epoch 46/100 17/17 - 0s - loss: 40.2950 - q_latent_loss: 2.3979 - p_out_loss: 39.5852 Epoch 47/100 17/17 - 0s - loss: 3341.2693 - q_latent_loss: 2.3869 - p_out_loss: 3340.5627 Epoch 48/100 17/17 - 0s - loss: 317.7818 - q_latent_loss: 2.3705 - p_out_loss: 317.0801 Epoch 49/100 17/17 - 0s - loss: 129.0085 - q_latent_loss: 2.3577 - p_out_loss: 128.3107 Epoch 50/100 17/17 - 0s - loss: 677.0181 - q_latent_loss: 2.3475 - p_out_loss: 676.3232 Epoch 51/100 17/17 - 0s - loss: 44.6301 - q_latent_loss: 2.3379 - p_out_loss: 43.9381 Epoch 52/100 17/17 - 0s - loss: 13.6527 - q_latent_loss: 2.3290 - p_out_loss: 12.9633 Epoch 53/100 17/17 - 0s - loss: 2174.0337 - q_latent_loss: 2.3206 - p_out_loss: 2173.3469 Epoch 54/100 17/17 - 0s - loss: 85.2265 - q_latent_loss: 2.3118 - p_out_loss: 84.5422 Epoch 55/100 17/17 - 0s - loss: 13.3743 - q_latent_loss: 2.3037 - p_out_loss: 12.6924 Epoch 56/100 17/17 - 0s - loss: 46996.4805 - q_latent_loss: 2.2929 - p_out_loss: 46995.8008 Epoch 57/100 17/17 - 0s - loss: 23.0730 - q_latent_loss: 2.2527 - p_out_loss: 22.4061 Epoch 58/100 17/17 - 0s - loss: 11.3692 - q_latent_loss: 2.2361 - p_out_loss: 10.7074 Epoch 59/100 17/17 - 0s - loss: 25.0329 - q_latent_loss: 2.2285 - p_out_loss: 24.3733 Epoch 60/100 17/17 - 0s - loss: 17.7706 - q_latent_loss: 2.2227 - p_out_loss: 17.1126 Epoch 61/100 17/17 - 0s - loss: 10.4981 - q_latent_loss: 2.2176 - p_out_loss: 9.8417 Epoch 62/100 17/17 - 0s - loss: 32.7279 - q_latent_loss: 2.2127 - p_out_loss: 32.0729 Epoch 63/100 17/17 - 0s - loss: 30.3548 - q_latent_loss: 2.2081 - p_out_loss: 29.7012 Epoch 64/100 17/17 - 0s - loss: 30.8280 - q_latent_loss: 2.2037 - p_out_loss: 30.1757 Epoch 65/100 17/17 - 0s - loss: 41.9700 - q_latent_loss: 2.1996 - p_out_loss: 41.3189 Epoch 66/100 17/17 - 0s - loss: 54.7435 - q_latent_loss: 2.1956 - p_out_loss: 54.0936 Epoch 67/100 17/17 - 0s - loss: 43.0750 - q_latent_loss: 2.1918 - p_out_loss: 42.4262 Epoch 68/100 17/17 - 0s - loss: 243.1561 - q_latent_loss: 2.1882 - p_out_loss: 242.5083 Epoch 69/100 17/17 - 0s - loss: 22.0350 - q_latent_loss: 2.1842 - p_out_loss: 21.3885 Epoch 70/100 17/17 - 0s - loss: 99.8952 - q_latent_loss: 2.1805 - p_out_loss: 99.2498 Epoch 71/100 17/17 - 0s - loss: 31.7489 - q_latent_loss: 2.1772 - p_out_loss: 31.1044 Epoch 72/100 17/17 - 0s - loss: 10.3156 - q_latent_loss: 2.1741 - p_out_loss: 9.6721 Epoch 73/100 17/17 - 0s - loss: 10.8083 - q_latent_loss: 2.1710 - p_out_loss: 10.1656 Epoch 74/100 17/17 - 0s - loss: 149.1215 - q_latent_loss: 2.1682 - p_out_loss: 148.4797 Epoch 75/100 17/17 - 0s - loss: 11.4474 - q_latent_loss: 2.1655 - p_out_loss: 10.8064 Epoch 76/100 17/17 - 0s - loss: 11.3532 - q_latent_loss: 2.1629 - p_out_loss: 10.7130 Epoch 77/100 17/17 - 0s - loss: 9.8263 - q_latent_loss: 2.1603 - p_out_loss: 9.1868 Epoch 78/100 17/17 - 0s - loss: 12.8481 - q_latent_loss: 2.1578 - p_out_loss: 12.2094 Epoch 79/100 17/17 - 0s - loss: 10.0819 - q_latent_loss: 2.1554 - p_out_loss: 9.4439 Epoch 80/100 17/17 - 0s - loss: 9.9589 - q_latent_loss: 2.1531 - p_out_loss: 9.3216 Epoch 81/100 17/17 - 0s - loss: 148.1879 - q_latent_loss: 2.1508 - p_out_loss: 147.5513 Epoch 82/100 17/17 - 0s - loss: 13.6919 - q_latent_loss: 2.1483 - p_out_loss: 13.0560 Epoch 83/100 17/17 - 0s - loss: 11.4130 - q_latent_loss: 2.1462 - p_out_loss: 10.7777 Epoch 84/100 17/17 - 0s - loss: 62.1876 - q_latent_loss: 2.1442 - p_out_loss: 61.5529 Epoch 85/100 17/17 - 0s - loss: 37.1363 - q_latent_loss: 2.1424 - p_out_loss: 36.5021 Epoch 86/100 17/17 - 0s - loss: 9.0239 - q_latent_loss: 2.1406 - p_out_loss: 8.3903 Epoch 87/100 17/17 - 0s - loss: 9.6573 - q_latent_loss: 2.1389 - p_out_loss: 9.0242 Epoch 88/100 17/17 - 0s - loss: 16.5087 - q_latent_loss: 2.1371 - p_out_loss: 15.8761 Epoch 89/100 17/17 - 0s - loss: 9.0933 - q_latent_loss: 2.1355 - p_out_loss: 8.4612 Epoch 90/100 17/17 - 0s - loss: 11.1045 - q_latent_loss: 2.1339 - p_out_loss: 10.4729 Epoch 91/100 17/17 - 0s - loss: 14.6627 - q_latent_loss: 2.1323 - p_out_loss: 14.0315 Epoch 92/100 17/17 - 0s - loss: 12.7246 - q_latent_loss: 2.1308 - p_out_loss: 12.0939 Epoch 93/100 17/17 - 0s - loss: 18.2482 - q_latent_loss: 2.1294 - p_out_loss: 17.6179 Epoch 94/100 17/17 - 0s - loss: 12.0889 - q_latent_loss: 2.1280 - p_out_loss: 11.4590 Epoch 95/100 17/17 - 0s - loss: 35.7015 - q_latent_loss: 2.1267 - p_out_loss: 35.0720 Epoch 96/100 17/17 - 0s - loss: 156.0881 - q_latent_loss: 2.1253 - p_out_loss: 155.4590 Epoch 97/100 17/17 - 0s - loss: 8.8568 - q_latent_loss: 2.1240 - p_out_loss: 8.2280 Epoch 98/100 17/17 - 0s - loss: 10.9563 - q_latent_loss: 2.1228 - p_out_loss: 10.3279 Epoch 99/100 17/17 - 0s - loss: 10.1586 - q_latent_loss: 2.1217 - p_out_loss: 9.5306 Epoch 100/100 17/17 - 0s - loss: 14.0194 - q_latent_loss: 2.1206 - p_out_loss: 13.3917 lat_wts = model_ . get_layer ( \"latent_loc\" ) . weights lat_locs = np . ones (( 1 , LATENT_SIZE )) @ lat_wts [ 0 ] . numpy () + lat_wts [ 1 ] . numpy () mix_wts = model_ . get_layer ( \"out_loc\" ) . weights model_out = lat_locs @ mix_wts [ 0 ] . numpy () + mix_wts [ 1 ] . numpy () true_out = mix_mat @ true_dist . mean () . numpy () print ( f \"Model est lat: { lat_locs } \" ) print ( f \"Model est out: { model_out } \" ) print ( f \"prior mean: { prior . mean () . numpy () } \" ) print ( f \"true lat: { true_dist . mean () . numpy () } \" ) print ( f \"true out: { true_out . T } \" ) Model est lat: [[ 0.51195845 -1.02728739 0.67845761 -0.11073773]] Model est out: [[ 0.10048061 1.36010552 0.30864524 -0.09840383 1.17217551 -0.67099368 0.95406085 0.03414997]] prior mean: [ 0.5117957 -0.8991166 0.66152537 -0.11197621] true lat: [-1. 1. 5. -5.] true out: [ 0.12000006 2.4699998 -2.76 -2.5 1.53 -1.3 1.31 0.05999994] # test LearnableMultivariateNormalDiag prior_factory = LearnableMultivariateNormalDiag ( LATENT_SIZE ) learnable_prior = prior_factory () sample = learnable_prior . sample (( 100 , 64 )) print ( sample . shape ) print ( learnable_prior . trainable_variables ) (100, 64, 4) (<tf.Variable 'learnable_multivariate_normal_diag_2/mean:0' shape=(4,) dtype=float32, numpy=array([ 0.16748714, -0.1799583 , 0.0387747 , 0.11378615], dtype=float32)>, <tf.Variable 'learnable_multivariate_normal_diag_2/transformed_scale:0' shape=(4,) dtype=float32, numpy=array([-0.11407143, 0.06062925, 0.02439827, -0.01735771], dtype=float32)>) K . clear_session () model_ = make_model ( learnable_prior ) model_ . compile ( optimizer = 'adam' , loss = [ lambda _ , model_latent : tfd . kl_divergence ( model_latent , learnable_prior ), lambda y_true , model_out : - model_out . log_prob ( y_true )], loss_weights = [ 0.0 , 1.0 ]) print ( learnable_prior . trainable_variables ) print ([ _ . name for _ in model_ . trainable_variables ]) hist = model_ . fit ( ds , epochs = N_EPOCHS , verbose = 2 ) lat_wts = model_ . get_layer ( \"latent_loc\" ) . weights lat_locs = np . ones (( 1 , LATENT_SIZE )) @ lat_wts [ 0 ] . numpy () + lat_wts [ 1 ] . numpy () mix_wts = model_ . get_layer ( \"out_loc\" ) . weights model_out = lat_locs @ mix_wts [ 0 ] . numpy () + mix_wts [ 1 ] . numpy () true_out = mix_mat @ true_dist . mean () . numpy () print ( f \"Model est lat: { lat_locs } \" ) print ( f \"Model est out: { model_out } \" ) print ( f \"prior mean: { learnable_prior . mean () . numpy () } \" ) print ( f \"true lat: { true_dist . mean () . numpy () } \" ) print ( f \"true out: { true_out . T } \" ) (<tf.Variable 'learnable_multivariate_normal_diag_2/mean:0' shape=(4,) dtype=float32, numpy=array([ 0.16748714, -0.1799583 , 0.0387747 , 0.11378615], dtype=float32)>, <tf.Variable 'learnable_multivariate_normal_diag_2/transformed_scale:0' shape=(4,) dtype=float32, numpy=array([-0.11407143, 0.06062925, 0.02439827, -0.01735771], dtype=float32)>) ['dense/kernel:0', 'dense/bias:0', 'latent_loc/kernel:0', 'latent_loc/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'out_loc/kernel:0', 'out_loc/bias:0', 'learnable_multivariate_normal_diag_2/mean:0', 'learnable_multivariate_normal_diag_2/transformed_scale:0'] Epoch 1/100 17/17 - 0s - loss: 266.6295 - q_latent_loss: 6.5640 - p_out_loss: 264.6859 Epoch 2/100 17/17 - 0s - loss: 2032.0966 - q_latent_loss: 6.2853 - p_out_loss: 2030.2358 Epoch 3/100 17/17 - 0s - loss: 83.5799 - q_latent_loss: 6.0718 - p_out_loss: 81.7824 Epoch 4/100 17/17 - 0s - loss: 82.7522 - q_latent_loss: 5.8942 - p_out_loss: 81.0072 Epoch 5/100 17/17 - 0s - loss: 59.2224 - q_latent_loss: 5.7269 - p_out_loss: 57.5269 Epoch 6/100 17/17 - 0s - loss: 38.8948 - q_latent_loss: 5.5706 - p_out_loss: 37.2456 Epoch 7/100 17/17 - 0s - loss: 47.8537 - q_latent_loss: 5.4227 - p_out_loss: 46.2483 Epoch 8/100 17/17 - 0s - loss: 60.9186 - q_latent_loss: 5.2828 - p_out_loss: 59.3546 Epoch 9/100 17/17 - 0s - loss: 80.7008 - q_latent_loss: 5.1479 - p_out_loss: 79.1768 Epoch 10/100 17/17 - 0s - loss: 29.5548 - q_latent_loss: 5.0204 - p_out_loss: 28.0686 Epoch 11/100 17/17 - 0s - loss: 100.5337 - q_latent_loss: 4.9013 - p_out_loss: 99.0827 Epoch 12/100 17/17 - 0s - loss: 208.5356 - q_latent_loss: 4.7856 - p_out_loss: 207.1189 Epoch 13/100 17/17 - 0s - loss: 47.4895 - q_latent_loss: 4.6692 - p_out_loss: 46.1072 Epoch 14/100 17/17 - 0s - loss: 51.8070 - q_latent_loss: 4.5624 - p_out_loss: 50.4563 Epoch 15/100 17/17 - 0s - loss: 49.2825 - q_latent_loss: 4.4640 - p_out_loss: 47.9610 Epoch 16/100 17/17 - 0s - loss: 63.7341 - q_latent_loss: 4.3716 - p_out_loss: 62.4399 Epoch 17/100 17/17 - 0s - loss: 35.2299 - q_latent_loss: 4.2837 - p_out_loss: 33.9617 Epoch 18/100 17/17 - 0s - loss: 45.8432 - q_latent_loss: 4.2006 - p_out_loss: 44.5997 Epoch 19/100 17/17 - 0s - loss: 25.7876 - q_latent_loss: 4.1215 - p_out_loss: 24.5675 Epoch 20/100 17/17 - 0s - loss: 268.8558 - q_latent_loss: 4.0396 - p_out_loss: 267.6599 Epoch 21/100 17/17 - 0s - loss: 45.2869 - q_latent_loss: 3.9513 - p_out_loss: 44.1171 Epoch 22/100 17/17 - 0s - loss: 30.1766 - q_latent_loss: 3.8787 - p_out_loss: 29.0284 Epoch 23/100 17/17 - 0s - loss: 32.2969 - q_latent_loss: 3.8108 - p_out_loss: 31.1688 Epoch 24/100 17/17 - 0s - loss: 64.0437 - q_latent_loss: 3.7457 - p_out_loss: 62.9348 Epoch 25/100 17/17 - 0s - loss: 39.9464 - q_latent_loss: 3.6825 - p_out_loss: 38.8562 Epoch 26/100 17/17 - 0s - loss: 33.5094 - q_latent_loss: 3.6220 - p_out_loss: 32.4372 Epoch 27/100 17/17 - 0s - loss: 31.4306 - q_latent_loss: 3.5643 - p_out_loss: 30.3755 Epoch 28/100 17/17 - 0s - loss: 27.8061 - q_latent_loss: 3.5087 - p_out_loss: 26.7674 Epoch 29/100 17/17 - 0s - loss: 65.8272 - q_latent_loss: 3.4540 - p_out_loss: 64.8047 Epoch 30/100 17/17 - 0s - loss: 25.9475 - q_latent_loss: 3.4009 - p_out_loss: 24.9408 Epoch 31/100 17/17 - 0s - loss: 30.2780 - q_latent_loss: 3.3515 - p_out_loss: 29.2859 Epoch 32/100 17/17 - 0s - loss: 21.8850 - q_latent_loss: 3.3044 - p_out_loss: 20.9068 Epoch 33/100 17/17 - 0s - loss: 36.6851 - q_latent_loss: 3.2587 - p_out_loss: 35.7204 Epoch 34/100 17/17 - 0s - loss: 25.5569 - q_latent_loss: 3.2120 - p_out_loss: 24.6061 Epoch 35/100 17/17 - 0s - loss: 24.6902 - q_latent_loss: 3.1682 - p_out_loss: 23.7523 Epoch 36/100 17/17 - 0s - loss: 116.0450 - q_latent_loss: 3.1269 - p_out_loss: 115.1194 Epoch 37/100 17/17 - 0s - loss: 20.0418 - q_latent_loss: 3.0908 - p_out_loss: 19.1268 Epoch 38/100 17/17 - 0s - loss: 56.1398 - q_latent_loss: 3.0497 - p_out_loss: 55.2370 Epoch 39/100 17/17 - 0s - loss: 27.5171 - q_latent_loss: 3.0067 - p_out_loss: 26.6270 Epoch 40/100 17/17 - 0s - loss: 20.7006 - q_latent_loss: 2.9684 - p_out_loss: 19.8219 Epoch 41/100 17/17 - 0s - loss: 26.9046 - q_latent_loss: 2.9328 - p_out_loss: 26.0364 Epoch 42/100 17/17 - 0s - loss: 18.7693 - q_latent_loss: 2.8996 - p_out_loss: 17.9110 Epoch 43/100 17/17 - 0s - loss: 22.3650 - q_latent_loss: 2.8670 - p_out_loss: 21.5163 Epoch 44/100 17/17 - 0s - loss: 32.9155 - q_latent_loss: 2.8352 - p_out_loss: 32.0763 Epoch 45/100 17/17 - 0s - loss: 19.9130 - q_latent_loss: 2.8037 - p_out_loss: 19.0830 Epoch 46/100 17/17 - 0s - loss: 19.9001 - q_latent_loss: 2.7740 - p_out_loss: 19.0789 Epoch 47/100 17/17 - 0s - loss: 25.4838 - q_latent_loss: 2.7436 - p_out_loss: 24.6716 Epoch 48/100 17/17 - 0s - loss: 23.9622 - q_latent_loss: 2.7135 - p_out_loss: 23.1589 Epoch 49/100 17/17 - 0s - loss: 20.7703 - q_latent_loss: 2.6849 - p_out_loss: 19.9756 Epoch 50/100 17/17 - 0s - loss: 19.6302 - q_latent_loss: 2.6576 - p_out_loss: 18.8435 Epoch 51/100 17/17 - 0s - loss: 18.7125 - q_latent_loss: 2.6321 - p_out_loss: 17.9334 Epoch 52/100 17/17 - 0s - loss: 21.4065 - q_latent_loss: 2.6073 - p_out_loss: 20.6347 Epoch 53/100 17/17 - 0s - loss: 37.3685 - q_latent_loss: 2.5831 - p_out_loss: 36.6039 Epoch 54/100 17/17 - 0s - loss: 15.8975 - q_latent_loss: 2.5606 - p_out_loss: 15.1395 Epoch 55/100 17/17 - 0s - loss: 15.6574 - q_latent_loss: 2.5387 - p_out_loss: 14.9059 Epoch 56/100 17/17 - 0s - loss: 28.7901 - q_latent_loss: 2.5174 - p_out_loss: 28.0449 Epoch 57/100 17/17 - 0s - loss: 99.3240 - q_latent_loss: 2.4972 - p_out_loss: 98.5848 Epoch 58/100 17/17 - 0s - loss: 19.6783 - q_latent_loss: 2.4761 - p_out_loss: 18.9453 Epoch 59/100 17/17 - 0s - loss: 18.9958 - q_latent_loss: 2.4563 - p_out_loss: 18.2688 Epoch 60/100 17/17 - 0s - loss: 21.3663 - q_latent_loss: 2.4364 - p_out_loss: 20.6451 Epoch 61/100 17/17 - 0s - loss: 26.8008 - q_latent_loss: 2.4179 - p_out_loss: 26.0850 Epoch 62/100 17/17 - 0s - loss: 13.9355 - q_latent_loss: 2.3984 - p_out_loss: 13.2256 Epoch 63/100 17/17 - 0s - loss: 14.0786 - q_latent_loss: 2.3803 - p_out_loss: 13.3740 Epoch 64/100 17/17 - 0s - loss: 20.6991 - q_latent_loss: 2.3634 - p_out_loss: 19.9995 Epoch 65/100 17/17 - 0s - loss: 33.9438 - q_latent_loss: 2.3476 - p_out_loss: 33.2488 Epoch 66/100 17/17 - 0s - loss: 19.5023 - q_latent_loss: 2.3325 - p_out_loss: 18.8118 Epoch 67/100 17/17 - 0s - loss: 16.1214 - q_latent_loss: 2.3179 - p_out_loss: 15.4353 Epoch 68/100 17/17 - 0s - loss: 33.3983 - q_latent_loss: 2.3044 - p_out_loss: 32.7162 Epoch 69/100 17/17 - 0s - loss: 14.1833 - q_latent_loss: 2.2933 - p_out_loss: 13.5045 Epoch 70/100 17/17 - 0s - loss: 33.0913 - q_latent_loss: 2.2802 - p_out_loss: 32.4163 Epoch 71/100 17/17 - 0s - loss: 15.5565 - q_latent_loss: 2.2661 - p_out_loss: 14.8857 Epoch 72/100 17/17 - 0s - loss: 23.7552 - q_latent_loss: 2.2522 - p_out_loss: 23.0885 Epoch 73/100 17/17 - 0s - loss: 15.8186 - q_latent_loss: 2.2402 - p_out_loss: 15.1554 Epoch 74/100 17/17 - 0s - loss: 15.8109 - q_latent_loss: 2.2277 - p_out_loss: 15.1514 Epoch 75/100 17/17 - 0s - loss: 23.2216 - q_latent_loss: 2.2153 - p_out_loss: 22.5659 Epoch 76/100 17/17 - 0s - loss: 17.1244 - q_latent_loss: 2.2021 - p_out_loss: 16.4725 Epoch 77/100 17/17 - 0s - loss: 20.2818 - q_latent_loss: 2.1875 - p_out_loss: 19.6343 Epoch 78/100 17/17 - 0s - loss: 20.1146 - q_latent_loss: 2.1751 - p_out_loss: 19.4708 Epoch 79/100 17/17 - 0s - loss: 12.0626 - q_latent_loss: 2.1647 - p_out_loss: 11.4218 Epoch 80/100 17/17 - 0s - loss: 17.5959 - q_latent_loss: 2.1547 - p_out_loss: 16.9580 Epoch 81/100 17/17 - 0s - loss: 46.9798 - q_latent_loss: 2.1428 - p_out_loss: 46.3454 Epoch 82/100 17/17 - 0s - loss: 20.0080 - q_latent_loss: 2.1244 - p_out_loss: 19.3792 Epoch 83/100 17/17 - 0s - loss: 11.8902 - q_latent_loss: 2.1120 - p_out_loss: 11.2651 Epoch 84/100 17/17 - 0s - loss: 17.5359 - q_latent_loss: 2.1015 - p_out_loss: 16.9139 Epoch 85/100 17/17 - 0s - loss: 14.8084 - q_latent_loss: 2.0917 - p_out_loss: 14.1892 Epoch 86/100 17/17 - 0s - loss: 9.6016 - q_latent_loss: 2.0823 - p_out_loss: 8.9852 Epoch 87/100 17/17 - 0s - loss: 13.4432 - q_latent_loss: 2.0736 - p_out_loss: 12.8294 Epoch 88/100 17/17 - 0s - loss: 16.5978 - q_latent_loss: 2.0652 - p_out_loss: 15.9865 Epoch 89/100 17/17 - 0s - loss: 21.3484 - q_latent_loss: 2.0557 - p_out_loss: 20.7399 Epoch 90/100 17/17 - 0s - loss: 11.3400 - q_latent_loss: 2.0439 - p_out_loss: 10.7350 Epoch 91/100 17/17 - 0s - loss: 14.2551 - q_latent_loss: 2.0345 - p_out_loss: 13.6529 Epoch 92/100 17/17 - 0s - loss: 14.2384 - q_latent_loss: 2.0268 - p_out_loss: 13.6385 Epoch 93/100 17/17 - 0s - loss: 16.3489 - q_latent_loss: 2.0194 - p_out_loss: 15.7511 Epoch 94/100 17/17 - 0s - loss: 14.2265 - q_latent_loss: 2.0118 - p_out_loss: 13.6310 Epoch 95/100 17/17 - 0s - loss: 11.5992 - q_latent_loss: 2.0041 - p_out_loss: 11.0060 Epoch 96/100 17/17 - 0s - loss: 11.7333 - q_latent_loss: 1.9971 - p_out_loss: 11.1421 Epoch 97/100 17/17 - 0s - loss: 12.1329 - q_latent_loss: 1.9904 - p_out_loss: 11.5438 Epoch 98/100 17/17 - 0s - loss: 13.7211 - q_latent_loss: 1.9832 - p_out_loss: 13.1341 Epoch 99/100 17/17 - 0s - loss: 37.2112 - q_latent_loss: 1.9745 - p_out_loss: 36.6267 Epoch 100/100 17/17 - 0s - loss: 9.3972 - q_latent_loss: 1.9630 - p_out_loss: 8.8161 Model est lat: [[ 2.51292503 -1.26424221 -1.11180196 -0.02588509]] Model est out: [[-0.27425705 2.39304429 -2.49596335 0.29950965 1.37276651 -0.43098222 -0.45473986 0.07839915]] prior mean: [ 1.3514248 -1.2266612 -0.8751619 -0.03475915] true lat: [-1. 1. 5. -5.] true out: [ 0.12000006 2.4699998 -2.76 -2.5 1.53 -1.3 1.31 0.05999994]","title":"Tensorflow Probability Utilities"},{"location":"DSAE/tfp_utils/#latent-dynamic-factor","text":"# Return 3 outputs, the first 2 are null #ds_dyn = ds.map(lambda x, y: (x, (y[0], y[0], y[1]))) ds_dyn = ds . map ( lambda x , y : ( x , y [ 1 ])) KL_WEIGHT = 0.001 LATENT_SIZE_DYNAMIC = 1 # Integer dimensionality of each dynamic, time-variant latent variable `z_t`. K . clear_session () tmp = LearnableMultivariateNormalDiagCell ( 3 , 4 ) #tmp.build((None, 10, 5)) #tmp.summary() # test DynamicEncoder and LearnableMultivariateNormalDiagCell K . clear_session () dynamic_encoder = DynamicEncoder ( N_HIDDEN , N_TIMES , LATENT_SIZE_DYNAMIC ) sample , dynamic_prior = dynamic_encoder . sample_dynamic_prior ( N_TIMES , samples = N_SAMPLES , batches = 1 ) print ( sample . shape ) print ( \"mean:\" , np . squeeze ( dynamic_prior . mean ())) print ( \"stddev:\" , np . squeeze ( dynamic_prior . stddev ())) print ([ _ . name for _ in dynamic_encoder . trainable_variables ]) (2, 1, 10, 1) mean: [[ 0. 0.42388976 0.45631832 0.365768 0.20130846 0.37873474 0.31262326 0.26073667 0.15399611 0.14049806] [ 0. 0.08804662 0.0361465 -0.03267653 -0.08733355 0.19941618 0.30335566 0.3730844 0.2744042 0.17948757]] stddev: [[1.00001 0.929902 0.9554563 0.99371654 1.0142238 0.97018814 1.0006421 1.0033575 1.0105829 1.0065393 ] [1.00001 0.9952911 1.0008274 1.0000954 0.99874425 0.98230976 0.9771384 0.9683764 1.000174 1.0049998 ]] ['learnable_multivariate_normal_diag_cell/mvndiagcell_lstm/kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_lstm/recurrent_kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_lstm/bias:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_loc/kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_loc/bias:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_scale/kernel:0', 'learnable_multivariate_normal_diag_cell/mvndiagcell_scale/bias:0'] K . clear_session () f_model = FactorizedAutoEncoder ( N_HIDDEN , N_TIMES , LATENT_SIZE , LATENT_SIZE_DYNAMIC , N_SENSORS ) # Most of the trainable variables don't present themselves until the model pieces are called. print ([ _ . name for _ in f_model . static_encoder . trainable_variables ]) print ([ _ . name for _ in f_model . dynamic_encoder . trainable_variables ]) print ([ _ . name for _ in f_model . decoder . trainable_variables ]) [] ['learnable_multivariate_normal_diag/mean:0', 'learnable_multivariate_normal_diag/untransformed_stddev:0'] [] [] N_EPOCHS = 200 if False : f_model . compile ( optimizer = 'adam' , loss = lambda y_true , model_out : - model_out . log_prob ( y_true )) hist = f_model . fit ( ds_dyn , epochs = N_EPOCHS , verbose = 2 ) else : @tf . function def grad ( model , inputs , preds ): with tf . GradientTape () as tape : q_f = model . static_encoder ( inputs ) q_z = model . dynamic_encoder ( inputs ) p_full = model . decoder ([ tf . convert_to_tensor ( q_f ), tf . convert_to_tensor ( q_z )]) # Reconstruction log-likelihood: p(output|input) recon_post_log_prob = p_full . log_prob ( preds ) recon_post_log_prob = tf . reduce_sum ( recon_post_log_prob , axis =- 1 ) # Sum over time axis recon_post_log_prob = tf . reduce_mean ( recon_post_log_prob ) # KL Divergence - analytical # Static static_prior = model . static_encoder . static_prior_factory () stat_kl = tfd . kl_divergence ( q_f , static_prior ) stat_kl = KL_WEIGHT * stat_kl stat_kl = tf . reduce_mean ( stat_kl ) # Dynamic _ , dynamic_prior = model . dynamic_encoder . sample_dynamic_prior ( N_TIMES , samples = 1 , batches = 1 ) dyn_kl = tfd . kl_divergence ( q_z , dynamic_prior ) dyn_kl = tf . reduce_sum ( dyn_kl , axis =- 1 ) dyn_kl = tf . squeeze ( dyn_kl ) dyn_kl = KL_WEIGHT * dyn_kl dyn_kl = tf . reduce_mean ( dyn_kl ) loss = - recon_post_log_prob + stat_kl + dyn_kl grads = tape . gradient ( loss , model . trainable_variables ) return loss , grads , ( - recon_post_log_prob , stat_kl , dyn_kl ) optim = tf . keras . optimizers . Adam ( learning_rate = 1e-3 ) for epoch_ix in range ( N_EPOCHS ): for step_ix , batch in enumerate ( ds_dyn ): inputs , preds = batch loss , grads , loss_comps = grad ( f_model , inputs , preds ) optim . apply_gradients ( zip ( grads , f_model . trainable_variables )) if ( step_ix % 200 ) == 0 : print ( '.' ) print ( f \"Epoch { epoch_ix } / { N_EPOCHS } : \\t loss= { loss : .3f } ; \" f \"Losses: { [ _ . numpy () for _ in loss_comps ] } \" ) . Epoch 0/200: loss=3777.438; Losses: [3777.3972, 0.0028260916, 0.03819199] . Epoch 1/200: loss=908.620; Losses: [908.5834, 0.002681077, 0.034407526] . Epoch 2/200: loss=682.733; Losses: [682.7001, 0.0025911012, 0.030505255] . Epoch 3/200: loss=317.985; Losses: [317.9555, 0.0024803109, 0.027142774] . Epoch 4/200: loss=737.753; Losses: [737.7305, 0.0024128703, 0.019867169] . Epoch 5/200: loss=293.983; Losses: [293.9585, 0.0023704215, 0.022514882] . Epoch 6/200: loss=412.075; Losses: [412.0592, 0.002335041, 0.013460781] . Epoch 7/200: loss=306.618; Losses: [306.60327, 0.002284743, 0.012861049] . Epoch 8/200: loss=215.916; Losses: [215.9029, 0.0022479186, 0.0111077] . Epoch 9/200: loss=223.136; Losses: [223.12366, 0.0022122823, 0.010420884] . Epoch 10/200: loss=300.156; Losses: [300.14383, 0.0021807426, 0.009667382] . Epoch 11/200: loss=179.766; Losses: [179.75607, 0.0021481065, 0.007676568] . Epoch 12/200: loss=215.981; Losses: [215.97124, 0.0021149626, 0.008112778] . Epoch 13/200: loss=208.054; Losses: [208.04565, 0.0020882282, 0.006530414] . Epoch 14/200: loss=207.146; Losses: [207.13806, 0.0020594192, 0.0063194335] . Epoch 15/200: loss=261.805; Losses: [261.7982, 0.0020306753, 0.0045144106] . Epoch 16/200: loss=178.393; Losses: [178.38637, 0.0020005947, 0.0045015276] . Epoch 17/200: loss=284.872; Losses: [284.86642, 0.0019730518, 0.003997615] . Epoch 18/200: loss=212.054; Losses: [212.04866, 0.0019469936, 0.0034680453] . Epoch 19/200: loss=145.862; Losses: [145.85641, 0.001922644, 0.004011639] . Epoch 20/200: loss=182.153; Losses: [182.14563, 0.0018981744, 0.0059485184] . Epoch 21/200: loss=154.575; Losses: [154.56941, 0.0018728755, 0.0038126395] . Epoch 22/200: loss=214.752; Losses: [214.74734, 0.0018469194, 0.003135754] . Epoch 23/200: loss=179.347; Losses: [179.34248, 0.001825613, 0.0029100403] . Epoch 24/200: loss=354.274; Losses: [354.26898, 0.0018005224, 0.0028155171] . Epoch 25/200: loss=181.006; Losses: [181.0021, 0.0017763268, 0.0022955306] . Epoch 26/200: loss=142.006; Losses: [142.00166, 0.0017520584, 0.0022001117] . Epoch 27/200: loss=158.932; Losses: [158.92723, 0.0017273662, 0.0026816982] . Epoch 28/200: loss=175.159; Losses: [175.15494, 0.0017028436, 0.0019087334] . Epoch 29/200: loss=167.915; Losses: [167.91084, 0.0016797789, 0.002798946] . Epoch 30/200: loss=152.785; Losses: [152.78006, 0.001658167, 0.0029456303] . Epoch 31/200: loss=158.407; Losses: [158.40344, 0.0016350556, 0.0018697139] . Epoch 32/200: loss=151.065; Losses: [151.06094, 0.0016126116, 0.00282249] . Epoch 33/200: loss=181.075; Losses: [181.07072, 0.0015892526, 0.0025259533] . Epoch 34/200: loss=157.210; Losses: [157.20605, 0.0015682159, 0.0026225548] . Epoch 35/200: loss=151.200; Losses: [151.19623, 0.0015464819, 0.0017979483] . Epoch 36/200: loss=157.111; Losses: [157.10796, 0.0015237778, 0.0016808716] . Epoch 37/200: loss=160.398; Losses: [160.39449, 0.0015015532, 0.0018031715] . Epoch 38/200: loss=133.418; Losses: [133.41472, 0.0014805306, 0.0017712188] . Epoch 39/200: loss=161.662; Losses: [161.65845, 0.0014592485, 0.0018676165] . Epoch 40/200: loss=181.789; Losses: [181.78532, 0.0014379938, 0.0023018767] . Epoch 41/200: loss=183.568; Losses: [183.56451, 0.00142015, 0.001671126] . Epoch 42/200: loss=211.679; Losses: [211.67618, 0.0014024411, 0.001817507] . Epoch 43/200: loss=235.384; Losses: [235.38095, 0.0013794828, 0.0018946148] . Epoch 44/200: loss=139.088; Losses: [139.08447, 0.0013571468, 0.0019089653] . Epoch 45/200: loss=160.254; Losses: [160.25092, 0.0013359843, 0.0013933791] . Epoch 46/200: loss=142.206; Losses: [142.20291, 0.0013167453, 0.0014015753] . Epoch 47/200: loss=138.814; Losses: [138.8115, 0.0012925405, 0.0014298331] . Epoch 48/200: loss=130.677; Losses: [130.67343, 0.0012679367, 0.0021604125] . Epoch 49/200: loss=145.296; Losses: [145.29306, 0.0012432866, 0.0013332999] . Epoch 50/200: loss=133.338; Losses: [133.33516, 0.0012180805, 0.0012685797] . Epoch 51/200: loss=138.212; Losses: [138.20908, 0.0011976506, 0.0017989981] . Epoch 52/200: loss=136.139; Losses: [136.13644, 0.0011768966, 0.001470595] . Epoch 53/200: loss=141.839; Losses: [141.83646, 0.0011539405, 0.0017275128] . Epoch 54/200: loss=159.297; Losses: [159.29402, 0.0011311076, 0.0017414299] . Epoch 55/200: loss=125.919; Losses: [125.91669, 0.0011091225, 0.0013509693] . Epoch 56/200: loss=135.710; Losses: [135.7079, 0.0010871431, 0.0010571101] . Epoch 57/200: loss=124.548; Losses: [124.545654, 0.0010660599, 0.0011921946] . Epoch 58/200: loss=128.607; Losses: [128.60472, 0.0010461143, 0.0010578154] . Epoch 59/200: loss=200.879; Losses: [200.87674, 0.0010245068, 0.0014237395] . Epoch 60/200: loss=181.939; Losses: [181.93698, 0.0010024481, 0.0010916217] . Epoch 61/200: loss=161.069; Losses: [161.06737, 0.0009815091, 0.0009930782] . Epoch 62/200: loss=129.661; Losses: [129.65881, 0.0009596758, 0.001090972] . Epoch 63/200: loss=342.733; Losses: [342.73068, 0.000939325, 0.001181667] . Epoch 64/200: loss=160.802; Losses: [160.8003, 0.00091621274, 0.0012079075] . Epoch 65/200: loss=123.200; Losses: [123.19836, 0.00089694076, 0.0009983401] . Epoch 66/200: loss=134.465; Losses: [134.46295, 0.00087896077, 0.0009002821] . Epoch 67/200: loss=205.839; Losses: [205.83714, 0.0008604548, 0.001061962] . Epoch 68/200: loss=144.191; Losses: [144.18906, 0.0008421927, 0.0011492949] . Epoch 69/200: loss=164.397; Losses: [164.39539, 0.0008238552, 0.0010998722] . Epoch 70/200: loss=131.024; Losses: [131.02272, 0.00080561615, 0.000867295] . Epoch 71/200: loss=130.408; Losses: [130.40652, 0.0007878286, 0.0009589862] . Epoch 72/200: loss=120.511; Losses: [120.509705, 0.0007217523, 0.0008722847] . Epoch 73/200: loss=122.388; Losses: [122.38655, 0.00069110864, 0.00080618635] . Epoch 74/200: loss=123.200; Losses: [123.198654, 0.0006731994, 0.0008244566] . Epoch 75/200: loss=117.884; Losses: [117.88217, 0.00065816526, 0.00086460914] . Epoch 76/200: loss=123.508; Losses: [123.50694, 0.0006448629, 0.0008477152] . Epoch 77/200: loss=121.749; Losses: [121.74744, 0.0006321136, 0.0008150753] . Epoch 78/200: loss=145.549; Losses: [145.5473, 0.00061951997, 0.00082959904] . Epoch 79/200: loss=135.341; Losses: [135.33992, 0.00060778105, 0.0007312283] . Epoch 80/200: loss=131.476; Losses: [131.47452, 0.0005965105, 0.0008391714] . Epoch 81/200: loss=123.978; Losses: [123.976944, 0.00058624754, 0.0008059401] . Epoch 82/200: loss=136.084; Losses: [136.08298, 0.0005766748, 0.0007252015] . Epoch 83/200: loss=137.815; Losses: [137.81375, 0.00056776253, 0.0009108439] . Epoch 84/200: loss=116.955; Losses: [116.95401, 0.0005592232, 0.0008040637] . Epoch 85/200: loss=131.525; Losses: [131.52376, 0.00055153086, 0.0007604256] . Epoch 86/200: loss=135.716; Losses: [135.71432, 0.00054452394, 0.0006871256] . Epoch 87/200: loss=191.940; Losses: [191.93927, 0.0005378095, 0.0006448448] . Epoch 88/200: loss=170.746; Losses: [170.74509, 0.00053181086, 0.0006591724] . Epoch 89/200: loss=121.373; Losses: [121.37161, 0.00052640436, 0.00079500565] . Epoch 90/200: loss=126.909; Losses: [126.90761, 0.0005213883, 0.0006021685] . Epoch 91/200: loss=122.121; Losses: [122.120255, 0.0005157513, 0.0006873938] . Epoch 92/200: loss=129.156; Losses: [129.15442, 0.0005111307, 0.00064897194] . Epoch 93/200: loss=113.183; Losses: [113.18219, 0.0005073488, 0.000602577] . Epoch 94/200: loss=146.389; Losses: [146.38794, 0.00050397916, 0.0005585851] . Epoch 95/200: loss=130.446; Losses: [130.44531, 0.0005009744, 0.00056175387] . Epoch 96/200: loss=118.884; Losses: [118.88327, 0.0004950377, 0.0005437781] . Epoch 97/200: loss=114.319; Losses: [114.3183, 0.0004938163, 0.0006134198] . Epoch 98/200: loss=134.747; Losses: [134.74594, 0.0004912615, 0.0005468172] . Epoch 99/200: loss=127.224; Losses: [127.22336, 0.0004886875, 0.00050384714] . Epoch 100/200: loss=123.007; Losses: [123.00618, 0.0004862357, 0.00056520273] . Epoch 101/200: loss=130.374; Losses: [130.3726, 0.0004841056, 0.0005738659] . Epoch 102/200: loss=120.120; Losses: [120.11898, 0.00048118114, 0.00054365897] . Epoch 103/200: loss=107.167; Losses: [107.16606, 0.00047940924, 0.0004886348] . Epoch 104/200: loss=112.270; Losses: [112.268585, 0.00047771176, 0.0004745159] . Epoch 105/200: loss=125.537; Losses: [125.53565, 0.0004758754, 0.00047247266] . Epoch 106/200: loss=109.324; Losses: [109.32308, 0.00047426036, 0.00046340926] . Epoch 107/200: loss=113.328; Losses: [113.327286, 0.0004729222, 0.00046490182] . Epoch 108/200: loss=117.106; Losses: [117.10452, 0.000471713, 0.00062898267] . Epoch 109/200: loss=122.371; Losses: [122.37039, 0.0004705812, 0.00051386596] . Epoch 110/200: loss=119.422; Losses: [119.42122, 0.0004696009, 0.0005573735] . Epoch 111/200: loss=131.784; Losses: [131.78348, 0.000468354, 0.00041559048] . Epoch 112/200: loss=124.476; Losses: [124.475006, 0.00046699354, 0.00041292777] . Epoch 113/200: loss=104.487; Losses: [104.486534, 0.00046530017, 0.00042556314] . Epoch 114/200: loss=119.418; Losses: [119.41684, 0.0004641684, 0.00039730535] . Epoch 115/200: loss=117.776; Losses: [117.77547, 0.00046339296, 0.00056288636] . Epoch 116/200: loss=112.189; Losses: [112.18817, 0.0004628609, 0.00045002214] . Epoch 117/200: loss=116.317; Losses: [116.31613, 0.0004616853, 0.00036934114] . Epoch 118/200: loss=159.105; Losses: [159.10422, 0.00046110825, 0.0003716088] . Epoch 119/200: loss=116.958; Losses: [116.95712, 0.00045984008, 0.0003543413] . Epoch 120/200: loss=108.100; Losses: [108.09944, 0.00045923653, 0.00045118056] . Epoch 121/200: loss=107.565; Losses: [107.56447, 0.00045848632, 0.00033903003] . Epoch 122/200: loss=117.631; Losses: [117.62992, 0.0004574218, 0.00033954927] . Epoch 123/200: loss=116.075; Losses: [116.07385, 0.0004564249, 0.00036835673] . Epoch 124/200: loss=106.798; Losses: [106.79701, 0.0004566427, 0.00032678706] . Epoch 125/200: loss=113.363; Losses: [113.36252, 0.0004562596, 0.00042438688] . Epoch 126/200: loss=118.104; Losses: [118.10279, 0.00045581322, 0.00032525152] . Epoch 127/200: loss=113.516; Losses: [113.51486, 0.00045547614, 0.0005056638] . Epoch 128/200: loss=117.624; Losses: [117.62353, 0.00045549794, 0.00034517745] . Epoch 129/200: loss=112.273; Losses: [112.272316, 0.00045538746, 0.00029629772] . Epoch 130/200: loss=113.328; Losses: [113.32768, 0.0004549961, 0.0003071945] . Epoch 131/200: loss=111.756; Losses: [111.75513, 0.00045427072, 0.00032724047] . Epoch 132/200: loss=107.796; Losses: [107.795494, 0.00045377907, 0.00027464304] . Epoch 133/200: loss=150.595; Losses: [150.59428, 0.00045307074, 0.0003010978] . Epoch 134/200: loss=120.134; Losses: [120.13356, 0.00045292114, 0.00029552256] . Epoch 135/200: loss=120.130; Losses: [120.12947, 0.00045320712, 0.0002585037] . Epoch 136/200: loss=117.070; Losses: [117.06926, 0.0004533619, 0.00026611943] . Epoch 137/200: loss=111.006; Losses: [111.00518, 0.00045333267, 0.0002824646] . Epoch 138/200: loss=115.901; Losses: [115.90064, 0.00045347284, 0.00030576388] . Epoch 139/200: loss=111.147; Losses: [111.146286, 0.000453111, 0.0002558468] . Epoch 140/200: loss=103.128; Losses: [103.12687, 0.0004522237, 0.00038727812] . Epoch 141/200: loss=115.025; Losses: [115.024475, 0.00045187408, 0.0002339398] . Epoch 142/200: loss=117.170; Losses: [117.16969, 0.0004520767, 0.00023050333] . Epoch 143/200: loss=105.315; Losses: [105.31448, 0.0004517807, 0.00026579303] . Epoch 144/200: loss=114.114; Losses: [114.113625, 0.00045176974, 0.0002442702] . Epoch 145/200: loss=108.179; Losses: [108.178154, 0.00045183185, 0.00022483827] . Epoch 146/200: loss=119.408; Losses: [119.407074, 0.0004509559, 0.00021656642] . Epoch 147/200: loss=116.504; Losses: [116.50336, 0.000450821, 0.00021879328] . Epoch 148/200: loss=108.465; Losses: [108.464005, 0.0004506137, 0.00031175395] . Epoch 149/200: loss=99.284; Losses: [99.28293, 0.00045024417, 0.00022024836] . Epoch 150/200: loss=105.143; Losses: [105.14198, 0.00044986696, 0.00024956765] . Epoch 151/200: loss=107.015; Losses: [107.01389, 0.0004503439, 0.00019209863] . Epoch 152/200: loss=109.961; Losses: [109.96058, 0.00045052002, 0.00036505712] . Epoch 153/200: loss=110.943; Losses: [110.94235, 0.00045058262, 0.00019362733] . Epoch 154/200: loss=105.146; Losses: [105.14586, 0.0004505078, 0.00018350873] . Epoch 155/200: loss=153.239; Losses: [153.23862, 0.00045094165, 0.00018688777] . Epoch 156/200: loss=97.193; Losses: [97.192276, 0.0004497521, 0.0002643012] . Epoch 157/200: loss=116.076; Losses: [116.075356, 0.00044927179, 0.00018770616] . Epoch 158/200: loss=99.644; Losses: [99.64349, 0.00044897772, 0.00019957994] . Epoch 159/200: loss=101.686; Losses: [101.68573, 0.00044913022, 0.0001649716] . Epoch 160/200: loss=114.998; Losses: [114.99737, 0.00044872603, 0.0001598363] . Epoch 161/200: loss=126.449; Losses: [126.44795, 0.00044798924, 0.00017636445] . Epoch 162/200: loss=99.323; Losses: [99.32204, 0.00044971833, 0.0001718228] . Epoch 163/200: loss=118.403; Losses: [118.402115, 0.0004499098, 0.00016231032] . Epoch 164/200: loss=101.217; Losses: [101.21654, 0.00044922353, 0.00015090306] . Epoch 165/200: loss=132.002; Losses: [132.0016, 0.0004491811, 0.00018679435] . Epoch 166/200: loss=103.262; Losses: [103.26103, 0.00044870118, 0.00014671378] . Epoch 167/200: loss=98.593; Losses: [98.592026, 0.0004482735, 0.00017167021] . Epoch 168/200: loss=102.641; Losses: [102.64062, 0.00044823167, 0.0001966377] . Epoch 169/200: loss=110.199; Losses: [110.19867, 0.00044768318, 0.00014072815] . Epoch 170/200: loss=98.456; Losses: [98.45533, 0.00044640992, 0.00013351238] . Epoch 171/200: loss=107.700; Losses: [107.698944, 0.00044608887, 0.000128763] . Epoch 172/200: loss=110.314; Losses: [110.31317, 0.0004454155, 0.00015472547] . Epoch 173/200: loss=101.824; Losses: [101.82384, 0.00044520054, 0.00012376827] . Epoch 174/200: loss=100.615; Losses: [100.61448, 0.00044518447, 0.00012106997] . Epoch 175/200: loss=99.010; Losses: [99.00989, 0.00044499052, 0.0001265088] . Epoch 176/200: loss=104.999; Losses: [104.99841, 0.0004448745, 0.00017745573] . Epoch 177/200: loss=98.012; Losses: [98.0118, 0.0004448767, 0.00016406355] . Epoch 178/200: loss=99.610; Losses: [99.60982, 0.0004446858, 0.00011498472] . Epoch 179/200: loss=108.899; Losses: [108.89821, 0.00044491427, 0.00010847509] . Epoch 180/200: loss=118.136; Losses: [118.13521, 0.00044519745, 0.00010489453] . Epoch 181/200: loss=98.810; Losses: [98.80894, 0.000445671, 0.00012609128] . Epoch 182/200: loss=96.406; Losses: [96.40544, 0.0004462903, 0.00010188887] . Epoch 183/200: loss=98.501; Losses: [98.50068, 0.00044781342, 9.952572e-05] . Epoch 184/200: loss=97.149; Losses: [97.14829, 0.00044934792, 0.00010874969] . Epoch 185/200: loss=100.637; Losses: [100.63678, 0.00044996737, 9.560937e-05] . Epoch 186/200: loss=97.202; Losses: [97.201294, 0.00045056257, 9.1939364e-05] . Epoch 187/200: loss=99.839; Losses: [99.83876, 0.0004511009, 8.99044e-05] . Epoch 188/200: loss=118.457; Losses: [118.45691, 0.00045174357, 9.007633e-05] . Epoch 189/200: loss=102.419; Losses: [102.41877, 0.00045339097, 9.094182e-05] . Epoch 190/200: loss=110.813; Losses: [110.812386, 0.00045527803, 8.5699685e-05] . Epoch 191/200: loss=99.384; Losses: [99.38332, 0.000456504, 8.375079e-05] . Epoch 192/200: loss=103.581; Losses: [103.58075, 0.0004564843, 9.893996e-05] . Epoch 193/200: loss=97.621; Losses: [97.62078, 0.00045904273, 8.179152e-05] . Epoch 194/200: loss=94.909; Losses: [94.90842, 0.00046064917, 7.898855e-05] . Epoch 195/200: loss=100.840; Losses: [100.83898, 0.0004623049, 8.4420986e-05] . Epoch 196/200: loss=98.157; Losses: [98.15616, 0.00046370056, 8.1935854e-05] . Epoch 197/200: loss=95.283; Losses: [95.28199, 0.00046543585, 7.4171934e-05] . Epoch 198/200: loss=98.005; Losses: [98.00419, 0.0004669357, 7.385877e-05] . Epoch 199/200: loss=103.609; Losses: [103.608406, 0.00046879202, 7.1431816e-05] _ , dyn_prior = f_model . dynamic_encoder . sample_dynamic_prior ( 10 ) np . squeeze ( dyn_prior . mean () . numpy ()) array([-1.6796231, -2.5568666, -2.4644861, -2.4013069, -2.3772488, -2.3707619, -2.377105 , -2.332031 , -2.3327737, -2.360692 ], dtype=float32) K . clear_session () dynamic_prior = RNNMultivariateNormalDiag ( VariationalLSTMCell ( N_HIDDEN , output_dim = LATENT_SIZE_DYNAMIC ), n_timesteps = N_TIMES , output_dim = LATENT_SIZE_DYNAMIC ) sample = dynamic_prior . sample (( N_SAMPLES , BATCH_SIZE )) print ( sample . shape ) print ( dynamic_prior . mean ()) (2, 6, 10, 1) tf.Tensor( [[ 0. ] [ 0.04328619] [ 0.08498121] [-0.17377347] [-0.09743058] [-0.30255282] [-0.22110605] [-0.36379734] [-0.30933833] [-0.13590682]], shape=(10, 1), dtype=float32)","title":"Latent Dynamic Factor"},{"location":"Miscellaneous/junk_model_inspect/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); model.inspect causes problems when working in model namespace because import inspect breaks things. if False: # Temporarily disable this test until I can recreate the model from pathlib import Path import os from tensorflow.keras.models import load_model if Path.cwd().stem == 'indl': os.chdir(Path.cwd().parent) layer_idx = 20 # [2, 6, 10, 14] n_steps = 100 max_n_filters = 25 model_file = Path.cwd() / 'data' / 'kjm_ecog' / 'converted' / 'faces_basic' / 'mv_model_full.h5' model = load_model(str(model_file)) # When processing softmax classification layer, # second last dense layer should be converted from relu to linear. if (layer_idx == len(model.layers) - 1) and (model.layers[-2].activation != tf.keras.activations.linear): model.layers[-2].activation = tf.keras.activations.linear import tempfile # Save and load the model to actually apply the change. tmp_path = Path(tempfile.gettempdir()) / (next(tempfile._get_candidate_names()) + '.h5') try: model.save(str(tmp_path)) model = load_model(str(tmp_path)) finally: tmp_path.unlink() model.summary() maximizing_activations = visualize_layer(model, layer_idx, epochs=n_steps, loss_as_exclusive=True, upsampling_steps=1, upsampling_factor=1, filter_range=(0, max_n_filters), output_dim=(701, model.get_input_shape_at(0)[-1])) # Stitch timeseries together into one mega timeseries with NaN gaps. stitched_data = _stitch_filters(maximizing_activations, n=2, sort_by_activation=False) import matplotlib.pyplot as plt # Create a colour code cycler e.g. 'C0', 'C1', etc. from itertools import cycle colour_codes = map('C{}'.format, cycle(range(10))) plt.figure() for chan_ix in [15, 9, 8]: plt.plot(stitched_data[:, :, chan_ix], color=next(colour_codes)) plt.show()","title":"Junk model inspect"},{"location":"Miscellaneous/kernels/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Kernels Some useful kernels. import numpy as np import scipy.signal import matplotlib.pyplot as plt srate = 1000 spk_rate = 13.0 # Avg 30 spikes per second tvec = np.arange(srate) / srate spikeevents = (np.random.rand(srate) < (spk_rate / srate)).astype(np.float32) spiketimes = tvec[spikeevents.nonzero()] from indl.misc.kernels import sskernel, Gauss # Shimazaki et al. auto-kernel-width kernel_width = sskernel(spiketimes - spiketimes[0], nbs=0)[2] kernel_param = 1 / (2.0 * 2.7) * kernel_width span_fac = 3.0 t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Gauss(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.plot(t_kern, kernel) plt.xlim([-0.5, 0.5]) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd457d51910>] kernel_param = 0.050 # msec stdev span_fac = 3.0 # How many stdevs wide the kernel should be. Too short will truncate kernel. t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Gauss(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.plot(t_kern, kernel) plt.xlim([-0.5, 0.5]) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd455bcb0a0>] from indl.misc.kernels import Boxcar kernel_param = 0.05 # The width of the rectangle in seconds span_fac = np.sqrt(3.0) kernel_param /= (2*np.sqrt(3.0)) t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Boxcar(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.xlim([-0.5, 0.5]) plt.plot(t_kern, kernel) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd455a97c70>] from indl.misc.kernels import Alpha kernel_param = 0.03 # tau kernel_param *= np.sqrt(2) span_fac = 6.0 t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Alpha(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') print(np.sum(spikeevents), np.mean(spikerates)) plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.xlim([-0.5, 0.5]) plt.plot(t_kern, kernel) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) 10.0 9.538681202301868 [<matplotlib.lines.Line2D at 0x7fd4559f6ac0>] from indl.misc.kernels import Exponential kernel_param = 0.05 # the time constant tau when the kernel reaches 1/e the maximum. span_fac = 6.0 t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Exponential(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.xlim([-0.5, 0.5]) plt.plot(t_kern, kernel) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd45594adf0>]","title":"Kernels"},{"location":"Miscellaneous/kernels/#kernels","text":"Some useful kernels. import numpy as np import scipy.signal import matplotlib.pyplot as plt srate = 1000 spk_rate = 13.0 # Avg 30 spikes per second tvec = np.arange(srate) / srate spikeevents = (np.random.rand(srate) < (spk_rate / srate)).astype(np.float32) spiketimes = tvec[spikeevents.nonzero()] from indl.misc.kernels import sskernel, Gauss # Shimazaki et al. auto-kernel-width kernel_width = sskernel(spiketimes - spiketimes[0], nbs=0)[2] kernel_param = 1 / (2.0 * 2.7) * kernel_width span_fac = 3.0 t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Gauss(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.plot(t_kern, kernel) plt.xlim([-0.5, 0.5]) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd457d51910>] kernel_param = 0.050 # msec stdev span_fac = 3.0 # How many stdevs wide the kernel should be. Too short will truncate kernel. t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Gauss(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.plot(t_kern, kernel) plt.xlim([-0.5, 0.5]) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd455bcb0a0>] from indl.misc.kernels import Boxcar kernel_param = 0.05 # The width of the rectangle in seconds span_fac = np.sqrt(3.0) kernel_param /= (2*np.sqrt(3.0)) t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Boxcar(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.xlim([-0.5, 0.5]) plt.plot(t_kern, kernel) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd455a97c70>] from indl.misc.kernels import Alpha kernel_param = 0.03 # tau kernel_param *= np.sqrt(2) span_fac = 6.0 t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Alpha(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') print(np.sum(spikeevents), np.mean(spikerates)) plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.xlim([-0.5, 0.5]) plt.plot(t_kern, kernel) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) 10.0 9.538681202301868 [<matplotlib.lines.Line2D at 0x7fd4559f6ac0>] from indl.misc.kernels import Exponential kernel_param = 0.05 # the time constant tau when the kernel reaches 1/e the maximum. span_fac = 6.0 t_kern = np.arange(-span_fac * kernel_param, span_fac * kernel_param + (1 / srate), 1 / srate) kernel = Exponential(t_kern, kernel_param) spikerates = scipy.signal.convolve(spikeevents, kernel, 'same') plt.subplot(3, 1, 1) plt.plot(tvec, spikeevents) plt.subplot(3, 1, 2) plt.xlim([-0.5, 0.5]) plt.plot(t_kern, kernel) plt.subplot(3, 1, 3) plt.plot(tvec, spikerates) [<matplotlib.lines.Line2D at 0x7fd45594adf0>]","title":"Kernels"},{"location":"Miscellaneous/metrics/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Custom Metrics dprime [ src ] import numpy as np from indl.metrics import dprime y_true = np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) y_pred = np.array([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]) dprime(y_true, y_pred) (1.4847266404679265, 1.5839845538068775, 33.333333333333336)","title":"Metrics"},{"location":"Miscellaneous/metrics/#custom-metrics","text":"","title":"Custom Metrics"},{"location":"Miscellaneous/metrics/#dprime","text":"[ src ] import numpy as np from indl.metrics import dprime y_true = np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) y_pred = np.array([1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1]) dprime(y_true, y_pred) (1.4847266404679265, 1.5839845538068775, 33.333333333333336)","title":"dprime"},{"location":"Miscellaneous/sigfuncs/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Signal Functions Some useful signal functions. * sigmoid * minimum_jerk from indl.misc.sigfuncs import sigmoid import numpy as np import matplotlib.pyplot as plt x = np . arange ( - 6 , 6 , 0.1 ) plt . subplot ( 1 , 2 , 1 ) for B in [ 0.5 , 1 , 2 , 5 , 10 ]: plt . plot ( x , sigmoid ( x , B = B ), label = f \"B= { B } \" ) plt . legend () plt . subplot ( 1 , 2 , 2 ) for x_offset in [ - 3.0 , - 1.5 , 0 , 1.5 , 3.0 ]: plt . plot ( x , sigmoid ( x , x_offset = x_offset ), label = f \" { x_offset } \" ) plt . legend () plt . show () a = np . array ([[ 0.2 , 0.5 ]]) . T sigmoid ( x , A = a ) . shape (2, 120) from indl.misc.sigfuncs import minimum_jerk x = np . arange ( 0 , 6.0 , 0.1 ) for degree in [ 0 , 1 , 2 ]: plt . plot ( x , minimum_jerk ( x , degree = degree ), label = f \" { degree } \" ) plt . legend () plt . show () a = np . random . rand ( 5 , 2 ) Y = minimum_jerk ( x , a0 = a [:, 0 ], af = a [:, 1 ], degree = 0 ) plt . plot ( x , Y ) plt . show ()","title":"Sigfuncs"},{"location":"Miscellaneous/sigfuncs/#signal-functions","text":"Some useful signal functions. * sigmoid * minimum_jerk from indl.misc.sigfuncs import sigmoid import numpy as np import matplotlib.pyplot as plt x = np . arange ( - 6 , 6 , 0.1 ) plt . subplot ( 1 , 2 , 1 ) for B in [ 0.5 , 1 , 2 , 5 , 10 ]: plt . plot ( x , sigmoid ( x , B = B ), label = f \"B= { B } \" ) plt . legend () plt . subplot ( 1 , 2 , 2 ) for x_offset in [ - 3.0 , - 1.5 , 0 , 1.5 , 3.0 ]: plt . plot ( x , sigmoid ( x , x_offset = x_offset ), label = f \" { x_offset } \" ) plt . legend () plt . show () a = np . array ([[ 0.2 , 0.5 ]]) . T sigmoid ( x , A = a ) . shape (2, 120) from indl.misc.sigfuncs import minimum_jerk x = np . arange ( 0 , 6.0 , 0.1 ) for degree in [ 0 , 1 , 2 ]: plt . plot ( x , minimum_jerk ( x , degree = degree ), label = f \" { degree } \" ) plt . legend () plt . show () a = np . random . rand ( 5 , 2 ) Y = minimum_jerk ( x , a0 = a [:, 0 ], af = a [:, 1 ], degree = 0 ) plt . plot ( x , Y ) plt . show ()","title":"Signal Functions"}]}