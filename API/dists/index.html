
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.6">
    
    
      
        <title>dists - indl</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.cd566b2a.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#dists" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="indl" class="md-header__button md-logo" aria-label="indl" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            indl
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              dists
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/SachsLab/indl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="indl" class="md-nav__button md-logo" aria-label="indl" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    indl
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SachsLab/indl/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        data
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          dists
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        dists
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#indl.dists" class="md-nav__link">
    indl.dists
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell" class="md-nav__link">
    LearnableMultivariateNormalCell
  </a>
  
    <nav class="md-nav" aria-label="LearnableMultivariateNormalCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell.zero_state" class="md-nav__link">
    zero_state()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag" class="md-nav__link">
    LearnableMultivariateNormalDiag
  </a>
  
    <nav class="md-nav" aria-label="LearnableMultivariateNormalDiag">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.loc" class="md-nav__link">
    loc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.scale_diag" class="md-nav__link">
    scale_diag
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_learnable_mvn_params" class="md-nav__link">
    make_learnable_mvn_params()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_mvn_dist_fn" class="md-nav__link">
    make_mvn_dist_fn()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_mvn_prior" class="md-nav__link">
    make_mvn_prior()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_variational" class="md-nav__link">
    make_variational()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.sequential" class="md-nav__link">
    sequential
  </a>
  
    <nav class="md-nav" aria-label="sequential">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.AR1ProcessMVNGenerator" class="md-nav__link">
    AR1ProcessMVNGenerator
  </a>
  
    <nav class="md-nav" aria-label="AR1ProcessMVNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.AR1ProcessMVNGenerator.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMVNGenerator" class="md-nav__link">
    RNNMVNGenerator
  </a>
  
    <nav class="md-nav" aria-label="RNNMVNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMVNGenerator.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMVNGenerator.get_dist" class="md-nav__link">
    get_dist()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMultivariateNormalDiag" class="md-nav__link">
    RNNMultivariateNormalDiag
  </a>
  
    <nav class="md-nav" aria-label="RNNMultivariateNormalDiag">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMultivariateNormalDiag.cross_entropy" class="md-nav__link">
    cross_entropy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMultivariateNormalDiag.kl_divergence" class="md-nav__link">
    kl_divergence()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.TiledMVNGenerator" class="md-nav__link">
    TiledMVNGenerator
  </a>
  
    <nav class="md-nav" aria-label="TiledMVNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.TiledMVNGenerator.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.TiledMVNGenerator.get_dist" class="md-nav__link">
    get_dist()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.VariationalLSTMCell" class="md-nav__link">
    VariationalLSTMCell
  </a>
  
    <nav class="md-nav" aria-label="VariationalLSTMCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.VariationalLSTMCell.build" class="md-nav__link">
    build()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.VariationalLSTMCell.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../layers/" class="md-nav__link">
        layers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../misc/" class="md-nav__link">
        misc
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../rnn/" class="md-nav__link">
        rnn
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_7" type="checkbox" id="__nav_2_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_7">
          Model
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_7">
          <span class="md-nav__icon md-icon"></span>
          Model
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../model/beta_vae/" class="md-nav__link">
        model.beta_vae
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../model/lfads/" class="md-nav__link">
        lfads
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_8" type="checkbox" id="__nav_2_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_8">
          Utils
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Utils" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_8">
          <span class="md-nav__icon md-icon"></span>
          Utils
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/fileio/" class="md-nav__link">
        fileio
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/metrics/" class="md-nav__link">
        metrics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/regularizers/" class="md-nav__link">
        regularizers
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          DSAE
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="DSAE" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          DSAE
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DSAE/dsae/" class="md-nav__link">
        Dsae
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DSAE/recurrent_layers/" class="md-nav__link">
        Recurrent layers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DSAE/tfp_notes/" class="md-nav__link">
        Tfp notes
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DSAE/tfp_utils/" class="md-nav__link">
        Tfp utils
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Miscellaneous
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Miscellaneous" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Miscellaneous
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Miscellaneous/junk_model_inspect/" class="md-nav__link">
        Junk model inspect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Miscellaneous/kernels/" class="md-nav__link">
        Kernels
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Miscellaneous/metrics/" class="md-nav__link">
        Metrics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Miscellaneous/sigfuncs/" class="md-nav__link">
        Sigfuncs
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#indl.dists" class="md-nav__link">
    indl.dists
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell" class="md-nav__link">
    LearnableMultivariateNormalCell
  </a>
  
    <nav class="md-nav" aria-label="LearnableMultivariateNormalCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalCell.zero_state" class="md-nav__link">
    zero_state()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag" class="md-nav__link">
    LearnableMultivariateNormalDiag
  </a>
  
    <nav class="md-nav" aria-label="LearnableMultivariateNormalDiag">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.loc" class="md-nav__link">
    loc
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.scale_diag" class="md-nav__link">
    scale_diag
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.LearnableMultivariateNormalDiag.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_learnable_mvn_params" class="md-nav__link">
    make_learnable_mvn_params()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_mvn_dist_fn" class="md-nav__link">
    make_mvn_dist_fn()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_mvn_prior" class="md-nav__link">
    make_mvn_prior()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.make_variational" class="md-nav__link">
    make_variational()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indl.dists.sequential" class="md-nav__link">
    sequential
  </a>
  
    <nav class="md-nav" aria-label="sequential">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.AR1ProcessMVNGenerator" class="md-nav__link">
    AR1ProcessMVNGenerator
  </a>
  
    <nav class="md-nav" aria-label="AR1ProcessMVNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.AR1ProcessMVNGenerator.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMVNGenerator" class="md-nav__link">
    RNNMVNGenerator
  </a>
  
    <nav class="md-nav" aria-label="RNNMVNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMVNGenerator.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMVNGenerator.get_dist" class="md-nav__link">
    get_dist()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMultivariateNormalDiag" class="md-nav__link">
    RNNMultivariateNormalDiag
  </a>
  
    <nav class="md-nav" aria-label="RNNMultivariateNormalDiag">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMultivariateNormalDiag.cross_entropy" class="md-nav__link">
    cross_entropy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.RNNMultivariateNormalDiag.kl_divergence" class="md-nav__link">
    kl_divergence()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.TiledMVNGenerator" class="md-nav__link">
    TiledMVNGenerator
  </a>
  
    <nav class="md-nav" aria-label="TiledMVNGenerator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.TiledMVNGenerator.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.TiledMVNGenerator.get_dist" class="md-nav__link">
    get_dist()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.VariationalLSTMCell" class="md-nav__link">
    VariationalLSTMCell
  </a>
  
    <nav class="md-nav" aria-label="VariationalLSTMCell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.VariationalLSTMCell.build" class="md-nav__link">
    build()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indl.dists.sequential.VariationalLSTMCell.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
<a href="https://github.com/SachsLab/indl/edit/master/docs/API/dists.md" title="Edit this page" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
</a>


<h1 id="dists">dists</h1>


  <div class="doc doc-object doc-module">

<a id="indl.dists"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">










  <div class="doc doc-object doc-class">



<h2 id="indl.dists.LearnableMultivariateNormalCell" class="doc doc-heading">
        <code>
LearnableMultivariateNormalCell            (<span title="tensorflow.python.keras.engine.training.Model">Model</span>)
        </code>



</h2>

    <div class="doc doc-contents ">

      <p>Multivariate normal distribution RNN cell.</p>
<p>The model is a RNN-based recurrent function that computes the
parameters for a multivariate normal distribution at each timestep <code>t</code>.
Based on:
https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L242</p>

        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">LearnableMultivariateNormalCell</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Multivariate normal distribution RNN cell.</span>

<span class="sd">    The model is a RNN-based recurrent function that computes the</span>
<span class="sd">    parameters for a multivariate normal distribution at each timestep `t`.</span>
<span class="sd">    Based on:</span>
<span class="sd">    https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L242</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">shift_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">cell_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span><span class="p">,</span> <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructs a learnable multivariate normal cell.</span>

<span class="sd">        Args:</span>
<span class="sd">          units: Dimensionality of the RNN function parameters.</span>
<span class="sd">          out_dim: The dimensionality of the distribution.</span>
<span class="sd">          shift_std: Shift applied to MVN std before building the dist. Providing a shift</span>
<span class="sd">            toward the expected std allows the input values to be closer to 0.</span>
<span class="sd">          cell_type: an RNN cell type among &#39;lstm&#39;, &#39;gru&#39;, &#39;rnn&#39;, &#39;gruclip&#39;. case-insensitive.</span>
<span class="sd">          offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LearnableMultivariateNormalCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offdiag</span> <span class="o">=</span> <span class="n">offdiag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span> <span class="o">=</span> <span class="n">out_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span>
        <span class="k">if</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;LSTM&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">implementation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell&quot;</span><span class="p">)</span>
            <span class="c1"># why does the jupyter notebook version require implementation=1 but not in pycharm?</span>
        <span class="k">elif</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;GRU&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvnell&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;RNN&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">SimpleRNNCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;GRUCLIP&#39;</span><span class="p">):</span>
            <span class="kn">from</span> <span class="nn">indl.rnn.gru_clip</span> <span class="kn">import</span> <span class="n">GRUClipCell</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">GRUClipCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cell_type </span><span class="si">%s</span><span class="s2"> not recognized&quot;</span> <span class="o">%</span> <span class="n">cell_type</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loc_layer</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell_loc&quot;</span><span class="p">)</span>
        <span class="n">n_scale_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">tfpl</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="o">.</span><span class="n">params_size</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span> <span class="o">-</span> <span class="n">out_dim</span><span class="p">)</span> <span class="k">if</span> <span class="n">offdiag</span>\
            <span class="k">else</span> <span class="p">(</span><span class="n">tfpl</span><span class="o">.</span><span class="n">IndependentNormal</span><span class="o">.</span><span class="n">params_size</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span> <span class="o">-</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_untransformed_layer</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_scale_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvndiagcell_scale&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_scale_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">shift_std</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1">#def build(self, input_shape):</span>
        <span class="c1">#super(LearnableMultivariateNormalDiagCell, self).build(input_shape)</span>
        <span class="c1">#self.lstm_cell.build(input_shape)</span>
        <span class="c1">#self.loc_layer.build(input_shape)</span>
        <span class="c1">#self.scale_untransformed_layer.build(input_shape)</span>
        <span class="c1">#self.built = True</span>

    <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_batch_shape</span><span class="o">=</span><span class="p">()):</span>
        <span class="sd">&quot;&quot;&quot;Returns an initial state for the RNN cell.</span>

<span class="sd">        Args:</span>
<span class="sd">          sample_batch_shape: A 0D or 1D tensor of the combined sample and</span>
<span class="sd">            batch shape.</span>

<span class="sd">        Returns:</span>
<span class="sd">          A tuple of the initial previous output at timestep 0 of shape</span>
<span class="sd">          [sample_batch_shape, dimensions], and the cell state.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">zero_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">sample_batch_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">sample_batch_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">sample_batch_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">out_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">sample_batch_shape</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">previous_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">previous_output</span><span class="p">,</span> <span class="n">zero_state</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Runs the model to generate a distribution for a single timestep.</span>

<span class="sd">        This generates a batched MultivariateNormalDiag distribution using</span>
<span class="sd">        the output of the recurrent model at the current timestep to</span>
<span class="sd">        parameterize the distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">          inputs: The sampled value of `z` at the previous timestep, i.e.,</span>
<span class="sd">            `z_{t-1}`, of shape [..., dimensions].</span>
<span class="sd">            `z_0` should be set to the empty matrix.</span>
<span class="sd">          state: A tuple containing the (hidden, cell) state.</span>

<span class="sd">        Returns:</span>
<span class="sd">          A tuple of a MultivariateNormalDiag distribution, and the state of</span>
<span class="sd">          the recurrent function at the end of the current timestep. The</span>
<span class="sd">          distribution will have event shape [dimensions], batch shape</span>
<span class="sd">          [...], and sample shape [sample_shape, ..., dimensions].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># In order to allow the user to pass in a single example without a batch</span>
        <span class="c1"># dimension, we always expand the input to at least two dimensions, then</span>
        <span class="c1"># fix the output shape to remove the batch dimension if necessary.</span>
        <span class="n">original_shape</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">parms_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">original_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span><span class="p">]),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc_layer</span><span class="p">(</span><span class="n">out</span><span class="p">),</span> <span class="n">parms_shape</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_untransformed_layer</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">scale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale_shift</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">parms_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offdiag</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span> <span class="n">state</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="indl.dists.LearnableMultivariateNormalCell.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">shift_std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cell_type</span><span class="o">=</span><span class="s1">&#39;lstm&#39;</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Constructs a learnable multivariate normal cell.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>units</code></td>
        <td><code>int</code></td>
        <td><p>Dimensionality of the RNN function parameters.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>out_dim</code></td>
        <td><code>int</code></td>
        <td><p>The dimensionality of the distribution.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>shift_std</code></td>
        <td><code>float</code></td>
        <td><p>Shift applied to MVN std before building the dist. Providing a shift
toward the expected std allows the input values to be closer to 0.</p></td>
        <td><code>0.1</code></td>
      </tr>
      <tr>
        <td><code>cell_type</code></td>
        <td><code>str</code></td>
        <td><p>an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive.</p></td>
        <td><code>&#39;lstm&#39;</code></td>
      </tr>
      <tr>
        <td><code>offdiag</code></td>
        <td><code>bool</code></td>
        <td><p>set True to allow non-zero covariance (within-timestep) in the returned distribution.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
             <span class="n">shift_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">cell_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span><span class="p">,</span> <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a learnable multivariate normal cell.</span>

<span class="sd">    Args:</span>
<span class="sd">      units: Dimensionality of the RNN function parameters.</span>
<span class="sd">      out_dim: The dimensionality of the distribution.</span>
<span class="sd">      shift_std: Shift applied to MVN std before building the dist. Providing a shift</span>
<span class="sd">        toward the expected std allows the input values to be closer to 0.</span>
<span class="sd">      cell_type: an RNN cell type among &#39;lstm&#39;, &#39;gru&#39;, &#39;rnn&#39;, &#39;gruclip&#39;. case-insensitive.</span>
<span class="sd">      offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LearnableMultivariateNormalCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">offdiag</span> <span class="o">=</span> <span class="n">offdiag</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span> <span class="o">=</span> <span class="n">out_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span>
    <span class="k">if</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;LSTM&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">implementation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell&quot;</span><span class="p">)</span>
        <span class="c1"># why does the jupyter notebook version require implementation=1 but not in pycharm?</span>
    <span class="k">elif</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;GRU&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvnell&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;RNN&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">SimpleRNNCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">cell_type</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;GRUCLIP&#39;</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">indl.rnn.gru_clip</span> <span class="kn">import</span> <span class="n">GRUClipCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span> <span class="o">=</span> <span class="n">GRUClipCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cell_type </span><span class="si">%s</span><span class="s2"> not recognized&quot;</span> <span class="o">%</span> <span class="n">cell_type</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">loc_layer</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvncell_loc&quot;</span><span class="p">)</span>
    <span class="n">n_scale_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">tfpl</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="o">.</span><span class="n">params_size</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span> <span class="o">-</span> <span class="n">out_dim</span><span class="p">)</span> <span class="k">if</span> <span class="n">offdiag</span>\
        <span class="k">else</span> <span class="p">(</span><span class="n">tfpl</span><span class="o">.</span><span class="n">IndependentNormal</span><span class="o">.</span><span class="n">params_size</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span> <span class="o">-</span> <span class="n">out_dim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scale_untransformed_layer</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_scale_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mvndiagcell_scale&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_scale_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">shift_std</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1">#def build(self, input_shape):</span>
    <span class="c1">#super(LearnableMultivariateNormalDiagCell, self).build(input_shape)</span>
    <span class="c1">#self.lstm_cell.build(input_shape)</span>
    <span class="c1">#self.loc_layer.build(input_shape)</span>
    <span class="c1">#self.scale_untransformed_layer.build(input_shape)</span>
    <span class="c1">#self.built = True</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="indl.dists.LearnableMultivariateNormalCell.call" class="doc doc-heading">
<code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Runs the model to generate a distribution for a single timestep.</p>
<p>This generates a batched MultivariateNormalDiag distribution using
the output of the recurrent model at the current timestep to
parameterize the distribution.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>inputs</code></td>
        <td></td>
        <td><p>The sampled value of <code>z</code> at the previous timestep, i.e.,
<code>z_{t-1}</code>, of shape [..., dimensions].
<code>z_0</code> should be set to the empty matrix.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>state</code></td>
        <td></td>
        <td><p>A tuple containing the (hidden, cell) state.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>A tuple of a MultivariateNormalDiag distribution, and the state of
the recurrent function at the end of the current timestep. The
distribution will have event shape [dimensions], batch shape
[...], and sample shape [sample_shape, ..., dimensions].</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs the model to generate a distribution for a single timestep.</span>

<span class="sd">    This generates a batched MultivariateNormalDiag distribution using</span>
<span class="sd">    the output of the recurrent model at the current timestep to</span>
<span class="sd">    parameterize the distribution.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: The sampled value of `z` at the previous timestep, i.e.,</span>
<span class="sd">        `z_{t-1}`, of shape [..., dimensions].</span>
<span class="sd">        `z_0` should be set to the empty matrix.</span>
<span class="sd">      state: A tuple containing the (hidden, cell) state.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of a MultivariateNormalDiag distribution, and the state of</span>
<span class="sd">      the recurrent function at the end of the current timestep. The</span>
<span class="sd">      distribution will have event shape [dimensions], batch shape</span>
<span class="sd">      [...], and sample shape [sample_shape, ..., dimensions].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># In order to allow the user to pass in a single example without a batch</span>
    <span class="c1"># dimension, we always expand the input to at least two dimensions, then</span>
    <span class="c1"># fix the output shape to remove the batch dimension if necessary.</span>
    <span class="n">original_shape</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">parms_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">original_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span><span class="p">]),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc_layer</span><span class="p">(</span><span class="n">out</span><span class="p">),</span> <span class="n">parms_shape</span><span class="p">)</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_untransformed_layer</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">scale</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale_shift</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">parms_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offdiag</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">),</span> <span class="n">state</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="indl.dists.LearnableMultivariateNormalCell.zero_state" class="doc doc-heading">
<code class="highlight language-python"><span class="n">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_batch_shape</span><span class="o">=</span><span class="p">())</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns an initial state for the RNN cell.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>sample_batch_shape</code></td>
        <td></td>
        <td><p>A 0D or 1D tensor of the combined sample and
batch shape.</p></td>
        <td><code>()</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>A tuple of the initial previous output at timestep 0 of shape
[sample_batch_shape, dimensions], and the cell state.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_batch_shape</span><span class="o">=</span><span class="p">()):</span>
    <span class="sd">&quot;&quot;&quot;Returns an initial state for the RNN cell.</span>

<span class="sd">    Args:</span>
<span class="sd">      sample_batch_shape: A 0D or 1D tensor of the combined sample and</span>
<span class="sd">        batch shape.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of the initial previous output at timestep 0 of shape</span>
<span class="sd">      [sample_batch_shape, dimensions], and the cell state.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">zero_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">sample_batch_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">sample_batch_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">sample_batch_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">out_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">sample_batch_shape</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dimensions</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">previous_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">previous_output</span><span class="p">,</span> <span class="n">zero_state</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="indl.dists.LearnableMultivariateNormalDiag" class="doc doc-heading">
        <code>
LearnableMultivariateNormalDiag            (<span title="tensorflow.python.keras.engine.training.Model">Model</span>)
        </code>



</h2>

    <div class="doc doc-contents ">

      <p>Learnable multivariate diagonal normal distribution.</p>
<p>The model is a multivariate normal distribution with learnable
<code>mean</code> and <code>stddev</code> parameters.</p>
<p>See make_mvn_prior for a description.</p>

        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">LearnableMultivariateNormalDiag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Learnable multivariate diagonal normal distribution.</span>

<span class="sd">    The model is a multivariate normal distribution with learnable</span>
<span class="sd">    `mean` and `stddev` parameters.</span>

<span class="sd">    See make_mvn_prior for a description.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructs a learnable multivariate diagonal normal model.</span>

<span class="sd">        Args:</span>
<span class="sd">          dimensions: An integer corresponding to the dimensionality of the</span>
<span class="sd">            distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LearnableMultivariateNormalDiag</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dimensions</span> <span class="o">=</span> <span class="n">dimensions</span>
            <span class="k">if</span> <span class="n">trainable_mean</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">dimensions</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dimensions</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">trainable_var</span><span class="p">:</span>
                <span class="n">_scale_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">init_std</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">TransformedVariable</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">dimensions</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">init_std</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                    <span class="n">bijector</span><span class="o">=</span><span class="n">tfb</span><span class="o">.</span><span class="n">Chain</span><span class="p">([</span><span class="n">tfb</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">),</span> <span class="n">tfb</span><span class="o">.</span><span class="n">Softplus</span><span class="p">(),</span> <span class="n">tfb</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span><span class="n">_scale_shift</span><span class="p">)]),</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;transformed_scale&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">init_std</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dimensions</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Allow this Model to be called without inputs.</span>
        <span class="n">dummy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimensions</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">LearnableMultivariateNormalDiag</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span>
            <span class="n">dummy</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Runs the model to generate multivariate normal distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">          inputs: Unused.</span>

<span class="sd">        Returns:</span>
<span class="sd">          A MultivariateNormalDiag distribution with event shape</span>
<span class="sd">          [dimensions], batch shape [], and sample shape [sample_shape,</span>
<span class="sd">          dimensions].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">del</span> <span class="n">inputs</span>  <span class="c1"># unused</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_diag</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">loc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The mean of the normal distribution.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">scale_diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The diagonal standard deviation of the normal distribution.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h3 id="indl.dists.LearnableMultivariateNormalDiag.loc" class="doc doc-heading">
<code class="highlight language-python"><span class="n">loc</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>The mean of the normal distribution.</p>
    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h3 id="indl.dists.LearnableMultivariateNormalDiag.scale_diag" class="doc doc-heading">
<code class="highlight language-python"><span class="n">scale_diag</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>The diagonal standard deviation of the normal distribution.</p>
    </div>

  </div>







  <div class="doc doc-object doc-method">



<h3 id="indl.dists.LearnableMultivariateNormalDiag.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Constructs a learnable multivariate diagonal normal model.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>dimensions</code></td>
        <td></td>
        <td><p>An integer corresponding to the dimensionality of the
distribution.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a learnable multivariate diagonal normal model.</span>

<span class="sd">    Args:</span>
<span class="sd">      dimensions: An integer corresponding to the dimensionality of the</span>
<span class="sd">        distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LearnableMultivariateNormalDiag</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dimensions</span> <span class="o">=</span> <span class="n">dimensions</span>
        <span class="k">if</span> <span class="n">trainable_mean</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">dimensions</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dimensions</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trainable_var</span><span class="p">:</span>
            <span class="n">_scale_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">init_std</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">TransformedVariable</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">dimensions</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">init_std</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                <span class="n">bijector</span><span class="o">=</span><span class="n">tfb</span><span class="o">.</span><span class="n">Chain</span><span class="p">([</span><span class="n">tfb</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">),</span> <span class="n">tfb</span><span class="o">.</span><span class="n">Softplus</span><span class="p">(),</span> <span class="n">tfb</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span><span class="n">_scale_shift</span><span class="p">)]),</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;transformed_scale&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">init_std</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dimensions</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="indl.dists.LearnableMultivariateNormalDiag.call" class="doc doc-heading">
<code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Runs the model to generate multivariate normal distribution.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>inputs</code></td>
        <td></td>
        <td><p>Unused.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>A MultivariateNormalDiag distribution with event shape
[dimensions], batch shape [], and sample shape [sample_shape,
dimensions].</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs the model to generate multivariate normal distribution.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: Unused.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A MultivariateNormalDiag distribution with event shape</span>
<span class="sd">      [dimensions], batch shape [], and sample shape [sample_shape,</span>
<span class="sd">      dimensions].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">del</span> <span class="n">inputs</span>  <span class="c1"># unused</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_diag</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>




  <div class="doc doc-object doc-function">



<h2 id="indl.dists.make_learnable_mvn_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">make_learnable_mvn_params</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Return mean (loc) and stddev (scale) parameters for initializing multivariate normal distributions.
If trainable_mean then it will be initialized with random normal (stddev=0.1), otherwise zeros.
If trainable_var then it will be initialized with random normal centered at a value such that the
    bijector transformation yields the value in init_std. When init_std is 1.0 (default) then the
    inverse-bijected value is approximately 0.0.
    If not trainable_var then scale is a vector or matrix of init_std of appropriate shape for the dist.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ndim</code></td>
        <td><code>int</code></td>
        <td><p>Number of dimensions.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>init_std</code></td>
        <td><code>float</code></td>
        <td><p>Initial value for the standard deviation.</p></td>
        <td><code>1.0</code></td>
      </tr>
      <tr>
        <td><code>trainable_mean</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not the mean (loc) is a trainable tf.Variable.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>trainable_var</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not the variance (scale) is a trainable tf.Variable.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>offdiag</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not off-diagonal elements are allowed.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>      <p>Returns: loc, scale</p>

        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_learnable_mvn_params</span><span class="p">(</span><span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">init_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                              <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return mean (loc) and stddev (scale) parameters for initializing multivariate normal distributions.</span>
<span class="sd">    If trainable_mean then it will be initialized with random normal (stddev=0.1), otherwise zeros.</span>
<span class="sd">    If trainable_var then it will be initialized with random normal centered at a value such that the</span>
<span class="sd">        bijector transformation yields the value in init_std. When init_std is 1.0 (default) then the</span>
<span class="sd">        inverse-bijected value is approximately 0.0.</span>
<span class="sd">        If not trainable_var then scale is a vector or matrix of init_std of appropriate shape for the dist.</span>
<span class="sd">    Args:</span>
<span class="sd">        ndim: Number of dimensions.</span>
<span class="sd">        init_std: Initial value for the standard deviation.</span>
<span class="sd">        trainable_mean: Whether or not the mean (loc) is a trainable tf.Variable.</span>
<span class="sd">        trainable_var: Whether or not the variance (scale) is a trainable tf.Variable.</span>
<span class="sd">        offdiag: Whether or not off-diagonal elements are allowed.</span>

<span class="sd">    Returns: loc, scale</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">trainable_mean</span><span class="p">:</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">ndim</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span>
    <span class="c1"># Initialize the variance (scale), trainable or not, offdiag or not.</span>
    <span class="k">if</span> <span class="n">trainable_var</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">offdiag</span><span class="p">:</span>
            <span class="n">_ndim</span> <span class="o">=</span> <span class="p">[</span><span class="n">ndim</span><span class="p">,</span> <span class="n">ndim</span><span class="p">]</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">TransformedVariable</span><span class="p">(</span>
                <span class="c1"># init_std * tf.eye(ndim, dtype=tf.float32),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">_ndim</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">init_std</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                <span class="n">tfp</span><span class="o">.</span><span class="n">bijectors</span><span class="o">.</span><span class="n">FillScaleTriL</span><span class="p">(),</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;prior_scale&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_scale_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">init_std</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># tfp.math.softplus_inverse(init_std)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">TransformedVariable</span><span class="p">(</span>
                <span class="c1"># init_std * tf.ones(ndim, dtype=tf.float32),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">ndim</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">init_std</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                <span class="n">tfb</span><span class="o">.</span><span class="n">Chain</span><span class="p">([</span><span class="n">tfb</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">),</span> <span class="n">tfb</span><span class="o">.</span><span class="n">Softplus</span><span class="p">(),</span> <span class="n">tfb</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span><span class="n">_scale_shift</span><span class="p">)]),</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;prior_scale&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">offdiag</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">init_std</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">init_std</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="indl.dists.make_mvn_dist_fn" class="doc doc-heading">
<code class="highlight language-python"><span class="n">make_mvn_dist_fn</span><span class="p">(</span><span class="n">_x_</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">shift_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loc_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_mvn_diag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Take a 1-D tensor and use it to parameterize a MVN dist.
This doesn't return the distribution, but the function to make the distribution and its arguments.
make_dist_fn, [loc, scale]
You can supply it to tfpl.DistributionLambda</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>_x_</code></td>
        <td><code>Tensor</code></td>
        <td></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>ndim</code></td>
        <td><code>int</code></td>
        <td></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>shift_std</code></td>
        <td><code>float</code></td>
        <td></td>
        <td><code>1.0</code></td>
      </tr>
      <tr>
        <td><code>offdiag</code></td>
        <td><code>bool</code></td>
        <td></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>loc_name</code></td>
        <td><code>Optional[str]</code></td>
        <td></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>scale_name</code></td>
        <td><code>Optional[str]</code></td>
        <td></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>use_mvn_diag</code></td>
        <td><code>bool</code></td>
        <td></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[Callable[[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.ops.Tensor], tensorflow_probability.python.distributions.distribution.Distribution], List[tensorflow.python.framework.ops.Tensor]]</code></td>
      <td><p>make_dist_fn, [loc, scale]</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_mvn_dist_fn</span><span class="p">(</span><span class="n">_x_</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">shift_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                     <span class="n">loc_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">scale_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">use_mvn_diag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
                     <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Distribution</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Take a 1-D tensor and use it to parameterize a MVN dist.</span>
<span class="sd">    This doesn&#39;t return the distribution, but the function to make the distribution and its arguments.</span>
<span class="sd">    make_dist_fn, [loc, scale]</span>
<span class="sd">    You can supply it to tfpl.DistributionLambda</span>

<span class="sd">    Args:</span>
<span class="sd">        _x_:</span>
<span class="sd">        ndim:</span>
<span class="sd">        shift_std:</span>
<span class="sd">        offdiag:</span>
<span class="sd">        loc_name:</span>
<span class="sd">        scale_name:</span>
<span class="sd">        use_mvn_diag:</span>

<span class="sd">    Returns:</span>
<span class="sd">        make_dist_fn, [loc, scale]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_scale_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">shift_std</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">_loc</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">loc_name</span><span class="p">)(</span><span class="n">_x_</span><span class="p">)</span>

    <span class="n">n_scale_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">tfpl</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="o">.</span><span class="n">params_size</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span> <span class="o">-</span> <span class="n">ndim</span><span class="p">)</span> <span class="k">if</span> <span class="n">offdiag</span>\
        <span class="k">else</span> <span class="p">(</span><span class="n">tfpl</span><span class="o">.</span><span class="n">IndependentNormal</span><span class="o">.</span><span class="n">params_size</span><span class="p">(</span><span class="n">ndim</span><span class="p">)</span> <span class="o">-</span> <span class="n">ndim</span><span class="p">)</span>
    <span class="n">_scale</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_scale_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">scale_name</span><span class="p">)(</span><span class="n">_x_</span><span class="p">)</span>
    <span class="n">_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">_scale</span> <span class="o">+</span> <span class="n">_scale_shift</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span>
    <span class="k">if</span> <span class="n">offdiag</span><span class="p">:</span>
        <span class="n">_scale</span> <span class="o">=</span> <span class="n">tfb</span><span class="o">.</span><span class="n">FillTriangular</span><span class="p">()(</span><span class="n">_scale</span><span class="p">)</span>
        <span class="n">make_dist_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_mvn_diag</span><span class="p">:</span>  <span class="c1"># Match type with prior</span>
            <span class="n">make_dist_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">make_dist_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">make_dist_fn</span><span class="p">,</span> <span class="p">[</span><span class="n">_loc</span><span class="p">,</span> <span class="n">_scale</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="indl.dists.make_mvn_prior" class="doc doc-heading">
<code class="highlight language-python"><span class="n">make_mvn_prior</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Creates a tensorflow-probability distribution:
    MultivariateNormalTriL if offdiag else MultivariateNormalDiag
Mean (loc) and sigma (scale) can be trainable or not.
Mean initializes to random.normal around 0 (stddev=0.1) if trainable, else zeros.
Scale initialies to init_std if not trainable. If it is trainable, it initializes
 to a tfp TransformedVariable that will be centered at 0 for easy training under the hood,
 but will be transformed via softplus to give something initially close to init_var.</p>
<p>loc and scale are tracked by the MVNDiag class.</p>
<p>For LFADS ics prior, trainable_mean=True, trainable_var=False
For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True
In either case, var was initialized with 0.1 (==&gt; logvar with log(0.1))
Unlike the LFADS' LearnableDiagonalGaussian, here we don't support multi-dimensional, just a vector.</p>
<p>See also LearnableMultivariateNormalDiag for a tf.keras.Model version of this.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ndim</code></td>
        <td><code>int</code></td>
        <td><p>latent dimension of distribution. Currently only supports 1 d (I think )</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>init_std</code></td>
        <td><code>float</code></td>
        <td><p>initial standard deviation of the gaussian. If trainable_var then the initial standard deviation
will be drawn from a random.normal distribution with mean init_std and stddev 1/10th of that.</p></td>
        <td><code>1.0</code></td>
      </tr>
      <tr>
        <td><code>trainable_mean</code></td>
        <td><code>bool</code></td>
        <td><p>If the mean should be a tf.Variable</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>trainable_var</code></td>
        <td><code>bool</code></td>
        <td><p>If the variance/stddev/scale (whatever you call it) should be a tf.Variable</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>offdiag</code></td>
        <td><code>bool</code></td>
        <td><p>If the variance-covariance matrix is allowed non-zero off-diagonal elements.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL]</code></td>
      <td><p>A tensorflow-probability distribution (either MultivariateNormalTriL or MultivariateNormalDiag).</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_mvn_prior</span><span class="p">(</span><span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">init_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                   <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">,</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a tensorflow-probability distribution:</span>
<span class="sd">        MultivariateNormalTriL if offdiag else MultivariateNormalDiag</span>
<span class="sd">    Mean (loc) and sigma (scale) can be trainable or not.</span>
<span class="sd">    Mean initializes to random.normal around 0 (stddev=0.1) if trainable, else zeros.</span>
<span class="sd">    Scale initialies to init_std if not trainable. If it is trainable, it initializes</span>
<span class="sd">     to a tfp TransformedVariable that will be centered at 0 for easy training under the hood,</span>
<span class="sd">     but will be transformed via softplus to give something initially close to init_var.</span>

<span class="sd">    loc and scale are tracked by the MVNDiag class.</span>

<span class="sd">    For LFADS ics prior, trainable_mean=True, trainable_var=False</span>
<span class="sd">    For LFADS cos prior (if not using AR1), trainable_mean=False, trainable_var=True</span>
<span class="sd">    In either case, var was initialized with 0.1 (==&gt; logvar with log(0.1))</span>
<span class="sd">    Unlike the LFADS&#39; LearnableDiagonalGaussian, here we don&#39;t support multi-dimensional, just a vector.</span>

<span class="sd">    See also LearnableMultivariateNormalDiag for a tf.keras.Model version of this.</span>

<span class="sd">    Args:</span>
<span class="sd">        ndim: latent dimension of distribution. Currently only supports 1 d (I think )</span>
<span class="sd">        init_std: initial standard deviation of the gaussian. If trainable_var then the initial standard deviation</span>
<span class="sd">            will be drawn from a random.normal distribution with mean init_std and stddev 1/10th of that.</span>
<span class="sd">        trainable_mean: If the mean should be a tf.Variable</span>
<span class="sd">        trainable_var: If the variance/stddev/scale (whatever you call it) should be a tf.Variable</span>
<span class="sd">        offdiag: If the variance-covariance matrix is allowed non-zero off-diagonal elements.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensorflow-probability distribution (either MultivariateNormalTriL or MultivariateNormalDiag).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">make_learnable_mvn_params</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span>
                                           <span class="n">trainable_mean</span><span class="o">=</span><span class="n">trainable_mean</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="n">trainable_var</span><span class="p">,</span>
                                           <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">)</span>

    <span class="c1"># Initialize the prior.</span>
    <span class="k">if</span> <span class="n">offdiag</span><span class="p">:</span>
        <span class="c1"># Note: Diag must be &gt; 0, upper triangular must be 0, and lower triangular may be != 0.</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span>
            <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span>
            <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="c1"># kl_exact needs same dist types for prior and latent.</span>
        <span class="c1"># We would switch to the next line if we switched our latent to using tf.Independent(tfd.Normal)</span>
        <span class="c1"># prior = tfd.Independent(tfd.Normal(loc=tf.zeros(ndim), scale=1), reinterpreted_batch_ndims=1)</span>

    <span class="k">return</span> <span class="n">prior</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="indl.dists.make_variational" class="doc doc-heading">
<code class="highlight language-python"><span class="n">make_variational</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dist_dim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">samps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">loc_name</span><span class="o">=</span><span class="s1">&#39;loc&#39;</span><span class="p">,</span> <span class="n">scale_name</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">dist_name</span><span class="o">=</span><span class="s1">&#39;q&#39;</span><span class="p">,</span> <span class="n">use_mvn_diag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Take an input tensor and return a multivariate normal distribution parameterized by that input tensor.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>x</code></td>
        <td><code>Tensor</code></td>
        <td><p>input tensor</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dist_dim</code></td>
        <td><code>int</code></td>
        <td><p>the dimensionality of the distribution</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>init_std</code></td>
        <td><code>float</code></td>
        <td><p>initial stddev SHIFT of the distribution when input is 0.</p></td>
        <td><code>1.0</code></td>
      </tr>
      <tr>
        <td><code>offdiag</code></td>
        <td><code>bool</code></td>
        <td><p>whether or not to include covariances</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>samps</code></td>
        <td><code>int</code></td>
        <td><p>the number of samples to draw when using implied convert_to_tensor_fn</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>loc_name</code></td>
        <td></td>
        <td><p>not used (I need to handle naming better)</p></td>
        <td><code>&#39;loc&#39;</code></td>
      </tr>
      <tr>
        <td><code>scale_name</code></td>
        <td></td>
        <td><p>not used</p></td>
        <td><code>&#39;scale&#39;</code></td>
      </tr>
      <tr>
        <td><code>dist_name</code></td>
        <td></td>
        <td><p>not used</p></td>
        <td><code>&#39;q&#39;</code></td>
      </tr>
      <tr>
        <td><code>use_mvn_diag</code></td>
        <td><code>bool</code></td>
        <td><p>whether to use tfd.MultivariateNormal(Diag|TriL) (True) or tfd.Independent(tfd.Normal) (False)
Latter is untested. Note that the mvn dists will put the timesteps dimension (if present in the input)
into the "batch dimension" while the "event" dimension will be the last dimension only.
You can use tfd.Independent(q_dist, reinterpreted_batch_ndims=1) to move the timestep dimension to the
event dimension if necessary. (tfd.Independent doesn't play well with tf.keras.Model inputs/outputs).</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag, tensorflow_probability.python.distributions.mvn_tril.MultivariateNormalTriL, tensorflow_probability.python.distributions.independent.Independent]</code></td>
      <td><p>A tfd.Distribution. The distribution is of type MultivariateNormalDiag (or MultivariateNormalTriL if offdiag)
if use_mvn_diag is set.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/__init__.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_variational</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dist_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                     <span class="n">init_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                     <span class="n">samps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="n">loc_name</span><span class="o">=</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span> <span class="n">scale_name</span><span class="o">=</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span>
                     <span class="n">dist_name</span><span class="o">=</span><span class="s2">&quot;q&quot;</span><span class="p">,</span>
                     <span class="n">use_mvn_diag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
                     <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">,</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">,</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Take an input tensor and return a multivariate normal distribution parameterized by that input tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: input tensor</span>
<span class="sd">        dist_dim: the dimensionality of the distribution</span>
<span class="sd">        init_std: initial stddev SHIFT of the distribution when input is 0.</span>
<span class="sd">        offdiag: whether or not to include covariances</span>
<span class="sd">        samps: the number of samples to draw when using implied convert_to_tensor_fn</span>
<span class="sd">        loc_name: not used (I need to handle naming better)</span>
<span class="sd">        scale_name: not used</span>
<span class="sd">        dist_name: not used</span>
<span class="sd">        use_mvn_diag: whether to use tfd.MultivariateNormal(Diag|TriL) (True) or tfd.Independent(tfd.Normal) (False)</span>
<span class="sd">            Latter is untested. Note that the mvn dists will put the timesteps dimension (if present in the input)</span>
<span class="sd">            into the &quot;batch dimension&quot; while the &quot;event&quot; dimension will be the last dimension only.</span>
<span class="sd">            You can use tfd.Independent(q_dist, reinterpreted_batch_ndims=1) to move the timestep dimension to the</span>
<span class="sd">            event dimension if necessary. (tfd.Independent doesn&#39;t play well with tf.keras.Model inputs/outputs).</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tfd.Distribution. The distribution is of type MultivariateNormalDiag (or MultivariateNormalTriL if offdiag)</span>
<span class="sd">        if use_mvn_diag is set.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">make_dist_fn</span><span class="p">,</span> <span class="n">dist_params</span> <span class="o">=</span> <span class="n">make_mvn_dist_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dist_dim</span><span class="p">,</span> <span class="n">shift_std</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span>
                                                 <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">,</span>
                                                 <span class="c1"># loc_name=loc_name, scale_name=scale_name,</span>
                                                 <span class="n">use_mvn_diag</span><span class="o">=</span><span class="n">use_mvn_diag</span><span class="p">)</span>
    <span class="c1"># Python `callable` that takes a `tfd.Distribution`</span>
    <span class="c1">#         instance and returns a `tf.Tensor`-like object.</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    # Unfortunately I couldn&#39;t get this to work :(</span>
<span class="sd">    # Will have to explicitly q_f.value() | qf.mean() from dist in train_step</span>
<span class="sd">    def custom_convert_fn(d, training=None):</span>
<span class="sd">        if training is None:</span>
<span class="sd">            training = K.learning_phase()</span>
<span class="sd">        output = tf_utils.smart_cond(training,</span>
<span class="sd">                                     lambda: d.sample(samps),</span>
<span class="sd">                                     lambda: d.mean()</span>
<span class="sd">                                     )</span>
<span class="sd">        return output</span>
<span class="sd">    def convert_fn(d):</span>
<span class="sd">        return K.in_train_phase(tfd.Distribution.sample if samps &lt;= 1 else lambda: d.sample(samps),</span>
<span class="sd">        lambda: d.mean())</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">convert_fn</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Distribution</span><span class="o">.</span><span class="n">sample</span> <span class="k">if</span> <span class="n">samps</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="k">else</span> <span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">samps</span><span class="p">)</span>
    <span class="n">q_dist</span> <span class="o">=</span> <span class="n">tfpl</span><span class="o">.</span><span class="n">DistributionLambda</span><span class="p">(</span><span class="n">make_distribution_fn</span><span class="o">=</span><span class="n">make_dist_fn</span><span class="p">,</span>
                                     <span class="n">convert_to_tensor_fn</span><span class="o">=</span><span class="n">convert_fn</span><span class="p">,</span>
                                     <span class="p">)(</span><span class="n">dist_params</span><span class="p">)</span>
    <span class="c1"># if tf.shape(x).shape[0] &gt; 2:</span>
    <span class="c1">#     q_dist = tfd.Independent(q_dist, reinterpreted_batch_ndims=1)</span>
    <span class="k">return</span> <span class="n">q_dist</span>
</code></pre></div>
        </details>
    </div>

  </div>





  <div class="doc doc-object doc-module">



<h2 id="indl.dists.sequential" class="doc doc-heading">
        <code>sequential</code>



</h2>

    <div class="doc doc-contents ">




  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h3 id="indl.dists.sequential.AR1ProcessMVNGenerator" class="doc doc-heading">
        <code>
AR1ProcessMVNGenerator            (<span title="indl.dists.sequential.IProcessMVNGenerator">IProcessMVNGenerator</span>)
        </code>



</h3>

    <div class="doc doc-contents ">

      <p>Similar to LFADS' LearnableAutoRegressive1Prior.
Here we use the terminology from:
https://en.wikipedia.org/wiki/Autoregressive_model#Example:_An_AR(1)_process</p>
<p>The autoregressive function takes the form:
    E(X_t) = E(c) + phi * E(X_{t-1}) + e_t
E(c) is a constant.
phi is a parameter, which is equivalent to exp(-1/tau) = exp(-exp(-logtau)).
    where tau is a time constant.
e_t is white noise with zero-mean with evar = sigma_e**2</p>
<p>When there's no previous sample, E(X_t) = E(c) + e_t,
    which is a draw from N(c, sigma_e<strong>2)
When there is a previous sample, E(X_t) = E(c) + phi * E(X_{t-1}) + e_t,
    which means a draw from N(c + phi * X_{t-1}, sigma_p</strong>2)
    where sigma_p<strong>2 = phi</strong>2 * var(X_{t-1}) + sigma_e<strong>2 = sigma_e</strong>2 / (1 - phi**2)
    or logpvar = logevar - (log(1 - phi) + log(1 + phi))</p>
<p>Note that this could be roughly equivalent to tfd.Autoregressive if it was passed
a <code>distribution_fn</code> with the same transition.</p>
<p>See issue: https://github.com/snel-repo/lfads-cd/issues/1</p>

        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">AR1ProcessMVNGenerator</span><span class="p">(</span><span class="n">IProcessMVNGenerator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Similar to LFADS&#39; LearnableAutoRegressive1Prior.</span>
<span class="sd">    Here we use the terminology from:</span>
<span class="sd">    https://en.wikipedia.org/wiki/Autoregressive_model#Example:_An_AR(1)_process</span>

<span class="sd">    The autoregressive function takes the form:</span>
<span class="sd">        E(X_t) = E(c) + phi * E(X_{t-1}) + e_t</span>
<span class="sd">    E(c) is a constant.</span>
<span class="sd">    phi is a parameter, which is equivalent to exp(-1/tau) = exp(-exp(-logtau)).</span>
<span class="sd">        where tau is a time constant.</span>
<span class="sd">    e_t is white noise with zero-mean with evar = sigma_e**2</span>

<span class="sd">    When there&#39;s no previous sample, E(X_t) = E(c) + e_t,</span>
<span class="sd">        which is a draw from N(c, sigma_e**2)</span>
<span class="sd">    When there is a previous sample, E(X_t) = E(c) + phi * E(X_{t-1}) + e_t,</span>
<span class="sd">        which means a draw from N(c + phi * X_{t-1}, sigma_p**2)</span>
<span class="sd">        where sigma_p**2 = phi**2 * var(X_{t-1}) + sigma_e**2 = sigma_e**2 / (1 - phi**2)</span>
<span class="sd">        or logpvar = logevar - (log(1 - phi) + log(1 + phi))</span>

<span class="sd">    Note that this could be roughly equivalent to tfd.Autoregressive if it was passed</span>
<span class="sd">    a `distribution_fn` with the same transition.</span>

<span class="sd">    See issue: https://github.com/snel-repo/lfads-cd/issues/1</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_taus</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]],</span>
                 <span class="n">init_std</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">trainable_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">trainable_tau</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">trainable_var</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>


<span class="sd">        Args:</span>
<span class="sd">            init_taus: Initial values of tau</span>
<span class="sd">            init_std: Initial value of sigma_e</span>
<span class="sd">            trainable_mean: set True if the mean (e_c) is trainable.</span>
<span class="sd">            trainable_tau: set True to</span>
<span class="sd">            trainable_nvar:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span> <span class="o">=</span> <span class="n">offdiag</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init_taus</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">init_taus</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_taus</span><span class="p">]</span>
        <span class="c1"># TODO: Add time axis for easier broadcasting</span>
        <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_taus</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_e_c</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_scale</span> <span class="o">=</span> <span class="n">make_learnable_mvn_params</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span>
                                                             <span class="n">trainable_mean</span><span class="o">=</span><span class="n">trainable_mean</span><span class="p">,</span>
                                                             <span class="n">trainable_var</span><span class="o">=</span><span class="n">trainable_var</span><span class="p">,</span>
                                                             <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logtau</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">init_taus</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable_tau</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_phi</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">_logtau</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_p_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_e_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_phi</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_phi</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fixed</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">locs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scales</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Add a time dimension</span>
        <span class="n">e_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_e_c</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">e_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_e_scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">p_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_p_scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">sample</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">e_c</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="p">[</span><span class="n">samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">e_c</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_phi</span> <span class="o">*</span> <span class="n">sample</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">p_scale</span> <span class="k">if</span> <span class="n">_</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">e_scale</span>
            <span class="n">locs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
            <span class="n">scales</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span><span class="p">:</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
            <span class="n">sample_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="n">sample</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">sample_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">locs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span><span class="p">:</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

        <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sample</span><span class="p">,</span> <span class="n">dist</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.AR1ProcessMVNGenerator.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_taus</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">trainable_tau</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h4>

    <div class="doc doc-contents ">


<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>init_taus</code></td>
        <td><code>Union[float, List[float]]</code></td>
        <td><p>Initial values of tau</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>init_std</code></td>
        <td><code>Union[float, List[float]]</code></td>
        <td><p>Initial value of sigma_e</p></td>
        <td><code>0.1</code></td>
      </tr>
      <tr>
        <td><code>trainable_mean</code></td>
        <td><code>bool</code></td>
        <td><p>set True if the mean (e_c) is trainable.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>trainable_tau</code></td>
        <td><code>bool</code></td>
        <td><p>set True to</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>trainable_nvar</code></td>
        <td></td>
        <td></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_taus</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]],</span>
             <span class="n">init_std</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
             <span class="n">trainable_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
             <span class="n">trainable_tau</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
             <span class="n">trainable_var</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
             <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>


<span class="sd">    Args:</span>
<span class="sd">        init_taus: Initial values of tau</span>
<span class="sd">        init_std: Initial value of sigma_e</span>
<span class="sd">        trainable_mean: set True if the mean (e_c) is trainable.</span>
<span class="sd">        trainable_tau: set True to</span>
<span class="sd">        trainable_nvar:</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span> <span class="o">=</span> <span class="n">offdiag</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init_taus</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
        <span class="n">init_taus</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_taus</span><span class="p">]</span>
    <span class="c1"># TODO: Add time axis for easier broadcasting</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_taus</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_e_c</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_e_scale</span> <span class="o">=</span> <span class="n">make_learnable_mvn_params</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span>
                                                         <span class="n">trainable_mean</span><span class="o">=</span><span class="n">trainable_mean</span><span class="p">,</span>
                                                         <span class="n">trainable_var</span><span class="o">=</span><span class="n">trainable_var</span><span class="p">,</span>
                                                         <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_logtau</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">init_taus</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable_tau</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_phi</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">_logtau</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_p_scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_e_scale</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_phi</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_phi</span><span class="p">)))</span>
</code></pre></div>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>




  <div class="doc doc-object doc-class">



<h3 id="indl.dists.sequential.RNNMVNGenerator" class="doc doc-heading">
        <code>
RNNMVNGenerator            (<span title="indl.dists.sequential.IProcessMVNGenerator">IProcessMVNGenerator</span>)
        </code>



</h3>

    <div class="doc doc-contents ">

      <p>Similar to DSAE's LearnableMultivariateNormalDiagCell</p>

        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">RNNMVNGenerator</span><span class="p">(</span><span class="n">IProcessMVNGenerator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Similar to DSAE&#39;s LearnableMultivariateNormalDiagCell</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">cell_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">shift_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            units: Dimensionality of the RNN function parameters.</span>
<span class="sd">            out_dim: The dimensionality of the distribution.</span>
<span class="sd">            cell_type: an RNN cell type among &#39;lstm&#39;, &#39;gru&#39;, &#39;rnn&#39;, &#39;gruclip&#39;. case-insensitive.</span>
<span class="sd">            shift_std: Shift applied to MVN std before building the dist. Providing a shift</span>
<span class="sd">                toward the expected std allows the input values to be closer to 0.</span>
<span class="sd">            offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">LearnableMultivariateNormalCell</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">cell_type</span><span class="o">=</span><span class="n">cell_type</span><span class="p">,</span>
                                                    <span class="n">shift_std</span><span class="o">=</span><span class="n">shift_std</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fixed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Samples from self.cell `timesteps` times.</span>
<span class="sd">        On each step, the previous (sample, state) is fed back into the cell</span>
<span class="sd">        (zero_state used for 0th step).</span>

<span class="sd">        The cell returns a multivariate normal diagonal distribution for each timestep.</span>
<span class="sd">        We collect each timestep-dist&#39;s params (loc and scale), then use them to create</span>
<span class="sd">        the return value: a single MVN diag dist that has a dimension for timesteps.</span>

<span class="sd">        The cell returns a full dist for each timestep so that we can &#39;sample&#39; it.</span>
<span class="sd">        If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent</span>
<span class="sd">        to doing a generative RNN (init state = zeros, return_sequences=True) then passing</span>
<span class="sd">        those values through a pair of Dense layers to parameterize a single MVNDiag.</span>

<span class="sd">        Args:</span>
<span class="sd">            timesteps: Number of times to sample from the dynamic_prior_cell. Output will have</span>
<span class="sd">            samples: Number of samples to draw from the latent distribution.</span>
<span class="sd">            batch_size: Number of sequences to sample.</span>
<span class="sd">            fixed: Boolean for whether or not to share the same random</span>
<span class="sd">                    sample across all sequences in batch.</span>
<span class="sd">https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887</span>
<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">fixed</span><span class="p">:</span>
            <span class="n">sample_batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sample_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="n">sample</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">([</span><span class="n">samples</span><span class="p">,</span> <span class="n">sample_batch_size</span><span class="p">])</span>
        <span class="n">locs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scales</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scale_parm_name</span> <span class="o">=</span> <span class="s2">&quot;scale_tril&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">offdiag</span> <span class="k">else</span> <span class="s2">&quot;scale_diag&quot;</span>  <span class="c1"># TODO: Check this for offdiag</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
            <span class="n">dist</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
            <span class="n">locs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">])</span>
            <span class="n">scales</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">scale_parm_name</span><span class="p">])</span>
            <span class="n">sample_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="n">sample</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">sample_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">locs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fixed</span><span class="p">:</span>  <span class="c1"># tile along the batch axis</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">sample</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">offdiag</span><span class="p">:</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

        <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sample</span><span class="p">,</span> <span class="n">dist</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.RNNMVNGenerator.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">cell_type</span><span class="p">,</span> <span class="n">shift_std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h4>

    <div class="doc doc-contents ">


<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>units</code></td>
        <td><code>int</code></td>
        <td><p>Dimensionality of the RNN function parameters.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>out_dim</code></td>
        <td><code>int</code></td>
        <td><p>The dimensionality of the distribution.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>cell_type</code></td>
        <td><code>str</code></td>
        <td><p>an RNN cell type among 'lstm', 'gru', 'rnn', 'gruclip'. case-insensitive.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>shift_std</code></td>
        <td><code>float</code></td>
        <td><p>Shift applied to MVN std before building the dist. Providing a shift
toward the expected std allows the input values to be closer to 0.</p></td>
        <td><code>0.1</code></td>
      </tr>
      <tr>
        <td><code>offdiag</code></td>
        <td><code>bool</code></td>
        <td><p>set True to allow non-zero covariance (within-timestep) in the returned distribution.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">cell_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">shift_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        units: Dimensionality of the RNN function parameters.</span>
<span class="sd">        out_dim: The dimensionality of the distribution.</span>
<span class="sd">        cell_type: an RNN cell type among &#39;lstm&#39;, &#39;gru&#39;, &#39;rnn&#39;, &#39;gruclip&#39;. case-insensitive.</span>
<span class="sd">        shift_std: Shift applied to MVN std before building the dist. Providing a shift</span>
<span class="sd">            toward the expected std allows the input values to be closer to 0.</span>
<span class="sd">        offdiag: set True to allow non-zero covariance (within-timestep) in the returned distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">LearnableMultivariateNormalCell</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">cell_type</span><span class="o">=</span><span class="n">cell_type</span><span class="p">,</span>
                                                <span class="n">shift_std</span><span class="o">=</span><span class="n">shift_std</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.RNNMVNGenerator.get_dist" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fixed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <div class="highlight"><pre><span></span><code>    Samples from self.cell `timesteps` times.
    On each step, the previous (sample, state) is fed back into the cell
    (zero_state used for 0th step).

    The cell returns a multivariate normal diagonal distribution for each timestep.
    We collect each timestep-dist&#39;s params (loc and scale), then use them to create
    the return value: a single MVN diag dist that has a dimension for timesteps.

    The cell returns a full dist for each timestep so that we can &#39;sample&#39; it.
    If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent
    to doing a generative RNN (init state = zeros, return_sequences=True) then passing
    those values through a pair of Dense layers to parameterize a single MVNDiag.

    !!! args
        timesteps: Number of times to sample from the dynamic_prior_cell. Output will have
        samples: Number of samples to draw from the latent distribution.
        batch_size: Number of sequences to sample.
        !!! fixed &quot;Boolean for whether or not to share the same random&quot;
                sample across all sequences in batch.
</code></pre></div>
<p>https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887
        Returns:</p>

        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fixed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Samples from self.cell `timesteps` times.</span>
<span class="sd">        On each step, the previous (sample, state) is fed back into the cell</span>
<span class="sd">        (zero_state used for 0th step).</span>

<span class="sd">        The cell returns a multivariate normal diagonal distribution for each timestep.</span>
<span class="sd">        We collect each timestep-dist&#39;s params (loc and scale), then use them to create</span>
<span class="sd">        the return value: a single MVN diag dist that has a dimension for timesteps.</span>

<span class="sd">        The cell returns a full dist for each timestep so that we can &#39;sample&#39; it.</span>
<span class="sd">        If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent</span>
<span class="sd">        to doing a generative RNN (init state = zeros, return_sequences=True) then passing</span>
<span class="sd">        those values through a pair of Dense layers to parameterize a single MVNDiag.</span>

<span class="sd">        Args:</span>
<span class="sd">            timesteps: Number of times to sample from the dynamic_prior_cell. Output will have</span>
<span class="sd">            samples: Number of samples to draw from the latent distribution.</span>
<span class="sd">            batch_size: Number of sequences to sample.</span>
<span class="sd">            fixed: Boolean for whether or not to share the same random</span>
<span class="sd">                    sample across all sequences in batch.</span>
<span class="sd">https://github.com/tensorflow/probability/blob/698e0101aecf46c42858db7952ee3024e091c291/tensorflow_probability/examples/disentangled_vae.py#L887</span>
<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">fixed</span><span class="p">:</span>
            <span class="n">sample_batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sample_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

        <span class="n">sample</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">([</span><span class="n">samples</span><span class="p">,</span> <span class="n">sample_batch_size</span><span class="p">])</span>
        <span class="n">locs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scales</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scale_parm_name</span> <span class="o">=</span> <span class="s2">&quot;scale_tril&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">offdiag</span> <span class="k">else</span> <span class="s2">&quot;scale_diag&quot;</span>  <span class="c1"># TODO: Check this for offdiag</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
            <span class="n">dist</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
            <span class="n">locs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">])</span>
            <span class="n">scales</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">scale_parm_name</span><span class="p">])</span>
            <span class="n">sample_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="n">sample</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">sample_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">locs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fixed</span><span class="p">:</span>  <span class="c1"># tile along the batch axis</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">sample</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">offdiag</span><span class="p">:</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

        <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sample</span><span class="p">,</span> <span class="n">dist</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="indl.dists.sequential.RNNMultivariateNormalDiag" class="doc doc-heading">
        <code>
RNNMultivariateNormalDiag            (<span title="tensorflow_probability.python.distributions.mvn_diag.MultivariateNormalDiag">MultivariateNormalDiag</span>)
        </code>



</h3>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">RNNMultivariateNormalDiag</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cell</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rnn_mvn_diag&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">cell</span>
        <span class="k">if</span> <span class="n">output_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">,</span> <span class="s1">&#39;output_dim&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">,</span> <span class="s1">&#39;output_dim&#39;</span><span class="p">):</span>
            <span class="n">output_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">output_dim</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">units</span>

        <span class="n">h0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">units</span><span class="p">])</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">units</span><span class="p">])</span>
        <span class="n">input0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="s1">&#39;reset_dropout_mask&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">reset_dropout_mask</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">reset_recurrent_dropout_mask</span><span class="p">()</span>

        <span class="n">input_</span> <span class="o">=</span> <span class="n">input0</span>
        <span class="n">states_</span> <span class="o">=</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">)</span>
        <span class="n">successive_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">):</span>
            <span class="n">input_</span><span class="p">,</span> <span class="n">states_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">states_</span><span class="p">)</span>
            <span class="n">successive_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>

        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">_</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;distribution&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">successive_outputs</span><span class="p">],</span>
                        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">scale_diag</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">_</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;distribution&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;scale_diag&quot;</span><span class="p">]</span>
                               <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">successive_outputs</span><span class="p">],</span>
                               <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">RNNMultivariateNormalDiag</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale_diag</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">










  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.RNNMultivariateNormalDiag.cross_entropy" class="doc doc-heading">
<code class="highlight language-python"><span class="n">cross_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cross_entropy&#39;</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Computes the (Shannon) cross entropy.</p>
<p>Denote this distribution (<code>self</code>) by <code>P</code> and the <code>other</code> distribution by
<code>Q</code>. Assuming <code>P, Q</code> are absolutely continuous with respect to
one another and permit densities <code>p(x) dr(x)</code> and <code>q(x) dr(x)</code>, (Shannon)
cross entropy is defined as:</p>
<div class="highlight"><pre><span></span><code>H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x)
</code></pre></div>
<p>where <code>F</code> denotes the support of the random variable <code>X ~ P</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>other</code></td>
        <td></td>
        <td><p><code>tfp.distributions.Distribution</code> instance.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>name</code></td>
        <td></td>
        <td><p>Python <code>str</code> prepended to names of ops created by this function.</p></td>
        <td><code>&#39;cross_entropy&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>cross_entropy</code></td>
      <td><p><code>self.dtype</code> <code>Tensor</code> with shape <code>[B1, ..., Bn]</code>
  representing <code>n</code> different calculations of (Shannon) cross entropy.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;cross_entropy&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes the (Shannon) cross entropy.</span>

<span class="sd">  Denote this distribution (`self`) by `P` and the `other` distribution by</span>
<span class="sd">  `Q`. Assuming `P, Q` are absolutely continuous with respect to</span>
<span class="sd">  one another and permit densities `p(x) dr(x)` and `q(x) dr(x)`, (Shannon)</span>
<span class="sd">  cross entropy is defined as:</span>

<span class="sd">  ```none</span>
<span class="sd">  H[P, Q] = E_p[-log q(X)] = -int_F p(x) log q(x) dr(x)</span>
<span class="sd">  ```</span>

<span class="sd">  where `F` denotes the support of the random variable `X ~ P`.</span>

<span class="sd">  Args:</span>
<span class="sd">    other: `tfp.distributions.Distribution` instance.</span>
<span class="sd">    name: Python `str` prepended to names of ops created by this function.</span>

<span class="sd">  Returns:</span>
<span class="sd">    cross_entropy: `self.dtype` `Tensor` with shape `[B1, ..., Bn]`</span>
<span class="sd">      representing `n` different calculations of (Shannon) cross entropy.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name_and_control_scope</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cross_entropy</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.RNNMultivariateNormalDiag.kl_divergence" class="doc doc-heading">
<code class="highlight language-python"><span class="n">kl_divergence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;kl_divergence&#39;</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Computes the Kullback--Leibler divergence.</p>
<p>Denote this distribution (<code>self</code>) by <code>p</code> and the <code>other</code> distribution by
<code>q</code>. Assuming <code>p, q</code> are absolutely continuous with respect to reference
measure <code>r</code>, the KL divergence is defined as:</p>
<div class="highlight"><pre><span></span><code>KL[p, q] = E_p[log(p(X)/q(X))]
         = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x)
         = H[p, q] - H[p]
</code></pre></div>
<p>where <code>F</code> denotes the support of the random variable <code>X ~ p</code>, <code>H[., .]</code>
denotes (Shannon) cross entropy, and <code>H[.]</code> denotes (Shannon) entropy.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>other</code></td>
        <td></td>
        <td><p><code>tfp.distributions.Distribution</code> instance.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>name</code></td>
        <td></td>
        <td><p>Python <code>str</code> prepended to names of ops created by this function.</p></td>
        <td><code>&#39;kl_divergence&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>kl_divergence</code></td>
      <td><p><code>self.dtype</code> <code>Tensor</code> with shape <code>[B1, ..., Bn]</code>
  representing <code>n</code> different calculations of the Kullback-Leibler
  divergence.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">kl_divergence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;kl_divergence&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes the Kullback--Leibler divergence.</span>

<span class="sd">  Denote this distribution (`self`) by `p` and the `other` distribution by</span>
<span class="sd">  `q`. Assuming `p, q` are absolutely continuous with respect to reference</span>
<span class="sd">  measure `r`, the KL divergence is defined as:</span>

<span class="sd">  ```none</span>
<span class="sd">  KL[p, q] = E_p[log(p(X)/q(X))]</span>
<span class="sd">           = -int_F p(x) log q(x) dr(x) + int_F p(x) log p(x) dr(x)</span>
<span class="sd">           = H[p, q] - H[p]</span>
<span class="sd">  ```</span>

<span class="sd">  where `F` denotes the support of the random variable `X ~ p`, `H[., .]`</span>
<span class="sd">  denotes (Shannon) cross entropy, and `H[.]` denotes (Shannon) entropy.</span>

<span class="sd">  Args:</span>
<span class="sd">    other: `tfp.distributions.Distribution` instance.</span>
<span class="sd">    name: Python `str` prepended to names of ops created by this function.</span>

<span class="sd">  Returns:</span>
<span class="sd">    kl_divergence: `self.dtype` `Tensor` with shape `[B1, ..., Bn]`</span>
<span class="sd">      representing `n` different calculations of the Kullback-Leibler</span>
<span class="sd">      divergence.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># NOTE: We do not enter a `self._name_and_control_scope` here.  We rely on</span>
  <span class="c1"># `tfd.kl_divergence(self, other)` to use `_name_and_control_scope` to apply</span>
  <span class="c1"># assertions on both Distributions.</span>
  <span class="c1">#</span>
  <span class="c1"># Subclasses that override `Distribution.kl_divergence` or `_kl_divergence`</span>
  <span class="c1"># must ensure that assertions are applied for both `self` and `other`.</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kl_divergence</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="indl.dists.sequential.TiledMVNGenerator" class="doc doc-heading">
        <code>
TiledMVNGenerator            (<span title="indl.dists.sequential.IProcessMVNGenerator">IProcessMVNGenerator</span>)
        </code>



</h3>

    <div class="doc doc-contents ">

      <p>Similar to LFADS' LearnableDiagonalGaussian.
Uses a single learnable loc and scale which are tiled across timesteps.</p>

        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">TiledMVNGenerator</span><span class="p">(</span><span class="n">IProcessMVNGenerator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Similar to LFADS&#39; LearnableDiagonalGaussian.</span>
<span class="sd">    Uses a single learnable loc and scale which are tiled across timesteps.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">init_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">trainable_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            latent_dim: Number of dimensions in a single timestep  (params[&#39;f_latent_size&#39;])</span>
<span class="sd">            init_std: Initial value of standard deviation (params[&#39;q_z_init_std&#39;])</span>
<span class="sd">            trainable_mean: True if mean should be trainable (params[&#39;z_prior_train_mean&#39;])</span>
<span class="sd">            trainable_var: True if variance should be trainable (params[&#39;z_prior_train_var&#39;])</span>
<span class="sd">            offdiag: True if off-diagonal elements (non-orthogonality) allowed. (params[&#39;z_prior_off_diag&#39;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span> <span class="o">=</span> <span class="n">offdiag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">make_learnable_mvn_params</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span>
                                                           <span class="n">trainable_mean</span><span class="o">=</span><span class="n">trainable_mean</span><span class="p">,</span>
                                                           <span class="n">trainable_var</span><span class="o">=</span><span class="n">trainable_var</span><span class="p">,</span>
                                                           <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tiles the saved loc and scale to the same shape as `posterior` then uses them to</span>
<span class="sd">        create a MVN dist with appropriate shape. Each timestep has the same loc and</span>
<span class="sd">        scale but if it were sampled then each timestep would return different values.</span>
<span class="sd">        Args:</span>
<span class="sd">            timesteps:</span>
<span class="sd">            samples:</span>
<span class="sd">            batch_size:</span>
<span class="sd">        Returns:</span>
<span class="sd">            MVNDiag distribution of the same shape as `posterior`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loc</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="n">samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">]),</span> <span class="n">dist</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.TiledMVNGenerator.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">trainable_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">offdiag</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h4>

    <div class="doc doc-contents ">


<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>latent_dim</code></td>
        <td><code>int</code></td>
        <td><p>Number of dimensions in a single timestep  (params['f_latent_size'])</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>init_std</code></td>
        <td><code>float</code></td>
        <td><p>Initial value of standard deviation (params['q_z_init_std'])</p></td>
        <td><code>0.1</code></td>
      </tr>
      <tr>
        <td><code>trainable_mean</code></td>
        <td><code>bool</code></td>
        <td><p>True if mean should be trainable (params['z_prior_train_mean'])</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>trainable_var</code></td>
        <td><code>bool</code></td>
        <td><p>True if variance should be trainable (params['z_prior_train_var'])</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>offdiag</code></td>
        <td><code>bool</code></td>
        <td><p>True if off-diagonal elements (non-orthogonality) allowed. (params['z_prior_off_diag'])</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">init_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
             <span class="n">trainable_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">trainable_var</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
             <span class="n">offdiag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        latent_dim: Number of dimensions in a single timestep  (params[&#39;f_latent_size&#39;])</span>
<span class="sd">        init_std: Initial value of standard deviation (params[&#39;q_z_init_std&#39;])</span>
<span class="sd">        trainable_mean: True if mean should be trainable (params[&#39;z_prior_train_mean&#39;])</span>
<span class="sd">        trainable_var: True if variance should be trainable (params[&#39;z_prior_train_var&#39;])</span>
<span class="sd">        offdiag: True if off-diagonal elements (non-orthogonality) allowed. (params[&#39;z_prior_off_diag&#39;])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span> <span class="o">=</span> <span class="n">offdiag</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">make_learnable_mvn_params</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="n">init_std</span><span class="p">,</span>
                                                       <span class="n">trainable_mean</span><span class="o">=</span><span class="n">trainable_mean</span><span class="p">,</span>
                                                       <span class="n">trainable_var</span><span class="o">=</span><span class="n">trainable_var</span><span class="p">,</span>
                                                       <span class="n">offdiag</span><span class="o">=</span><span class="n">offdiag</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.TiledMVNGenerator.get_dist" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Tiles the saved loc and scale to the same shape as <code>posterior</code> then uses them to
create a MVN dist with appropriate shape. Each timestep has the same loc and
scale but if it were sampled then each timestep would return different values.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>timesteps</code></td>
        <td></td>
        <td></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>samples</code></td>
        <td></td>
        <td></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>batch_size</code></td>
        <td></td>
        <td></td>
        <td><code>1</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>MVNDiag distribution of the same shape as <code>posterior</code></p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tiles the saved loc and scale to the same shape as `posterior` then uses them to</span>
<span class="sd">    create a MVN dist with appropriate shape. Each timestep has the same loc and</span>
<span class="sd">    scale but if it were sampled then each timestep would return different values.</span>
<span class="sd">    Args:</span>
<span class="sd">        timesteps:</span>
<span class="sd">        samples:</span>
<span class="sd">        batch_size:</span>
<span class="sd">    Returns:</span>
<span class="sd">        MVNDiag distribution of the same shape as `posterior`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loc</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_offdiag</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="n">samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">]),</span> <span class="n">dist</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="indl.dists.sequential.VariationalLSTMCell" class="doc doc-heading">
        <code>
VariationalLSTMCell            (<span title="tensorflow.python.keras.layers.recurrent_v2.LSTMCell">LSTMCell</span>)
        </code>



</h3>

    <div class="doc doc-contents ">


        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">VariationalLSTMCell</span><span class="p">(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span>
                 <span class="n">make_dist_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">make_dist_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VariationalLSTMCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_fn</span> <span class="o">=</span> <span class="n">make_dist_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_model</span> <span class="o">=</span> <span class="n">make_dist_model</span>

        <span class="c1"># For some reason the below code doesn&#39;t work during build.</span>
        <span class="c1"># So I don&#39;t know how to use the outer VariationalRNN to set this cell&#39;s output_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scale_diag</span><span class="o">=</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fake_cell_output</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,))</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;VarLSTMCell_loc&quot;</span><span class="p">)(</span><span class="n">fake_cell_output</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;VarLSTMCell_scale&quot;</span><span class="p">)(</span><span class="n">fake_cell_output</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">scale</span> <span class="o">+</span> <span class="n">scale_shift</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span>
            <span class="n">dist_layer</span> <span class="o">=</span> <span class="n">tfpl</span><span class="o">.</span><span class="n">DistributionLambda</span><span class="p">(</span>
                <span class="n">make_distribution_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">make_dist_fn</span><span class="p">,</span>
                <span class="c1"># TODO: convert_to_tensor_fn=lambda s: s.sample(N_SAMPLES)</span>
            <span class="p">)([</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">fake_cell_output</span><span class="p">,</span> <span class="n">dist_layer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VariationalLSTMCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="c1"># It would be good to defer making self.make_dist_model until here,</span>
        <span class="c1"># but it doesn&#39;t work for some reason.</span>

    <span class="c1"># def input_zero(self, inputs_):</span>
    <span class="c1">#    input0 = inputs_[..., -1, :]</span>
    <span class="c1">#    input0 = tf.matmul(input0, tf.zeros((input0.shape[-1], self.units)))</span>
    <span class="c1">#    dist0 = self.make_dist_model(input0)</span>
    <span class="c1">#    return dist0</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">VariationalLSTMCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_model</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dist</span><span class="p">,</span> <span class="n">state</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">










  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.VariationalLSTMCell.build" class="doc doc-heading">
<code class="highlight language-python"><span class="n">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <code>Layer</code> or <code>Model</code>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <code>Layer</code> subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>input_shape</code></td>
        <td></td>
        <td><p>Instance of <code>TensorShape</code>, or list of instances of
<code>TensorShape</code> if the layer expects a list of inputs
(one instance per input).</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">VariationalLSTMCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="c1"># It would be good to defer making self.make_dist_model until here,</span>
    <span class="c1"># but it doesn&#39;t work for some reason.</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h4 id="indl.dists.sequential.VariationalLSTMCell.call" class="doc doc-heading">
<code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h4>

    <div class="doc doc-contents ">

      <p>This is where the layer's logic lives.</p>
<p>Note here that <code>call()</code> method in <code>tf.keras</code> is little bit different
from <code>keras</code> API. In <code>keras</code> API, you can pass support masking for
layers as additional arguments. Whereas <code>tf.keras</code> has <code>compute_mask()</code>
method to support masking.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>inputs</code></td>
        <td></td>
        <td><p>Input tensor, or list/tuple of input tensors.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td></td>
        <td><p>Additional keyword arguments. Currently unused.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>A tensor or list/tuple of tensors.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>indl/dists/sequential.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">VariationalLSTMCell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dist_model</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span><span class="p">,</span> <span class="n">state</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>




  </div>

    </div>

  </div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../data/" class="md-footer__link md-footer__link--prev" aria-label="Previous: data" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              data
            </div>
          </div>
        </a>
      
      
        
        <a href="../layers/" class="md-footer__link md-footer__link--next" aria-label="Next: layers" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              layers
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../../assets/javascripts/bundle.1514a9a0.min.js"></script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>