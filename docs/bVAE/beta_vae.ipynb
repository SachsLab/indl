{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\beta$ Variational Autoencoders to Disentangle Multi-channel Spiking Data\n",
    "\n",
    "I already have quite a few general notes on $\\beta$ Variational Autoencoders with Tensorflow Probability in the IntracranialNeurophysDL repository [here](https://github.com/SachsLab/IntracranialNeurophysDL/blob/master/notebooks/05_04_betaVAE_TFP.ipynb). This notebook provides $\\beta$-VAE component implementations that are more useful with our macaque PFC data.\n",
    "\n",
    "Here we define a series of model-builder functions. Each function takes `params`, a dictionary of hyperparameters, and `inputs` containing one or more Keras tensors, and each returns the model outputs and other intermediate variables that need to be tracked.\n",
    "\n",
    "We have generic functions to create the graphs for f- and z-encoders; we have a function to create the first part of the decoder graph; and a function to complete the decoder graph.\n",
    "\n",
    "We also provide an end-to-end model to show how to use it.\n",
    "\n",
    "These components are exported to our indl library. Our separate data analysis notebooks import this module, and possibly others (e.g., LFADS) to build models for analyzing our data. We don't do significant data analysis here.\n",
    "\n",
    "As much as possible, we try to make the functions generic enough that we can use parameters to switch between different $\\beta$-VAE implementations.\n",
    "\n",
    "We identify 4 different VAE models for consideration:\n",
    "* [disentangled sequential autoencoders (DSAE)](https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/disentangled_vae.py) ([Li and Mandt, ICML 2018](https://arxiv.org/pdf/1803.02991.pdf)) - \"Full\" model.\n",
    "* Same as above - \"Factorized' model\n",
    "* [FHVAE](https://github.com/wnhsu/ScalableFHVAE) ([Hsu and Glass](https://arxiv.org/pdf/1804.03201.pdf))\n",
    "* [LFADS (latest: AutoLFADS)](https://github.com/snel-repo/lfads-cd/) ([Keshtkaran, ..., Pandarinath, 2021](https://www.biorxiv.org/content/10.1101/2021.01.13.426570v1))\n",
    "\n",
    "The below table provides some differences between the models, but is perhaps incorrect and needs to be updated. Please do not rely on it.\n",
    "\n",
    "|              | LFADS                     | DSAE full                       | DSAE factorized | FHVAE    |\n",
    "| :---         | :---                      | :---                            | :---            | :---     |\n",
    "| f RNN        | Bidir. GRU                | Bidir. LSTM                     | --              | LSTM x2  |\n",
    "| f prior      | $\\mathcal{N}(0,\\kappa I)$ | $\\mathcal{N}(\\mu_z,\\sigma_z I)$ | --              | $\\mathcal{N}(\\mu_2,0.5^2I)$ |\n",
    "| z RNN        | A: Bidir. GRU, B:GRU      | Bdir. LSTM -> RNN               | MLP             | LSTM x2  |\n",
    "| z RNN input  | A: x; B: (A(x), fac)      | concat(x, tile(f))              | $x_t$           | concat(input, tile(f)) |\n",
    "| z prior      | LearnableAutoRegressive1Prior | LSTM(0)                         | --              | $\\mathcal{N}(0,I)$ |\n",
    "| Decoder RNN  | GRU                       | ??                              | ??              | LSTM x2  |\n",
    "| RNN input0   | 0 / z                     | ??                              | ??              | concat(f, z) |\n",
    "| RNN state0   | f                         | ??                              | ??              | 0  |\n",
    "| RNN output   | -MLP-> fac -MLP-> rates   | ??                              | ??              | (x_mu, x_logvar) |\n",
    "| Decoder loss | -log(p spike\\|Poisson(rates)) | ??                          | ??              | sparse sce with logits |\n",
    "| Learning rate| 1e-2 decay 0.95 every 6   | ??                              | ??              | ?? |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We separate our hyperparameters into non-tunable 'arguments' and tunable 'parameters'. This helps with the hyperparameter optimization framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare inputs\n",
    "\n",
    "Apply dropout, split f_encoder inputs off from inputs to prevent acausal modeling (optional), coordinated dropout (optional), CV mask (not implemented yet), Dense to input factors (optional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 246, 36)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 246, 36)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 246, 36)]    0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "coordinated_dropout (Coordinate ((None, 246, 36), (N 0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 0, 36)]      0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 246, 36)]    0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 coordinated_dropout[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[(TensorShape([16, 246, 36]), tf.float32), (TensorShape([16, 246, 36]), tf.float32), (TensorShape([16, 246, 36]), tf.bool)]\n"
     ]
    }
   ],
   "source": [
    "test_prepare_inputs(n_times=246)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *f*-Encoder\n",
    "\n",
    "Transform full sequence of \"features\" (`inputs` or `ReadIn(inputs)`) through (1) RNN then (2) affine to yield parameters of latent posterior distribution:\n",
    "$$q(f | x_{1:T})$$\n",
    "This distribution is a multivariate normal, optionally with off-diagonal elements allowed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loss will include the KL divergence between the static latent posterior and a prior. The prior is a learnable multivariate normal diagonal. The prior is initialized with a mean of 0 and a stddev of 1 but these are trainable by default.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"f_encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 36)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "f_rnn_0 (Bidirectional)         (None, 256)          126720      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           f_rnn_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "f_scale (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 10)]         0           f_scale[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softplus (TensorFlo [(None, 10)]         0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "f_loc (Dense)                   (None, 10)           2570        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 10)]         0           tf_op_layer_Softplus[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "q_f (DistributionLambda)        ((None, 10), (None,  0           f_loc[0][0]                      \n",
      "                                                                 tf_op_layer_AddV2_1[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 131,860\n",
      "Trainable params: 131,860\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "tfp.distributions.MultivariateNormalDiag(\"f_encoder_model_q_f_MultivariateNormalDiag\", batch_shape=[16], event_shape=[10], dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 93.19866   81.839386  73.49664   45.901627  50.906715  36.570427\n",
      "  62.996284  89.13544   78.416565  38.75402   85.56836   71.12454\n",
      "  51.789825 100.711395  86.70568   89.89396 ], shape=(16,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_create_f_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *z*-Encoder\n",
    "\n",
    "$q(z_t | x_{1:T})$\n",
    "\n",
    "I have also seen this called the \"Dynamic Encoder\", or in LFADS the \"Controller Input\" encoder.\n",
    "\n",
    "The *z*-Encoder varies quite a bit between the different Disentangling/$\\beta$ Variational Autoencoder implementations. Indeed, in some formulations it isn't used at all, such as the LFADS model without inferred controller input.\n",
    "\n",
    "* The inputs are the original data sequences ($x_t$).\n",
    "* Unlike the *f*-encoder, here we output full sequences.\n",
    "* The output sequences parameterize a multivariate normal distribution **at each timestep**\n",
    "* The encoder itself has as its first layer\n",
    "    * a RNN (LSTM, GRU), often bidirectional, or\n",
    "    * a simple MLP as in the DHSAE Factorized model\n",
    "* If the first layer is an RNN then there is usually a second layer forward-only RNN.\n",
    "\n",
    "### Extra Details - DHSAE Full\n",
    "\n",
    "* The inputs are concatenated with a tiled sample from $q(f)$.\n",
    "* We've added the option to instead concatenate on the inputs into the second RNN.\n",
    "\n",
    "### Extra Details - LFADS\n",
    "\n",
    "* Like its f-Encoder, the RNN cells are a GRU with clipping.\n",
    "* The secondary RNN input is the output from the primary RNN concatenated with the **decoder RNN's previous step + transformed through the factor Dense layer**.\n",
    "\n",
    "Because the LFADS secondary RNN is so complicated, it is integrated into the decoder RNN itself in a \"complex cell\". The complex cell includes the z2-cell, making the z2 outputs variational in $q(z_t)$, sampling $q(z_t)$ for the inputs to the generative RNN cell, passing the output of the generative RNN step through a Dense to-factors layer, and finally using that output as one of the inputs to the z2 cell. If `params['gen_cell_type']` is `\"Complex\"`, then we assume that LFADS is being used and we thus skip the second RNN in `create_z_encoder` and we skip making the latents variational in `make_z_variational`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Rework this\n",
    "# TODO: Compare to LFADS' prior on enc_z.\n",
    "def sample_dynamic_prior(self, timesteps, samples=1, batches=1, fixed=False):\n",
    "    \"\"\"\n",
    "    Samples from self.dynamic_prior_cell `timesteps` times.\n",
    "    On each step, the previous (sample, state) is fed back into the cell\n",
    "    (zero_state used for 0th step).\n",
    "\n",
    "    The cell returns a multivariate normal diagonal distribution for each timestep.\n",
    "    We collect each timestep-dist's params (loc and scale), then use them to create\n",
    "    the return value: a single MVN diag dist that has a dimension for timesteps.\n",
    "\n",
    "    The cell returns a full dist for each timestep so that we can 'sample' it.\n",
    "    If our sample size is 1, and our cell is an RNN cell, then this is roughly equivalent\n",
    "    to doing a generative RNN (init state = zeros, return_sequences=True) then passing\n",
    "    those values through a pair of Dense layers to parameterize a single MVNDiag.\n",
    "\n",
    "    :param timesteps: Number of timesteps to sample for each sequence.\n",
    "    :param samples: Number of samples to draw from the latent distribution.\n",
    "    :param batches: Number of sequences to sample.\n",
    "    :param fixed: Boolean for whether or not to share the same random\n",
    "        sample across all sequences in batch.\n",
    "    \"\"\"\n",
    "    if fixed:\n",
    "        sample_batch_size = 1\n",
    "    else:\n",
    "        sample_batch_size = batches\n",
    "\n",
    "    sample, state = self.dynamic_prior_cell.zero_state([samples, sample_batch_size])\n",
    "    locs = []\n",
    "    scale_diags = []\n",
    "    sample_list = []\n",
    "    for _ in range(timesteps):\n",
    "        dist, state = self.dynamic_prior_cell(sample, state)\n",
    "        sample = dist.sample()\n",
    "        locs.append(dist.parameters[\"loc\"])\n",
    "        scale_diags.append(dist.parameters[\"scale_diag\"])\n",
    "        sample_list.append(sample)\n",
    "\n",
    "    sample = tf.stack(sample_list, axis=2)\n",
    "    loc = tf.stack(locs, axis=2)\n",
    "    scale_diag = tf.stack(scale_diags, axis=2)\n",
    "\n",
    "    if fixed:  # tile along the batch axis\n",
    "        sample = sample + tf.zeros([batches, 1, 1])\n",
    "\n",
    "    return sample, tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale_diag)\n",
    "    # TODO: Move 1 of the batch dims into event dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"z_encoder_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 36)]        0         \n",
      "_________________________________________________________________\n",
      "z_rnn_1 (Bidirectional)      (None, None, 32)          5088      \n",
      "=================================================================\n",
      "Total params: 5,088\n",
      "Trainable params: 5,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'> (16, 246, 32)\n"
     ]
    }
   ],
   "source": [
    "test_create_z_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prior_cell = LearnableMultivariateNormalDiagCell(3, 4, cell_type='gru')\n",
    "sample, state = dynamic_prior_cell.zero_state([1, 1])\n",
    "locs = []\n",
    "scale_diags = []\n",
    "sample_list = []\n",
    "for _ in range(161):\n",
    "    dist, state = dynamic_prior_cell(sample, state)\n",
    "    sample = dist.sample()\n",
    "    locs.append(dist.parameters[\"loc\"])\n",
    "    scale_diags.append(dist.parameters[\"scale_diag\"])\n",
    "    sample_list.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator (Decoder part 1)\n",
    "\n",
    "$p(x_t | z_t, f)$\n",
    "\n",
    "The generator is an RNN that outputs full sequences from the encoded latents which comprise a single-timestep latent vector (*f*) and optionally a low-dimensional sequence ($z_t$). Note that these latents are distributions, and therefore must be sampled from to get the initial state and/or the inputs to the generative RNN.\n",
    "\n",
    "The generative RNN outputs a sequence. This sequence is typically transformed through a Dense layer to yield the \"factors\". However, in LFADS the factors are fedback to the z2_encoder step-by-step, and this cannot be accomplished in a normal sequential layer connection. Instead, LFADS includes the dense layer inside a \"ComplexCell\". To be consistent with the LFADS implementation we need to include the to-dense layer in other `create_generator_` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indl.model.lfads.complex_cell import ComplexCell\n",
    "\n",
    "\n",
    "def create_generator_LFADS():\n",
    "    \"\"\"\n",
    "    units_gen,\n",
    "    units_con,\n",
    "    factors_dim,\n",
    "    co_dim,\n",
    "    ext_input_dim,\n",
    "    inject_ext_input_to_gen,\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Sample/Mean from $q(f)$. This will replace the first element in generator init_states\n",
    "    #  TODO: need a custom function for sample-during-train-mean-during-test. See nn.dropout for inspiration.\n",
    "    # TODO: Sample from $q(z_t)$, and optionally concat with ext_input, to build generator inputs.\n",
    "    \n",
    "    \n",
    "    # TODO: continue generator from lfads-cd/lfadslite.py start at 495\n",
    "    custom_cell = ComplexCell(\n",
    "        params['gen_dim'],  # Units in generator GRU\n",
    "        con_hidden_state_dim,  # Units in controller GRU\n",
    "        params['factors_dim'],\n",
    "        params['co_dim'],\n",
    "        params['ext_input_dim'],\n",
    "        True,\n",
    "    )\n",
    "    generator = tfkl.RNN(custom_cell, return_sequences=True,\n",
    "                         # recurrent_regularizer=tf.keras.regularizers.l2(l=gen_l2_reg),\n",
    "                         name='gen_rnn')\n",
    "    init_states = generator.get_initial_state(gen_input)\n",
    "    \n",
    "    \n",
    "    gen_output = generator(gen_input, initial_state=init_states)\n",
    "    factors = gen_output[-1]\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Probabilistic Reconstructed Input (Decoder part 2)\n",
    "\n",
    "The factors are passed through a Dense layer and the outputs are the same dimensionality as the inputs, but instead of reconstructing the inputs, they parameterize a distribution representing the inputs. This distribution can be Gaussian or Poisson, with the latter being more appropriate for (binned) spike counts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}